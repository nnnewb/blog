<!doctype html><html lang=zh-cn>
<head><meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Intro 因为自己搭了个博客，一时兴起，就想写个动态的博客背景。毕竟用 django 后端渲染，前端只有 jquery 和 bootstrap 已经够 low 了，虽说极简风格也很棒，但是多少有点亮眼的东西才好办不是吗。
转载注明来源。
为了方便讲解，整个思路分为两个部分：音乐播放和背景绘制。
一、音乐播放 1.1 AudioContext 概述部分懒得自己写，参考 MDN 的描述。
 AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。
 1.2 浏览器支持状况 AudioContext标准目前还是草案，不过新 chrome 已经实现了。我使用的 chrome 版本如下。
版本 70.0.3538.77（正式版本） （64 位） 如果发现 console 报错或者其他问题请检查浏览器版本，所有支持的浏览器可以在这个链接查看。
1.3 AudioContext 和音频处理图 关于AudioContext我的了解不是很深入，所以只在需要用到的部分进行概述。
首先，关于音频处理图的概念。
这个名词不甚直观，我用过虚幻，所以用虚幻的Blueprint来类比理解。音频处理图，其实是一系列音频处理的模块，连接构成一张数据结构中的“图”，从一般使用的角度来讲，一个播放音频的图，就是AudioSource -&amp;gt; AudioContext.destination，两个节点构成的图。其中有很多特殊的节点可以对音频进行处理，比如音频增益节点GainNode。
对于音频处理的部分介绍就到这里为止，毕竟真的了解不多，不过从 MDN 的文档看，可用的处理节点还是非常多的，就等标准制订完成了。
1.4 加载音频文件并播放 音频文件加载使用典型的JavaScript接口FileReader实现。
一个非常简单的实例是这样
首先是 html 里写上 input
&amp;lt;html&amp;gt; &amp;lt;body&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; accept=&amp;#34;audio/*&amp;#34; onchange=&amp;#34;onInputChange&amp;#34; /&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 然后在 javascript 里读文件内容。
function onInputChange(files) { const reader = new FileReader(); reader."><title>AudioContext技术和音乐可视化（1）</title>
<link rel=canonical href=https://nnnewb.github.io/blog/p/audiocontext%E6%8A%80%E6%9C%AF%E5%92%8C%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%961/>
<link rel=stylesheet href=/blog/scss/style.min.css><meta property="og:title" content="AudioContext技术和音乐可视化（1）">
<meta property="og:description" content="Intro 因为自己搭了个博客，一时兴起，就想写个动态的博客背景。毕竟用 django 后端渲染，前端只有 jquery 和 bootstrap 已经够 low 了，虽说极简风格也很棒，但是多少有点亮眼的东西才好办不是吗。
转载注明来源。
为了方便讲解，整个思路分为两个部分：音乐播放和背景绘制。
一、音乐播放 1.1 AudioContext 概述部分懒得自己写，参考 MDN 的描述。
 AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。
 1.2 浏览器支持状况 AudioContext标准目前还是草案，不过新 chrome 已经实现了。我使用的 chrome 版本如下。
版本 70.0.3538.77（正式版本） （64 位） 如果发现 console 报错或者其他问题请检查浏览器版本，所有支持的浏览器可以在这个链接查看。
1.3 AudioContext 和音频处理图 关于AudioContext我的了解不是很深入，所以只在需要用到的部分进行概述。
首先，关于音频处理图的概念。
这个名词不甚直观，我用过虚幻，所以用虚幻的Blueprint来类比理解。音频处理图，其实是一系列音频处理的模块，连接构成一张数据结构中的“图”，从一般使用的角度来讲，一个播放音频的图，就是AudioSource -&amp;gt; AudioContext.destination，两个节点构成的图。其中有很多特殊的节点可以对音频进行处理，比如音频增益节点GainNode。
对于音频处理的部分介绍就到这里为止，毕竟真的了解不多，不过从 MDN 的文档看，可用的处理节点还是非常多的，就等标准制订完成了。
1.4 加载音频文件并播放 音频文件加载使用典型的JavaScript接口FileReader实现。
一个非常简单的实例是这样
首先是 html 里写上 input
&amp;lt;html&amp;gt; &amp;lt;body&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; accept=&amp;#34;audio/*&amp;#34; onchange=&amp;#34;onInputChange&amp;#34; /&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 然后在 javascript 里读文件内容。
function onInputChange(files) { const reader = new FileReader(); reader.">
<meta property="og:url" content="https://nnnewb.github.io/blog/p/audiocontext%E6%8A%80%E6%9C%AF%E5%92%8C%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%961/">
<meta property="og:site_name" content="weakptr's 笔记">
<meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="javascript"><meta property="article:published_time" content="2018-11-07T02:48:00+08:00"><meta property="article:modified_time" content="2018-11-07T02:48:00+08:00">
<meta name=twitter:title content="AudioContext技术和音乐可视化（1）">
<meta name=twitter:description content="Intro 因为自己搭了个博客，一时兴起，就想写个动态的博客背景。毕竟用 django 后端渲染，前端只有 jquery 和 bootstrap 已经够 low 了，虽说极简风格也很棒，但是多少有点亮眼的东西才好办不是吗。
转载注明来源。
为了方便讲解，整个思路分为两个部分：音乐播放和背景绘制。
一、音乐播放 1.1 AudioContext 概述部分懒得自己写，参考 MDN 的描述。
 AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。
 1.2 浏览器支持状况 AudioContext标准目前还是草案，不过新 chrome 已经实现了。我使用的 chrome 版本如下。
版本 70.0.3538.77（正式版本） （64 位） 如果发现 console 报错或者其他问题请检查浏览器版本，所有支持的浏览器可以在这个链接查看。
1.3 AudioContext 和音频处理图 关于AudioContext我的了解不是很深入，所以只在需要用到的部分进行概述。
首先，关于音频处理图的概念。
这个名词不甚直观，我用过虚幻，所以用虚幻的Blueprint来类比理解。音频处理图，其实是一系列音频处理的模块，连接构成一张数据结构中的“图”，从一般使用的角度来讲，一个播放音频的图，就是AudioSource -&amp;gt; AudioContext.destination，两个节点构成的图。其中有很多特殊的节点可以对音频进行处理，比如音频增益节点GainNode。
对于音频处理的部分介绍就到这里为止，毕竟真的了解不多，不过从 MDN 的文档看，可用的处理节点还是非常多的，就等标准制订完成了。
1.4 加载音频文件并播放 音频文件加载使用典型的JavaScript接口FileReader实现。
一个非常简单的实例是这样
首先是 html 里写上 input
&amp;lt;html&amp;gt; &amp;lt;body&amp;gt; &amp;lt;input type=&amp;#34;file&amp;#34; accept=&amp;#34;audio/*&amp;#34; onchange=&amp;#34;onInputChange&amp;#34; /&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 然后在 javascript 里读文件内容。
function onInputChange(files) { const reader = new FileReader(); reader.">
</head>
<body class="article-page has-toc">
<script>(function(){const a='StackColorScheme';localStorage.getItem(a)||localStorage.setItem(a,"dark")})()</script><script>(function(){const b='StackColorScheme',a=localStorage.getItem(b),c=window.matchMedia('(prefers-color-scheme: dark)').matches===!0;a=='dark'||a==='auto'&&c?document.documentElement.dataset.scheme='dark':document.documentElement.dataset.scheme='light'})()</script>
<div class="container main-container flex
extended">
<div id=article-toolbar>
<a href=https://nnnewb.github.io/blog class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg>
<span>返回</span>
</a>
</div>
<main class="main full-width">
<article class=main-article>
<header class=article-header>
<div class=article-details>
<header class=article-category>
<a href=/blog/categories/javascript/>
javascript
</a>
</header>
<h2 class=article-title>
<a href=/blog/p/audiocontext%E6%8A%80%E6%9C%AF%E5%92%8C%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%961/>AudioContext技术和音乐可视化（1）</a>
</h2>
<footer class=article-time>
<div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2018年 11月 7日</time>
</div>
<div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>
阅读时长: 2 分钟
</time>
</div>
</footer>
</div>
</header>
<section class=article-content>
<h2 id=intro>Intro</h2>
<p>因为自己搭了个博客，一时兴起，就想写个动态的博客背景。毕竟用 django 后端渲染，前端只有 jquery 和 bootstrap 已经够 low 了，虽说极简风格也很棒，但是多少有点亮眼的东西才好办不是吗。</p>
<p>转载注明来源。</p>
<p>为了方便讲解，整个思路分为两个部分：音乐播放和背景绘制。</p>
<h2 id=一音乐播放>一、音乐播放</h2>
<h3 id=11-audiocontext>1.1 AudioContext</h3>
<p>概述部分懒得自己写，参考 MDN 的描述。</p>
<blockquote>
<p><strong>AudioContext</strong>接口表示由音频模块连接而成的音频处理图，每个模块对应一个<a class=link href=https://developer.mozilla.org/zh-CN/docs/Web/API/AudioNode target=_blank rel=noopener><code>AudioNode</code></a>。<strong>AudioContext</strong>可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建<strong>AudioContext</strong>对象，因为一切都发生在这个环境之中。</p>
</blockquote>
<h3 id=12-浏览器支持状况>1.2 浏览器支持状况</h3>
<p><code>AudioContext标准</code>目前还是草案，不过新 chrome 已经实现了。我使用的 chrome 版本如下。</p>
<pre><code>版本 70.0.3538.77（正式版本） （64 位）
</code></pre><p>如果发现 console 报错或者其他问题请检查浏览器版本，所有支持的浏览器可以在这个<a class=link href=https://developer.mozilla.org/en-US/docs/Web/API/AudioContext target=_blank rel=noopener>链接</a>查看。</p>
<h3 id=13-audiocontext-和音频处理图>1.3 AudioContext 和音频处理图</h3>
<p>关于<code>AudioContext</code>我的了解不是很深入，所以只在需要用到的部分进行概述。</p>
<p>首先，关于<strong>音频处理图</strong>的概念。</p>
<p>这个名词不甚直观，我用过虚幻，所以用虚幻的<code>Blueprint</code>来类比理解。音频处理图，其实是一系列音频处理的模块，连接构成一张数据结构中的“图”，从一般使用的角度来讲，一个播放音频的图，就是<code>AudioSource -> AudioContext.destination</code>，两个节点构成的图。其中有很多特殊的节点可以对音频进行处理，比如音频增益节点<code>GainNode</code>。</p>
<p>对于音频处理的部分介绍就到这里为止，毕竟真的了解不多，不过从 MDN 的文档看，可用的处理节点还是非常多的，就等标准制订完成了。</p>
<h3 id=14-加载音频文件并播放>1.4 加载音频文件并播放</h3>
<p>音频文件加载使用典型的<code>JavaScript</code>接口<code>FileReader</code>实现。</p>
<p>一个非常简单的实例是这样</p>
<p>首先是 html 里写上 input</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-html data-lang=html><span class=p>&lt;</span><span class=nt>html</span><span class=p>&gt;</span>
  <span class=p>&lt;</span><span class=nt>body</span><span class=p>&gt;</span>
    <span class=p>&lt;</span><span class=nt>input</span> <span class=na>type</span><span class=o>=</span><span class=s>&#34;file&#34;</span> <span class=na>accept</span><span class=o>=</span><span class=s>&#34;audio/*&#34;</span> <span class=na>onchange</span><span class=o>=</span><span class=s>&#34;onInputChange&#34;</span> <span class=p>/&gt;</span>
  <span class=p>&lt;/</span><span class=nt>body</span><span class=p>&gt;</span>
<span class=p>&lt;/</span><span class=nt>html</span><span class=p>&gt;</span>
</code></pre></div><p>然后在 javascript 里读文件内容。</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-javascript data-lang=javascript><span class=kd>function</span> <span class=nx>onInputChange</span><span class=p>(</span><span class=nx>files</span><span class=p>)</span> <span class=p>{</span>
  <span class=kr>const</span> <span class=nx>reader</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>FileReader</span><span class=p>();</span>
  <span class=nx>reader</span><span class=p>.</span><span class=nx>onload</span> <span class=o>=</span> <span class=p>(</span><span class=nx>event</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=p>{</span>
    <span class=c1>// event.target.result 就是我们的文件内容了
</span><span class=c1></span>  <span class=p>};</span>
  <span class=nx>reader</span><span class=p>.</span><span class=nx>readAsArrayBuffer</span><span class=p>(</span><span class=nx>files</span><span class=p>[</span><span class=mi>0</span><span class=p>]);</span>
<span class=p>}</span>
</code></pre></div><p>文件读取就是这么简单，所以回到那个问题：说了那么多，音乐到底怎么放？</p>
<p>答案是用<code>AudioContext</code>的<code>decodeAudioData</code>方法。</p>
<p>所以从上面的 js 里做少许修改——</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-javascript data-lang=javascript><span class=c1>// 创建一个新的 AudioContext
</span><span class=c1></span><span class=kr>const</span> <span class=nx>ctx</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>AudioContext</span><span class=p>();</span>

<span class=kd>function</span> <span class=nx>onInputChange</span><span class=p>(</span><span class=nx>files</span><span class=p>)</span> <span class=p>{</span>
  <span class=kr>const</span> <span class=nx>reader</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>FileReader</span><span class=p>();</span>
  <span class=nx>reader</span><span class=p>.</span><span class=nx>onload</span> <span class=o>=</span> <span class=p>(</span><span class=nx>event</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=p>{</span>
    <span class=c1>// event.target.result 就是我们的文件内容了
</span><span class=c1></span>    <span class=c1>// 解码它
</span><span class=c1></span>    <span class=nx>ctx</span><span class=p>.</span><span class=nx>decodeAudioData</span><span class=p>(</span><span class=nx>event</span><span class=p>.</span><span class=nx>target</span><span class=p>.</span><span class=nx>result</span><span class=p>).</span><span class=nx>then</span><span class=p>((</span><span class=nx>decoded</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=p>{</span>
      <span class=c1>// 解码后的音频数据作为音频源
</span><span class=c1></span>      <span class=kr>const</span> <span class=nx>audioBufferSourceNode</span> <span class=o>=</span> <span class=nx>ctx</span><span class=p>.</span><span class=nx>createBufferSource</span><span class=p>();</span>
      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>buffer</span> <span class=o>=</span> <span class=nx>decoded</span><span class=p>;</span>
      <span class=c1>// 把音源 node 和输出 node 连接，boom——
</span><span class=c1></span>      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>connect</span><span class=p>(</span><span class=nx>ctx</span><span class=p>.</span><span class=nx>destination</span><span class=p>);</span>
      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>start</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span>
      <span class=c1>// 收工。
</span><span class=c1></span>    <span class=p>});</span>
  <span class=p>};</span>
  <span class=nx>reader</span><span class=p>.</span><span class=nx>readAsArrayBuffer</span><span class=p>(</span><span class=nx>files</span><span class=p>[</span><span class=mi>0</span><span class=p>]);</span>
<span class=p>}</span>
</code></pre></div><h3 id=15-分析频谱>1.5 分析频谱</h3>
<p>频谱的概念我建议搜一下<strong>傅里叶变换</strong>，关于时域和频域转换的计算过程和数学原理直接略（因为不懂），至今我还只理解到时域和频域的概念以及傅里叶变换的实现接受采样返回采样数一半长的频域数据&mldr;&mldr;</p>
<p>不班门弄斧了。</p>
<p>以前写<code>python</code>的时候用的<code>numpy</code>来进行傅里叶变换取得频域数据，现在在浏览器上用 js 着实有些难受。不过幸好，<code>AudioContext</code>直接支持了一个音频分析的 node，叫做<code>AudioAnalyserNode</code>。</p>
<p>这个 Node 处于音源 Node 和播放输出 Node 之间，想象一道数据流，音源 Node 把离散的采样数据交给 Analyser，Analyser 再交给输出 Node。</p>
<p>直接看代码实例。</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-javascript data-lang=javascript><span class=c1>// 创建一个新的 AudioContext
</span><span class=c1></span><span class=kr>const</span> <span class=nx>ctx</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>AudioContext</span><span class=p>();</span>
<span class=c1>// 解码后的音频数据作为音频源
</span><span class=c1>// 为了方便管理，将这些Node都放置在回调函数外部
</span><span class=c1></span><span class=kr>const</span> <span class=nx>audioBufferSourceNode</span> <span class=o>=</span> <span class=nx>ctx</span><span class=p>.</span><span class=nx>createBufferSource</span><span class=p>();</span>

<span class=c1>// 创建音频分析Node!
</span><span class=c1></span><span class=kr>const</span> <span class=nx>audioAnalyser</span> <span class=o>=</span> <span class=nx>ctx</span><span class=p>.</span><span class=nx>createAnalyser</span><span class=p>();</span>
<span class=c1>// 注意注意！这里配置傅里叶变换使用的采样窗口大小！比如说，我们要256个频域数据，那么采样就应该是512。
</span><span class=c1>// 具体对应频率请自行搜傅里叶变换相关博文。
</span><span class=c1></span><span class=nx>audioAnalyser</span><span class=p>.</span><span class=nx>fftSize</span> <span class=o>=</span> <span class=mi>512</span><span class=p>;</span>

<span class=kd>function</span> <span class=nx>onInputChange</span><span class=p>(</span><span class=nx>files</span><span class=p>)</span> <span class=p>{</span>
  <span class=kr>const</span> <span class=nx>reader</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>FileReader</span><span class=p>();</span>
  <span class=nx>reader</span><span class=p>.</span><span class=nx>onload</span> <span class=o>=</span> <span class=p>(</span><span class=nx>event</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=p>{</span>
    <span class=c1>// event.target.result 就是我们的文件内容了
</span><span class=c1></span>    <span class=c1>// 解码它
</span><span class=c1></span>    <span class=nx>ctx</span><span class=p>.</span><span class=nx>decodeAudioData</span><span class=p>(</span><span class=nx>event</span><span class=p>.</span><span class=nx>target</span><span class=p>.</span><span class=nx>result</span><span class=p>).</span><span class=nx>then</span><span class=p>((</span><span class=nx>decoded</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=p>{</span>
      <span class=c1>// 停止原先的音频源
</span><span class=c1></span>      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>stop</span><span class=p>();</span>
      <span class=c1>// 先把音频源Node和Analyser连接。
</span><span class=c1></span>      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>connect</span><span class=p>(</span><span class=nx>audioAnalyser</span><span class=p>);</span>
      <span class=c1>// 然后把Analyser和destination连接。
</span><span class=c1></span>      <span class=nx>audioAnalyser</span><span class=p>.</span><span class=nx>connect</span><span class=p>(</span><span class=nx>ctx</span><span class=p>.</span><span class=nx>destination</span><span class=p>);</span>
      <span class=c1>// 修改音频源数据
</span><span class=c1></span>      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>buffer</span> <span class=o>=</span> <span class=nx>decoded</span><span class=p>;</span>
      <span class=nx>audioBufferSourceNode</span><span class=p>.</span><span class=nx>start</span><span class=p>(</span><span class=mi>0</span><span class=p>);</span>
      <span class=c1>// 收工。
</span><span class=c1></span>    <span class=p>});</span>
  <span class=p>};</span>
  <span class=nx>reader</span><span class=p>.</span><span class=nx>readAsArrayBuffer</span><span class=p>(</span><span class=nx>files</span><span class=p>[</span><span class=mi>0</span><span class=p>]);</span>
<span class=p>}</span>

<span class=nb>window</span><span class=p>.</span><span class=nx>requestAnimationFrame</span><span class=p>(</span><span class=kd>function</span> <span class=p>()</span> <span class=p>{</span>
  <span class=c1>// 读取频域数据
</span><span class=c1></span>  <span class=kr>const</span> <span class=nx>freqData</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>Uint8Array</span><span class=p>(</span><span class=nx>audioAnalyser</span><span class=p>.</span><span class=nx>frequencyBinCount</span><span class=p>);</span>
  <span class=nx>console</span><span class=p>.</span><span class=nx>log</span><span class=p>(</span><span class=nx>freqData</span><span class=p>);</span>
<span class=p>});</span>
</code></pre></div><p>频域数据是二维的，频率（数组下标）和能量（下标对应值）。悄悄补一句，数学上应该说是该频率函数图像的振幅？</p>
<p>其实获得了这个频域数据，继续画出我们常见的条状频域图就很容易了。参考我一朋友的博客。<a class=link href=https://misuzu.moe/music/index.html target=_blank rel=noopener>misuzu.moe</a>，可以看看效果。</p>
<p>关于<code>AudioContext</code>的介绍先到此为止，等我找时间继续写。</p>
<blockquote>
<p>PS：代码不保证复制粘贴就能运行，领会精神，遇到问题查查文档。MDN 比我这博客详细多了。</p>
</blockquote>
</section>
<footer class=article-footer>
<section class=article-tags>
<a href=/blog/tags/javascript/>javascript</a>
</section>
<section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span>
</section>
</footer>
</article>
<aside class=related-contents--wrapper>
<h2 class=section-title>相关文章</h2>
<div class=related-contents>
<div class="flex article-list--tile">
<article>
<a href=/blog/p/%E7%94%A8-tree-sitter-%E5%86%99%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/>
<div class=article-details>
<h2 class=article-title>用 tree-sitter 写一个代码高亮</h2>
</div>
</a>
</article>
<article>
<a href=/blog/p/%E7%8E%A9%E7%8E%A9-tree-sitter/>
<div class=article-details>
<h2 class=article-title>玩玩 tree-sitter</h2>
</div>
</a>
</article>
<article>
<a href=/blog/p/audiocontext-%E6%8A%80%E6%9C%AF%E5%92%8C%E9%9F%B3%E4%B9%90%E5%8F%AF%E8%A7%86%E5%8C%962/>
<div class=article-details>
<h2 class=article-title>AudioContext 技术和音乐可视化（2）</h2>
</div>
</a>
</article>
</div>
</div>
</aside>
<footer class=site-footer>
<section class=copyright>
&copy;
2021 weakptr's 笔记
</section>
<section class=powerby>
GitHub Pages <br>
Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> <br>
Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.1.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a>
</section>
</footer>
<div class=pswp tabindex=-1 role=dialog aria-hidden=true>
<div class=pswp__bg></div>
<div class=pswp__scroll-wrap>
<div class=pswp__container>
<div class=pswp__item></div>
<div class=pswp__item></div>
<div class=pswp__item></div>
</div>
<div class="pswp__ui pswp__ui--hidden">
<div class=pswp__top-bar>
<div class=pswp__counter></div>
<button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
<div class=pswp__preloader>
<div class=pswp__preloader__icn>
<div class=pswp__preloader__cut>
<div class=pswp__preloader__donut></div>
</div>
</div>
</div>
</div>
<div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
<div class=pswp__share-tooltip></div>
</div>
<button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
</button>
<div class=pswp__caption>
<div class=pswp__caption__center></div>
</div>
</div>
</div>
</div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous>
</main>
<aside class="sidebar right-sidebar sticky">
<section class="widget archives">
<div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
</div>
<h2 class="widget-title section-title">目录</h2>
<div class=widget--toc>
<nav id=TableOfContents>
<ol>
<li><a href=#intro>Intro</a></li>
<li><a href=#一音乐播放>一、音乐播放</a>
<ol>
<li><a href=#11-audiocontext>1.1 AudioContext</a></li>
<li><a href=#12-浏览器支持状况>1.2 浏览器支持状况</a></li>
<li><a href=#13-audiocontext-和音频处理图>1.3 AudioContext 和音频处理图</a></li>
<li><a href=#14-加载音频文件并播放>1.4 加载音频文件并播放</a></li>
<li><a href=#15-分析频谱>1.5 分析频谱</a></li>
</ol>
</li>
</ol>
</nav>
</div>
</section>
</aside>
</div>
<script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous defer></script><script type=text/javascript src=/blog/ts/main.js defer></script>
<script>(function(){const a=document.createElement('link');a.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",a.type="text/css",a.rel="stylesheet",document.head.appendChild(a)})()</script>
</body>
</html>