<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>工作杂谈 on weakptr's 笔记</title><link>https://nnnewb.github.io/blog/tags/%E5%B7%A5%E4%BD%9C%E6%9D%82%E8%B0%88/</link><description>Recent content in 工作杂谈 on weakptr's 笔记</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Fri, 31 Dec 2021 18:30:00 +0800</lastBuildDate><atom:link href="https://nnnewb.github.io/blog/tags/%E5%B7%A5%E4%BD%9C%E6%9D%82%E8%B0%88/index.xml" rel="self" type="application/rss+xml"/><item><title>记一次API响应时间优化</title><link>https://nnnewb.github.io/blog/p/an-api-response-time-optimize/</link><pubDate>Fri, 31 Dec 2021 18:30:00 +0800</pubDate><guid>https://nnnewb.github.io/blog/p/an-api-response-time-optimize/</guid><description>前言 刚接手管理后台的后端服务，先随便挑个什么东西下手看看。正好注意到一个简单的接口返回时间都蛮长的，于是拿刚从 opentelemetry 的 issue/pr 里抄来的 sqlmw 包装驱动来分析优化下性能。
0x01 性能分析 预判 下手前预估下可能存在瓶颈的地方。对于这次下手的接口（get_users），整个实现也没几行代码，只有两三个查询，数据量也不大，但是耗时有80ms+。
其他接口有快有慢，并没有表现出同时增加耗时，而且开发服务器架在内网，排除网络原因，大概还是服务本身的存在的问题。于是考虑瓶颈在数据库或代码中，但具体肯定是要看代码去分析的。既然判断是代码里的问题，那下一步就是测量下耗时情况了。
对于go，pprof虽然是个不错的主意，但实话说部署在 kubernetes 里，配 pprof 去拉结果有点麻烦，而且还有点点用不惯。正好这个项目里早就配置了 opentracing+jaeger做分布式跟踪，所以就直接抄一下 opentelemetry 的 otelsql ，把SQL查询的详细耗时情况记录下来，就可以开始分析了。
opentracing收集数据 otelsql 原理是用 sqlmw 在 sql 驱动层级上进行包装sql ==&amp;gt; sqlmw.Driver{mysql.Driver} 。go的sql调用sqlmw.Driver，sqlmw.Driver调用mysql.Driver，如此而已，具体不解释。
从otelsql借鉴下思路即可，现在 opentracing 已经和 opencensus 合并成了 opentelemetry，但项目也没法说升级就升级，毕竟项目架构设计稀烂，太多地方和 opentracing、jaeger-client 强耦合了。把otelsql里用sqlmw的部分抄出来，改成opentracing的方式创建span完事。
func (in *sqlInterceptor) ConnExecContext(ctx context.Context, conn driver.ExecerContext, query string, args []driver.NamedValue) (driver.Result, error) { span, ctx := opentracing.StartSpanFromContext(ctx, &amp;#34;ConnExecContext&amp;#34;) defer span.Finish() span.LogKV(&amp;#34;sql.query&amp;#34;, query) return conn.ExecContext(ctx, query, args) } 如此一来， 当go的sql库访问数据库的时候，就会在jaeger里记录一个span，可以清晰地看到耗时情况。</description></item></channel></rss>