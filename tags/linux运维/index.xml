<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>linux运维 on weakptr's 笔记</title><link>https://nnnewb.github.io/blog/tags/linux%E8%BF%90%E7%BB%B4/</link><description>Recent content in linux运维 on weakptr's 笔记</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 27 Dec 2021 15:21:00 +0800</lastBuildDate><atom:link href="https://nnnewb.github.io/blog/tags/linux%E8%BF%90%E7%BB%B4/index.xml" rel="self" type="application/rss+xml"/><item><title>排查一个kubectl无反应的问题</title><link>https://nnnewb.github.io/blog/p/why-my-kubectl-not-responding/</link><pubDate>Mon, 27 Dec 2021 15:21:00 +0800</pubDate><guid>https://nnnewb.github.io/blog/p/why-my-kubectl-not-responding/</guid><description>懒得分段了，就当做是讲个故事吧。
背景大概是这样。
内网公共开发机上配置了 k3s 集群，同时后端开发工作也在这台开发机上进行（通过vscode remote-ssh）。因为公司太抠门，开发机只有117G硬盘容量，除去必要的开发工具、系统环境之类的东西，实际可用一直没超过50%，机器上又跑了很多东西，像是 gitlab-runner、docker的registry、MySQL、elasticsearch、开发集群服务等等，差不多每一两个星期都会出现 disk-pressure 的 taint，导致 pod 被 evicted。实话说能跑就很满足了，毕竟公司抠门到开发部门的上行带宽都贼小，如果把镜像推送到公网的registry去部署的话体验更差。
今天（周一）来公司之后调了下gitlab-ci，给一个前端项目做持续部署。因为前端对kubernetes这套不熟悉，也没有相关的服务器权限，总之就是很难让他们自己来。但是产品部门又喜欢提那种“按钮移到右上角”、“加个图片”之类的需求（对，我司还没有需求管理系统，开发就是个撸码的无情工具人），前端老是过来找我去部署下环境，就搞得摸鱼都摸不痛快。
所以，当当当~当~，整一个持续部署呗，反正是个纯前端项目，不用部署配套的后端代码，写个dockerfile再写个helm chart就差不多了，ci调了调构建镜像就完事，不过因为ci部署需要访问集群，所以又改了下.kube/config，删了之前尝试csr方式添加用户的时候加多的 user 和 context ，复制了一份挂载到 runner 容器里。
然后&amp;hellip;&amp;hellip;问题就来了。
同事忽然告诉我办公室的服务挂了，于是下意识地打出kgp，卡住。
等了一会儿，还是卡住。
又等了一会儿，坐不住了。试了下kubectl cluster-info，继续卡住。
开始慌了，想起今天的机器有点卡，先看看 free -h 有没有内存泄漏之类的问题导致阻塞，结果发现并没有，于是继续看 htop，cpu使用率也比较正常。再看df -h | grep -vE 'shm|overlay'，发现硬盘使用率96%（估计硬盘主控想死的心都有了，揪着4%的可用空间想把PE数平均到各个区块恐怕不容易）。
找到问题后松了口气，十有八九是又出现 evicted 了。二话不说直接 docker system df，看到30多G的 build cache 顿时惊了，肯定不是go的构建缓存（手动挂载优化了），那就是 node_modules 又立奇功了。node_modules=黑洞果然不是吹的。
清理完使用率恢复到63%，但依然有种不安感萦绕于心，于是再次尝试kgp，卡住。
等了一会儿，喝口水，继续卡着。
又等了一会儿，淦。
想了想，journalctl -r -u k3s看看日志，并没有什么发现，倒是注意到很多linkerd之类的我们部门经理搞事的时候遗留下来的玩意儿在报错，service mesh 我不熟，但寻思应该不会影响 kubectl 吧，k3s 本体的 api-server 应该不归 linkerd 管。更何况 linkerd 本身就没配好。再翻了翻看到下面的内容。
6 12月 25 21:16:07 office k3s[794]: I1225 13:16:07.</description></item><item><title>在raspbian上手动编译vim8.2</title><link>https://nnnewb.github.io/blog/p/build-vim8.2-manually-on-raspbian/</link><pubDate>Sat, 25 Dec 2021 10:37:00 +0800</pubDate><guid>https://nnnewb.github.io/blog/p/build-vim8.2-manually-on-raspbian/</guid><description>前言 raspbian上自带的vim版本还是低了点，像是coc.nvim之类的插件弹警告就搞得很烦。我寻思自己编译一个吧。
0x01 下载源码 从vim官网下载源码（或者可以从GitHub下，出于网络考虑还是直接从ftp下了），下完直接scp传到树莓派上，tar xf解压好准备开整。
0x02 配置 惯例先看看文档，README.md里指出源码安装去看src/INSTALL，所以跟着去看。
在 Unix 一节中提到直接make+make install就完事，但我要的不是编译个默认版本的vim，毕竟还有插件会用到vim的 Pyhon/Python3 特性，比如ycm。
继续往下翻会看到编译依赖。
% sudo apt install git % sudo apt install make % sudo apt install clang % sudo apt install libtool-bin 跟着把依赖装好，clang估计是可选项，gcc肯定是能编译vim的。不过以防万一反正全装上。
后面终于看到了Python3添加支持的方式。
Add Python 3 support: % sudo apt install libpython3-dev Uncomment this line in Makefile: &amp;quot;CONF_OPT_PYTHON3 = --enable-python3interp&amp;quot; % make reconfig 虽然说文档让取消注释，但是我不想改东西。所以记一下--enable-python3interp，等会儿加入configure的参数。
后面又有个关于gui的，因为不使用gui，所以也记一下。
Unix: COMPILING WITH/WITHOUT GUI
NOTE: This is incomplete, look in Makefile for more info.</description></item><item><title>简单的ECK部署</title><link>https://nnnewb.github.io/blog/p/simple-eck-cluster-deployment/</link><pubDate>Tue, 30 Nov 2021 11:13:00 +0800</pubDate><guid>https://nnnewb.github.io/blog/p/simple-eck-cluster-deployment/</guid><description>前言 因为工作需要，得在自己搭建的集群里部署一个 Elasticsearch 。又因为是云端的集群，在 k8s 外用 docker 单独起一个 ES 明显更难维护（但部署更简单），于是选择用 ECK 。
ECK 就是 Elastic Cloud on Kubernetes 的缩写，可以理解成部署在 Kubernetes 上的 Elasticsearch 。当然不止 ES 。
部署 ES 的过程遇到几个问题记录下怎么解决的。
ES 使用自签名证书，导致 HTTP 不能连接。 ECK 需要安装 IK 分词插件。 ECK 默认密码每次部署都重新生成，而且默认用户权限过大。 ECK 默认没配 PVC ，数据没有持久化。 接下来逐个解决。
0x01 自签名证书 自签名证书解决方法有几个
改客户端，让客户端用自签名证书连接。很麻烦。 生成一个固定的证书，让ES和客户端都用这个证书，客户端和ES都要改。很麻烦。 禁用 ES 的自签名证书。 考虑到是私有的测试环境，不搞这些烦人的东西，直接禁用。
修改 YAML 如下。
apiVersion:elasticsearch.k8s.elastic.co/v1kind:Elasticsearchmetadata:name:elasticsearchspec:http:tls:selfSignedCertificate:disabled:true注意 spec.http.tls.selfSignedCertificate.disabled 这个字段。
参考文档：Orchestrating Elastic Stack applications - Access Elastic Stack services - TLS certificates</description></item><item><title>运维瞎记 2021年11月11日</title><link>https://nnnewb.github.io/blog/p/blind-op-2021-11-11/</link><pubDate>Thu, 11 Nov 2021 10:19:00 +0800</pubDate><guid>https://nnnewb.github.io/blog/p/blind-op-2021-11-11/</guid><description>记虚拟机网络未连接 起因 因为Ubuntu server安装时更新的话需要从网络下载，慢的一批，所以安装的时候虚拟机的网络断开了，安装好启动之后才重新链接。
但是&amp;hellip;
连接后进入系统却发现并没有网络（VirtualBox），检查 networkctl 发现 enp0s3 是 off 状态。
原因 别问，不知道。
处理 顺藤摸瓜不求甚解了。
看到 enp0s3 是 off 那就先查查怎么解决。
sudo ip link set enp0s3 up 再检查连接状态。
networkctl status 发现连接进入 downgrade 状态，搜索得知是未分配 IP 地址。
sudo dhclient enp0s3 报了一个奇怪的CMP什么的错误，不管了。再检查下网络。
networkctl 发现 enp0s3 进入 routable 状态，大功告成。
总结 我总结个蛋。</description></item><item><title>升级公司的 GitLab</title><link>https://nnnewb.github.io/blog/p/%E5%8D%87%E7%BA%A7%E5%85%AC%E5%8F%B8%E7%9A%84-gitlab/</link><pubDate>Thu, 15 Jul 2021 16:02:41 +0800</pubDate><guid>https://nnnewb.github.io/blog/p/%E5%8D%87%E7%BA%A7%E5%85%AC%E5%8F%B8%E7%9A%84-gitlab/</guid><description>公司目前跑的 gitlab 是很久以前部署的，当前版本 8.4.2 。升级目标是 13.12.Z 。部署方式是 docker 。
宿主机配置不高，系统 Ubuntu 15.04 。眼下这个时间，这个Ubuntu版本，基本宣告没法用了。直接在线升级容易把引导搞挂，到时候还得亲自去实体机上折腾引导，麻烦。暂时不管宿主机。
情况概述 因为 GitLab 版本实在太低了，以至于连一个能集成的 CI/CD 工具都找不到。即使 jenkins 都只能很勉强地动起来，偏偏 jenkins 还不能满足需要（也可能是我太菜，反正公司没人玩得转 jenkins）。
但开发需要 CI/CD 来解决持续构建和部署的问题，不得不考虑升级了。
1. 备份 什么都别说了，开干前最重要的事情就是备份，免得把自己玩死。
最常用的备份手段自然是 tar 。不过 gitlab 数据目录实在太大了，要是直接运行 tar -czpf gitlab.tar.gz ./gitlab 不知道跑多久，也不知道有没有卡死。
于是上技术手段：用 pv 显示个进度条。
pv 项目的首页在 ivarch.com。因为服务器还在跑ubuntu 15.10，现在连个能用的源都没啦。只好下载了源码，在 wsl 里编译好推上去。
最终命令如下。
sudo tar cf - ./gitlab -P | pv -s $(sudo du -sb ./gitlab | awk &amp;#39;{print $1}&amp;#39;) | gzip &amp;gt; gitlab.</description></item></channel></rss>